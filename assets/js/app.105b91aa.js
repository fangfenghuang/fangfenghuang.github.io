(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[]]);!function(n){function e(e){for(var r,i,s=e[0],c=e[1],l=e[2],d=0,u=[];d<s.length;d++)i=s[d],Object.prototype.hasOwnProperty.call(a,i)&&a[i]&&u.push(a[i][0]),a[i]=0;for(r in c)Object.prototype.hasOwnProperty.call(c,r)&&(n[r]=c[r]);for(p&&p(e);u.length;)u.shift()();return o.push.apply(o,l||[]),t()}function t(){for(var n,e=0;e<o.length;e++){for(var t=o[e],r=!0,s=1;s<t.length;s++){var c=t[s];0!==a[c]&&(r=!1)}r&&(o.splice(e--,1),n=i(i.s=t[0]))}return n}var r={},a={1:0},o=[];function i(e){if(r[e])return r[e].exports;var t=r[e]={i:e,l:!1,exports:{}};return n[e].call(t.exports,t,t.exports,i),t.l=!0,t.exports}i.e=function(n){var e=[],t=a[n];if(0!==t)if(t)e.push(t[2]);else{var r=new Promise((function(e,r){t=a[n]=[e,r]}));e.push(t[2]=r);var o,s=document.createElement("script");s.charset="utf-8",s.timeout=120,i.nc&&s.setAttribute("nonce",i.nc),s.src=function(n){return i.p+"assets/js/"+({}[n]||n)+"."+{2:"22dca872",3:"759551b0",4:"fb5fef80",5:"3ff92d1d",6:"99f416e3",7:"d996c5d0",8:"0ff2779d",9:"8582675e",10:"f0b9a357",11:"5e9d4442",12:"fd9fb50c",13:"a25462a4",14:"b3f50169",15:"48ec85a3",16:"23a381fd",17:"fce4526e",18:"5a7f9410",19:"9bd92abb",20:"cd613adc",21:"39678e7d",22:"18a1b0a4",23:"e81728ef",24:"2c47f148",25:"133e8693",26:"4c8f984a",27:"a2f30984",28:"bed824b7",29:"d25cd053",30:"5ed0a170",31:"78e76f31",32:"bde44dbe",33:"bbd5bc1e",34:"c395058a",35:"85e8117c",36:"ebde3125",37:"11468077",38:"58b8d85a",39:"fb78a74b",40:"fdd8e7f7",41:"9bda7a27",42:"6683d568",43:"b861cc49",44:"87a8ca0e",45:"d0365d4c",46:"ceb92d03",47:"58262ccf",48:"606fd8c4",49:"72883bce",50:"5fd90d00",51:"fed4a052",52:"e2ccdabe",53:"1e80aaaa",54:"d19130a3",55:"fc584fda",56:"f45b3334",57:"ddc391da",58:"9c01d07f",59:"28b9f481",60:"433f82be",61:"c7d46345",62:"0592d1ca",63:"5d5a64e8",64:"a5e108ea",65:"44bb9e5a",66:"22992592",67:"d8a16172",68:"fd3f16aa",69:"8176ca55",70:"0b5afd7c",71:"a29933fb",72:"05d914d5",73:"0aaf4b9a",74:"704e02ac",75:"f53c0442",76:"0e5684e0",77:"2e14a486",78:"f1629604",79:"462d6518",80:"26135f6e",81:"3d843fba",82:"cd3c3a45",83:"f1068b1a",84:"1b3fe5ad",85:"5424faa1",86:"94ec5ced",87:"f3fd6943",88:"06bd6e5d",89:"186aa41e",90:"5be9795c",91:"537fe6e4",92:"e51f855c",93:"db2f174b",94:"d9451de8"}[n]+".js"}(n);var c=new Error;o=function(e){s.onerror=s.onload=null,clearTimeout(l);var t=a[n];if(0!==t){if(t){var r=e&&("load"===e.type?"missing":e.type),o=e&&e.target&&e.target.src;c.message="Loading chunk "+n+" failed.\n("+r+": "+o+")",c.name="ChunkLoadError",c.type=r,c.request=o,t[1](c)}a[n]=void 0}};var l=setTimeout((function(){o({type:"timeout",target:s})}),12e4);s.onerror=s.onload=o,document.head.appendChild(s)}return Promise.all(e)},i.m=n,i.c=r,i.d=function(n,e,t){i.o(n,e)||Object.defineProperty(n,e,{enumerable:!0,get:t})},i.r=function(n){"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(n,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(n,"__esModule",{value:!0})},i.t=function(n,e){if(1&e&&(n=i(n)),8&e)return n;if(4&e&&"object"==typeof n&&n&&n.__esModule)return n;var t=Object.create(null);if(i.r(t),Object.defineProperty(t,"default",{enumerable:!0,value:n}),2&e&&"string"!=typeof n)for(var r in n)i.d(t,r,function(e){return n[e]}.bind(null,r));return t},i.n=function(n){var e=n&&n.__esModule?function(){return n.default}:function(){return n};return i.d(e,"a",e),e},i.o=function(n,e){return Object.prototype.hasOwnProperty.call(n,e)},i.p="/",i.oe=function(n){throw console.error(n),n};var s=window.webpackJsonp=window.webpackJsonp||[],c=s.push.bind(s);s.push=e,s=s.slice();for(var l=0;l<s.length;l++)e(s[l]);var p=c;o.push([102,0]),t()}([function(n,e,t){"use strict";function r(n,e,t,r,a,o,i,s){var c,l="function"==typeof n?n.options:n;if(e&&(l.render=e,l.staticRenderFns=t,l._compiled=!0),r&&(l.functional=!0),o&&(l._scopeId="data-v-"+o),i?(c=function(n){(n=n||this.$vnode&&this.$vnode.ssrContext||this.parent&&this.parent.$vnode&&this.parent.$vnode.ssrContext)||"undefined"==typeof __VUE_SSR_CONTEXT__||(n=__VUE_SSR_CONTEXT__),a&&a.call(this,n),n&&n._registeredComponents&&n._registeredComponents.add(i)},l._ssrRegister=c):a&&(c=s?function(){a.call(this,(l.functional?this.parent:this).$root.$options.shadowRoot)}:a),c)if(l.functional){l._injectStyles=c;var p=l.render;l.render=function(n,e){return c.call(e),p(n,e)}}else{var d=l.beforeCreate;l.beforeCreate=d?[].concat(d,c):[c]}return{exports:n,options:l}}t.d(e,"a",(function(){return r}))},function(n,e){n.exports=function(n){return"function"==typeof n}},function(n,e,t){var r=t(25),a=Function.prototype,o=a.bind,i=a.call,s=r&&o.bind(i,i);n.exports=r?function(n){return n&&s(n)}:function(n){return n&&function(){return i.apply(n,arguments)}}},function(n,e){var t=function(n){return n&&n.Math==Math&&n};n.exports=t("object"==typeof globalThis&&globalThis)||t("object"==typeof window&&window)||t("object"==typeof self&&self)||t("object"==typeof global&&global)||function(){return this}()||Function("return this")()},function(n,e){n.exports=function(n){try{return!!n()}catch(n){return!0}}},function(n,e){var t=Array.isArray;n.exports=t},function(n,e,t){var r=t(67),a="object"==typeof self&&self&&self.Object===Object&&self,o=r||a||Function("return this")();n.exports=o},function(n,e,t){var r=t(4);n.exports=!r((function(){return 7!=Object.defineProperty({},1,{get:function(){return 7}})[1]}))},function(n,e,t){var r=t(2),a=t(45),o=r({}.hasOwnProperty);n.exports=Object.hasOwn||function(n,e){return o(a(n),e)}},function(n,e,t){var r=t(1);n.exports=function(n){return"object"==typeof n?null!==n:r(n)}},function(n,e,t){var r=t(157),a=t(160);n.exports=function(n,e){var t=a(n,e);return r(t)?t:void 0}},function(n,e,t){"use strict";t.d(e,"e",(function(){return r})),t.d(e,"b",(function(){return o})),t.d(e,"j",(function(){return i})),t.d(e,"g",(function(){return c})),t.d(e,"h",(function(){return l})),t.d(e,"i",(function(){return p})),t.d(e,"c",(function(){return d})),t.d(e,"f",(function(){return u})),t.d(e,"l",(function(){return m})),t.d(e,"m",(function(){return h})),t.d(e,"d",(function(){return f})),t.d(e,"k",(function(){return v})),t.d(e,"n",(function(){return b})),t.d(e,"a",(function(){return y}));const r=/#.*$/,a=/\.(md|html)$/,o=/\/$/,i=/^[a-z]+:/i;function s(n){return decodeURI(n).replace(r,"").replace(a,"")}function c(n){return i.test(n)}function l(n){return/^mailto:/.test(n)}function p(n){return/^tel:/.test(n)}function d(n){if(c(n))return n;if(!n)return"404";const e=n.match(r),t=e?e[0]:"",a=s(n);return o.test(a)?n:a+".html"+t}function u(n,e){const t=n.hash,a=function(n){const e=n&&n.match(r);if(e)return e[0]}(e);if(a&&t!==a)return!1;return s(n.path)===s(e)}function m(n,e,t){if(c(e))return{type:"external",path:e};t&&(e=function(n,e,t){const r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;const a=e.split("/");t&&a[a.length-1]||a.pop();const o=n.replace(/^\//,"").split("/");for(let n=0;n<o.length;n++){const e=o[n];".."===e?a.pop():"."!==e&&a.push(e)}""!==a[0]&&a.unshift("");return a.join("/")}(e,t));const r=s(e);for(let e=0;e<n.length;e++)if(s(n[e].regularPath)===r)return Object.assign({},n[e],{type:"page",path:d(n[e].path)});return console.error(`[vuepress] No matching page found for sidebar item "${e}"`),{}}function h(n,e,t,r){const{pages:a,themeConfig:o}=t,i=r&&o.locales&&o.locales[r]||o;if("auto"===(n.frontmatter.sidebar||i.sidebar||o.sidebar))return g(n);const s=i.sidebar||o.sidebar;if(s){const{base:t,config:r}=function(n,e){if(Array.isArray(e))return{base:"/",config:e};for(const r in e)if(0===(t=n,/(\.html|\/)$/.test(t)?t:t+"/").indexOf(encodeURI(r)))return{base:r,config:e[r]};var t;return{}}(e,s);return"auto"===r?g(n):r?r.map(n=>function n(e,t,r,a=1){if("string"==typeof e)return m(t,e,r);if(Array.isArray(e))return Object.assign(m(t,e[0],r),{title:e[1]});{a>3&&console.error("[vuepress] detected a too deep nested sidebar group.");const o=e.children||[];return 0===o.length&&e.path?Object.assign(m(t,e.path,r),{title:e.title}):{type:"group",path:e.path,title:e.title,sidebarDepth:e.sidebarDepth,initialOpenGroupIndex:e.initialOpenGroupIndex,children:o.map(e=>n(e,t,r,a+1)),collapsable:!1!==e.collapsable}}}(n,a,t)):[]}return[]}function g(n){const e=f(n.headers||[]);return[{type:"group",collapsable:!1,title:n.title,path:null,children:e.map(e=>({type:"auto",title:e.title,basePath:n.path,path:n.path+"#"+e.slug,children:e.children||[]}))}]}function f(n){let e;return(n=n.map(n=>Object.assign({},n))).forEach(n=>{2===n.level?e=n:e&&(e.children||(e.children=[])).push(n)}),n.filter(n=>2===n.level)}function v(n){return Object.assign(n,{type:n.items&&n.items.length?"links":"link"})}function b(n){return Object.prototype.toString.call(n).match(/\[object (.*?)\]/)[1].toLowerCase()}function k(n){let e=n.frontmatter.date||n.lastUpdated||new Date,t=new Date(e);return"Invalid Date"==t&&e&&(t=new Date(e.replace(/-/g,"/"))),t.getTime()}function y(n,e){return k(e)-k(n)}},function(n,e){n.exports=function(n){return null!=n&&"object"==typeof n}},function(n,e,t){var r=t(14),a=t(142),o=t(143),i=r?r.toStringTag:void 0;n.exports=function(n){return null==n?void 0===n?"[object Undefined]":"[object Null]":i&&i in Object(n)?a(n):o(n)}},function(n,e,t){var r=t(6).Symbol;n.exports=r},function(n,e,t){var r=t(7),a=t(61),o=t(98),i=t(24),s=t(52),c=TypeError,l=Object.defineProperty,p=Object.getOwnPropertyDescriptor;e.f=r?o?function(n,e,t){if(i(n),e=s(e),i(t),"function"==typeof n&&"prototype"===e&&"value"in t&&"writable"in t&&!t.writable){var r=p(n,e);r&&r.writable&&(n[e]=t.value,t={configurable:"configurable"in t?t.configurable:r.configurable,enumerable:"enumerable"in t?t.enumerable:r.enumerable,writable:!1})}return l(n,e,t)}:l:function(n,e,t){if(i(n),e=s(e),i(t),a)try{return l(n,e,t)}catch(n){}if("get"in t||"set"in t)throw c("Accessors not supported");return"value"in t&&(n[e]=t.value),n}},function(n,e,t){var r=t(3),a=t(1),o=function(n){return a(n)?n:void 0};n.exports=function(n,e){return arguments.length<2?o(r[n]):r[n]&&r[n][e]}},function(n,e,t){var r=t(7),a=t(15),o=t(29);n.exports=r?function(n,e,t){return a.f(n,e,o(1,t))}:function(n,e,t){return n[e]=t,n}},function(n,e,t){var r=t(147),a=t(148),o=t(149),i=t(150),s=t(151);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=a,c.prototype.get=o,c.prototype.has=i,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(69);n.exports=function(n,e){for(var t=n.length;t--;)if(r(n[t][0],e))return t;return-1}},function(n,e,t){var r=t(10)(Object,"create");n.exports=r},function(n,e,t){var r=t(169);n.exports=function(n,e){var t=n.__data__;return r(e)?t["string"==typeof e?"string":"hash"]:t.map}},function(n,e,t){var r=t(40);n.exports=function(n){if("string"==typeof n||r(n))return n;var e=n+"";return"0"==e&&1/n==-1/0?"-0":e}},function(n,e,t){var r,a;
/* NProgress, (c) 2013, 2014 Rico Sta. Cruz - http://ricostacruz.com/nprogress
 * @license MIT */void 0===(a="function"==typeof(r=function(){var n,e,t={version:"0.2.0"},r=t.settings={minimum:.08,easing:"ease",positionUsing:"",speed:200,trickle:!0,trickleRate:.02,trickleSpeed:800,showSpinner:!0,barSelector:'[role="bar"]',spinnerSelector:'[role="spinner"]',parent:"body",template:'<div class="bar" role="bar"><div class="peg"></div></div><div class="spinner" role="spinner"><div class="spinner-icon"></div></div>'};function a(n,e,t){return n<e?e:n>t?t:n}function o(n){return 100*(-1+n)}t.configure=function(n){var e,t;for(e in n)void 0!==(t=n[e])&&n.hasOwnProperty(e)&&(r[e]=t);return this},t.status=null,t.set=function(n){var e=t.isStarted();n=a(n,r.minimum,1),t.status=1===n?null:n;var c=t.render(!e),l=c.querySelector(r.barSelector),p=r.speed,d=r.easing;return c.offsetWidth,i((function(e){""===r.positionUsing&&(r.positionUsing=t.getPositioningCSS()),s(l,function(n,e,t){var a;return(a="translate3d"===r.positionUsing?{transform:"translate3d("+o(n)+"%,0,0)"}:"translate"===r.positionUsing?{transform:"translate("+o(n)+"%,0)"}:{"margin-left":o(n)+"%"}).transition="all "+e+"ms "+t,a}(n,p,d)),1===n?(s(c,{transition:"none",opacity:1}),c.offsetWidth,setTimeout((function(){s(c,{transition:"all "+p+"ms linear",opacity:0}),setTimeout((function(){t.remove(),e()}),p)}),p)):setTimeout(e,p)})),this},t.isStarted=function(){return"number"==typeof t.status},t.start=function(){t.status||t.set(0);var n=function(){setTimeout((function(){t.status&&(t.trickle(),n())}),r.trickleSpeed)};return r.trickle&&n(),this},t.done=function(n){return n||t.status?t.inc(.3+.5*Math.random()).set(1):this},t.inc=function(n){var e=t.status;return e?("number"!=typeof n&&(n=(1-e)*a(Math.random()*e,.1,.95)),e=a(e+n,0,.994),t.set(e)):t.start()},t.trickle=function(){return t.inc(Math.random()*r.trickleRate)},n=0,e=0,t.promise=function(r){return r&&"resolved"!==r.state()?(0===e&&t.start(),n++,e++,r.always((function(){0==--e?(n=0,t.done()):t.set((n-e)/n)})),this):this},t.render=function(n){if(t.isRendered())return document.getElementById("nprogress");l(document.documentElement,"nprogress-busy");var e=document.createElement("div");e.id="nprogress",e.innerHTML=r.template;var a,i=e.querySelector(r.barSelector),c=n?"-100":o(t.status||0),p=document.querySelector(r.parent);return s(i,{transition:"all 0 linear",transform:"translate3d("+c+"%,0,0)"}),r.showSpinner||(a=e.querySelector(r.spinnerSelector))&&u(a),p!=document.body&&l(p,"nprogress-custom-parent"),p.appendChild(e),e},t.remove=function(){p(document.documentElement,"nprogress-busy"),p(document.querySelector(r.parent),"nprogress-custom-parent");var n=document.getElementById("nprogress");n&&u(n)},t.isRendered=function(){return!!document.getElementById("nprogress")},t.getPositioningCSS=function(){var n=document.body.style,e="WebkitTransform"in n?"Webkit":"MozTransform"in n?"Moz":"msTransform"in n?"ms":"OTransform"in n?"O":"";return e+"Perspective"in n?"translate3d":e+"Transform"in n?"translate":"margin"};var i=function(){var n=[];function e(){var t=n.shift();t&&t(e)}return function(t){n.push(t),1==n.length&&e()}}(),s=function(){var n=["Webkit","O","Moz","ms"],e={};function t(t){return t=t.replace(/^-ms-/,"ms-").replace(/-([\da-z])/gi,(function(n,e){return e.toUpperCase()})),e[t]||(e[t]=function(e){var t=document.body.style;if(e in t)return e;for(var r,a=n.length,o=e.charAt(0).toUpperCase()+e.slice(1);a--;)if((r=n[a]+o)in t)return r;return e}(t))}function r(n,e,r){e=t(e),n.style[e]=r}return function(n,e){var t,a,o=arguments;if(2==o.length)for(t in e)void 0!==(a=e[t])&&e.hasOwnProperty(t)&&r(n,t,a);else r(n,o[1],o[2])}}();function c(n,e){return("string"==typeof n?n:d(n)).indexOf(" "+e+" ")>=0}function l(n,e){var t=d(n),r=t+e;c(t,e)||(n.className=r.substring(1))}function p(n,e){var t,r=d(n);c(n,e)&&(t=r.replace(" "+e+" "," "),n.className=t.substring(1,t.length-1))}function d(n){return(" "+(n.className||"")+" ").replace(/\s+/gi," ")}function u(n){n&&n.parentNode&&n.parentNode.removeChild(n)}return t})?r.call(e,t,e,n):r)||(n.exports=a)},function(n,e,t){var r=t(9),a=String,o=TypeError;n.exports=function(n){if(r(n))return n;throw o(a(n)+" is not an object")}},function(n,e,t){var r=t(4);n.exports=!r((function(){var n=function(){}.bind();return"function"!=typeof n||n.hasOwnProperty("prototype")}))},function(n,e,t){var r=t(43),a=t(51);n.exports=function(n){return r(a(n))}},function(n,e,t){var r=t(3),a=t(58),o=t(8),i=t(60),s=t(56),c=t(55),l=a("wks"),p=r.Symbol,d=p&&p.for,u=c?p:p&&p.withoutSetter||i;n.exports=function(n){if(!o(l,n)||!s&&"string"!=typeof l[n]){var e="Symbol."+n;s&&o(p,n)?l[n]=p[n]:l[n]=c&&d?d(e):u(e)}return l[n]}},function(n,e,t){var r=t(25),a=Function.prototype.call;n.exports=r?a.bind(a):function(){return a.apply(a,arguments)}},function(n,e){n.exports=function(n,e){return{enumerable:!(1&n),configurable:!(2&n),writable:!(4&n),value:e}}},function(n,e,t){var r=t(2),a=r({}.toString),o=r("".slice);n.exports=function(n){return o(a(n),8,-1)}},function(n,e,t){var r=t(3),a=t(32),o=r["__core-js_shared__"]||a("__core-js_shared__",{});n.exports=o},function(n,e,t){var r=t(3),a=Object.defineProperty;n.exports=function(n,e){try{a(r,n,{value:e,configurable:!0,writable:!0})}catch(t){r[n]=e}return e}},function(n,e,t){var r=t(141),a=t(12),o=Object.prototype,i=o.hasOwnProperty,s=o.propertyIsEnumerable,c=r(function(){return arguments}())?r:function(n){return a(n)&&i.call(n,"callee")&&!s.call(n,"callee")};n.exports=c},function(n,e,t){var r=t(10)(t(6),"Map");n.exports=r},function(n,e){n.exports=function(n){var e=typeof n;return null!=n&&("object"==e||"function"==e)}},function(n,e,t){var r=t(161),a=t(168),o=t(170),i=t(171),s=t(172);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=a,c.prototype.get=o,c.prototype.has=i,c.prototype.set=s,n.exports=c},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n){t[++e]=n})),t}},function(n,e){n.exports=function(n){return"number"==typeof n&&n>-1&&n%1==0&&n<=9007199254740991}},function(n,e,t){var r=t(5),a=t(40),o=/\.|\[(?:[^[\]]*|(["'])(?:(?!\1)[^\\]|\\.)*?\1)\]/,i=/^\w*$/;n.exports=function(n,e){if(r(n))return!1;var t=typeof n;return!("number"!=t&&"symbol"!=t&&"boolean"!=t&&null!=n&&!a(n))||(i.test(n)||!o.test(n)||null!=e&&n in Object(e))}},function(n,e,t){var r=t(13),a=t(12);n.exports=function(n){return"symbol"==typeof n||a(n)&&"[object Symbol]"==r(n)}},function(n,e){n.exports=function(n){return n}},function(n,e,t){var r=t(3),a=t(50).f,o=t(17),i=t(110),s=t(32),c=t(63),l=t(122);n.exports=function(n,e){var t,p,d,u,m,h=n.target,g=n.global,f=n.stat;if(t=g?r:f?r[h]||s(h,{}):(r[h]||{}).prototype)for(p in e){if(u=e[p],d=n.dontCallGetSet?(m=a(t,p))&&m.value:t[p],!l(g?p:h+(f?".":"#")+p,n.forced)&&void 0!==d){if(typeof u==typeof d)continue;c(u,d)}(n.sham||d&&d.sham)&&o(u,"sham",!0),i(t,p,u,n)}}},function(n,e,t){var r=t(2),a=t(4),o=t(30),i=Object,s=r("".split);n.exports=a((function(){return!i("z").propertyIsEnumerable(0)}))?function(n){return"String"==o(n)?s(n,""):i(n)}:i},function(n,e,t){var r=t(1),a=t(108),o=TypeError;n.exports=function(n){if(r(n))return n;throw o(a(n)+" is not a function")}},function(n,e,t){var r=t(51),a=Object;n.exports=function(n){return a(r(n))}},function(n,e){n.exports={}},function(n,e,t){var r=t(120);n.exports=function(n){return r(n.length)}},function(n,e){n.exports=function(n){return n.webpackPolyfill||(n.deprecate=function(){},n.paths=[],n.children||(n.children=[]),Object.defineProperty(n,"loaded",{enumerable:!0,get:function(){return n.l}}),Object.defineProperty(n,"id",{enumerable:!0,get:function(){return n.i}}),n.webpackPolyfill=1),n}},function(n,e){var t=/^\s+|\s+$/g,r=/^[-+]0x[0-9a-f]+$/i,a=/^0b[01]+$/i,o=/^0o[0-7]+$/i,i=parseInt,s="object"==typeof global&&global&&global.Object===Object&&global,c="object"==typeof self&&self&&self.Object===Object&&self,l=s||c||Function("return this")(),p=Object.prototype.toString,d=Math.max,u=Math.min,m=function(){return l.Date.now()};function h(n){var e=typeof n;return!!n&&("object"==e||"function"==e)}function g(n){if("number"==typeof n)return n;if(function(n){return"symbol"==typeof n||function(n){return!!n&&"object"==typeof n}(n)&&"[object Symbol]"==p.call(n)}(n))return NaN;if(h(n)){var e="function"==typeof n.valueOf?n.valueOf():n;n=h(e)?e+"":e}if("string"!=typeof n)return 0===n?n:+n;n=n.replace(t,"");var s=a.test(n);return s||o.test(n)?i(n.slice(2),s?2:8):r.test(n)?NaN:+n}n.exports=function(n,e,t){var r,a,o,i,s,c,l=0,p=!1,f=!1,v=!0;if("function"!=typeof n)throw new TypeError("Expected a function");function b(e){var t=r,o=a;return r=a=void 0,l=e,i=n.apply(o,t)}function k(n){return l=n,s=setTimeout(E,e),p?b(n):i}function y(n){var t=n-c;return void 0===c||t>=e||t<0||f&&n-l>=o}function E(){var n=m();if(y(n))return _(n);s=setTimeout(E,function(n){var t=e-(n-c);return f?u(t,o-(n-l)):t}(n))}function _(n){return s=void 0,v&&r?b(n):(r=a=void 0,i)}function x(){var n=m(),t=y(n);if(r=arguments,a=this,c=n,t){if(void 0===s)return k(c);if(f)return s=setTimeout(E,e),b(c)}return void 0===s&&(s=setTimeout(E,e)),i}return e=g(e)||0,h(t)&&(p=!!t.leading,o=(f="maxWait"in t)?d(g(t.maxWait)||0,e):o,v="trailing"in t?!!t.trailing:v),x.cancel=function(){void 0!==s&&clearTimeout(s),l=0,r=c=a=s=void 0},x.flush=function(){return void 0===s?i:_(m())},x}},function(n,e,t){var r=t(7),a=t(28),o=t(104),i=t(29),s=t(26),c=t(52),l=t(8),p=t(61),d=Object.getOwnPropertyDescriptor;e.f=r?d:function(n,e){if(n=s(n),e=c(e),p)try{return d(n,e)}catch(n){}if(l(n,e))return i(!a(o.f,n,e),n[e])}},function(n,e){var t=TypeError;n.exports=function(n){if(null==n)throw t("Can't call method on "+n);return n}},function(n,e,t){var r=t(105),a=t(53);n.exports=function(n){var e=r(n,"string");return a(e)?e:e+""}},function(n,e,t){var r=t(16),a=t(1),o=t(54),i=t(55),s=Object;n.exports=i?function(n){return"symbol"==typeof n}:function(n){var e=r("Symbol");return a(e)&&o(e.prototype,s(n))}},function(n,e,t){var r=t(2);n.exports=r({}.isPrototypeOf)},function(n,e,t){var r=t(56);n.exports=r&&!Symbol.sham&&"symbol"==typeof Symbol.iterator},function(n,e,t){var r=t(57),a=t(4);n.exports=!!Object.getOwnPropertySymbols&&!a((function(){var n=Symbol();return!String(n)||!(Object(n)instanceof Symbol)||!Symbol.sham&&r&&r<41}))},function(n,e,t){var r,a,o=t(3),i=t(106),s=o.process,c=o.Deno,l=s&&s.versions||c&&c.version,p=l&&l.v8;p&&(a=(r=p.split("."))[0]>0&&r[0]<4?1:+(r[0]+r[1])),!a&&i&&(!(r=i.match(/Edge\/(\d+)/))||r[1]>=74)&&(r=i.match(/Chrome\/(\d+)/))&&(a=+r[1]),n.exports=a},function(n,e,t){var r=t(59),a=t(31);(n.exports=function(n,e){return a[n]||(a[n]=void 0!==e?e:{})})("versions",[]).push({version:"3.24.0",mode:r?"pure":"global",copyright:"© 2014-2022 Denis Pushkarev (zloirock.ru)",license:"https://github.com/zloirock/core-js/blob/v3.24.0/LICENSE",source:"https://github.com/zloirock/core-js"})},function(n,e){n.exports=!1},function(n,e,t){var r=t(2),a=0,o=Math.random(),i=r(1..toString);n.exports=function(n){return"Symbol("+(void 0===n?"":n)+")_"+i(++a+o,36)}},function(n,e,t){var r=t(7),a=t(4),o=t(97);n.exports=!r&&!a((function(){return 7!=Object.defineProperty(o("div"),"a",{get:function(){return 7}}).a}))},function(n,e,t){var r=t(2),a=t(1),o=t(31),i=r(Function.toString);a(o.inspectSource)||(o.inspectSource=function(n){return i(n)}),n.exports=o.inspectSource},function(n,e,t){var r=t(8),a=t(115),o=t(50),i=t(15);n.exports=function(n,e,t){for(var s=a(e),c=i.f,l=o.f,p=0;p<s.length;p++){var d=s[p];r(n,d)||t&&r(t,d)||c(n,d,l(e,d))}}},function(n,e,t){var r=t(119);n.exports=function(n){var e=+n;return e!=e||0===e?0:r(e)}},function(n,e,t){var r=t(2),a=t(24),o=t(129);n.exports=Object.setPrototypeOf||("__proto__"in{}?function(){var n,e=!1,t={};try{(n=r(Object.getOwnPropertyDescriptor(Object.prototype,"__proto__").set))(t,[]),e=t instanceof Array}catch(n){}return function(t,r){return a(t),o(r),e?n(t,r):t.__proto__=r,t}}():void 0)},function(n,e){n.exports=function(n,e){for(var t=-1,r=e.length,a=n.length;++t<r;)n[a+t]=e[t];return n}},function(n,e){var t="object"==typeof global&&global&&global.Object===Object&&global;n.exports=t},function(n,e,t){var r=t(18),a=t(152),o=t(153),i=t(154),s=t(155),c=t(156);function l(n){var e=this.__data__=new r(n);this.size=e.size}l.prototype.clear=a,l.prototype.delete=o,l.prototype.get=i,l.prototype.has=s,l.prototype.set=c,n.exports=l},function(n,e){n.exports=function(n,e){return n===e||n!=n&&e!=e}},function(n,e,t){var r=t(13),a=t(35);n.exports=function(n){if(!a(n))return!1;var e=r(n);return"[object Function]"==e||"[object GeneratorFunction]"==e||"[object AsyncFunction]"==e||"[object Proxy]"==e}},function(n,e){var t=Function.prototype.toString;n.exports=function(n){if(null!=n){try{return t.call(n)}catch(n){}try{return n+""}catch(n){}}return""}},function(n,e,t){var r=t(173),a=t(12);n.exports=function n(e,t,o,i,s){return e===t||(null==e||null==t||!a(e)&&!a(t)?e!=e&&t!=t:r(e,t,o,i,n,s))}},function(n,e,t){var r=t(74),a=t(176),o=t(75);n.exports=function(n,e,t,i,s,c){var l=1&t,p=n.length,d=e.length;if(p!=d&&!(l&&d>p))return!1;var u=c.get(n),m=c.get(e);if(u&&m)return u==e&&m==n;var h=-1,g=!0,f=2&t?new r:void 0;for(c.set(n,e),c.set(e,n);++h<p;){var v=n[h],b=e[h];if(i)var k=l?i(b,v,h,e,n,c):i(v,b,h,n,e,c);if(void 0!==k){if(k)continue;g=!1;break}if(f){if(!a(e,(function(n,e){if(!o(f,e)&&(v===n||s(v,n,t,i,c)))return f.push(e)}))){g=!1;break}}else if(v!==b&&!s(v,b,t,i,c)){g=!1;break}}return c.delete(n),c.delete(e),g}},function(n,e,t){var r=t(36),a=t(174),o=t(175);function i(n){var e=-1,t=null==n?0:n.length;for(this.__data__=new r;++e<t;)this.add(n[e])}i.prototype.add=i.prototype.push=a,i.prototype.has=o,n.exports=i},function(n,e){n.exports=function(n,e){return n.has(e)}},function(n,e,t){var r=t(186),a=t(192),o=t(80);n.exports=function(n){return o(n)?r(n):a(n)}},function(n,e,t){(function(n){var r=t(6),a=t(188),o=e&&!e.nodeType&&e,i=o&&"object"==typeof n&&n&&!n.nodeType&&n,s=i&&i.exports===o?r.Buffer:void 0,c=(s?s.isBuffer:void 0)||a;n.exports=c}).call(this,t(48)(n))},function(n,e){var t=/^(?:0|[1-9]\d*)$/;n.exports=function(n,e){var r=typeof n;return!!(e=null==e?9007199254740991:e)&&("number"==r||"symbol"!=r&&t.test(n))&&n>-1&&n%1==0&&n<e}},function(n,e,t){var r=t(189),a=t(190),o=t(191),i=o&&o.isTypedArray,s=i?a(i):r;n.exports=s},function(n,e,t){var r=t(70),a=t(38);n.exports=function(n){return null!=n&&a(n.length)&&!r(n)}},function(n,e,t){var r=t(10)(t(6),"Set");n.exports=r},function(n,e,t){var r=t(35);n.exports=function(n){return n==n&&!r(n)}},function(n,e){n.exports=function(n,e){return function(t){return null!=t&&(t[n]===e&&(void 0!==e||n in Object(t)))}}},function(n,e,t){var r=t(85),a=t(22);n.exports=function(n,e){for(var t=0,o=(e=r(e,n)).length;null!=n&&t<o;)n=n[a(e[t++])];return t&&t==o?n:void 0}},function(n,e,t){var r=t(5),a=t(39),o=t(203),i=t(206);n.exports=function(n,e){return r(n)?n:a(n,e)?[n]:o(i(n))}},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){},function(n,e,t){var r=t(139),a=t(144),o=t(215),i=t(223),s=t(232),c=t(101),l=o((function(n){var e=c(n);return s(e)&&(e=void 0),i(r(n,1,s,!0),a(e,2))}));n.exports=l},function(n,e,t){"use strict";
/*!
 * escape-html
 * Copyright(c) 2012-2013 TJ Holowaychuk
 * Copyright(c) 2015 Andreas Lubbe
 * Copyright(c) 2015 Tiancheng "Timothy" Gu
 * MIT Licensed
 */var r=/["'&<>]/;n.exports=function(n){var e,t=""+n,a=r.exec(t);if(!a)return t;var o="",i=0,s=0;for(i=a.index;i<t.length;i++){switch(t.charCodeAt(i)){case 34:e="&quot;";break;case 38:e="&amp;";break;case 39:e="&#39;";break;case 60:e="&lt;";break;case 62:e="&gt;";break;default:continue}s!==i&&(o+=t.substring(s,i)),s=i+1,o+=e}return s!==i?o+t.substring(s,i):o}},function(n,e,t){"use strict";t.r(e);var r={name:"CodeBlock",props:{title:{type:String,required:!0},active:{type:Boolean,default:!1}}},a=(t(235),t(0)),o=Object(a.a)(r,(function(){return(0,this._self._c)("div",{staticClass:"theme-code-block",class:{"theme-code-block__active":this.active}},[this._t("default")],2)}),[],!1,null,"4f1e9d0c",null);e.default=o.exports},function(n,e,t){"use strict";t.r(e);var r={name:"CodeGroup",data:()=>({codeTabs:[],activeCodeTabIndex:-1}),watch:{activeCodeTabIndex(n){this.codeTabs.forEach(n=>{n.elm.classList.remove("theme-code-block__active")}),this.codeTabs[n].elm.classList.add("theme-code-block__active")}},mounted(){this.codeTabs=(this.$slots.default||[]).filter(n=>Boolean(n.componentOptions)).map((n,e)=>(""===n.componentOptions.propsData.active&&(this.activeCodeTabIndex=e),{title:n.componentOptions.propsData.title,elm:n.elm})),-1===this.activeCodeTabIndex&&this.codeTabs.length>0&&(this.activeCodeTabIndex=0)},methods:{changeCodeTab(n){this.activeCodeTabIndex=n}}},a=(t(236),t(0)),o=Object(a.a)(r,(function(){var n=this,e=n._self._c;return e("div",{staticClass:"theme-code-group"},[e("div",{staticClass:"theme-code-group__nav"},[e("ul",{staticClass:"theme-code-group__ul"},n._l(n.codeTabs,(function(t,r){return e("li",{key:t.title,staticClass:"theme-code-group__li"},[e("button",{staticClass:"theme-code-group__nav-tab",class:{"theme-code-group__nav-tab-active":r===n.activeCodeTabIndex},on:{click:function(e){return n.changeCodeTab(r)}}},[n._v("\n            "+n._s(t.title)+"\n          ")])])})),0)]),n._v(" "),n._t("default"),n._v(" "),n.codeTabs.length<1?e("pre",{staticClass:"pre-blank"},[n._v("// Make sure to add code blocks to your code group")]):n._e()],2)}),[],!1,null,"2f5f1757",null);e.default=o.exports},function(n,e){n.exports=["constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf"]},function(n,e,t){var r=t(3),a=t(9),o=r.document,i=a(o)&&a(o.createElement);n.exports=function(n){return i?o.createElement(n):{}}},function(n,e,t){var r=t(7),a=t(4);n.exports=r&&a((function(){return 42!=Object.defineProperty((function(){}),"prototype",{value:42,writable:!1}).prototype}))},function(n,e,t){var r=t(58),a=t(60),o=r("keys");n.exports=function(n){return o[n]||(o[n]=a(n))}},function(n,e,t){var r=t(2),a=t(8),o=t(26),i=t(117).indexOf,s=t(46),c=r([].push);n.exports=function(n,e){var t,r=o(n),l=0,p=[];for(t in r)!a(s,t)&&a(r,t)&&c(p,t);for(;e.length>l;)a(r,t=e[l++])&&(~i(p,t)||c(p,t));return p}},function(n,e){n.exports=function(n){var e=null==n?0:n.length;return e?n[e-1]:void 0}},function(n,e,t){n.exports=t(243)},function(n,e,t){"use strict";var r=t(42),a=t(123).left,o=t(124),i=t(57),s=t(125);r({target:"Array",proto:!0,forced:!o("reduce")||!s&&i>79&&i<83},{reduce:function(n){var e=arguments.length;return a(this,n,e,e>1?arguments[1]:void 0)}})},function(n,e,t){"use strict";var r={}.propertyIsEnumerable,a=Object.getOwnPropertyDescriptor,o=a&&!r.call({1:2},1);e.f=o?function(n){var e=a(this,n);return!!e&&e.enumerable}:r},function(n,e,t){var r=t(28),a=t(9),o=t(53),i=t(107),s=t(109),c=t(27),l=TypeError,p=c("toPrimitive");n.exports=function(n,e){if(!a(n)||o(n))return n;var t,c=i(n,p);if(c){if(void 0===e&&(e="default"),t=r(c,n,e),!a(t)||o(t))return t;throw l("Can't convert object to primitive value")}return void 0===e&&(e="number"),s(n,e)}},function(n,e,t){var r=t(16);n.exports=r("navigator","userAgent")||""},function(n,e,t){var r=t(44);n.exports=function(n,e){var t=n[e];return null==t?void 0:r(t)}},function(n,e){var t=String;n.exports=function(n){try{return t(n)}catch(n){return"Object"}}},function(n,e,t){var r=t(28),a=t(1),o=t(9),i=TypeError;n.exports=function(n,e){var t,s;if("string"===e&&a(t=n.toString)&&!o(s=r(t,n)))return s;if(a(t=n.valueOf)&&!o(s=r(t,n)))return s;if("string"!==e&&a(t=n.toString)&&!o(s=r(t,n)))return s;throw i("Can't convert object to primitive value")}},function(n,e,t){var r=t(1),a=t(15),o=t(111),i=t(32);n.exports=function(n,e,t,s){s||(s={});var c=s.enumerable,l=void 0!==s.name?s.name:e;if(r(t)&&o(t,l,s),s.global)c?n[e]=t:i(e,t);else{try{s.unsafe?n[e]&&(c=!0):delete n[e]}catch(n){}c?n[e]=t:a.f(n,e,{value:t,enumerable:!1,configurable:!s.nonConfigurable,writable:!s.nonWritable})}return n}},function(n,e,t){var r=t(4),a=t(1),o=t(8),i=t(7),s=t(112).CONFIGURABLE,c=t(62),l=t(113),p=l.enforce,d=l.get,u=Object.defineProperty,m=i&&!r((function(){return 8!==u((function(){}),"length",{value:8}).length})),h=String(String).split("String"),g=n.exports=function(n,e,t){"Symbol("===String(e).slice(0,7)&&(e="["+String(e).replace(/^Symbol\(([^)]*)\)/,"$1")+"]"),t&&t.getter&&(e="get "+e),t&&t.setter&&(e="set "+e),(!o(n,"name")||s&&n.name!==e)&&(i?u(n,"name",{value:e,configurable:!0}):n.name=e),m&&t&&o(t,"arity")&&n.length!==t.arity&&u(n,"length",{value:t.arity});try{t&&o(t,"constructor")&&t.constructor?i&&u(n,"prototype",{writable:!1}):n.prototype&&(n.prototype=void 0)}catch(n){}var r=p(n);return o(r,"source")||(r.source=h.join("string"==typeof e?e:"")),n};Function.prototype.toString=g((function(){return a(this)&&d(this).source||c(this)}),"toString")},function(n,e,t){var r=t(7),a=t(8),o=Function.prototype,i=r&&Object.getOwnPropertyDescriptor,s=a(o,"name"),c=s&&"something"===function(){}.name,l=s&&(!r||r&&i(o,"name").configurable);n.exports={EXISTS:s,PROPER:c,CONFIGURABLE:l}},function(n,e,t){var r,a,o,i=t(114),s=t(3),c=t(2),l=t(9),p=t(17),d=t(8),u=t(31),m=t(99),h=t(46),g=s.TypeError,f=s.WeakMap;if(i||u.state){var v=u.state||(u.state=new f),b=c(v.get),k=c(v.has),y=c(v.set);r=function(n,e){if(k(v,n))throw new g("Object already initialized");return e.facade=n,y(v,n,e),e},a=function(n){return b(v,n)||{}},o=function(n){return k(v,n)}}else{var E=m("state");h[E]=!0,r=function(n,e){if(d(n,E))throw new g("Object already initialized");return e.facade=n,p(n,E,e),e},a=function(n){return d(n,E)?n[E]:{}},o=function(n){return d(n,E)}}n.exports={set:r,get:a,has:o,enforce:function(n){return o(n)?a(n):r(n,{})},getterFor:function(n){return function(e){var t;if(!l(e)||(t=a(e)).type!==n)throw g("Incompatible receiver, "+n+" required");return t}}}},function(n,e,t){var r=t(3),a=t(1),o=t(62),i=r.WeakMap;n.exports=a(i)&&/native code/.test(o(i))},function(n,e,t){var r=t(16),a=t(2),o=t(116),i=t(121),s=t(24),c=a([].concat);n.exports=r("Reflect","ownKeys")||function(n){var e=o.f(s(n)),t=i.f;return t?c(e,t(n)):e}},function(n,e,t){var r=t(100),a=t(96).concat("length","prototype");e.f=Object.getOwnPropertyNames||function(n){return r(n,a)}},function(n,e,t){var r=t(26),a=t(118),o=t(47),i=function(n){return function(e,t,i){var s,c=r(e),l=o(c),p=a(i,l);if(n&&t!=t){for(;l>p;)if((s=c[p++])!=s)return!0}else for(;l>p;p++)if((n||p in c)&&c[p]===t)return n||p||0;return!n&&-1}};n.exports={includes:i(!0),indexOf:i(!1)}},function(n,e,t){var r=t(64),a=Math.max,o=Math.min;n.exports=function(n,e){var t=r(n);return t<0?a(t+e,0):o(t,e)}},function(n,e){var t=Math.ceil,r=Math.floor;n.exports=Math.trunc||function(n){var e=+n;return(e>0?r:t)(e)}},function(n,e,t){var r=t(64),a=Math.min;n.exports=function(n){return n>0?a(r(n),9007199254740991):0}},function(n,e){e.f=Object.getOwnPropertySymbols},function(n,e,t){var r=t(4),a=t(1),o=/#|\.prototype\./,i=function(n,e){var t=c[s(n)];return t==p||t!=l&&(a(e)?r(e):!!e)},s=i.normalize=function(n){return String(n).replace(o,".").toLowerCase()},c=i.data={},l=i.NATIVE="N",p=i.POLYFILL="P";n.exports=i},function(n,e,t){var r=t(44),a=t(45),o=t(43),i=t(47),s=TypeError,c=function(n){return function(e,t,c,l){r(t);var p=a(e),d=o(p),u=i(p),m=n?u-1:0,h=n?-1:1;if(c<2)for(;;){if(m in d){l=d[m],m+=h;break}if(m+=h,n?m<0:u<=m)throw s("Reduce of empty array with no initial value")}for(;n?m>=0:u>m;m+=h)m in d&&(l=t(l,d[m],m,p));return l}};n.exports={left:c(!1),right:c(!0)}},function(n,e,t){"use strict";var r=t(4);n.exports=function(n,e){var t=[][n];return!!t&&r((function(){t.call(null,e||function(){return 1},1)}))}},function(n,e,t){var r=t(30),a=t(3);n.exports="process"==r(a.process)},function(n,e,t){var r=t(42),a=t(3),o=t(127),i=t(128),s=a.WebAssembly,c=7!==Error("e",{cause:7}).cause,l=function(n,e){var t={};t[n]=i(n,e,c),r({global:!0,constructor:!0,arity:1,forced:c},t)},p=function(n,e){if(s&&s[n]){var t={};t[n]=i("WebAssembly."+n,e,c),r({target:"WebAssembly",stat:!0,constructor:!0,arity:1,forced:c},t)}};l("Error",(function(n){return function(e){return o(n,this,arguments)}})),l("EvalError",(function(n){return function(e){return o(n,this,arguments)}})),l("RangeError",(function(n){return function(e){return o(n,this,arguments)}})),l("ReferenceError",(function(n){return function(e){return o(n,this,arguments)}})),l("SyntaxError",(function(n){return function(e){return o(n,this,arguments)}})),l("TypeError",(function(n){return function(e){return o(n,this,arguments)}})),l("URIError",(function(n){return function(e){return o(n,this,arguments)}})),p("CompileError",(function(n){return function(e){return o(n,this,arguments)}})),p("LinkError",(function(n){return function(e){return o(n,this,arguments)}})),p("RuntimeError",(function(n){return function(e){return o(n,this,arguments)}}))},function(n,e,t){var r=t(25),a=Function.prototype,o=a.apply,i=a.call;n.exports="object"==typeof Reflect&&Reflect.apply||(r?i.bind(o):function(){return i.apply(o,arguments)})},function(n,e,t){"use strict";var r=t(16),a=t(8),o=t(17),i=t(54),s=t(65),c=t(63),l=t(130),p=t(131),d=t(132),u=t(136),m=t(137),h=t(138),g=t(7),f=t(59);n.exports=function(n,e,t,v){var b=v?2:1,k=n.split("."),y=k[k.length-1],E=r.apply(null,k);if(E){var _=E.prototype;if(!f&&a(_,"cause")&&delete _.cause,!t)return E;var x=r("Error"),w=e((function(n,e){var t=d(v?e:n,void 0),r=v?new E(n):new E;return void 0!==t&&o(r,"message",t),h&&o(r,"stack",m(r.stack,2)),this&&i(_,this)&&p(r,this,w),arguments.length>b&&u(r,arguments[b]),r}));if(w.prototype=_,"Error"!==y?s?s(w,x):c(w,x,{name:!0}):g&&"stackTraceLimit"in E&&(l(w,E,"stackTraceLimit"),l(w,E,"prepareStackTrace")),c(w,E),!f)try{_.name!==y&&o(_,"name",y),_.constructor=w}catch(n){}return w}}},function(n,e,t){var r=t(1),a=String,o=TypeError;n.exports=function(n){if("object"==typeof n||r(n))return n;throw o("Can't set "+a(n)+" as a prototype")}},function(n,e,t){var r=t(15).f;n.exports=function(n,e,t){t in n||r(n,t,{configurable:!0,get:function(){return e[t]},set:function(n){e[t]=n}})}},function(n,e,t){var r=t(1),a=t(9),o=t(65);n.exports=function(n,e,t){var i,s;return o&&r(i=e.constructor)&&i!==t&&a(s=i.prototype)&&s!==t.prototype&&o(n,s),n}},function(n,e,t){var r=t(133);n.exports=function(n,e){return void 0===n?arguments.length<2?"":e:r(n)}},function(n,e,t){var r=t(134),a=String;n.exports=function(n){if("Symbol"===r(n))throw TypeError("Cannot convert a Symbol value to a string");return a(n)}},function(n,e,t){var r=t(135),a=t(1),o=t(30),i=t(27)("toStringTag"),s=Object,c="Arguments"==o(function(){return arguments}());n.exports=r?o:function(n){var e,t,r;return void 0===n?"Undefined":null===n?"Null":"string"==typeof(t=function(n,e){try{return n[e]}catch(n){}}(e=s(n),i))?t:c?o(e):"Object"==(r=o(e))&&a(e.callee)?"Arguments":r}},function(n,e,t){var r={};r[t(27)("toStringTag")]="z",n.exports="[object z]"===String(r)},function(n,e,t){var r=t(9),a=t(17);n.exports=function(n,e){r(e)&&"cause"in e&&a(n,"cause",e.cause)}},function(n,e,t){var r=t(2),a=Error,o=r("".replace),i=String(a("zxcasd").stack),s=/\n\s*at [^:]*:[^\n]*/,c=s.test(i);n.exports=function(n,e){if(c&&"string"==typeof n&&!a.prepareStackTrace)for(;e--;)n=o(n,s,"");return n}},function(n,e,t){var r=t(4),a=t(29);n.exports=!r((function(){var n=Error("a");return!("stack"in n)||(Object.defineProperty(n,"stack",a(1,7)),7!==n.stack)}))},function(n,e,t){var r=t(66),a=t(140);n.exports=function n(e,t,o,i,s){var c=-1,l=e.length;for(o||(o=a),s||(s=[]);++c<l;){var p=e[c];t>0&&o(p)?t>1?n(p,t-1,o,i,s):r(s,p):i||(s[s.length]=p)}return s}},function(n,e,t){var r=t(14),a=t(33),o=t(5),i=r?r.isConcatSpreadable:void 0;n.exports=function(n){return o(n)||a(n)||!!(i&&n&&n[i])}},function(n,e,t){var r=t(13),a=t(12);n.exports=function(n){return a(n)&&"[object Arguments]"==r(n)}},function(n,e,t){var r=t(14),a=Object.prototype,o=a.hasOwnProperty,i=a.toString,s=r?r.toStringTag:void 0;n.exports=function(n){var e=o.call(n,s),t=n[s];try{n[s]=void 0;var r=!0}catch(n){}var a=i.call(n);return r&&(e?n[s]=t:delete n[s]),a}},function(n,e){var t=Object.prototype.toString;n.exports=function(n){return t.call(n)}},function(n,e,t){var r=t(145),a=t(201),o=t(41),i=t(5),s=t(212);n.exports=function(n){return"function"==typeof n?n:null==n?o:"object"==typeof n?i(n)?a(n[0],n[1]):r(n):s(n)}},function(n,e,t){var r=t(146),a=t(200),o=t(83);n.exports=function(n){var e=a(n);return 1==e.length&&e[0][2]?o(e[0][0],e[0][1]):function(t){return t===n||r(t,n,e)}}},function(n,e,t){var r=t(68),a=t(72);n.exports=function(n,e,t,o){var i=t.length,s=i,c=!o;if(null==n)return!s;for(n=Object(n);i--;){var l=t[i];if(c&&l[2]?l[1]!==n[l[0]]:!(l[0]in n))return!1}for(;++i<s;){var p=(l=t[i])[0],d=n[p],u=l[1];if(c&&l[2]){if(void 0===d&&!(p in n))return!1}else{var m=new r;if(o)var h=o(d,u,p,n,e,m);if(!(void 0===h?a(u,d,3,o,m):h))return!1}}return!0}},function(n,e){n.exports=function(){this.__data__=[],this.size=0}},function(n,e,t){var r=t(19),a=Array.prototype.splice;n.exports=function(n){var e=this.__data__,t=r(e,n);return!(t<0)&&(t==e.length-1?e.pop():a.call(e,t,1),--this.size,!0)}},function(n,e,t){var r=t(19);n.exports=function(n){var e=this.__data__,t=r(e,n);return t<0?void 0:e[t][1]}},function(n,e,t){var r=t(19);n.exports=function(n){return r(this.__data__,n)>-1}},function(n,e,t){var r=t(19);n.exports=function(n,e){var t=this.__data__,a=r(t,n);return a<0?(++this.size,t.push([n,e])):t[a][1]=e,this}},function(n,e,t){var r=t(18);n.exports=function(){this.__data__=new r,this.size=0}},function(n,e){n.exports=function(n){var e=this.__data__,t=e.delete(n);return this.size=e.size,t}},function(n,e){n.exports=function(n){return this.__data__.get(n)}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e,t){var r=t(18),a=t(34),o=t(36);n.exports=function(n,e){var t=this.__data__;if(t instanceof r){var i=t.__data__;if(!a||i.length<199)return i.push([n,e]),this.size=++t.size,this;t=this.__data__=new o(i)}return t.set(n,e),this.size=t.size,this}},function(n,e,t){var r=t(70),a=t(158),o=t(35),i=t(71),s=/^\[object .+?Constructor\]$/,c=Function.prototype,l=Object.prototype,p=c.toString,d=l.hasOwnProperty,u=RegExp("^"+p.call(d).replace(/[\\^$.*+?()[\]{}|]/g,"\\$&").replace(/hasOwnProperty|(function).*?(?=\\\()| for .+?(?=\\\])/g,"$1.*?")+"$");n.exports=function(n){return!(!o(n)||a(n))&&(r(n)?u:s).test(i(n))}},function(n,e,t){var r,a=t(159),o=(r=/[^.]+$/.exec(a&&a.keys&&a.keys.IE_PROTO||""))?"Symbol(src)_1."+r:"";n.exports=function(n){return!!o&&o in n}},function(n,e,t){var r=t(6)["__core-js_shared__"];n.exports=r},function(n,e){n.exports=function(n,e){return null==n?void 0:n[e]}},function(n,e,t){var r=t(162),a=t(18),o=t(34);n.exports=function(){this.size=0,this.__data__={hash:new r,map:new(o||a),string:new r}}},function(n,e,t){var r=t(163),a=t(164),o=t(165),i=t(166),s=t(167);function c(n){var e=-1,t=null==n?0:n.length;for(this.clear();++e<t;){var r=n[e];this.set(r[0],r[1])}}c.prototype.clear=r,c.prototype.delete=a,c.prototype.get=o,c.prototype.has=i,c.prototype.set=s,n.exports=c},function(n,e,t){var r=t(20);n.exports=function(){this.__data__=r?r(null):{},this.size=0}},function(n,e){n.exports=function(n){var e=this.has(n)&&delete this.__data__[n];return this.size-=e?1:0,e}},function(n,e,t){var r=t(20),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;if(r){var t=e[n];return"__lodash_hash_undefined__"===t?void 0:t}return a.call(e,n)?e[n]:void 0}},function(n,e,t){var r=t(20),a=Object.prototype.hasOwnProperty;n.exports=function(n){var e=this.__data__;return r?void 0!==e[n]:a.call(e,n)}},function(n,e,t){var r=t(20);n.exports=function(n,e){var t=this.__data__;return this.size+=this.has(n)?0:1,t[n]=r&&void 0===e?"__lodash_hash_undefined__":e,this}},function(n,e,t){var r=t(21);n.exports=function(n){var e=r(this,n).delete(n);return this.size-=e?1:0,e}},function(n,e){n.exports=function(n){var e=typeof n;return"string"==e||"number"==e||"symbol"==e||"boolean"==e?"__proto__"!==n:null===n}},function(n,e,t){var r=t(21);n.exports=function(n){return r(this,n).get(n)}},function(n,e,t){var r=t(21);n.exports=function(n){return r(this,n).has(n)}},function(n,e,t){var r=t(21);n.exports=function(n,e){var t=r(this,n),a=t.size;return t.set(n,e),this.size+=t.size==a?0:1,this}},function(n,e,t){var r=t(68),a=t(73),o=t(177),i=t(180),s=t(196),c=t(5),l=t(77),p=t(79),d="[object Object]",u=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,m,h,g){var f=c(n),v=c(e),b=f?"[object Array]":s(n),k=v?"[object Array]":s(e),y=(b="[object Arguments]"==b?d:b)==d,E=(k="[object Arguments]"==k?d:k)==d,_=b==k;if(_&&l(n)){if(!l(e))return!1;f=!0,y=!1}if(_&&!y)return g||(g=new r),f||p(n)?a(n,e,t,m,h,g):o(n,e,b,t,m,h,g);if(!(1&t)){var x=y&&u.call(n,"__wrapped__"),w=E&&u.call(e,"__wrapped__");if(x||w){var A=x?n.value():n,C=w?e.value():e;return g||(g=new r),h(A,C,t,m,g)}}return!!_&&(g||(g=new r),i(n,e,t,m,h,g))}},function(n,e){n.exports=function(n){return this.__data__.set(n,"__lodash_hash_undefined__"),this}},function(n,e){n.exports=function(n){return this.__data__.has(n)}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length;++t<r;)if(e(n[t],t,n))return!0;return!1}},function(n,e,t){var r=t(14),a=t(178),o=t(69),i=t(73),s=t(179),c=t(37),l=r?r.prototype:void 0,p=l?l.valueOf:void 0;n.exports=function(n,e,t,r,l,d,u){switch(t){case"[object DataView]":if(n.byteLength!=e.byteLength||n.byteOffset!=e.byteOffset)return!1;n=n.buffer,e=e.buffer;case"[object ArrayBuffer]":return!(n.byteLength!=e.byteLength||!d(new a(n),new a(e)));case"[object Boolean]":case"[object Date]":case"[object Number]":return o(+n,+e);case"[object Error]":return n.name==e.name&&n.message==e.message;case"[object RegExp]":case"[object String]":return n==e+"";case"[object Map]":var m=s;case"[object Set]":var h=1&r;if(m||(m=c),n.size!=e.size&&!h)return!1;var g=u.get(n);if(g)return g==e;r|=2,u.set(n,e);var f=i(m(n),m(e),r,l,d,u);return u.delete(n),f;case"[object Symbol]":if(p)return p.call(n)==p.call(e)}return!1}},function(n,e,t){var r=t(6).Uint8Array;n.exports=r},function(n,e){n.exports=function(n){var e=-1,t=Array(n.size);return n.forEach((function(n,r){t[++e]=[r,n]})),t}},function(n,e,t){var r=t(181),a=Object.prototype.hasOwnProperty;n.exports=function(n,e,t,o,i,s){var c=1&t,l=r(n),p=l.length;if(p!=r(e).length&&!c)return!1;for(var d=p;d--;){var u=l[d];if(!(c?u in e:a.call(e,u)))return!1}var m=s.get(n),h=s.get(e);if(m&&h)return m==e&&h==n;var g=!0;s.set(n,e),s.set(e,n);for(var f=c;++d<p;){var v=n[u=l[d]],b=e[u];if(o)var k=c?o(b,v,u,e,n,s):o(v,b,u,n,e,s);if(!(void 0===k?v===b||i(v,b,t,o,s):k)){g=!1;break}f||(f="constructor"==u)}if(g&&!f){var y=n.constructor,E=e.constructor;y==E||!("constructor"in n)||!("constructor"in e)||"function"==typeof y&&y instanceof y&&"function"==typeof E&&E instanceof E||(g=!1)}return s.delete(n),s.delete(e),g}},function(n,e,t){var r=t(182),a=t(183),o=t(76);n.exports=function(n){return r(n,o,a)}},function(n,e,t){var r=t(66),a=t(5);n.exports=function(n,e,t){var o=e(n);return a(n)?o:r(o,t(n))}},function(n,e,t){var r=t(184),a=t(185),o=Object.prototype.propertyIsEnumerable,i=Object.getOwnPropertySymbols,s=i?function(n){return null==n?[]:(n=Object(n),r(i(n),(function(e){return o.call(n,e)})))}:a;n.exports=s},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=0,o=[];++t<r;){var i=n[t];e(i,t,n)&&(o[a++]=i)}return o}},function(n,e){n.exports=function(){return[]}},function(n,e,t){var r=t(187),a=t(33),o=t(5),i=t(77),s=t(78),c=t(79),l=Object.prototype.hasOwnProperty;n.exports=function(n,e){var t=o(n),p=!t&&a(n),d=!t&&!p&&i(n),u=!t&&!p&&!d&&c(n),m=t||p||d||u,h=m?r(n.length,String):[],g=h.length;for(var f in n)!e&&!l.call(n,f)||m&&("length"==f||d&&("offset"==f||"parent"==f)||u&&("buffer"==f||"byteLength"==f||"byteOffset"==f)||s(f,g))||h.push(f);return h}},function(n,e){n.exports=function(n,e){for(var t=-1,r=Array(n);++t<n;)r[t]=e(t);return r}},function(n,e){n.exports=function(){return!1}},function(n,e,t){var r=t(13),a=t(38),o=t(12),i={};i["[object Float32Array]"]=i["[object Float64Array]"]=i["[object Int8Array]"]=i["[object Int16Array]"]=i["[object Int32Array]"]=i["[object Uint8Array]"]=i["[object Uint8ClampedArray]"]=i["[object Uint16Array]"]=i["[object Uint32Array]"]=!0,i["[object Arguments]"]=i["[object Array]"]=i["[object ArrayBuffer]"]=i["[object Boolean]"]=i["[object DataView]"]=i["[object Date]"]=i["[object Error]"]=i["[object Function]"]=i["[object Map]"]=i["[object Number]"]=i["[object Object]"]=i["[object RegExp]"]=i["[object Set]"]=i["[object String]"]=i["[object WeakMap]"]=!1,n.exports=function(n){return o(n)&&a(n.length)&&!!i[r(n)]}},function(n,e){n.exports=function(n){return function(e){return n(e)}}},function(n,e,t){(function(n){var r=t(67),a=e&&!e.nodeType&&e,o=a&&"object"==typeof n&&n&&!n.nodeType&&n,i=o&&o.exports===a&&r.process,s=function(){try{var n=o&&o.require&&o.require("util").types;return n||i&&i.binding&&i.binding("util")}catch(n){}}();n.exports=s}).call(this,t(48)(n))},function(n,e,t){var r=t(193),a=t(194),o=Object.prototype.hasOwnProperty;n.exports=function(n){if(!r(n))return a(n);var e=[];for(var t in Object(n))o.call(n,t)&&"constructor"!=t&&e.push(t);return e}},function(n,e){var t=Object.prototype;n.exports=function(n){var e=n&&n.constructor;return n===("function"==typeof e&&e.prototype||t)}},function(n,e,t){var r=t(195)(Object.keys,Object);n.exports=r},function(n,e){n.exports=function(n,e){return function(t){return n(e(t))}}},function(n,e,t){var r=t(197),a=t(34),o=t(198),i=t(81),s=t(199),c=t(13),l=t(71),p=l(r),d=l(a),u=l(o),m=l(i),h=l(s),g=c;(r&&"[object DataView]"!=g(new r(new ArrayBuffer(1)))||a&&"[object Map]"!=g(new a)||o&&"[object Promise]"!=g(o.resolve())||i&&"[object Set]"!=g(new i)||s&&"[object WeakMap]"!=g(new s))&&(g=function(n){var e=c(n),t="[object Object]"==e?n.constructor:void 0,r=t?l(t):"";if(r)switch(r){case p:return"[object DataView]";case d:return"[object Map]";case u:return"[object Promise]";case m:return"[object Set]";case h:return"[object WeakMap]"}return e}),n.exports=g},function(n,e,t){var r=t(10)(t(6),"DataView");n.exports=r},function(n,e,t){var r=t(10)(t(6),"Promise");n.exports=r},function(n,e,t){var r=t(10)(t(6),"WeakMap");n.exports=r},function(n,e,t){var r=t(82),a=t(76);n.exports=function(n){for(var e=a(n),t=e.length;t--;){var o=e[t],i=n[o];e[t]=[o,i,r(i)]}return e}},function(n,e,t){var r=t(72),a=t(202),o=t(209),i=t(39),s=t(82),c=t(83),l=t(22);n.exports=function(n,e){return i(n)&&s(e)?c(l(n),e):function(t){var i=a(t,n);return void 0===i&&i===e?o(t,n):r(e,i,3)}}},function(n,e,t){var r=t(84);n.exports=function(n,e,t){var a=null==n?void 0:r(n,e);return void 0===a?t:a}},function(n,e,t){var r=t(204),a=/[^.[\]]+|\[(?:(-?\d+(?:\.\d+)?)|(["'])((?:(?!\2)[^\\]|\\.)*?)\2)\]|(?=(?:\.|\[\])(?:\.|\[\]|$))/g,o=/\\(\\)?/g,i=r((function(n){var e=[];return 46===n.charCodeAt(0)&&e.push(""),n.replace(a,(function(n,t,r,a){e.push(r?a.replace(o,"$1"):t||n)})),e}));n.exports=i},function(n,e,t){var r=t(205);n.exports=function(n){var e=r(n,(function(n){return 500===t.size&&t.clear(),n})),t=e.cache;return e}},function(n,e,t){var r=t(36);function a(n,e){if("function"!=typeof n||null!=e&&"function"!=typeof e)throw new TypeError("Expected a function");var t=function(){var r=arguments,a=e?e.apply(this,r):r[0],o=t.cache;if(o.has(a))return o.get(a);var i=n.apply(this,r);return t.cache=o.set(a,i)||o,i};return t.cache=new(a.Cache||r),t}a.Cache=r,n.exports=a},function(n,e,t){var r=t(207);n.exports=function(n){return null==n?"":r(n)}},function(n,e,t){var r=t(14),a=t(208),o=t(5),i=t(40),s=r?r.prototype:void 0,c=s?s.toString:void 0;n.exports=function n(e){if("string"==typeof e)return e;if(o(e))return a(e,n)+"";if(i(e))return c?c.call(e):"";var t=e+"";return"0"==t&&1/e==-1/0?"-0":t}},function(n,e){n.exports=function(n,e){for(var t=-1,r=null==n?0:n.length,a=Array(r);++t<r;)a[t]=e(n[t],t,n);return a}},function(n,e,t){var r=t(210),a=t(211);n.exports=function(n,e){return null!=n&&a(n,e,r)}},function(n,e){n.exports=function(n,e){return null!=n&&e in Object(n)}},function(n,e,t){var r=t(85),a=t(33),o=t(5),i=t(78),s=t(38),c=t(22);n.exports=function(n,e,t){for(var l=-1,p=(e=r(e,n)).length,d=!1;++l<p;){var u=c(e[l]);if(!(d=null!=n&&t(n,u)))break;n=n[u]}return d||++l!=p?d:!!(p=null==n?0:n.length)&&s(p)&&i(u,p)&&(o(n)||a(n))}},function(n,e,t){var r=t(213),a=t(214),o=t(39),i=t(22);n.exports=function(n){return o(n)?r(i(n)):a(n)}},function(n,e){n.exports=function(n){return function(e){return null==e?void 0:e[n]}}},function(n,e,t){var r=t(84);n.exports=function(n){return function(e){return r(e,n)}}},function(n,e,t){var r=t(41),a=t(216),o=t(218);n.exports=function(n,e){return o(a(n,e,r),n+"")}},function(n,e,t){var r=t(217),a=Math.max;n.exports=function(n,e,t){return e=a(void 0===e?n.length-1:e,0),function(){for(var o=arguments,i=-1,s=a(o.length-e,0),c=Array(s);++i<s;)c[i]=o[e+i];i=-1;for(var l=Array(e+1);++i<e;)l[i]=o[i];return l[e]=t(c),r(n,this,l)}}},function(n,e){n.exports=function(n,e,t){switch(t.length){case 0:return n.call(e);case 1:return n.call(e,t[0]);case 2:return n.call(e,t[0],t[1]);case 3:return n.call(e,t[0],t[1],t[2])}return n.apply(e,t)}},function(n,e,t){var r=t(219),a=t(222)(r);n.exports=a},function(n,e,t){var r=t(220),a=t(221),o=t(41),i=a?function(n,e){return a(n,"toString",{configurable:!0,enumerable:!1,value:r(e),writable:!0})}:o;n.exports=i},function(n,e){n.exports=function(n){return function(){return n}}},function(n,e,t){var r=t(10),a=function(){try{var n=r(Object,"defineProperty");return n({},"",{}),n}catch(n){}}();n.exports=a},function(n,e){var t=Date.now;n.exports=function(n){var e=0,r=0;return function(){var a=t(),o=16-(a-r);if(r=a,o>0){if(++e>=800)return arguments[0]}else e=0;return n.apply(void 0,arguments)}}},function(n,e,t){var r=t(74),a=t(224),o=t(229),i=t(75),s=t(230),c=t(37);n.exports=function(n,e,t){var l=-1,p=a,d=n.length,u=!0,m=[],h=m;if(t)u=!1,p=o;else if(d>=200){var g=e?null:s(n);if(g)return c(g);u=!1,p=i,h=new r}else h=e?[]:m;n:for(;++l<d;){var f=n[l],v=e?e(f):f;if(f=t||0!==f?f:0,u&&v==v){for(var b=h.length;b--;)if(h[b]===v)continue n;e&&h.push(v),m.push(f)}else p(h,v,t)||(h!==m&&h.push(v),m.push(f))}return m}},function(n,e,t){var r=t(225);n.exports=function(n,e){return!!(null==n?0:n.length)&&r(n,e,0)>-1}},function(n,e,t){var r=t(226),a=t(227),o=t(228);n.exports=function(n,e,t){return e==e?o(n,e,t):r(n,a,t)}},function(n,e){n.exports=function(n,e,t,r){for(var a=n.length,o=t+(r?1:-1);r?o--:++o<a;)if(e(n[o],o,n))return o;return-1}},function(n,e){n.exports=function(n){return n!=n}},function(n,e){n.exports=function(n,e,t){for(var r=t-1,a=n.length;++r<a;)if(n[r]===e)return r;return-1}},function(n,e){n.exports=function(n,e,t){for(var r=-1,a=null==n?0:n.length;++r<a;)if(t(e,n[r]))return!0;return!1}},function(n,e,t){var r=t(81),a=t(231),o=t(37),i=r&&1/o(new r([,-0]))[1]==1/0?function(n){return new r(n)}:a;n.exports=i},function(n,e){n.exports=function(){}},function(n,e,t){var r=t(80),a=t(12);n.exports=function(n){return a(n)&&r(n)}},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(86)},function(n,e,t){"use strict";t(87)},function(n,e,t){},function(n,e,t){},function(n,e,t){"use strict";t(88)},function(n,e,t){"use strict";t(89)},function(n,e,t){"use strict";t(90)},function(n,e,t){"use strict";t(91)},function(n,e,t){"use strict";t.r(e);
/*!
 * Vue.js v2.7.8
 * (c) 2014-2022 Evan You
 * Released under the MIT License.
 */
var r=Object.freeze({}),a=Array.isArray;function o(n){return null==n}function i(n){return null!=n}function s(n){return!0===n}function c(n){return"string"==typeof n||"number"==typeof n||"symbol"==typeof n||"boolean"==typeof n}function l(n){return"function"==typeof n}function p(n){return null!==n&&"object"==typeof n}var d=Object.prototype.toString;function u(n){return"[object Object]"===d.call(n)}function m(n){return"[object RegExp]"===d.call(n)}function h(n){var e=parseFloat(String(n));return e>=0&&Math.floor(e)===e&&isFinite(n)}function g(n){return i(n)&&"function"==typeof n.then&&"function"==typeof n.catch}function f(n){return null==n?"":Array.isArray(n)||u(n)&&n.toString===d?JSON.stringify(n,null,2):String(n)}function v(n){var e=parseFloat(n);return isNaN(e)?n:e}function b(n,e){for(var t=Object.create(null),r=n.split(","),a=0;a<r.length;a++)t[r[a]]=!0;return e?function(n){return t[n.toLowerCase()]}:function(n){return t[n]}}b("slot,component",!0);var k=b("key,ref,slot,slot-scope,is");function y(n,e){if(n.length){var t=n.indexOf(e);if(t>-1)return n.splice(t,1)}}var E=Object.prototype.hasOwnProperty;function _(n,e){return E.call(n,e)}function x(n){var e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}var w=/-(\w)/g,A=x((function(n){return n.replace(w,(function(n,e){return e?e.toUpperCase():""}))})),C=x((function(n){return n.charAt(0).toUpperCase()+n.slice(1)})),B=/\B([A-Z])/g,T=x((function(n){return n.replace(B,"-$1").toLowerCase()}));var P=Function.prototype.bind?function(n,e){return n.bind(e)}:function(n,e){function t(t){var r=arguments.length;return r?r>1?n.apply(e,arguments):n.call(e,t):n.call(e)}return t._length=n.length,t};function I(n,e){e=e||0;for(var t=n.length-e,r=new Array(t);t--;)r[t]=n[t+e];return r}function S(n,e){for(var t in e)n[t]=e[t];return n}function z(n){for(var e={},t=0;t<n.length;t++)n[t]&&S(e,n[t]);return e}function D(n,e,t){}var O=function(n,e,t){return!1},j=function(n){return n};function q(n,e){if(n===e)return!0;var t=p(n),r=p(e);if(!t||!r)return!t&&!r&&String(n)===String(e);try{var a=Array.isArray(n),o=Array.isArray(e);if(a&&o)return n.length===e.length&&n.every((function(n,t){return q(n,e[t])}));if(n instanceof Date&&e instanceof Date)return n.getTime()===e.getTime();if(a||o)return!1;var i=Object.keys(n),s=Object.keys(e);return i.length===s.length&&i.every((function(t){return q(n[t],e[t])}))}catch(n){return!1}}function $(n,e){for(var t=0;t<n.length;t++)if(q(n[t],e))return t;return-1}function M(n){var e=!1;return function(){e||(e=!0,n.apply(this,arguments))}}function F(n,e){return n===e?0===n&&1/n!=1/e:n==n||e==e}var U=["component","directive","filter"],R=["beforeCreate","created","beforeMount","mounted","beforeUpdate","updated","beforeDestroy","destroyed","activated","deactivated","errorCaptured","serverPrefetch","renderTracked","renderTriggered"],L={optionMergeStrategies:Object.create(null),silent:!1,productionTip:!1,devtools:!1,performance:!1,errorHandler:null,warnHandler:null,ignoredElements:[],keyCodes:Object.create(null),isReservedTag:O,isReservedAttr:O,isUnknownElement:O,getTagNamespace:D,parsePlatformTagName:j,mustUseProp:O,async:!0,_lifecycleHooks:R},N=/a-zA-Z\u00B7\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u037D\u037F-\u1FFF\u200C-\u200D\u203F-\u2040\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD/;function G(n){var e=(n+"").charCodeAt(0);return 36===e||95===e}function K(n,e,t,r){Object.defineProperty(n,e,{value:t,enumerable:!!r,writable:!0,configurable:!0})}var V=new RegExp("[^".concat(N.source,".$_\\d]"));var H="__proto__"in{},Z="undefined"!=typeof window,W=Z&&window.navigator.userAgent.toLowerCase(),X=W&&/msie|trident/.test(W),Y=W&&W.indexOf("msie 9.0")>0,Q=W&&W.indexOf("edge/")>0;W&&W.indexOf("android");var J=W&&/iphone|ipad|ipod|ios/.test(W);W&&/chrome\/\d+/.test(W),W&&/phantomjs/.test(W);var nn,en=W&&W.match(/firefox\/(\d+)/),tn={}.watch,rn=!1;if(Z)try{var an={};Object.defineProperty(an,"passive",{get:function(){rn=!0}}),window.addEventListener("test-passive",null,an)}catch(n){}var on=function(){return void 0===nn&&(nn=!Z&&"undefined"!=typeof global&&(global.process&&"server"===global.process.env.VUE_ENV)),nn},sn=Z&&window.__VUE_DEVTOOLS_GLOBAL_HOOK__;function cn(n){return"function"==typeof n&&/native code/.test(n.toString())}var ln,pn="undefined"!=typeof Symbol&&cn(Symbol)&&"undefined"!=typeof Reflect&&cn(Reflect.ownKeys);ln="undefined"!=typeof Set&&cn(Set)?Set:function(){function n(){this.set=Object.create(null)}return n.prototype.has=function(n){return!0===this.set[n]},n.prototype.add=function(n){this.set[n]=!0},n.prototype.clear=function(){this.set=Object.create(null)},n}();var dn=null;function un(n){void 0===n&&(n=null),n||dn&&dn._scope.off(),dn=n,n&&n._scope.on()}var mn=function(){function n(n,e,t,r,a,o,i,s){this.tag=n,this.data=e,this.children=t,this.text=r,this.elm=a,this.ns=void 0,this.context=o,this.fnContext=void 0,this.fnOptions=void 0,this.fnScopeId=void 0,this.key=e&&e.key,this.componentOptions=i,this.componentInstance=void 0,this.parent=void 0,this.raw=!1,this.isStatic=!1,this.isRootInsert=!0,this.isComment=!1,this.isCloned=!1,this.isOnce=!1,this.asyncFactory=s,this.asyncMeta=void 0,this.isAsyncPlaceholder=!1}return Object.defineProperty(n.prototype,"child",{get:function(){return this.componentInstance},enumerable:!1,configurable:!0}),n}(),hn=function(n){void 0===n&&(n="");var e=new mn;return e.text=n,e.isComment=!0,e};function gn(n){return new mn(void 0,void 0,void 0,String(n))}function fn(n){var e=new mn(n.tag,n.data,n.children&&n.children.slice(),n.text,n.elm,n.context,n.componentOptions,n.asyncFactory);return e.ns=n.ns,e.isStatic=n.isStatic,e.key=n.key,e.isComment=n.isComment,e.fnContext=n.fnContext,e.fnOptions=n.fnOptions,e.fnScopeId=n.fnScopeId,e.asyncMeta=n.asyncMeta,e.isCloned=!0,e}var vn=0,bn=function(){function n(){this.id=vn++,this.subs=[]}return n.prototype.addSub=function(n){this.subs.push(n)},n.prototype.removeSub=function(n){y(this.subs,n)},n.prototype.depend=function(e){n.target&&n.target.addDep(this)},n.prototype.notify=function(n){var e=this.subs.slice();for(var t=0,r=e.length;t<r;t++){e[t].update()}},n}();bn.target=null;var kn=[];function yn(n){kn.push(n),bn.target=n}function En(){kn.pop(),bn.target=kn[kn.length-1]}var _n=Array.prototype,xn=Object.create(_n);["push","pop","shift","unshift","splice","sort","reverse"].forEach((function(n){var e=_n[n];K(xn,n,(function(){for(var t=[],r=0;r<arguments.length;r++)t[r]=arguments[r];var a,o=e.apply(this,t),i=this.__ob__;switch(n){case"push":case"unshift":a=t;break;case"splice":a=t.slice(2)}return a&&i.observeArray(a),i.dep.notify(),o}))}));var wn=Object.getOwnPropertyNames(xn),An={},Cn=!0;function Bn(n){Cn=n}var Tn={notify:D,depend:D,addSub:D,removeSub:D},Pn=function(){function n(n,e,t){if(void 0===e&&(e=!1),void 0===t&&(t=!1),this.value=n,this.shallow=e,this.mock=t,this.dep=t?Tn:new bn,this.vmCount=0,K(n,"__ob__",this),a(n)){if(!t)if(H)n.__proto__=xn;else for(var r=0,o=wn.length;r<o;r++){K(n,s=wn[r],xn[s])}e||this.observeArray(n)}else{var i=Object.keys(n);for(r=0;r<i.length;r++){var s;Sn(n,s=i[r],An,void 0,e,t)}}}return n.prototype.observeArray=function(n){for(var e=0,t=n.length;e<t;e++)In(n[e],!1,this.mock)},n}();function In(n,e,t){var r;if(!(!p(n)||Mn(n)||n instanceof mn))return _(n,"__ob__")&&n.__ob__ instanceof Pn?r=n.__ob__:!Cn||!t&&on()||!a(n)&&!u(n)||!Object.isExtensible(n)||n.__v_skip||(r=new Pn(n,e,t)),r}function Sn(n,e,t,r,o,i){var s=new bn,c=Object.getOwnPropertyDescriptor(n,e);if(!c||!1!==c.configurable){var l=c&&c.get,p=c&&c.set;l&&!p||t!==An&&2!==arguments.length||(t=n[e]);var d=!o&&In(t,!1,i);return Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){var e=l?l.call(n):t;return bn.target&&(s.depend(),d&&(d.dep.depend(),a(e)&&On(e))),Mn(e)&&!o?e.value:e},set:function(e){var r=l?l.call(n):t;if(F(r,e)){if(p)p.call(n,e);else{if(l)return;if(!o&&Mn(r)&&!Mn(e))return void(r.value=e);t=e}d=!o&&In(e,!1,i),s.notify()}}}),s}}function zn(n,e,t){if(!$n(n)){var r=n.__ob__;return a(n)&&h(e)?(n.length=Math.max(n.length,e),n.splice(e,1,t),r&&!r.shallow&&r.mock&&In(t,!1,!0),t):e in n&&!(e in Object.prototype)?(n[e]=t,t):n._isVue||r&&r.vmCount?t:r?(Sn(r.value,e,t,void 0,r.shallow,r.mock),r.dep.notify(),t):(n[e]=t,t)}}function Dn(n,e){if(a(n)&&h(e))n.splice(e,1);else{var t=n.__ob__;n._isVue||t&&t.vmCount||$n(n)||_(n,e)&&(delete n[e],t&&t.dep.notify())}}function On(n){for(var e=void 0,t=0,r=n.length;t<r;t++)(e=n[t])&&e.__ob__&&e.__ob__.dep.depend(),a(e)&&On(e)}function jn(n){return qn(n,!0),K(n,"__v_isShallow",!0),n}function qn(n,e){if(!$n(n)){In(n,e,on());0}}function $n(n){return!(!n||!n.__v_isReadonly)}function Mn(n){return!(!n||!0!==n.__v_isRef)}function Fn(n,e,t){Object.defineProperty(n,t,{enumerable:!0,configurable:!0,get:function(){var n=e[t];if(Mn(n))return n.value;var r=n&&n.__ob__;return r&&r.dep.depend(),n},set:function(n){var r=e[t];Mn(r)&&!Mn(n)?r.value=n:e[t]=n}})}"".concat("watcher"," callback"),"".concat("watcher"," getter"),"".concat("watcher"," cleanup");var Un;var Rn=function(){function n(n){void 0===n&&(n=!1),this.active=!0,this.effects=[],this.cleanups=[],!n&&Un&&(this.parent=Un,this.index=(Un.scopes||(Un.scopes=[])).push(this)-1)}return n.prototype.run=function(n){if(this.active){var e=Un;try{return Un=this,n()}finally{Un=e}}else 0},n.prototype.on=function(){Un=this},n.prototype.off=function(){Un=this.parent},n.prototype.stop=function(n){if(this.active){var e=void 0,t=void 0;for(e=0,t=this.effects.length;e<t;e++)this.effects[e].teardown();for(e=0,t=this.cleanups.length;e<t;e++)this.cleanups[e]();if(this.scopes)for(e=0,t=this.scopes.length;e<t;e++)this.scopes[e].stop(!0);if(this.parent&&!n){var r=this.parent.scopes.pop();r&&r!==this&&(this.parent.scopes[this.index]=r,r.index=this.index)}this.active=!1}},n}();function Ln(n){var e=n._provided,t=n.$parent&&n.$parent._provided;return t===e?n._provided=Object.create(t):e}var Nn=x((function(n){var e="&"===n.charAt(0),t="~"===(n=e?n.slice(1):n).charAt(0),r="!"===(n=t?n.slice(1):n).charAt(0);return{name:n=r?n.slice(1):n,once:t,capture:r,passive:e}}));function Gn(n,e){function t(){var n=t.fns;if(!a(n))return Ce(n,null,arguments,e,"v-on handler");for(var r=n.slice(),o=0;o<r.length;o++)Ce(r[o],null,arguments,e,"v-on handler")}return t.fns=n,t}function Kn(n,e,t,r,a,i){var c,l,p,d;for(c in n)l=n[c],p=e[c],d=Nn(c),o(l)||(o(p)?(o(l.fns)&&(l=n[c]=Gn(l,i)),s(d.once)&&(l=n[c]=a(d.name,l,d.capture)),t(d.name,l,d.capture,d.passive,d.params)):l!==p&&(p.fns=l,n[c]=p));for(c in e)o(n[c])&&r((d=Nn(c)).name,e[c],d.capture)}function Vn(n,e,t){var r;n instanceof mn&&(n=n.data.hook||(n.data.hook={}));var a=n[e];function c(){t.apply(this,arguments),y(r.fns,c)}o(a)?r=Gn([c]):i(a.fns)&&s(a.merged)?(r=a).fns.push(c):r=Gn([a,c]),r.merged=!0,n[e]=r}function Hn(n,e,t,r,a){if(i(e)){if(_(e,t))return n[t]=e[t],a||delete e[t],!0;if(_(e,r))return n[t]=e[r],a||delete e[r],!0}return!1}function Zn(n){return c(n)?[gn(n)]:a(n)?function n(e,t){var r,l,p,d,u=[];for(r=0;r<e.length;r++)o(l=e[r])||"boolean"==typeof l||(p=u.length-1,d=u[p],a(l)?l.length>0&&(Wn((l=n(l,"".concat(t||"","_").concat(r)))[0])&&Wn(d)&&(u[p]=gn(d.text+l[0].text),l.shift()),u.push.apply(u,l)):c(l)?Wn(d)?u[p]=gn(d.text+l):""!==l&&u.push(gn(l)):Wn(l)&&Wn(d)?u[p]=gn(d.text+l.text):(s(e._isVList)&&i(l.tag)&&o(l.key)&&i(t)&&(l.key="__vlist".concat(t,"_").concat(r,"__")),u.push(l)));return u}(n):void 0}function Wn(n){return i(n)&&i(n.text)&&!1===n.isComment}function Xn(n,e){var t,r,o,s,c=null;if(a(n)||"string"==typeof n)for(c=new Array(n.length),t=0,r=n.length;t<r;t++)c[t]=e(n[t],t);else if("number"==typeof n)for(c=new Array(n),t=0;t<n;t++)c[t]=e(t+1,t);else if(p(n))if(pn&&n[Symbol.iterator]){c=[];for(var l=n[Symbol.iterator](),d=l.next();!d.done;)c.push(e(d.value,c.length)),d=l.next()}else for(o=Object.keys(n),c=new Array(o.length),t=0,r=o.length;t<r;t++)s=o[t],c[t]=e(n[s],s,t);return i(c)||(c=[]),c._isVList=!0,c}function Yn(n,e,t,r){var a,o=this.$scopedSlots[n];o?(t=t||{},r&&(t=S(S({},r),t)),a=o(t)||(l(e)?e():e)):a=this.$slots[n]||(l(e)?e():e);var i=t&&t.slot;return i?this.$createElement("template",{slot:i},a):a}function Qn(n){return Pt(this.$options,"filters",n,!0)||j}function Jn(n,e){return a(n)?-1===n.indexOf(e):n!==e}function ne(n,e,t,r,a){var o=L.keyCodes[e]||t;return a&&r&&!L.keyCodes[e]?Jn(a,r):o?Jn(o,n):r?T(r)!==e:void 0===n}function ee(n,e,t,r,o){if(t)if(p(t)){a(t)&&(t=z(t));var i=void 0,s=function(a){if("class"===a||"style"===a||k(a))i=n;else{var s=n.attrs&&n.attrs.type;i=r||L.mustUseProp(e,s,a)?n.domProps||(n.domProps={}):n.attrs||(n.attrs={})}var c=A(a),l=T(a);c in i||l in i||(i[a]=t[a],o&&((n.on||(n.on={}))["update:".concat(a)]=function(n){t[a]=n}))};for(var c in t)s(c)}else;return n}function te(n,e){var t=this._staticTrees||(this._staticTrees=[]),r=t[n];return r&&!e||ae(r=t[n]=this.$options.staticRenderFns[n].call(this._renderProxy,this._c,this),"__static__".concat(n),!1),r}function re(n,e,t){return ae(n,"__once__".concat(e).concat(t?"_".concat(t):""),!0),n}function ae(n,e,t){if(a(n))for(var r=0;r<n.length;r++)n[r]&&"string"!=typeof n[r]&&oe(n[r],"".concat(e,"_").concat(r),t);else oe(n,e,t)}function oe(n,e,t){n.isStatic=!0,n.key=e,n.isOnce=t}function ie(n,e){if(e)if(u(e)){var t=n.on=n.on?S({},n.on):{};for(var r in e){var a=t[r],o=e[r];t[r]=a?[].concat(a,o):o}}else;return n}function se(n,e,t,r){e=e||{$stable:!t};for(var o=0;o<n.length;o++){var i=n[o];a(i)?se(i,e,t):i&&(i.proxy&&(i.fn.proxy=!0),e[i.key]=i.fn)}return r&&(e.$key=r),e}function ce(n,e){for(var t=0;t<e.length;t+=2){var r=e[t];"string"==typeof r&&r&&(n[e[t]]=e[t+1])}return n}function le(n,e){return"string"==typeof n?e+n:n}function pe(n){n._o=re,n._n=v,n._s=f,n._l=Xn,n._t=Yn,n._q=q,n._i=$,n._m=te,n._f=Qn,n._k=ne,n._b=ee,n._v=gn,n._e=hn,n._u=se,n._g=ie,n._d=ce,n._p=le}function de(n,e){if(!n||!n.length)return{};for(var t={},r=0,a=n.length;r<a;r++){var o=n[r],i=o.data;if(i&&i.attrs&&i.attrs.slot&&delete i.attrs.slot,o.context!==e&&o.fnContext!==e||!i||null==i.slot)(t.default||(t.default=[])).push(o);else{var s=i.slot,c=t[s]||(t[s]=[]);"template"===o.tag?c.push.apply(c,o.children||[]):c.push(o)}}for(var l in t)t[l].every(ue)&&delete t[l];return t}function ue(n){return n.isComment&&!n.asyncFactory||" "===n.text}function me(n){return n.isComment&&n.asyncFactory}function he(n,e,t,a){var o,i=Object.keys(t).length>0,s=e?!!e.$stable:!i,c=e&&e.$key;if(e){if(e._normalized)return e._normalized;if(s&&a&&a!==r&&c===a.$key&&!i&&!a.$hasNormal)return a;for(var l in o={},e)e[l]&&"$"!==l[0]&&(o[l]=ge(n,t,l,e[l]))}else o={};for(var p in t)p in o||(o[p]=fe(t,p));return e&&Object.isExtensible(e)&&(e._normalized=o),K(o,"$stable",s),K(o,"$key",c),K(o,"$hasNormal",i),o}function ge(n,e,t,r){var o=function(){var e=dn;un(n);var t=arguments.length?r.apply(null,arguments):r({}),o=(t=t&&"object"==typeof t&&!a(t)?[t]:Zn(t))&&t[0];return un(e),t&&(!o||1===t.length&&o.isComment&&!me(o))?void 0:t};return r.proxy&&Object.defineProperty(e,t,{get:o,enumerable:!0,configurable:!0}),o}function fe(n,e){return function(){return n[e]}}function ve(n){return{get attrs(){if(!n._attrsProxy){var e=n._attrsProxy={};K(e,"_v_attr_proxy",!0),be(e,n.$attrs,r,n,"$attrs")}return n._attrsProxy},get listeners(){n._listenersProxy||be(n._listenersProxy={},n.$listeners,r,n,"$listeners");return n._listenersProxy},get slots(){return function(n){n._slotsProxy||ye(n._slotsProxy={},n.$scopedSlots);return n._slotsProxy}(n)},emit:P(n.$emit,n),expose:function(e){e&&Object.keys(e).forEach((function(t){return Fn(n,e,t)}))}}}function be(n,e,t,r,a){var o=!1;for(var i in e)i in n?e[i]!==t[i]&&(o=!0):(o=!0,ke(n,i,r,a));for(var i in n)i in e||(o=!0,delete n[i]);return o}function ke(n,e,t,r){Object.defineProperty(n,e,{enumerable:!0,configurable:!0,get:function(){return t[r][e]}})}function ye(n,e){for(var t in e)n[t]=e[t];for(var t in n)t in e||delete n[t]}var Ee=null;function _e(n,e){return(n.__esModule||pn&&"Module"===n[Symbol.toStringTag])&&(n=n.default),p(n)?e.extend(n):n}function xe(n){if(a(n))for(var e=0;e<n.length;e++){var t=n[e];if(i(t)&&(i(t.componentOptions)||me(t)))return t}}function we(n,e,t,r,d,u){return(a(t)||c(t))&&(d=r,r=t,t=void 0),s(u)&&(d=2),function(n,e,t,r,c){if(i(t)&&i(t.__ob__))return hn();i(t)&&i(t.is)&&(e=t.is);if(!e)return hn();0;a(r)&&l(r[0])&&((t=t||{}).scopedSlots={default:r[0]},r.length=0);2===c?r=Zn(r):1===c&&(r=function(n){for(var e=0;e<n.length;e++)if(a(n[e]))return Array.prototype.concat.apply([],n);return n}(r));var d,u;if("string"==typeof e){var m=void 0;u=n.$vnode&&n.$vnode.ns||L.getTagNamespace(e),d=L.isReservedTag(e)?new mn(L.parsePlatformTagName(e),t,r,void 0,void 0,n):t&&t.pre||!i(m=Pt(n.$options,"components",e))?new mn(e,t,r,void 0,void 0,n):kt(m,t,n,r,e)}else d=kt(e,t,n,r);return a(d)?d:i(d)?(i(u)&&function n(e,t,r){e.ns=t,"foreignObject"===e.tag&&(t=void 0,r=!0);if(i(e.children))for(var a=0,c=e.children.length;a<c;a++){var l=e.children[a];i(l.tag)&&(o(l.ns)||s(r)&&"svg"!==l.tag)&&n(l,t,r)}}(d,u),i(t)&&function(n){p(n.style)&&Re(n.style);p(n.class)&&Re(n.class)}(t),d):hn()}(n,e,t,r,d)}function Ae(n,e,t){yn();try{if(e)for(var r=e;r=r.$parent;){var a=r.$options.errorCaptured;if(a)for(var o=0;o<a.length;o++)try{if(!1===a[o].call(r,n,e,t))return}catch(n){Be(n,r,"errorCaptured hook")}}Be(n,e,t)}finally{En()}}function Ce(n,e,t,r,a){var o;try{(o=t?n.apply(e,t):n.call(e))&&!o._isVue&&g(o)&&!o._handled&&(o.catch((function(n){return Ae(n,r,a+" (Promise/async)")})),o._handled=!0)}catch(n){Ae(n,r,a)}return o}function Be(n,e,t){if(L.errorHandler)try{return L.errorHandler.call(null,n,e,t)}catch(e){e!==n&&Te(e,null,"config.errorHandler")}Te(n,e,t)}function Te(n,e,t){if(!Z||"undefined"==typeof console)throw n;console.error(n)}var Pe,Ie=!1,Se=[],ze=!1;function De(){ze=!1;var n=Se.slice(0);Se.length=0;for(var e=0;e<n.length;e++)n[e]()}if("undefined"!=typeof Promise&&cn(Promise)){var Oe=Promise.resolve();Pe=function(){Oe.then(De),J&&setTimeout(D)},Ie=!0}else if(X||"undefined"==typeof MutationObserver||!cn(MutationObserver)&&"[object MutationObserverConstructor]"!==MutationObserver.toString())Pe="undefined"!=typeof setImmediate&&cn(setImmediate)?function(){setImmediate(De)}:function(){setTimeout(De,0)};else{var je=1,qe=new MutationObserver(De),$e=document.createTextNode(String(je));qe.observe($e,{characterData:!0}),Pe=function(){je=(je+1)%2,$e.data=String(je)},Ie=!0}function Me(n,e){var t;if(Se.push((function(){if(n)try{n.call(e)}catch(n){Ae(n,e,"nextTick")}else t&&t(e)})),ze||(ze=!0,Pe()),!n&&"undefined"!=typeof Promise)return new Promise((function(n){t=n}))}function Fe(n){return function(e,t){if(void 0===t&&(t=dn),t)return function(n,e,t){var r=n.$options;r[e]=At(r[e],t)}(t,n,e)}}Fe("beforeMount"),Fe("mounted"),Fe("beforeUpdate"),Fe("updated"),Fe("beforeDestroy"),Fe("destroyed"),Fe("errorCaptured"),Fe("activated"),Fe("deactivated"),Fe("serverPrefetch"),Fe("renderTracked"),Fe("renderTriggered");var Ue=new ln;function Re(n){return function n(e,t){var r,o,i=a(e);if(!i&&!p(e)||Object.isFrozen(e)||e instanceof mn)return;if(e.__ob__){var s=e.__ob__.dep.id;if(t.has(s))return;t.add(s)}if(i)for(r=e.length;r--;)n(e[r],t);else if(Mn(e))n(e.value,t);else for(o=Object.keys(e),r=o.length;r--;)n(e[o[r]],t)}(n,Ue),Ue.clear(),n}var Le,Ne=0,Ge=function(){function n(n,e,t,r,a){var o,i;o=this,void 0===(i=Un||(n?n._scope:void 0))&&(i=Un),i&&i.active&&i.effects.push(o),(this.vm=n)&&a&&(n._watcher=this),r?(this.deep=!!r.deep,this.user=!!r.user,this.lazy=!!r.lazy,this.sync=!!r.sync,this.before=r.before):this.deep=this.user=this.lazy=this.sync=!1,this.cb=t,this.id=++Ne,this.active=!0,this.post=!1,this.dirty=this.lazy,this.deps=[],this.newDeps=[],this.depIds=new ln,this.newDepIds=new ln,this.expression="",l(e)?this.getter=e:(this.getter=function(n){if(!V.test(n)){var e=n.split(".");return function(n){for(var t=0;t<e.length;t++){if(!n)return;n=n[e[t]]}return n}}}(e),this.getter||(this.getter=D)),this.value=this.lazy?void 0:this.get()}return n.prototype.get=function(){var n;yn(this);var e=this.vm;try{n=this.getter.call(e,e)}catch(n){if(!this.user)throw n;Ae(n,e,'getter for watcher "'.concat(this.expression,'"'))}finally{this.deep&&Re(n),En(),this.cleanupDeps()}return n},n.prototype.addDep=function(n){var e=n.id;this.newDepIds.has(e)||(this.newDepIds.add(e),this.newDeps.push(n),this.depIds.has(e)||n.addSub(this))},n.prototype.cleanupDeps=function(){for(var n=this.deps.length;n--;){var e=this.deps[n];this.newDepIds.has(e.id)||e.removeSub(this)}var t=this.depIds;this.depIds=this.newDepIds,this.newDepIds=t,this.newDepIds.clear(),t=this.deps,this.deps=this.newDeps,this.newDeps=t,this.newDeps.length=0},n.prototype.update=function(){this.lazy?this.dirty=!0:this.sync?this.run():dt(this)},n.prototype.run=function(){if(this.active){var n=this.get();if(n!==this.value||p(n)||this.deep){var e=this.value;if(this.value=n,this.user){var t='callback for watcher "'.concat(this.expression,'"');Ce(this.cb,this.vm,[n,e],this.vm,t)}else this.cb.call(this.vm,n,e)}}},n.prototype.evaluate=function(){this.value=this.get(),this.dirty=!1},n.prototype.depend=function(){for(var n=this.deps.length;n--;)this.deps[n].depend()},n.prototype.teardown=function(){if(this.vm&&!this.vm._isBeingDestroyed&&y(this.vm._scope.effects,this),this.active){for(var n=this.deps.length;n--;)this.deps[n].removeSub(this);this.active=!1,this.onStop&&this.onStop()}},n}();function Ke(n,e){Le.$on(n,e)}function Ve(n,e){Le.$off(n,e)}function He(n,e){var t=Le;return function r(){var a=e.apply(null,arguments);null!==a&&t.$off(n,r)}}function Ze(n,e,t){Le=n,Kn(e,t||{},Ke,Ve,He,n),Le=void 0}var We=null;function Xe(n){var e=We;return We=n,function(){We=e}}function Ye(n){for(;n&&(n=n.$parent);)if(n._inactive)return!0;return!1}function Qe(n,e){if(e){if(n._directInactive=!1,Ye(n))return}else if(n._directInactive)return;if(n._inactive||null===n._inactive){n._inactive=!1;for(var t=0;t<n.$children.length;t++)Qe(n.$children[t]);Je(n,"activated")}}function Je(n,e,t,r){void 0===r&&(r=!0),yn();var a=dn;r&&un(n);var o=n.$options[e],i="".concat(e," hook");if(o)for(var s=0,c=o.length;s<c;s++)Ce(o[s],n,t||null,n,i);n._hasHookEvent&&n.$emit("hook:"+e),r&&un(a),En()}var nt=[],et=[],tt={},rt=!1,at=!1,ot=0;var it=0,st=Date.now;if(Z&&!X){var ct=window.performance;ct&&"function"==typeof ct.now&&st()>document.createEvent("Event").timeStamp&&(st=function(){return ct.now()})}var lt=function(n,e){if(n.post){if(!e.post)return 1}else if(e.post)return-1;return n.id-e.id};function pt(){var n,e;for(it=st(),at=!0,nt.sort(lt),ot=0;ot<nt.length;ot++)(n=nt[ot]).before&&n.before(),e=n.id,tt[e]=null,n.run();var t=et.slice(),r=nt.slice();ot=nt.length=et.length=0,tt={},rt=at=!1,function(n){for(var e=0;e<n.length;e++)n[e]._inactive=!0,Qe(n[e],!0)}(t),function(n){var e=n.length;for(;e--;){var t=n[e],r=t.vm;r&&r._watcher===t&&r._isMounted&&!r._isDestroyed&&Je(r,"updated")}}(r),sn&&L.devtools&&sn.emit("flush")}function dt(n){var e=n.id;if(null==tt[e]&&(n!==bn.target||!n.noRecurse)){if(tt[e]=!0,at){for(var t=nt.length-1;t>ot&&nt[t].id>n.id;)t--;nt.splice(t+1,0,n)}else nt.push(n);rt||(rt=!0,Me(pt))}}function ut(n,e){if(n){for(var t=Object.create(null),r=pn?Reflect.ownKeys(n):Object.keys(n),a=0;a<r.length;a++){var o=r[a];if("__ob__"!==o){var i=n[o].from;if(i in e._provided)t[o]=e._provided[i];else if("default"in n[o]){var s=n[o].default;t[o]=l(s)?s.call(e):s}else 0}}return t}}function mt(n,e,t,o,i){var c,l=this,p=i.options;_(o,"_uid")?(c=Object.create(o))._original=o:(c=o,o=o._original);var d=s(p._compiled),u=!d;this.data=n,this.props=e,this.children=t,this.parent=o,this.listeners=n.on||r,this.injections=ut(p.inject,o),this.slots=function(){return l.$slots||he(o,n.scopedSlots,l.$slots=de(t,o)),l.$slots},Object.defineProperty(this,"scopedSlots",{enumerable:!0,get:function(){return he(o,n.scopedSlots,this.slots())}}),d&&(this.$options=p,this.$slots=this.slots(),this.$scopedSlots=he(o,n.scopedSlots,this.$slots)),p._scopeId?this._c=function(n,e,t,r){var i=we(c,n,e,t,r,u);return i&&!a(i)&&(i.fnScopeId=p._scopeId,i.fnContext=o),i}:this._c=function(n,e,t,r){return we(c,n,e,t,r,u)}}function ht(n,e,t,r,a){var o=fn(n);return o.fnContext=t,o.fnOptions=r,e.slot&&((o.data||(o.data={})).slot=e.slot),o}function gt(n,e){for(var t in e)n[A(t)]=e[t]}function ft(n){return n.name||n.__name||n._componentTag}pe(mt.prototype);var vt={init:function(n,e){if(n.componentInstance&&!n.componentInstance._isDestroyed&&n.data.keepAlive){var t=n;vt.prepatch(t,t)}else{(n.componentInstance=function(n,e){var t={_isComponent:!0,_parentVnode:n,parent:e},r=n.data.inlineTemplate;i(r)&&(t.render=r.render,t.staticRenderFns=r.staticRenderFns);return new n.componentOptions.Ctor(t)}(n,We)).$mount(e?n.elm:void 0,e)}},prepatch:function(n,e){var t=e.componentOptions;!function(n,e,t,a,o){var i=a.data.scopedSlots,s=n.$scopedSlots,c=!!(i&&!i.$stable||s!==r&&!s.$stable||i&&n.$scopedSlots.$key!==i.$key||!i&&n.$scopedSlots.$key),l=!!(o||n.$options._renderChildren||c),p=n.$vnode;n.$options._parentVnode=a,n.$vnode=a,n._vnode&&(n._vnode.parent=a),n.$options._renderChildren=o;var d=a.data.attrs||r;n._attrsProxy&&be(n._attrsProxy,d,p.data&&p.data.attrs||r,n,"$attrs")&&(l=!0),n.$attrs=d,t=t||r;var u=n.$options._parentListeners;if(n._listenersProxy&&be(n._listenersProxy,t,u||r,n,"$listeners"),n.$listeners=n.$options._parentListeners=t,Ze(n,t,u),e&&n.$options.props){Bn(!1);for(var m=n._props,h=n.$options._propKeys||[],g=0;g<h.length;g++){var f=h[g],v=n.$options.props;m[f]=It(f,v,e,n)}Bn(!0),n.$options.propsData=e}l&&(n.$slots=de(o,a.context),n.$forceUpdate())}(e.componentInstance=n.componentInstance,t.propsData,t.listeners,e,t.children)},insert:function(n){var e,t=n.context,r=n.componentInstance;r._isMounted||(r._isMounted=!0,Je(r,"mounted")),n.data.keepAlive&&(t._isMounted?((e=r)._inactive=!1,et.push(e)):Qe(r,!0))},destroy:function(n){var e=n.componentInstance;e._isDestroyed||(n.data.keepAlive?function n(e,t){if(!(t&&(e._directInactive=!0,Ye(e))||e._inactive)){e._inactive=!0;for(var r=0;r<e.$children.length;r++)n(e.$children[r]);Je(e,"deactivated")}}(e,!0):e.$destroy())}},bt=Object.keys(vt);function kt(n,e,t,c,l){if(!o(n)){var d=t.$options._base;if(p(n)&&(n=d.extend(n)),"function"==typeof n){var u;if(o(n.cid)&&void 0===(n=function(n,e){if(s(n.error)&&i(n.errorComp))return n.errorComp;if(i(n.resolved))return n.resolved;var t=Ee;if(t&&i(n.owners)&&-1===n.owners.indexOf(t)&&n.owners.push(t),s(n.loading)&&i(n.loadingComp))return n.loadingComp;if(t&&!i(n.owners)){var r=n.owners=[t],a=!0,c=null,l=null;t.$on("hook:destroyed",(function(){return y(r,t)}));var d=function(n){for(var e=0,t=r.length;e<t;e++)r[e].$forceUpdate();n&&(r.length=0,null!==c&&(clearTimeout(c),c=null),null!==l&&(clearTimeout(l),l=null))},u=M((function(t){n.resolved=_e(t,e),a?r.length=0:d(!0)})),m=M((function(e){i(n.errorComp)&&(n.error=!0,d(!0))})),h=n(u,m);return p(h)&&(g(h)?o(n.resolved)&&h.then(u,m):g(h.component)&&(h.component.then(u,m),i(h.error)&&(n.errorComp=_e(h.error,e)),i(h.loading)&&(n.loadingComp=_e(h.loading,e),0===h.delay?n.loading=!0:c=setTimeout((function(){c=null,o(n.resolved)&&o(n.error)&&(n.loading=!0,d(!1))}),h.delay||200)),i(h.timeout)&&(l=setTimeout((function(){l=null,o(n.resolved)&&m(null)}),h.timeout)))),a=!1,n.loading?n.loadingComp:n.resolved}}(u=n,d)))return function(n,e,t,r,a){var o=hn();return o.asyncFactory=n,o.asyncMeta={data:e,context:t,children:r,tag:a},o}(u,e,t,c,l);e=e||{},Gt(n),i(e.model)&&function(n,e){var t=n.model&&n.model.prop||"value",r=n.model&&n.model.event||"input";(e.attrs||(e.attrs={}))[t]=e.model.value;var o=e.on||(e.on={}),s=o[r],c=e.model.callback;i(s)?(a(s)?-1===s.indexOf(c):s!==c)&&(o[r]=[c].concat(s)):o[r]=c}(n.options,e);var m=function(n,e,t){var r=e.options.props;if(!o(r)){var a={},s=n.attrs,c=n.props;if(i(s)||i(c))for(var l in r){var p=T(l);Hn(a,c,l,p,!0)||Hn(a,s,l,p,!1)}return a}}(e,n);if(s(n.options.functional))return function(n,e,t,o,s){var c=n.options,l={},p=c.props;if(i(p))for(var d in p)l[d]=It(d,p,e||r);else i(t.attrs)&&gt(l,t.attrs),i(t.props)&&gt(l,t.props);var u=new mt(t,l,s,o,n),m=c.render.call(null,u._c,u);if(m instanceof mn)return ht(m,t,u.parent,c,u);if(a(m)){for(var h=Zn(m)||[],g=new Array(h.length),f=0;f<h.length;f++)g[f]=ht(h[f],t,u.parent,c,u);return g}}(n,m,e,t,c);var h=e.on;if(e.on=e.nativeOn,s(n.options.abstract)){var f=e.slot;e={},f&&(e.slot=f)}!function(n){for(var e=n.hook||(n.hook={}),t=0;t<bt.length;t++){var r=bt[t],a=e[r],o=vt[r];a===o||a&&a._merged||(e[r]=a?yt(o,a):o)}}(e);var v=ft(n.options)||l;return new mn("vue-component-".concat(n.cid).concat(v?"-".concat(v):""),e,void 0,void 0,void 0,t,{Ctor:n,propsData:m,listeners:h,tag:l,children:c},u)}}}function yt(n,e){var t=function(t,r){n(t,r),e(t,r)};return t._merged=!0,t}var Et=D,_t=L.optionMergeStrategies;function xt(n,e){if(!e)return n;for(var t,r,a,o=pn?Reflect.ownKeys(e):Object.keys(e),i=0;i<o.length;i++)"__ob__"!==(t=o[i])&&(r=n[t],a=e[t],_(n,t)?r!==a&&u(r)&&u(a)&&xt(r,a):zn(n,t,a));return n}function wt(n,e,t){return t?function(){var r=l(e)?e.call(t,t):e,a=l(n)?n.call(t,t):n;return r?xt(r,a):a}:e?n?function(){return xt(l(e)?e.call(this,this):e,l(n)?n.call(this,this):n)}:e:n}function At(n,e){var t=e?n?n.concat(e):a(e)?e:[e]:n;return t?function(n){for(var e=[],t=0;t<n.length;t++)-1===e.indexOf(n[t])&&e.push(n[t]);return e}(t):t}function Ct(n,e,t,r){var a=Object.create(n||null);return e?S(a,e):a}_t.data=function(n,e,t){return t?wt(n,e,t):e&&"function"!=typeof e?n:wt(n,e)},R.forEach((function(n){_t[n]=At})),U.forEach((function(n){_t[n+"s"]=Ct})),_t.watch=function(n,e,t,r){if(n===tn&&(n=void 0),e===tn&&(e=void 0),!e)return Object.create(n||null);if(!n)return e;var o={};for(var i in S(o,n),e){var s=o[i],c=e[i];s&&!a(s)&&(s=[s]),o[i]=s?s.concat(c):a(c)?c:[c]}return o},_t.props=_t.methods=_t.inject=_t.computed=function(n,e,t,r){if(!n)return e;var a=Object.create(null);return S(a,n),e&&S(a,e),a},_t.provide=wt;var Bt=function(n,e){return void 0===e?n:e};function Tt(n,e,t){if(l(e)&&(e=e.options),function(n,e){var t=n.props;if(t){var r,o,i={};if(a(t))for(r=t.length;r--;)"string"==typeof(o=t[r])&&(i[A(o)]={type:null});else if(u(t))for(var s in t)o=t[s],i[A(s)]=u(o)?o:{type:o};else 0;n.props=i}}(e),function(n,e){var t=n.inject;if(t){var r=n.inject={};if(a(t))for(var o=0;o<t.length;o++)r[t[o]]={from:t[o]};else if(u(t))for(var i in t){var s=t[i];r[i]=u(s)?S({from:i},s):{from:s}}else 0}}(e),function(n){var e=n.directives;if(e)for(var t in e){var r=e[t];l(r)&&(e[t]={bind:r,update:r})}}(e),!e._base&&(e.extends&&(n=Tt(n,e.extends,t)),e.mixins))for(var r=0,o=e.mixins.length;r<o;r++)n=Tt(n,e.mixins[r],t);var i,s={};for(i in n)c(i);for(i in e)_(n,i)||c(i);function c(r){var a=_t[r]||Bt;s[r]=a(n[r],e[r],t,r)}return s}function Pt(n,e,t,r){if("string"==typeof t){var a=n[e];if(_(a,t))return a[t];var o=A(t);if(_(a,o))return a[o];var i=C(o);return _(a,i)?a[i]:a[t]||a[o]||a[i]}}function It(n,e,t,r){var a=e[n],o=!_(t,n),i=t[n],s=Ot(Boolean,a.type);if(s>-1)if(o&&!_(a,"default"))i=!1;else if(""===i||i===T(n)){var c=Ot(String,a.type);(c<0||s<c)&&(i=!0)}if(void 0===i){i=function(n,e,t){if(!_(e,"default"))return;var r=e.default;0;if(n&&n.$options.propsData&&void 0===n.$options.propsData[t]&&void 0!==n._props[t])return n._props[t];return l(r)&&"Function"!==zt(e.type)?r.call(n):r}(r,a,n);var p=Cn;Bn(!0),In(i),Bn(p)}return i}var St=/^\s*function (\w+)/;function zt(n){var e=n&&n.toString().match(St);return e?e[1]:""}function Dt(n,e){return zt(n)===zt(e)}function Ot(n,e){if(!a(e))return Dt(e,n)?0:-1;for(var t=0,r=e.length;t<r;t++)if(Dt(e[t],n))return t;return-1}var jt={enumerable:!0,configurable:!0,get:D,set:D};function qt(n,e,t){jt.get=function(){return this[e][t]},jt.set=function(n){this[e][t]=n},Object.defineProperty(n,t,jt)}function $t(n){var e=n.$options;if(e.props&&function(n,e){var t=n.$options.propsData||{},r=n._props=jn({}),a=n.$options._propKeys=[];n.$parent&&Bn(!1);var o=function(o){a.push(o);var i=It(o,e,t,n);Sn(r,o,i),o in n||qt(n,"_props",o)};for(var i in e)o(i);Bn(!0)}(n,e.props),function(n){var e=n.$options,t=e.setup;if(t){var r=n._setupContext=ve(n);un(n),yn();var a=Ce(t,null,[n._props||jn({}),r],n,"setup");if(En(),un(),l(a))e.render=a;else if(p(a))if(n._setupState=a,a.__sfc){var o=n._setupProxy={};for(var i in a)"__sfc"!==i&&Fn(o,a,i)}else for(var i in a)G(i)||Fn(n,a,i);else 0}}(n),e.methods&&function(n,e){n.$options.props;for(var t in e)n[t]="function"!=typeof e[t]?D:P(e[t],n)}(n,e.methods),e.data)!function(n){var e=n.$options.data;u(e=n._data=l(e)?function(n,e){yn();try{return n.call(e,e)}catch(n){return Ae(n,e,"data()"),{}}finally{En()}}(e,n):e||{})||(e={});var t=Object.keys(e),r=n.$options.props,a=(n.$options.methods,t.length);for(;a--;){var o=t[a];0,r&&_(r,o)||G(o)||qt(n,"_data",o)}var i=In(e);i&&i.vmCount++}(n);else{var t=In(n._data={});t&&t.vmCount++}e.computed&&function(n,e){var t=n._computedWatchers=Object.create(null),r=on();for(var a in e){var o=e[a],i=l(o)?o:o.get;0,r||(t[a]=new Ge(n,i||D,D,Mt)),a in n||Ft(n,a,o)}}(n,e.computed),e.watch&&e.watch!==tn&&function(n,e){for(var t in e){var r=e[t];if(a(r))for(var o=0;o<r.length;o++)Lt(n,t,r[o]);else Lt(n,t,r)}}(n,e.watch)}var Mt={lazy:!0};function Ft(n,e,t){var r=!on();l(t)?(jt.get=r?Ut(e):Rt(t),jt.set=D):(jt.get=t.get?r&&!1!==t.cache?Ut(e):Rt(t.get):D,jt.set=t.set||D),Object.defineProperty(n,e,jt)}function Ut(n){return function(){var e=this._computedWatchers&&this._computedWatchers[n];if(e)return e.dirty&&e.evaluate(),bn.target&&e.depend(),e.value}}function Rt(n){return function(){return n.call(this,this)}}function Lt(n,e,t,r){return u(t)&&(r=t,t=t.handler),"string"==typeof t&&(t=n[t]),n.$watch(e,t,r)}var Nt=0;function Gt(n){var e=n.options;if(n.super){var t=Gt(n.super);if(t!==n.superOptions){n.superOptions=t;var r=function(n){var e,t=n.options,r=n.sealedOptions;for(var a in t)t[a]!==r[a]&&(e||(e={}),e[a]=t[a]);return e}(n);r&&S(n.extendOptions,r),(e=n.options=Tt(t,n.extendOptions)).name&&(e.components[e.name]=n)}}return e}function Kt(n){this._init(n)}function Vt(n){n.cid=0;var e=1;n.extend=function(n){n=n||{};var t=this,r=t.cid,a=n._Ctor||(n._Ctor={});if(a[r])return a[r];var o=ft(n)||ft(t.options);var i=function(n){this._init(n)};return(i.prototype=Object.create(t.prototype)).constructor=i,i.cid=e++,i.options=Tt(t.options,n),i.super=t,i.options.props&&function(n){var e=n.options.props;for(var t in e)qt(n.prototype,"_props",t)}(i),i.options.computed&&function(n){var e=n.options.computed;for(var t in e)Ft(n.prototype,t,e[t])}(i),i.extend=t.extend,i.mixin=t.mixin,i.use=t.use,U.forEach((function(n){i[n]=t[n]})),o&&(i.options.components[o]=i),i.superOptions=t.options,i.extendOptions=n,i.sealedOptions=S({},i.options),a[r]=i,i}}function Ht(n){return n&&(ft(n.Ctor.options)||n.tag)}function Zt(n,e){return a(n)?n.indexOf(e)>-1:"string"==typeof n?n.split(",").indexOf(e)>-1:!!m(n)&&n.test(e)}function Wt(n,e){var t=n.cache,r=n.keys,a=n._vnode;for(var o in t){var i=t[o];if(i){var s=i.name;s&&!e(s)&&Xt(t,o,r,a)}}}function Xt(n,e,t,r){var a=n[e];!a||r&&a.tag===r.tag||a.componentInstance.$destroy(),n[e]=null,y(t,e)}!function(n){n.prototype._init=function(n){var e=this;e._uid=Nt++,e._isVue=!0,e.__v_skip=!0,e._scope=new Rn(!0),n&&n._isComponent?function(n,e){var t=n.$options=Object.create(n.constructor.options),r=e._parentVnode;t.parent=e.parent,t._parentVnode=r;var a=r.componentOptions;t.propsData=a.propsData,t._parentListeners=a.listeners,t._renderChildren=a.children,t._componentTag=a.tag,e.render&&(t.render=e.render,t.staticRenderFns=e.staticRenderFns)}(e,n):e.$options=Tt(Gt(e.constructor),n||{},e),e._renderProxy=e,e._self=e,function(n){var e=n.$options,t=e.parent;if(t&&!e.abstract){for(;t.$options.abstract&&t.$parent;)t=t.$parent;t.$children.push(n)}n.$parent=t,n.$root=t?t.$root:n,n.$children=[],n.$refs={},n._provided=t?t._provided:Object.create(null),n._watcher=null,n._inactive=null,n._directInactive=!1,n._isMounted=!1,n._isDestroyed=!1,n._isBeingDestroyed=!1}(e),function(n){n._events=Object.create(null),n._hasHookEvent=!1;var e=n.$options._parentListeners;e&&Ze(n,e)}(e),function(n){n._vnode=null,n._staticTrees=null;var e=n.$options,t=n.$vnode=e._parentVnode,a=t&&t.context;n.$slots=de(e._renderChildren,a),n.$scopedSlots=t?he(n.$parent,t.data.scopedSlots,n.$slots):r,n._c=function(e,t,r,a){return we(n,e,t,r,a,!1)},n.$createElement=function(e,t,r,a){return we(n,e,t,r,a,!0)};var o=t&&t.data;Sn(n,"$attrs",o&&o.attrs||r,null,!0),Sn(n,"$listeners",e._parentListeners||r,null,!0)}(e),Je(e,"beforeCreate",void 0,!1),function(n){var e=ut(n.$options.inject,n);e&&(Bn(!1),Object.keys(e).forEach((function(t){Sn(n,t,e[t])})),Bn(!0))}(e),$t(e),function(n){var e=n.$options.provide;if(e){var t=l(e)?e.call(n):e;if(!p(t))return;for(var r=Ln(n),a=pn?Reflect.ownKeys(t):Object.keys(t),o=0;o<a.length;o++){var i=a[o];Object.defineProperty(r,i,Object.getOwnPropertyDescriptor(t,i))}}}(e),Je(e,"created"),e.$options.el&&e.$mount(e.$options.el)}}(Kt),function(n){var e={get:function(){return this._data}},t={get:function(){return this._props}};Object.defineProperty(n.prototype,"$data",e),Object.defineProperty(n.prototype,"$props",t),n.prototype.$set=zn,n.prototype.$delete=Dn,n.prototype.$watch=function(n,e,t){if(u(e))return Lt(this,n,e,t);(t=t||{}).user=!0;var r=new Ge(this,n,e,t);if(t.immediate){var a='callback for immediate watcher "'.concat(r.expression,'"');yn(),Ce(e,this,[r.value],this,a),En()}return function(){r.teardown()}}}(Kt),function(n){var e=/^hook:/;n.prototype.$on=function(n,t){var r=this;if(a(n))for(var o=0,i=n.length;o<i;o++)r.$on(n[o],t);else(r._events[n]||(r._events[n]=[])).push(t),e.test(n)&&(r._hasHookEvent=!0);return r},n.prototype.$once=function(n,e){var t=this;function r(){t.$off(n,r),e.apply(t,arguments)}return r.fn=e,t.$on(n,r),t},n.prototype.$off=function(n,e){var t=this;if(!arguments.length)return t._events=Object.create(null),t;if(a(n)){for(var r=0,o=n.length;r<o;r++)t.$off(n[r],e);return t}var i,s=t._events[n];if(!s)return t;if(!e)return t._events[n]=null,t;for(var c=s.length;c--;)if((i=s[c])===e||i.fn===e){s.splice(c,1);break}return t},n.prototype.$emit=function(n){var e=this,t=e._events[n];if(t){t=t.length>1?I(t):t;for(var r=I(arguments,1),a='event handler for "'.concat(n,'"'),o=0,i=t.length;o<i;o++)Ce(t[o],e,r,e,a)}return e}}(Kt),function(n){n.prototype._update=function(n,e){var t=this,r=t.$el,a=t._vnode,o=Xe(t);t._vnode=n,t.$el=a?t.__patch__(a,n):t.__patch__(t.$el,n,e,!1),o(),r&&(r.__vue__=null),t.$el&&(t.$el.__vue__=t),t.$vnode&&t.$parent&&t.$vnode===t.$parent._vnode&&(t.$parent.$el=t.$el)},n.prototype.$forceUpdate=function(){this._watcher&&this._watcher.update()},n.prototype.$destroy=function(){var n=this;if(!n._isBeingDestroyed){Je(n,"beforeDestroy"),n._isBeingDestroyed=!0;var e=n.$parent;!e||e._isBeingDestroyed||n.$options.abstract||y(e.$children,n),n._scope.stop(),n._data.__ob__&&n._data.__ob__.vmCount--,n._isDestroyed=!0,n.__patch__(n._vnode,null),Je(n,"destroyed"),n.$off(),n.$el&&(n.$el.__vue__=null),n.$vnode&&(n.$vnode.parent=null)}}}(Kt),function(n){pe(n.prototype),n.prototype.$nextTick=function(n){return Me(n,this)},n.prototype._render=function(){var n,e=this,t=e.$options,r=t.render,o=t._parentVnode;o&&e._isMounted&&(e.$scopedSlots=he(e.$parent,o.data.scopedSlots,e.$slots,e.$scopedSlots),e._slotsProxy&&ye(e._slotsProxy,e.$scopedSlots)),e.$vnode=o;try{un(e),Ee=e,n=r.call(e._renderProxy,e.$createElement)}catch(t){Ae(t,e,"render"),n=e._vnode}finally{Ee=null,un()}return a(n)&&1===n.length&&(n=n[0]),n instanceof mn||(n=hn()),n.parent=o,n}}(Kt);var Yt=[String,RegExp,Array],Qt={KeepAlive:{name:"keep-alive",abstract:!0,props:{include:Yt,exclude:Yt,max:[String,Number]},methods:{cacheVNode:function(){var n=this.cache,e=this.keys,t=this.vnodeToCache,r=this.keyToCache;if(t){var a=t.tag,o=t.componentInstance,i=t.componentOptions;n[r]={name:Ht(i),tag:a,componentInstance:o},e.push(r),this.max&&e.length>parseInt(this.max)&&Xt(n,e[0],e,this._vnode),this.vnodeToCache=null}}},created:function(){this.cache=Object.create(null),this.keys=[]},destroyed:function(){for(var n in this.cache)Xt(this.cache,n,this.keys)},mounted:function(){var n=this;this.cacheVNode(),this.$watch("include",(function(e){Wt(n,(function(n){return Zt(e,n)}))})),this.$watch("exclude",(function(e){Wt(n,(function(n){return!Zt(e,n)}))}))},updated:function(){this.cacheVNode()},render:function(){var n=this.$slots.default,e=xe(n),t=e&&e.componentOptions;if(t){var r=Ht(t),a=this.include,o=this.exclude;if(a&&(!r||!Zt(a,r))||o&&r&&Zt(o,r))return e;var i=this.cache,s=this.keys,c=null==e.key?t.Ctor.cid+(t.tag?"::".concat(t.tag):""):e.key;i[c]?(e.componentInstance=i[c].componentInstance,y(s,c),s.push(c)):(this.vnodeToCache=e,this.keyToCache=c),e.data.keepAlive=!0}return e||n&&n[0]}}};!function(n){var e={get:function(){return L}};Object.defineProperty(n,"config",e),n.util={warn:Et,extend:S,mergeOptions:Tt,defineReactive:Sn},n.set=zn,n.delete=Dn,n.nextTick=Me,n.observable=function(n){return In(n),n},n.options=Object.create(null),U.forEach((function(e){n.options[e+"s"]=Object.create(null)})),n.options._base=n,S(n.options.components,Qt),function(n){n.use=function(n){var e=this._installedPlugins||(this._installedPlugins=[]);if(e.indexOf(n)>-1)return this;var t=I(arguments,1);return t.unshift(this),l(n.install)?n.install.apply(n,t):l(n)&&n.apply(null,t),e.push(n),this}}(n),function(n){n.mixin=function(n){return this.options=Tt(this.options,n),this}}(n),Vt(n),function(n){U.forEach((function(e){n[e]=function(n,t){return t?("component"===e&&u(t)&&(t.name=t.name||n,t=this.options._base.extend(t)),"directive"===e&&l(t)&&(t={bind:t,update:t}),this.options[e+"s"][n]=t,t):this.options[e+"s"][n]}}))}(n)}(Kt),Object.defineProperty(Kt.prototype,"$isServer",{get:on}),Object.defineProperty(Kt.prototype,"$ssrContext",{get:function(){return this.$vnode&&this.$vnode.ssrContext}}),Object.defineProperty(Kt,"FunctionalRenderContext",{value:mt}),Kt.version="2.7.8";var Jt=b("style,class"),nr=b("input,textarea,option,select,progress"),er=b("contenteditable,draggable,spellcheck"),tr=b("events,caret,typing,plaintext-only"),rr=b("allowfullscreen,async,autofocus,autoplay,checked,compact,controls,declare,default,defaultchecked,defaultmuted,defaultselected,defer,disabled,enabled,formnovalidate,hidden,indeterminate,inert,ismap,itemscope,loop,multiple,muted,nohref,noresize,noshade,novalidate,nowrap,open,pauseonexit,readonly,required,reversed,scoped,seamless,selected,sortable,truespeed,typemustmatch,visible"),ar="http://www.w3.org/1999/xlink",or=function(n){return":"===n.charAt(5)&&"xlink"===n.slice(0,5)},ir=function(n){return or(n)?n.slice(6,n.length):""},sr=function(n){return null==n||!1===n};function cr(n){for(var e=n.data,t=n,r=n;i(r.componentInstance);)(r=r.componentInstance._vnode)&&r.data&&(e=lr(r.data,e));for(;i(t=t.parent);)t&&t.data&&(e=lr(e,t.data));return function(n,e){if(i(n)||i(e))return pr(n,dr(e));return""}(e.staticClass,e.class)}function lr(n,e){return{staticClass:pr(n.staticClass,e.staticClass),class:i(n.class)?[n.class,e.class]:e.class}}function pr(n,e){return n?e?n+" "+e:n:e||""}function dr(n){return Array.isArray(n)?function(n){for(var e,t="",r=0,a=n.length;r<a;r++)i(e=dr(n[r]))&&""!==e&&(t&&(t+=" "),t+=e);return t}(n):p(n)?function(n){var e="";for(var t in n)n[t]&&(e&&(e+=" "),e+=t);return e}(n):"string"==typeof n?n:""}var ur={svg:"http://www.w3.org/2000/svg",math:"http://www.w3.org/1998/Math/MathML"},mr=b("html,body,base,head,link,meta,style,title,address,article,aside,footer,header,h1,h2,h3,h4,h5,h6,hgroup,nav,section,div,dd,dl,dt,figcaption,figure,picture,hr,img,li,main,ol,p,pre,ul,a,b,abbr,bdi,bdo,br,cite,code,data,dfn,em,i,kbd,mark,q,rp,rt,rtc,ruby,s,samp,small,span,strong,sub,sup,time,u,var,wbr,area,audio,map,track,video,embed,object,param,source,canvas,script,noscript,del,ins,caption,col,colgroup,table,thead,tbody,td,th,tr,button,datalist,fieldset,form,input,label,legend,meter,optgroup,option,output,progress,select,textarea,details,dialog,menu,menuitem,summary,content,element,shadow,template,blockquote,iframe,tfoot"),hr=b("svg,animate,circle,clippath,cursor,defs,desc,ellipse,filter,font-face,foreignobject,g,glyph,image,line,marker,mask,missing-glyph,path,pattern,polygon,polyline,rect,switch,symbol,text,textpath,tspan,use,view",!0),gr=function(n){return mr(n)||hr(n)};var fr=Object.create(null);var vr=b("text,number,password,search,email,tel,url");var br=Object.freeze({__proto__:null,createElement:function(n,e){var t=document.createElement(n);return"select"!==n||e.data&&e.data.attrs&&void 0!==e.data.attrs.multiple&&t.setAttribute("multiple","multiple"),t},createElementNS:function(n,e){return document.createElementNS(ur[n],e)},createTextNode:function(n){return document.createTextNode(n)},createComment:function(n){return document.createComment(n)},insertBefore:function(n,e,t){n.insertBefore(e,t)},removeChild:function(n,e){n.removeChild(e)},appendChild:function(n,e){n.appendChild(e)},parentNode:function(n){return n.parentNode},nextSibling:function(n){return n.nextSibling},tagName:function(n){return n.tagName},setTextContent:function(n,e){n.textContent=e},setStyleScope:function(n,e){n.setAttribute(e,"")}}),kr={create:function(n,e){yr(e)},update:function(n,e){n.data.ref!==e.data.ref&&(yr(n,!0),yr(e))},destroy:function(n){yr(n,!0)}};function yr(n,e){var t=n.data.ref;if(i(t)){var r=n.context,o=n.componentInstance||n.elm,s=e?null:o,c=e?void 0:o;if(l(t))Ce(t,r,[s],r,"template ref function");else{var p=n.data.refInFor,d="string"==typeof t||"number"==typeof t,u=Mn(t),m=r.$refs;if(d||u)if(p){var h=d?m[t]:t.value;e?a(h)&&y(h,o):a(h)?h.includes(o)||h.push(o):d?(m[t]=[o],Er(r,t,m[t])):t.value=[o]}else if(d){if(e&&m[t]!==o)return;m[t]=c,Er(r,t,s)}else if(u){if(e&&t.value!==o)return;t.value=s}else 0}}}function Er(n,e,t){var r=n._setupState;r&&_(r,e)&&(Mn(r[e])?r[e].value=t:r[e]=t)}var _r=new mn("",{},[]),xr=["create","activate","update","remove","destroy"];function wr(n,e){return n.key===e.key&&n.asyncFactory===e.asyncFactory&&(n.tag===e.tag&&n.isComment===e.isComment&&i(n.data)===i(e.data)&&function(n,e){if("input"!==n.tag)return!0;var t,r=i(t=n.data)&&i(t=t.attrs)&&t.type,a=i(t=e.data)&&i(t=t.attrs)&&t.type;return r===a||vr(r)&&vr(a)}(n,e)||s(n.isAsyncPlaceholder)&&o(e.asyncFactory.error))}function Ar(n,e,t){var r,a,o={};for(r=e;r<=t;++r)i(a=n[r].key)&&(o[a]=r);return o}var Cr={create:Br,update:Br,destroy:function(n){Br(n,_r)}};function Br(n,e){(n.data.directives||e.data.directives)&&function(n,e){var t,r,a,o=n===_r,i=e===_r,s=Pr(n.data.directives,n.context),c=Pr(e.data.directives,e.context),l=[],p=[];for(t in c)r=s[t],a=c[t],r?(a.oldValue=r.value,a.oldArg=r.arg,Sr(a,"update",e,n),a.def&&a.def.componentUpdated&&p.push(a)):(Sr(a,"bind",e,n),a.def&&a.def.inserted&&l.push(a));if(l.length){var d=function(){for(var t=0;t<l.length;t++)Sr(l[t],"inserted",e,n)};o?Vn(e,"insert",d):d()}p.length&&Vn(e,"postpatch",(function(){for(var t=0;t<p.length;t++)Sr(p[t],"componentUpdated",e,n)}));if(!o)for(t in s)c[t]||Sr(s[t],"unbind",n,n,i)}(n,e)}var Tr=Object.create(null);function Pr(n,e){var t,r,a=Object.create(null);if(!n)return a;for(t=0;t<n.length;t++)(r=n[t]).modifiers||(r.modifiers=Tr),a[Ir(r)]=r,e._setupState&&e._setupState.__sfc&&(r.def=r.def||Pt(e,"_setupState","v-"+r.name)),r.def=r.def||Pt(e.$options,"directives",r.name);return a}function Ir(n){return n.rawName||"".concat(n.name,".").concat(Object.keys(n.modifiers||{}).join("."))}function Sr(n,e,t,r,a){var o=n.def&&n.def[e];if(o)try{o(t.elm,n,t,r,a)}catch(r){Ae(r,t.context,"directive ".concat(n.name," ").concat(e," hook"))}}var zr=[kr,Cr];function Dr(n,e){var t=e.componentOptions;if(!(i(t)&&!1===t.Ctor.options.inheritAttrs||o(n.data.attrs)&&o(e.data.attrs))){var r,a,c=e.elm,l=n.data.attrs||{},p=e.data.attrs||{};for(r in(i(p.__ob__)||s(p._v_attr_proxy))&&(p=e.data.attrs=S({},p)),p)a=p[r],l[r]!==a&&Or(c,r,a,e.data.pre);for(r in(X||Q)&&p.value!==l.value&&Or(c,"value",p.value),l)o(p[r])&&(or(r)?c.removeAttributeNS(ar,ir(r)):er(r)||c.removeAttribute(r))}}function Or(n,e,t,r){r||n.tagName.indexOf("-")>-1?jr(n,e,t):rr(e)?sr(t)?n.removeAttribute(e):(t="allowfullscreen"===e&&"EMBED"===n.tagName?"true":e,n.setAttribute(e,t)):er(e)?n.setAttribute(e,function(n,e){return sr(e)||"false"===e?"false":"contenteditable"===n&&tr(e)?e:"true"}(e,t)):or(e)?sr(t)?n.removeAttributeNS(ar,ir(e)):n.setAttributeNS(ar,e,t):jr(n,e,t)}function jr(n,e,t){if(sr(t))n.removeAttribute(e);else{if(X&&!Y&&"TEXTAREA"===n.tagName&&"placeholder"===e&&""!==t&&!n.__ieph){var r=function(e){e.stopImmediatePropagation(),n.removeEventListener("input",r)};n.addEventListener("input",r),n.__ieph=!0}n.setAttribute(e,t)}}var qr={create:Dr,update:Dr};function $r(n,e){var t=e.elm,r=e.data,a=n.data;if(!(o(r.staticClass)&&o(r.class)&&(o(a)||o(a.staticClass)&&o(a.class)))){var s=cr(e),c=t._transitionClasses;i(c)&&(s=pr(s,dr(c))),s!==t._prevClass&&(t.setAttribute("class",s),t._prevClass=s)}}var Mr,Fr={create:$r,update:$r};function Ur(n,e,t){var r=Mr;return function a(){var o=e.apply(null,arguments);null!==o&&Nr(n,a,t,r)}}var Rr=Ie&&!(en&&Number(en[1])<=53);function Lr(n,e,t,r){if(Rr){var a=it,o=e;e=o._wrapper=function(n){if(n.target===n.currentTarget||n.timeStamp>=a||n.timeStamp<=0||n.target.ownerDocument!==document)return o.apply(this,arguments)}}Mr.addEventListener(n,e,rn?{capture:t,passive:r}:t)}function Nr(n,e,t,r){(r||Mr).removeEventListener(n,e._wrapper||e,t)}function Gr(n,e){if(!o(n.data.on)||!o(e.data.on)){var t=e.data.on||{},r=n.data.on||{};Mr=e.elm||n.elm,function(n){if(i(n.__r)){var e=X?"change":"input";n[e]=[].concat(n.__r,n[e]||[]),delete n.__r}i(n.__c)&&(n.change=[].concat(n.__c,n.change||[]),delete n.__c)}(t),Kn(t,r,Lr,Nr,Ur,e.context),Mr=void 0}}var Kr,Vr={create:Gr,update:Gr,destroy:function(n){return Gr(n,_r)}};function Hr(n,e){if(!o(n.data.domProps)||!o(e.data.domProps)){var t,r,a=e.elm,c=n.data.domProps||{},l=e.data.domProps||{};for(t in(i(l.__ob__)||s(l._v_attr_proxy))&&(l=e.data.domProps=S({},l)),c)t in l||(a[t]="");for(t in l){if(r=l[t],"textContent"===t||"innerHTML"===t){if(e.children&&(e.children.length=0),r===c[t])continue;1===a.childNodes.length&&a.removeChild(a.childNodes[0])}if("value"===t&&"PROGRESS"!==a.tagName){a._value=r;var p=o(r)?"":String(r);Zr(a,p)&&(a.value=p)}else if("innerHTML"===t&&hr(a.tagName)&&o(a.innerHTML)){(Kr=Kr||document.createElement("div")).innerHTML="<svg>".concat(r,"</svg>");for(var d=Kr.firstChild;a.firstChild;)a.removeChild(a.firstChild);for(;d.firstChild;)a.appendChild(d.firstChild)}else if(r!==c[t])try{a[t]=r}catch(n){}}}}function Zr(n,e){return!n.composing&&("OPTION"===n.tagName||function(n,e){var t=!0;try{t=document.activeElement!==n}catch(n){}return t&&n.value!==e}(n,e)||function(n,e){var t=n.value,r=n._vModifiers;if(i(r)){if(r.number)return v(t)!==v(e);if(r.trim)return t.trim()!==e.trim()}return t!==e}(n,e))}var Wr={create:Hr,update:Hr},Xr=x((function(n){var e={},t=/:(.+)/;return n.split(/;(?![^(]*\))/g).forEach((function(n){if(n){var r=n.split(t);r.length>1&&(e[r[0].trim()]=r[1].trim())}})),e}));function Yr(n){var e=Qr(n.style);return n.staticStyle?S(n.staticStyle,e):e}function Qr(n){return Array.isArray(n)?z(n):"string"==typeof n?Xr(n):n}var Jr,na=/^--/,ea=/\s*!important$/,ta=function(n,e,t){if(na.test(e))n.style.setProperty(e,t);else if(ea.test(t))n.style.setProperty(T(e),t.replace(ea,""),"important");else{var r=aa(e);if(Array.isArray(t))for(var a=0,o=t.length;a<o;a++)n.style[r]=t[a];else n.style[r]=t}},ra=["Webkit","Moz","ms"],aa=x((function(n){if(Jr=Jr||document.createElement("div").style,"filter"!==(n=A(n))&&n in Jr)return n;for(var e=n.charAt(0).toUpperCase()+n.slice(1),t=0;t<ra.length;t++){var r=ra[t]+e;if(r in Jr)return r}}));function oa(n,e){var t=e.data,r=n.data;if(!(o(t.staticStyle)&&o(t.style)&&o(r.staticStyle)&&o(r.style))){var a,s,c=e.elm,l=r.staticStyle,p=r.normalizedStyle||r.style||{},d=l||p,u=Qr(e.data.style)||{};e.data.normalizedStyle=i(u.__ob__)?S({},u):u;var m=function(n,e){var t,r={};if(e)for(var a=n;a.componentInstance;)(a=a.componentInstance._vnode)&&a.data&&(t=Yr(a.data))&&S(r,t);(t=Yr(n.data))&&S(r,t);for(var o=n;o=o.parent;)o.data&&(t=Yr(o.data))&&S(r,t);return r}(e,!0);for(s in d)o(m[s])&&ta(c,s,"");for(s in m)(a=m[s])!==d[s]&&ta(c,s,null==a?"":a)}}var ia={create:oa,update:oa},sa=/\s+/;function ca(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(sa).forEach((function(e){return n.classList.add(e)})):n.classList.add(e);else{var t=" ".concat(n.getAttribute("class")||""," ");t.indexOf(" "+e+" ")<0&&n.setAttribute("class",(t+e).trim())}}function la(n,e){if(e&&(e=e.trim()))if(n.classList)e.indexOf(" ")>-1?e.split(sa).forEach((function(e){return n.classList.remove(e)})):n.classList.remove(e),n.classList.length||n.removeAttribute("class");else{for(var t=" ".concat(n.getAttribute("class")||""," "),r=" "+e+" ";t.indexOf(r)>=0;)t=t.replace(r," ");(t=t.trim())?n.setAttribute("class",t):n.removeAttribute("class")}}function pa(n){if(n){if("object"==typeof n){var e={};return!1!==n.css&&S(e,da(n.name||"v")),S(e,n),e}return"string"==typeof n?da(n):void 0}}var da=x((function(n){return{enterClass:"".concat(n,"-enter"),enterToClass:"".concat(n,"-enter-to"),enterActiveClass:"".concat(n,"-enter-active"),leaveClass:"".concat(n,"-leave"),leaveToClass:"".concat(n,"-leave-to"),leaveActiveClass:"".concat(n,"-leave-active")}})),ua=Z&&!Y,ma="transition",ha="transitionend",ga="animation",fa="animationend";ua&&(void 0===window.ontransitionend&&void 0!==window.onwebkittransitionend&&(ma="WebkitTransition",ha="webkitTransitionEnd"),void 0===window.onanimationend&&void 0!==window.onwebkitanimationend&&(ga="WebkitAnimation",fa="webkitAnimationEnd"));var va=Z?window.requestAnimationFrame?window.requestAnimationFrame.bind(window):setTimeout:function(n){return n()};function ba(n){va((function(){va(n)}))}function ka(n,e){var t=n._transitionClasses||(n._transitionClasses=[]);t.indexOf(e)<0&&(t.push(e),ca(n,e))}function ya(n,e){n._transitionClasses&&y(n._transitionClasses,e),la(n,e)}function Ea(n,e,t){var r=xa(n,e),a=r.type,o=r.timeout,i=r.propCount;if(!a)return t();var s="transition"===a?ha:fa,c=0,l=function(){n.removeEventListener(s,p),t()},p=function(e){e.target===n&&++c>=i&&l()};setTimeout((function(){c<i&&l()}),o+1),n.addEventListener(s,p)}var _a=/\b(transform|all)(,|$)/;function xa(n,e){var t,r=window.getComputedStyle(n),a=(r[ma+"Delay"]||"").split(", "),o=(r[ma+"Duration"]||"").split(", "),i=wa(a,o),s=(r[ga+"Delay"]||"").split(", "),c=(r[ga+"Duration"]||"").split(", "),l=wa(s,c),p=0,d=0;return"transition"===e?i>0&&(t="transition",p=i,d=o.length):"animation"===e?l>0&&(t="animation",p=l,d=c.length):d=(t=(p=Math.max(i,l))>0?i>l?"transition":"animation":null)?"transition"===t?o.length:c.length:0,{type:t,timeout:p,propCount:d,hasTransform:"transition"===t&&_a.test(r[ma+"Property"])}}function wa(n,e){for(;n.length<e.length;)n=n.concat(n);return Math.max.apply(null,e.map((function(e,t){return Aa(e)+Aa(n[t])})))}function Aa(n){return 1e3*Number(n.slice(0,-1).replace(",","."))}function Ca(n,e){var t=n.elm;i(t._leaveCb)&&(t._leaveCb.cancelled=!0,t._leaveCb());var r=pa(n.data.transition);if(!o(r)&&!i(t._enterCb)&&1===t.nodeType){for(var a=r.css,s=r.type,c=r.enterClass,d=r.enterToClass,u=r.enterActiveClass,m=r.appearClass,h=r.appearToClass,g=r.appearActiveClass,f=r.beforeEnter,b=r.enter,k=r.afterEnter,y=r.enterCancelled,E=r.beforeAppear,_=r.appear,x=r.afterAppear,w=r.appearCancelled,A=r.duration,C=We,B=We.$vnode;B&&B.parent;)C=B.context,B=B.parent;var T=!C._isMounted||!n.isRootInsert;if(!T||_||""===_){var P=T&&m?m:c,I=T&&g?g:u,S=T&&h?h:d,z=T&&E||f,D=T&&l(_)?_:b,O=T&&x||k,j=T&&w||y,q=v(p(A)?A.enter:A);0;var $=!1!==a&&!Y,F=Pa(D),U=t._enterCb=M((function(){$&&(ya(t,S),ya(t,I)),U.cancelled?($&&ya(t,P),j&&j(t)):O&&O(t),t._enterCb=null}));n.data.show||Vn(n,"insert",(function(){var e=t.parentNode,r=e&&e._pending&&e._pending[n.key];r&&r.tag===n.tag&&r.elm._leaveCb&&r.elm._leaveCb(),D&&D(t,U)})),z&&z(t),$&&(ka(t,P),ka(t,I),ba((function(){ya(t,P),U.cancelled||(ka(t,S),F||(Ta(q)?setTimeout(U,q):Ea(t,s,U)))}))),n.data.show&&(e&&e(),D&&D(t,U)),$||F||U()}}}function Ba(n,e){var t=n.elm;i(t._enterCb)&&(t._enterCb.cancelled=!0,t._enterCb());var r=pa(n.data.transition);if(o(r)||1!==t.nodeType)return e();if(!i(t._leaveCb)){var a=r.css,s=r.type,c=r.leaveClass,l=r.leaveToClass,d=r.leaveActiveClass,u=r.beforeLeave,m=r.leave,h=r.afterLeave,g=r.leaveCancelled,f=r.delayLeave,b=r.duration,k=!1!==a&&!Y,y=Pa(m),E=v(p(b)?b.leave:b);0;var _=t._leaveCb=M((function(){t.parentNode&&t.parentNode._pending&&(t.parentNode._pending[n.key]=null),k&&(ya(t,l),ya(t,d)),_.cancelled?(k&&ya(t,c),g&&g(t)):(e(),h&&h(t)),t._leaveCb=null}));f?f(x):x()}function x(){_.cancelled||(!n.data.show&&t.parentNode&&((t.parentNode._pending||(t.parentNode._pending={}))[n.key]=n),u&&u(t),k&&(ka(t,c),ka(t,d),ba((function(){ya(t,c),_.cancelled||(ka(t,l),y||(Ta(E)?setTimeout(_,E):Ea(t,s,_)))}))),m&&m(t,_),k||y||_())}}function Ta(n){return"number"==typeof n&&!isNaN(n)}function Pa(n){if(o(n))return!1;var e=n.fns;return i(e)?Pa(Array.isArray(e)?e[0]:e):(n._length||n.length)>1}function Ia(n,e){!0!==e.data.show&&Ca(e)}var Sa=function(n){var e,t,r={},l=n.modules,p=n.nodeOps;for(e=0;e<xr.length;++e)for(r[xr[e]]=[],t=0;t<l.length;++t)i(l[t][xr[e]])&&r[xr[e]].push(l[t][xr[e]]);function d(n){var e=p.parentNode(n);i(e)&&p.removeChild(e,n)}function u(n,e,t,a,o,c,l){if(i(n.elm)&&i(c)&&(n=c[l]=fn(n)),n.isRootInsert=!o,!function(n,e,t,a){var o=n.data;if(i(o)){var c=i(n.componentInstance)&&o.keepAlive;if(i(o=o.hook)&&i(o=o.init)&&o(n,!1),i(n.componentInstance))return m(n,e),h(t,n.elm,a),s(c)&&function(n,e,t,a){var o,s=n;for(;s.componentInstance;)if(s=s.componentInstance._vnode,i(o=s.data)&&i(o=o.transition)){for(o=0;o<r.activate.length;++o)r.activate[o](_r,s);e.push(s);break}h(t,n.elm,a)}(n,e,t,a),!0}}(n,e,t,a)){var d=n.data,u=n.children,f=n.tag;i(f)?(n.elm=n.ns?p.createElementNS(n.ns,f):p.createElement(f,n),k(n),g(n,u,e),i(d)&&v(n,e),h(t,n.elm,a)):s(n.isComment)?(n.elm=p.createComment(n.text),h(t,n.elm,a)):(n.elm=p.createTextNode(n.text),h(t,n.elm,a))}}function m(n,e){i(n.data.pendingInsert)&&(e.push.apply(e,n.data.pendingInsert),n.data.pendingInsert=null),n.elm=n.componentInstance.$el,f(n)?(v(n,e),k(n)):(yr(n),e.push(n))}function h(n,e,t){i(n)&&(i(t)?p.parentNode(t)===n&&p.insertBefore(n,e,t):p.appendChild(n,e))}function g(n,e,t){if(a(e)){0;for(var r=0;r<e.length;++r)u(e[r],t,n.elm,null,!0,e,r)}else c(n.text)&&p.appendChild(n.elm,p.createTextNode(String(n.text)))}function f(n){for(;n.componentInstance;)n=n.componentInstance._vnode;return i(n.tag)}function v(n,t){for(var a=0;a<r.create.length;++a)r.create[a](_r,n);i(e=n.data.hook)&&(i(e.create)&&e.create(_r,n),i(e.insert)&&t.push(n))}function k(n){var e;if(i(e=n.fnScopeId))p.setStyleScope(n.elm,e);else for(var t=n;t;)i(e=t.context)&&i(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e),t=t.parent;i(e=We)&&e!==n.context&&e!==n.fnContext&&i(e=e.$options._scopeId)&&p.setStyleScope(n.elm,e)}function y(n,e,t,r,a,o){for(;r<=a;++r)u(t[r],o,n,e,!1,t,r)}function E(n){var e,t,a=n.data;if(i(a))for(i(e=a.hook)&&i(e=e.destroy)&&e(n),e=0;e<r.destroy.length;++e)r.destroy[e](n);if(i(e=n.children))for(t=0;t<n.children.length;++t)E(n.children[t])}function _(n,e,t){for(;e<=t;++e){var r=n[e];i(r)&&(i(r.tag)?(x(r),E(r)):d(r.elm))}}function x(n,e){if(i(e)||i(n.data)){var t,a=r.remove.length+1;for(i(e)?e.listeners+=a:e=function(n,e){function t(){0==--t.listeners&&d(n)}return t.listeners=e,t}(n.elm,a),i(t=n.componentInstance)&&i(t=t._vnode)&&i(t.data)&&x(t,e),t=0;t<r.remove.length;++t)r.remove[t](n,e);i(t=n.data.hook)&&i(t=t.remove)?t(n,e):e()}else d(n.elm)}function w(n,e,t,r){for(var a=t;a<r;a++){var o=e[a];if(i(o)&&wr(n,o))return a}}function A(n,e,t,a,c,l){if(n!==e){i(e.elm)&&i(a)&&(e=a[c]=fn(e));var d=e.elm=n.elm;if(s(n.isAsyncPlaceholder))i(e.asyncFactory.resolved)?T(n.elm,e,t):e.isAsyncPlaceholder=!0;else if(s(e.isStatic)&&s(n.isStatic)&&e.key===n.key&&(s(e.isCloned)||s(e.isOnce)))e.componentInstance=n.componentInstance;else{var m,h=e.data;i(h)&&i(m=h.hook)&&i(m=m.prepatch)&&m(n,e);var g=n.children,v=e.children;if(i(h)&&f(e)){for(m=0;m<r.update.length;++m)r.update[m](n,e);i(m=h.hook)&&i(m=m.update)&&m(n,e)}o(e.text)?i(g)&&i(v)?g!==v&&function(n,e,t,r,a){var s,c,l,d=0,m=0,h=e.length-1,g=e[0],f=e[h],v=t.length-1,b=t[0],k=t[v],E=!a;for(0;d<=h&&m<=v;)o(g)?g=e[++d]:o(f)?f=e[--h]:wr(g,b)?(A(g,b,r,t,m),g=e[++d],b=t[++m]):wr(f,k)?(A(f,k,r,t,v),f=e[--h],k=t[--v]):wr(g,k)?(A(g,k,r,t,v),E&&p.insertBefore(n,g.elm,p.nextSibling(f.elm)),g=e[++d],k=t[--v]):wr(f,b)?(A(f,b,r,t,m),E&&p.insertBefore(n,f.elm,g.elm),f=e[--h],b=t[++m]):(o(s)&&(s=Ar(e,d,h)),o(c=i(b.key)?s[b.key]:w(b,e,d,h))?u(b,r,n,g.elm,!1,t,m):wr(l=e[c],b)?(A(l,b,r,t,m),e[c]=void 0,E&&p.insertBefore(n,l.elm,g.elm)):u(b,r,n,g.elm,!1,t,m),b=t[++m]);d>h?y(n,o(t[v+1])?null:t[v+1].elm,t,m,v,r):m>v&&_(e,d,h)}(d,g,v,t,l):i(v)?(i(n.text)&&p.setTextContent(d,""),y(d,null,v,0,v.length-1,t)):i(g)?_(g,0,g.length-1):i(n.text)&&p.setTextContent(d,""):n.text!==e.text&&p.setTextContent(d,e.text),i(h)&&i(m=h.hook)&&i(m=m.postpatch)&&m(n,e)}}}function C(n,e,t){if(s(t)&&i(n.parent))n.parent.data.pendingInsert=e;else for(var r=0;r<e.length;++r)e[r].data.hook.insert(e[r])}var B=b("attrs,class,staticClass,staticStyle,key");function T(n,e,t,r){var a,o=e.tag,c=e.data,l=e.children;if(r=r||c&&c.pre,e.elm=n,s(e.isComment)&&i(e.asyncFactory))return e.isAsyncPlaceholder=!0,!0;if(i(c)&&(i(a=c.hook)&&i(a=a.init)&&a(e,!0),i(a=e.componentInstance)))return m(e,t),!0;if(i(o)){if(i(l))if(n.hasChildNodes())if(i(a=c)&&i(a=a.domProps)&&i(a=a.innerHTML)){if(a!==n.innerHTML)return!1}else{for(var p=!0,d=n.firstChild,u=0;u<l.length;u++){if(!d||!T(d,l[u],t,r)){p=!1;break}d=d.nextSibling}if(!p||d)return!1}else g(e,l,t);if(i(c)){var h=!1;for(var f in c)if(!B(f)){h=!0,v(e,t);break}!h&&c.class&&Re(c.class)}}else n.data!==e.text&&(n.data=e.text);return!0}return function(n,e,t,a){if(!o(e)){var c,l=!1,d=[];if(o(n))l=!0,u(e,d);else{var m=i(n.nodeType);if(!m&&wr(n,e))A(n,e,d,null,null,a);else{if(m){if(1===n.nodeType&&n.hasAttribute("data-server-rendered")&&(n.removeAttribute("data-server-rendered"),t=!0),s(t)&&T(n,e,d))return C(e,d,!0),n;c=n,n=new mn(p.tagName(c).toLowerCase(),{},[],void 0,c)}var h=n.elm,g=p.parentNode(h);if(u(e,d,h._leaveCb?null:g,p.nextSibling(h)),i(e.parent))for(var v=e.parent,b=f(e);v;){for(var k=0;k<r.destroy.length;++k)r.destroy[k](v);if(v.elm=e.elm,b){for(var y=0;y<r.create.length;++y)r.create[y](_r,v);var x=v.data.hook.insert;if(x.merged)for(var w=1;w<x.fns.length;w++)x.fns[w]()}else yr(v);v=v.parent}i(g)?_([n],0,0):i(n.tag)&&E(n)}}return C(e,d,l),e.elm}i(n)&&E(n)}}({nodeOps:br,modules:[qr,Fr,Vr,Wr,ia,Z?{create:Ia,activate:Ia,remove:function(n,e){!0!==n.data.show?Ba(n,e):e()}}:{}].concat(zr)});Y&&document.addEventListener("selectionchange",(function(){var n=document.activeElement;n&&n.vmodel&&Fa(n,"input")}));var za={inserted:function(n,e,t,r){"select"===t.tag?(r.elm&&!r.elm._vOptions?Vn(t,"postpatch",(function(){za.componentUpdated(n,e,t)})):Da(n,e,t.context),n._vOptions=[].map.call(n.options,qa)):("textarea"===t.tag||vr(n.type))&&(n._vModifiers=e.modifiers,e.modifiers.lazy||(n.addEventListener("compositionstart",$a),n.addEventListener("compositionend",Ma),n.addEventListener("change",Ma),Y&&(n.vmodel=!0)))},componentUpdated:function(n,e,t){if("select"===t.tag){Da(n,e,t.context);var r=n._vOptions,a=n._vOptions=[].map.call(n.options,qa);if(a.some((function(n,e){return!q(n,r[e])})))(n.multiple?e.value.some((function(n){return ja(n,a)})):e.value!==e.oldValue&&ja(e.value,a))&&Fa(n,"change")}}};function Da(n,e,t){Oa(n,e,t),(X||Q)&&setTimeout((function(){Oa(n,e,t)}),0)}function Oa(n,e,t){var r=e.value,a=n.multiple;if(!a||Array.isArray(r)){for(var o,i,s=0,c=n.options.length;s<c;s++)if(i=n.options[s],a)o=$(r,qa(i))>-1,i.selected!==o&&(i.selected=o);else if(q(qa(i),r))return void(n.selectedIndex!==s&&(n.selectedIndex=s));a||(n.selectedIndex=-1)}}function ja(n,e){return e.every((function(e){return!q(e,n)}))}function qa(n){return"_value"in n?n._value:n.value}function $a(n){n.target.composing=!0}function Ma(n){n.target.composing&&(n.target.composing=!1,Fa(n.target,"input"))}function Fa(n,e){var t=document.createEvent("HTMLEvents");t.initEvent(e,!0,!0),n.dispatchEvent(t)}function Ua(n){return!n.componentInstance||n.data&&n.data.transition?n:Ua(n.componentInstance._vnode)}var Ra={model:za,show:{bind:function(n,e,t){var r=e.value,a=(t=Ua(t)).data&&t.data.transition,o=n.__vOriginalDisplay="none"===n.style.display?"":n.style.display;r&&a?(t.data.show=!0,Ca(t,(function(){n.style.display=o}))):n.style.display=r?o:"none"},update:function(n,e,t){var r=e.value;!r!=!e.oldValue&&((t=Ua(t)).data&&t.data.transition?(t.data.show=!0,r?Ca(t,(function(){n.style.display=n.__vOriginalDisplay})):Ba(t,(function(){n.style.display="none"}))):n.style.display=r?n.__vOriginalDisplay:"none")},unbind:function(n,e,t,r,a){a||(n.style.display=n.__vOriginalDisplay)}}},La={name:String,appear:Boolean,css:Boolean,mode:String,type:String,enterClass:String,leaveClass:String,enterToClass:String,leaveToClass:String,enterActiveClass:String,leaveActiveClass:String,appearClass:String,appearActiveClass:String,appearToClass:String,duration:[Number,String,Object]};function Na(n){var e=n&&n.componentOptions;return e&&e.Ctor.options.abstract?Na(xe(e.children)):n}function Ga(n){var e={},t=n.$options;for(var r in t.propsData)e[r]=n[r];var a=t._parentListeners;for(var r in a)e[A(r)]=a[r];return e}function Ka(n,e){if(/\d-keep-alive$/.test(e.tag))return n("keep-alive",{props:e.componentOptions.propsData})}var Va=function(n){return n.tag||me(n)},Ha=function(n){return"show"===n.name},Za={name:"transition",props:La,abstract:!0,render:function(n){var e=this,t=this.$slots.default;if(t&&(t=t.filter(Va)).length){0;var r=this.mode;0;var a=t[0];if(function(n){for(;n=n.parent;)if(n.data.transition)return!0}(this.$vnode))return a;var o=Na(a);if(!o)return a;if(this._leaving)return Ka(n,a);var i="__transition-".concat(this._uid,"-");o.key=null==o.key?o.isComment?i+"comment":i+o.tag:c(o.key)?0===String(o.key).indexOf(i)?o.key:i+o.key:o.key;var s=(o.data||(o.data={})).transition=Ga(this),l=this._vnode,p=Na(l);if(o.data.directives&&o.data.directives.some(Ha)&&(o.data.show=!0),p&&p.data&&!function(n,e){return e.key===n.key&&e.tag===n.tag}(o,p)&&!me(p)&&(!p.componentInstance||!p.componentInstance._vnode.isComment)){var d=p.data.transition=S({},s);if("out-in"===r)return this._leaving=!0,Vn(d,"afterLeave",(function(){e._leaving=!1,e.$forceUpdate()})),Ka(n,a);if("in-out"===r){if(me(o))return l;var u,m=function(){u()};Vn(s,"afterEnter",m),Vn(s,"enterCancelled",m),Vn(d,"delayLeave",(function(n){u=n}))}}return a}}},Wa=S({tag:String,moveClass:String},La);function Xa(n){n.elm._moveCb&&n.elm._moveCb(),n.elm._enterCb&&n.elm._enterCb()}function Ya(n){n.data.newPos=n.elm.getBoundingClientRect()}function Qa(n){var e=n.data.pos,t=n.data.newPos,r=e.left-t.left,a=e.top-t.top;if(r||a){n.data.moved=!0;var o=n.elm.style;o.transform=o.WebkitTransform="translate(".concat(r,"px,").concat(a,"px)"),o.transitionDuration="0s"}}delete Wa.mode;var Ja={Transition:Za,TransitionGroup:{props:Wa,beforeMount:function(){var n=this,e=this._update;this._update=function(t,r){var a=Xe(n);n.__patch__(n._vnode,n.kept,!1,!0),n._vnode=n.kept,a(),e.call(n,t,r)}},render:function(n){for(var e=this.tag||this.$vnode.data.tag||"span",t=Object.create(null),r=this.prevChildren=this.children,a=this.$slots.default||[],o=this.children=[],i=Ga(this),s=0;s<a.length;s++){if((p=a[s]).tag)if(null!=p.key&&0!==String(p.key).indexOf("__vlist"))o.push(p),t[p.key]=p,(p.data||(p.data={})).transition=i;else;}if(r){var c=[],l=[];for(s=0;s<r.length;s++){var p;(p=r[s]).data.transition=i,p.data.pos=p.elm.getBoundingClientRect(),t[p.key]?c.push(p):l.push(p)}this.kept=n(e,null,c),this.removed=l}return n(e,null,o)},updated:function(){var n=this.prevChildren,e=this.moveClass||(this.name||"v")+"-move";n.length&&this.hasMove(n[0].elm,e)&&(n.forEach(Xa),n.forEach(Ya),n.forEach(Qa),this._reflow=document.body.offsetHeight,n.forEach((function(n){if(n.data.moved){var t=n.elm,r=t.style;ka(t,e),r.transform=r.WebkitTransform=r.transitionDuration="",t.addEventListener(ha,t._moveCb=function n(r){r&&r.target!==t||r&&!/transform$/.test(r.propertyName)||(t.removeEventListener(ha,n),t._moveCb=null,ya(t,e))})}})))},methods:{hasMove:function(n,e){if(!ua)return!1;if(this._hasMove)return this._hasMove;var t=n.cloneNode();n._transitionClasses&&n._transitionClasses.forEach((function(n){la(t,n)})),ca(t,e),t.style.display="none",this.$el.appendChild(t);var r=xa(t);return this.$el.removeChild(t),this._hasMove=r.hasTransform}}}};function no(n,e){for(var t in e)n[t]=e[t];return n}Kt.config.mustUseProp=function(n,e,t){return"value"===t&&nr(n)&&"button"!==e||"selected"===t&&"option"===n||"checked"===t&&"input"===n||"muted"===t&&"video"===n},Kt.config.isReservedTag=gr,Kt.config.isReservedAttr=Jt,Kt.config.getTagNamespace=function(n){return hr(n)?"svg":"math"===n?"math":void 0},Kt.config.isUnknownElement=function(n){if(!Z)return!0;if(gr(n))return!1;if(n=n.toLowerCase(),null!=fr[n])return fr[n];var e=document.createElement(n);return n.indexOf("-")>-1?fr[n]=e.constructor===window.HTMLUnknownElement||e.constructor===window.HTMLElement:fr[n]=/HTMLUnknownElement/.test(e.toString())},S(Kt.options.directives,Ra),S(Kt.options.components,Ja),Kt.prototype.__patch__=Z?Sa:D,Kt.prototype.$mount=function(n,e){return function(n,e,t){var r;n.$el=e,n.$options.render||(n.$options.render=hn),Je(n,"beforeMount"),r=function(){n._update(n._render(),t)},new Ge(n,r,D,{before:function(){n._isMounted&&!n._isDestroyed&&Je(n,"beforeUpdate")}},!0),t=!1;var a=n._preWatchers;if(a)for(var o=0;o<a.length;o++)a[o].run();return null==n.$vnode&&(n._isMounted=!0,Je(n,"mounted")),n}(this,n=n&&Z?function(n){if("string"==typeof n){var e=document.querySelector(n);return e||document.createElement("div")}return n}(n):void 0,e)},Z&&setTimeout((function(){L.devtools&&sn&&sn.emit("init",Kt)}),0);var eo=/[!'()*]/g,to=function(n){return"%"+n.charCodeAt(0).toString(16)},ro=/%2C/g,ao=function(n){return encodeURIComponent(n).replace(eo,to).replace(ro,",")};function oo(n){try{return decodeURIComponent(n)}catch(n){0}return n}var io=function(n){return null==n||"object"==typeof n?n:String(n)};function so(n){var e={};return(n=n.trim().replace(/^(\?|#|&)/,""))?(n.split("&").forEach((function(n){var t=n.replace(/\+/g," ").split("="),r=oo(t.shift()),a=t.length>0?oo(t.join("=")):null;void 0===e[r]?e[r]=a:Array.isArray(e[r])?e[r].push(a):e[r]=[e[r],a]})),e):e}function co(n){var e=n?Object.keys(n).map((function(e){var t=n[e];if(void 0===t)return"";if(null===t)return ao(e);if(Array.isArray(t)){var r=[];return t.forEach((function(n){void 0!==n&&(null===n?r.push(ao(e)):r.push(ao(e)+"="+ao(n)))})),r.join("&")}return ao(e)+"="+ao(t)})).filter((function(n){return n.length>0})).join("&"):null;return e?"?"+e:""}var lo=/\/?$/;function po(n,e,t,r){var a=r&&r.options.stringifyQuery,o=e.query||{};try{o=uo(o)}catch(n){}var i={name:e.name||n&&n.name,meta:n&&n.meta||{},path:e.path||"/",hash:e.hash||"",query:o,params:e.params||{},fullPath:go(e,a),matched:n?ho(n):[]};return t&&(i.redirectedFrom=go(t,a)),Object.freeze(i)}function uo(n){if(Array.isArray(n))return n.map(uo);if(n&&"object"==typeof n){var e={};for(var t in n)e[t]=uo(n[t]);return e}return n}var mo=po(null,{path:"/"});function ho(n){for(var e=[];n;)e.unshift(n),n=n.parent;return e}function go(n,e){var t=n.path,r=n.query;void 0===r&&(r={});var a=n.hash;return void 0===a&&(a=""),(t||"/")+(e||co)(r)+a}function fo(n,e,t){return e===mo?n===e:!!e&&(n.path&&e.path?n.path.replace(lo,"")===e.path.replace(lo,"")&&(t||n.hash===e.hash&&vo(n.query,e.query)):!(!n.name||!e.name)&&(n.name===e.name&&(t||n.hash===e.hash&&vo(n.query,e.query)&&vo(n.params,e.params))))}function vo(n,e){if(void 0===n&&(n={}),void 0===e&&(e={}),!n||!e)return n===e;var t=Object.keys(n).sort(),r=Object.keys(e).sort();return t.length===r.length&&t.every((function(t,a){var o=n[t];if(r[a]!==t)return!1;var i=e[t];return null==o||null==i?o===i:"object"==typeof o&&"object"==typeof i?vo(o,i):String(o)===String(i)}))}function bo(n){for(var e=0;e<n.matched.length;e++){var t=n.matched[e];for(var r in t.instances){var a=t.instances[r],o=t.enteredCbs[r];if(a&&o){delete t.enteredCbs[r];for(var i=0;i<o.length;i++)a._isBeingDestroyed||o[i](a)}}}}var ko={name:"RouterView",functional:!0,props:{name:{type:String,default:"default"}},render:function(n,e){var t=e.props,r=e.children,a=e.parent,o=e.data;o.routerView=!0;for(var i=a.$createElement,s=t.name,c=a.$route,l=a._routerViewCache||(a._routerViewCache={}),p=0,d=!1;a&&a._routerRoot!==a;){var u=a.$vnode?a.$vnode.data:{};u.routerView&&p++,u.keepAlive&&a._directInactive&&a._inactive&&(d=!0),a=a.$parent}if(o.routerViewDepth=p,d){var m=l[s],h=m&&m.component;return h?(m.configProps&&yo(h,o,m.route,m.configProps),i(h,o,r)):i()}var g=c.matched[p],f=g&&g.components[s];if(!g||!f)return l[s]=null,i();l[s]={component:f},o.registerRouteInstance=function(n,e){var t=g.instances[s];(e&&t!==n||!e&&t===n)&&(g.instances[s]=e)},(o.hook||(o.hook={})).prepatch=function(n,e){g.instances[s]=e.componentInstance},o.hook.init=function(n){n.data.keepAlive&&n.componentInstance&&n.componentInstance!==g.instances[s]&&(g.instances[s]=n.componentInstance),bo(c)};var v=g.props&&g.props[s];return v&&(no(l[s],{route:c,configProps:v}),yo(f,o,c,v)),i(f,o,r)}};function yo(n,e,t,r){var a=e.props=function(n,e){switch(typeof e){case"undefined":return;case"object":return e;case"function":return e(n);case"boolean":return e?n.params:void 0;default:0}}(t,r);if(a){a=e.props=no({},a);var o=e.attrs=e.attrs||{};for(var i in a)n.props&&i in n.props||(o[i]=a[i],delete a[i])}}function Eo(n,e,t){var r=n.charAt(0);if("/"===r)return n;if("?"===r||"#"===r)return e+n;var a=e.split("/");t&&a[a.length-1]||a.pop();for(var o=n.replace(/^\//,"").split("/"),i=0;i<o.length;i++){var s=o[i];".."===s?a.pop():"."!==s&&a.push(s)}return""!==a[0]&&a.unshift(""),a.join("/")}function _o(n){return n.replace(/\/(?:\s*\/)+/g,"/")}var xo=Array.isArray||function(n){return"[object Array]"==Object.prototype.toString.call(n)},wo=Mo,Ao=Io,Co=function(n,e){return zo(Io(n,e),e)},Bo=zo,To=$o,Po=new RegExp(["(\\\\.)","([\\/.])?(?:(?:\\:(\\w+)(?:\\(((?:\\\\.|[^\\\\()])+)\\))?|\\(((?:\\\\.|[^\\\\()])+)\\))([+*?])?|(\\*))"].join("|"),"g");function Io(n,e){for(var t,r=[],a=0,o=0,i="",s=e&&e.delimiter||"/";null!=(t=Po.exec(n));){var c=t[0],l=t[1],p=t.index;if(i+=n.slice(o,p),o=p+c.length,l)i+=l[1];else{var d=n[o],u=t[2],m=t[3],h=t[4],g=t[5],f=t[6],v=t[7];i&&(r.push(i),i="");var b=null!=u&&null!=d&&d!==u,k="+"===f||"*"===f,y="?"===f||"*"===f,E=t[2]||s,_=h||g;r.push({name:m||a++,prefix:u||"",delimiter:E,optional:y,repeat:k,partial:b,asterisk:!!v,pattern:_?Oo(_):v?".*":"[^"+Do(E)+"]+?"})}}return o<n.length&&(i+=n.substr(o)),i&&r.push(i),r}function So(n){return encodeURI(n).replace(/[\/?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()}))}function zo(n,e){for(var t=new Array(n.length),r=0;r<n.length;r++)"object"==typeof n[r]&&(t[r]=new RegExp("^(?:"+n[r].pattern+")$",qo(e)));return function(e,r){for(var a="",o=e||{},i=(r||{}).pretty?So:encodeURIComponent,s=0;s<n.length;s++){var c=n[s];if("string"!=typeof c){var l,p=o[c.name];if(null==p){if(c.optional){c.partial&&(a+=c.prefix);continue}throw new TypeError('Expected "'+c.name+'" to be defined')}if(xo(p)){if(!c.repeat)throw new TypeError('Expected "'+c.name+'" to not repeat, but received `'+JSON.stringify(p)+"`");if(0===p.length){if(c.optional)continue;throw new TypeError('Expected "'+c.name+'" to not be empty')}for(var d=0;d<p.length;d++){if(l=i(p[d]),!t[s].test(l))throw new TypeError('Expected all "'+c.name+'" to match "'+c.pattern+'", but received `'+JSON.stringify(l)+"`");a+=(0===d?c.prefix:c.delimiter)+l}}else{if(l=c.asterisk?encodeURI(p).replace(/[?#]/g,(function(n){return"%"+n.charCodeAt(0).toString(16).toUpperCase()})):i(p),!t[s].test(l))throw new TypeError('Expected "'+c.name+'" to match "'+c.pattern+'", but received "'+l+'"');a+=c.prefix+l}}else a+=c}return a}}function Do(n){return n.replace(/([.+*?=^!:${}()[\]|\/\\])/g,"\\$1")}function Oo(n){return n.replace(/([=!:$\/()])/g,"\\$1")}function jo(n,e){return n.keys=e,n}function qo(n){return n&&n.sensitive?"":"i"}function $o(n,e,t){xo(e)||(t=e||t,e=[]);for(var r=(t=t||{}).strict,a=!1!==t.end,o="",i=0;i<n.length;i++){var s=n[i];if("string"==typeof s)o+=Do(s);else{var c=Do(s.prefix),l="(?:"+s.pattern+")";e.push(s),s.repeat&&(l+="(?:"+c+l+")*"),o+=l=s.optional?s.partial?c+"("+l+")?":"(?:"+c+"("+l+"))?":c+"("+l+")"}}var p=Do(t.delimiter||"/"),d=o.slice(-p.length)===p;return r||(o=(d?o.slice(0,-p.length):o)+"(?:"+p+"(?=$))?"),o+=a?"$":r&&d?"":"(?="+p+"|$)",jo(new RegExp("^"+o,qo(t)),e)}function Mo(n,e,t){return xo(e)||(t=e||t,e=[]),t=t||{},n instanceof RegExp?function(n,e){var t=n.source.match(/\((?!\?)/g);if(t)for(var r=0;r<t.length;r++)e.push({name:r,prefix:null,delimiter:null,optional:!1,repeat:!1,partial:!1,asterisk:!1,pattern:null});return jo(n,e)}(n,e):xo(n)?function(n,e,t){for(var r=[],a=0;a<n.length;a++)r.push(Mo(n[a],e,t).source);return jo(new RegExp("(?:"+r.join("|")+")",qo(t)),e)}(n,e,t):function(n,e,t){return $o(Io(n,t),e,t)}(n,e,t)}wo.parse=Ao,wo.compile=Co,wo.tokensToFunction=Bo,wo.tokensToRegExp=To;var Fo=Object.create(null);function Uo(n,e,t){e=e||{};try{var r=Fo[n]||(Fo[n]=wo.compile(n));return"string"==typeof e.pathMatch&&(e[0]=e.pathMatch),r(e,{pretty:!0})}catch(n){return""}finally{delete e[0]}}function Ro(n,e,t,r){var a="string"==typeof n?{path:n}:n;if(a._normalized)return a;if(a.name){var o=(a=no({},n)).params;return o&&"object"==typeof o&&(a.params=no({},o)),a}if(!a.path&&a.params&&e){(a=no({},a))._normalized=!0;var i=no(no({},e.params),a.params);if(e.name)a.name=e.name,a.params=i;else if(e.matched.length){var s=e.matched[e.matched.length-1].path;a.path=Uo(s,i,e.path)}else 0;return a}var c=function(n){var e="",t="",r=n.indexOf("#");r>=0&&(e=n.slice(r),n=n.slice(0,r));var a=n.indexOf("?");return a>=0&&(t=n.slice(a+1),n=n.slice(0,a)),{path:n,query:t,hash:e}}(a.path||""),l=e&&e.path||"/",p=c.path?Eo(c.path,l,t||a.append):l,d=function(n,e,t){void 0===e&&(e={});var r,a=t||so;try{r=a(n||"")}catch(n){r={}}for(var o in e){var i=e[o];r[o]=Array.isArray(i)?i.map(io):io(i)}return r}(c.query,a.query,r&&r.options.parseQuery),u=a.hash||c.hash;return u&&"#"!==u.charAt(0)&&(u="#"+u),{_normalized:!0,path:p,query:d,hash:u}}var Lo,No=function(){},Go={name:"RouterLink",props:{to:{type:[String,Object],required:!0},tag:{type:String,default:"a"},custom:Boolean,exact:Boolean,exactPath:Boolean,append:Boolean,replace:Boolean,activeClass:String,exactActiveClass:String,ariaCurrentValue:{type:String,default:"page"},event:{type:[String,Array],default:"click"}},render:function(n){var e=this,t=this.$router,r=this.$route,a=t.resolve(this.to,r,this.append),o=a.location,i=a.route,s=a.href,c={},l=t.options.linkActiveClass,p=t.options.linkExactActiveClass,d=null==l?"router-link-active":l,u=null==p?"router-link-exact-active":p,m=null==this.activeClass?d:this.activeClass,h=null==this.exactActiveClass?u:this.exactActiveClass,g=i.redirectedFrom?po(null,Ro(i.redirectedFrom),null,t):i;c[h]=fo(r,g,this.exactPath),c[m]=this.exact||this.exactPath?c[h]:function(n,e){return 0===n.path.replace(lo,"/").indexOf(e.path.replace(lo,"/"))&&(!e.hash||n.hash===e.hash)&&function(n,e){for(var t in e)if(!(t in n))return!1;return!0}(n.query,e.query)}(r,g);var f=c[h]?this.ariaCurrentValue:null,v=function(n){Ko(n)&&(e.replace?t.replace(o,No):t.push(o,No))},b={click:Ko};Array.isArray(this.event)?this.event.forEach((function(n){b[n]=v})):b[this.event]=v;var k={class:c},y=!this.$scopedSlots.$hasNormal&&this.$scopedSlots.default&&this.$scopedSlots.default({href:s,route:i,navigate:v,isActive:c[m],isExactActive:c[h]});if(y){if(1===y.length)return y[0];if(y.length>1||!y.length)return 0===y.length?n():n("span",{},y)}if("a"===this.tag)k.on=b,k.attrs={href:s,"aria-current":f};else{var E=function n(e){var t;if(e)for(var r=0;r<e.length;r++){if("a"===(t=e[r]).tag)return t;if(t.children&&(t=n(t.children)))return t}}(this.$slots.default);if(E){E.isStatic=!1;var _=E.data=no({},E.data);for(var x in _.on=_.on||{},_.on){var w=_.on[x];x in b&&(_.on[x]=Array.isArray(w)?w:[w])}for(var A in b)A in _.on?_.on[A].push(b[A]):_.on[A]=v;var C=E.data.attrs=no({},E.data.attrs);C.href=s,C["aria-current"]=f}else k.on=b}return n(this.tag,k,this.$slots.default)}};function Ko(n){if(!(n.metaKey||n.altKey||n.ctrlKey||n.shiftKey||n.defaultPrevented||void 0!==n.button&&0!==n.button)){if(n.currentTarget&&n.currentTarget.getAttribute){var e=n.currentTarget.getAttribute("target");if(/\b_blank\b/i.test(e))return}return n.preventDefault&&n.preventDefault(),!0}}var Vo="undefined"!=typeof window;function Ho(n,e,t,r,a){var o=e||[],i=t||Object.create(null),s=r||Object.create(null);n.forEach((function(n){!function n(e,t,r,a,o,i){var s=a.path,c=a.name;0;var l=a.pathToRegexpOptions||{},p=function(n,e,t){t||(n=n.replace(/\/$/,""));if("/"===n[0])return n;if(null==e)return n;return _o(e.path+"/"+n)}(s,o,l.strict);"boolean"==typeof a.caseSensitive&&(l.sensitive=a.caseSensitive);var d={path:p,regex:Zo(p,l),components:a.components||{default:a.component},alias:a.alias?"string"==typeof a.alias?[a.alias]:a.alias:[],instances:{},enteredCbs:{},name:c,parent:o,matchAs:i,redirect:a.redirect,beforeEnter:a.beforeEnter,meta:a.meta||{},props:null==a.props?{}:a.components?a.props:{default:a.props}};a.children&&a.children.forEach((function(a){var o=i?_o(i+"/"+a.path):void 0;n(e,t,r,a,d,o)}));t[d.path]||(e.push(d.path),t[d.path]=d);if(void 0!==a.alias)for(var u=Array.isArray(a.alias)?a.alias:[a.alias],m=0;m<u.length;++m){0;var h={path:u[m],children:a.children};n(e,t,r,h,o,d.path||"/")}c&&(r[c]||(r[c]=d))}(o,i,s,n,a)}));for(var c=0,l=o.length;c<l;c++)"*"===o[c]&&(o.push(o.splice(c,1)[0]),l--,c--);return{pathList:o,pathMap:i,nameMap:s}}function Zo(n,e){return wo(n,[],e)}function Wo(n,e){var t=Ho(n),r=t.pathList,a=t.pathMap,o=t.nameMap;function i(n,t,i){var s=Ro(n,t,!1,e),l=s.name;if(l){var p=o[l];if(!p)return c(null,s);var d=p.regex.keys.filter((function(n){return!n.optional})).map((function(n){return n.name}));if("object"!=typeof s.params&&(s.params={}),t&&"object"==typeof t.params)for(var u in t.params)!(u in s.params)&&d.indexOf(u)>-1&&(s.params[u]=t.params[u]);return s.path=Uo(p.path,s.params),c(p,s,i)}if(s.path){s.params={};for(var m=0;m<r.length;m++){var h=r[m],g=a[h];if(Xo(g.regex,s.path,s.params))return c(g,s,i)}}return c(null,s)}function s(n,t){var r=n.redirect,a="function"==typeof r?r(po(n,t,null,e)):r;if("string"==typeof a&&(a={path:a}),!a||"object"!=typeof a)return c(null,t);var s=a,l=s.name,p=s.path,d=t.query,u=t.hash,m=t.params;if(d=s.hasOwnProperty("query")?s.query:d,u=s.hasOwnProperty("hash")?s.hash:u,m=s.hasOwnProperty("params")?s.params:m,l){o[l];return i({_normalized:!0,name:l,query:d,hash:u,params:m},void 0,t)}if(p){var h=function(n,e){return Eo(n,e.parent?e.parent.path:"/",!0)}(p,n);return i({_normalized:!0,path:Uo(h,m),query:d,hash:u},void 0,t)}return c(null,t)}function c(n,t,r){return n&&n.redirect?s(n,r||t):n&&n.matchAs?function(n,e,t){var r=i({_normalized:!0,path:Uo(t,e.params)});if(r){var a=r.matched,o=a[a.length-1];return e.params=r.params,c(o,e)}return c(null,e)}(0,t,n.matchAs):po(n,t,r,e)}return{match:i,addRoute:function(n,e){var t="object"!=typeof n?o[n]:void 0;Ho([e||n],r,a,o,t),t&&t.alias.length&&Ho(t.alias.map((function(n){return{path:n,children:[e]}})),r,a,o,t)},getRoutes:function(){return r.map((function(n){return a[n]}))},addRoutes:function(n){Ho(n,r,a,o)}}}function Xo(n,e,t){var r=e.match(n);if(!r)return!1;if(!t)return!0;for(var a=1,o=r.length;a<o;++a){var i=n.keys[a-1];i&&(t[i.name||"pathMatch"]="string"==typeof r[a]?oo(r[a]):r[a])}return!0}var Yo=Vo&&window.performance&&window.performance.now?window.performance:Date;function Qo(){return Yo.now().toFixed(3)}var Jo=Qo();function ni(){return Jo}function ei(n){return Jo=n}var ti=Object.create(null);function ri(){"scrollRestoration"in window.history&&(window.history.scrollRestoration="manual");var n=window.location.protocol+"//"+window.location.host,e=window.location.href.replace(n,""),t=no({},window.history.state);return t.key=ni(),window.history.replaceState(t,"",e),window.addEventListener("popstate",ii),function(){window.removeEventListener("popstate",ii)}}function ai(n,e,t,r){if(n.app){var a=n.options.scrollBehavior;a&&n.app.$nextTick((function(){var o=function(){var n=ni();if(n)return ti[n]}(),i=a.call(n,e,t,r?o:null);i&&("function"==typeof i.then?i.then((function(n){di(n,o)})).catch((function(n){0})):di(i,o))}))}}function oi(){var n=ni();n&&(ti[n]={x:window.pageXOffset,y:window.pageYOffset})}function ii(n){oi(),n.state&&n.state.key&&ei(n.state.key)}function si(n){return li(n.x)||li(n.y)}function ci(n){return{x:li(n.x)?n.x:window.pageXOffset,y:li(n.y)?n.y:window.pageYOffset}}function li(n){return"number"==typeof n}var pi=/^#\d/;function di(n,e){var t,r="object"==typeof n;if(r&&"string"==typeof n.selector){var a=pi.test(n.selector)?document.getElementById(n.selector.slice(1)):document.querySelector(n.selector);if(a){var o=n.offset&&"object"==typeof n.offset?n.offset:{};e=function(n,e){var t=document.documentElement.getBoundingClientRect(),r=n.getBoundingClientRect();return{x:r.left-t.left-e.x,y:r.top-t.top-e.y}}(a,o={x:li((t=o).x)?t.x:0,y:li(t.y)?t.y:0})}else si(n)&&(e=ci(n))}else r&&si(n)&&(e=ci(n));e&&("scrollBehavior"in document.documentElement.style?window.scrollTo({left:e.x,top:e.y,behavior:n.behavior}):window.scrollTo(e.x,e.y))}var ui,mi=Vo&&((-1===(ui=window.navigator.userAgent).indexOf("Android 2.")&&-1===ui.indexOf("Android 4.0")||-1===ui.indexOf("Mobile Safari")||-1!==ui.indexOf("Chrome")||-1!==ui.indexOf("Windows Phone"))&&window.history&&"function"==typeof window.history.pushState);function hi(n,e){oi();var t=window.history;try{if(e){var r=no({},t.state);r.key=ni(),t.replaceState(r,"",n)}else t.pushState({key:ei(Qo())},"",n)}catch(t){window.location[e?"replace":"assign"](n)}}function gi(n){hi(n,!0)}function fi(n,e,t){var r=function(a){a>=n.length?t():n[a]?e(n[a],(function(){r(a+1)})):r(a+1)};r(0)}var vi={redirected:2,aborted:4,cancelled:8,duplicated:16};function bi(n,e){return yi(n,e,vi.redirected,'Redirected when going from "'+n.fullPath+'" to "'+function(n){if("string"==typeof n)return n;if("path"in n)return n.path;var e={};return Ei.forEach((function(t){t in n&&(e[t]=n[t])})),JSON.stringify(e,null,2)}(e)+'" via a navigation guard.')}function ki(n,e){return yi(n,e,vi.cancelled,'Navigation cancelled from "'+n.fullPath+'" to "'+e.fullPath+'" with a new navigation.')}function yi(n,e,t,r){var a=new Error(r);return a._isRouter=!0,a.from=n,a.to=e,a.type=t,a}var Ei=["params","query","hash"];function _i(n){return Object.prototype.toString.call(n).indexOf("Error")>-1}function xi(n,e){return _i(n)&&n._isRouter&&(null==e||n.type===e)}function wi(n){return function(e,t,r){var a=!1,o=0,i=null;Ai(n,(function(n,e,t,s){if("function"==typeof n&&void 0===n.cid){a=!0,o++;var c,l=Ti((function(e){var a;((a=e).__esModule||Bi&&"Module"===a[Symbol.toStringTag])&&(e=e.default),n.resolved="function"==typeof e?e:Lo.extend(e),t.components[s]=e,--o<=0&&r()})),p=Ti((function(n){var e="Failed to resolve async component "+s+": "+n;i||(i=_i(n)?n:new Error(e),r(i))}));try{c=n(l,p)}catch(n){p(n)}if(c)if("function"==typeof c.then)c.then(l,p);else{var d=c.component;d&&"function"==typeof d.then&&d.then(l,p)}}})),a||r()}}function Ai(n,e){return Ci(n.map((function(n){return Object.keys(n.components).map((function(t){return e(n.components[t],n.instances[t],n,t)}))})))}function Ci(n){return Array.prototype.concat.apply([],n)}var Bi="function"==typeof Symbol&&"symbol"==typeof Symbol.toStringTag;function Ti(n){var e=!1;return function(){for(var t=[],r=arguments.length;r--;)t[r]=arguments[r];if(!e)return e=!0,n.apply(this,t)}}var Pi=function(n,e){this.router=n,this.base=function(n){if(!n)if(Vo){var e=document.querySelector("base");n=(n=e&&e.getAttribute("href")||"/").replace(/^https?:\/\/[^\/]+/,"")}else n="/";"/"!==n.charAt(0)&&(n="/"+n);return n.replace(/\/$/,"")}(e),this.current=mo,this.pending=null,this.ready=!1,this.readyCbs=[],this.readyErrorCbs=[],this.errorCbs=[],this.listeners=[]};function Ii(n,e,t,r){var a=Ai(n,(function(n,r,a,o){var i=function(n,e){"function"!=typeof n&&(n=Lo.extend(n));return n.options[e]}(n,e);if(i)return Array.isArray(i)?i.map((function(n){return t(n,r,a,o)})):t(i,r,a,o)}));return Ci(r?a.reverse():a)}function Si(n,e){if(e)return function(){return n.apply(e,arguments)}}Pi.prototype.listen=function(n){this.cb=n},Pi.prototype.onReady=function(n,e){this.ready?n():(this.readyCbs.push(n),e&&this.readyErrorCbs.push(e))},Pi.prototype.onError=function(n){this.errorCbs.push(n)},Pi.prototype.transitionTo=function(n,e,t){var r,a=this;try{r=this.router.match(n,this.current)}catch(n){throw this.errorCbs.forEach((function(e){e(n)})),n}var o=this.current;this.confirmTransition(r,(function(){a.updateRoute(r),e&&e(r),a.ensureURL(),a.router.afterHooks.forEach((function(n){n&&n(r,o)})),a.ready||(a.ready=!0,a.readyCbs.forEach((function(n){n(r)})))}),(function(n){t&&t(n),n&&!a.ready&&(xi(n,vi.redirected)&&o===mo||(a.ready=!0,a.readyErrorCbs.forEach((function(e){e(n)}))))}))},Pi.prototype.confirmTransition=function(n,e,t){var r=this,a=this.current;this.pending=n;var o,i,s=function(n){!xi(n)&&_i(n)&&(r.errorCbs.length?r.errorCbs.forEach((function(e){e(n)})):console.error(n)),t&&t(n)},c=n.matched.length-1,l=a.matched.length-1;if(fo(n,a)&&c===l&&n.matched[c]===a.matched[l])return this.ensureURL(),n.hash&&ai(this.router,a,n,!1),s(((i=yi(o=a,n,vi.duplicated,'Avoided redundant navigation to current location: "'+o.fullPath+'".')).name="NavigationDuplicated",i));var p=function(n,e){var t,r=Math.max(n.length,e.length);for(t=0;t<r&&n[t]===e[t];t++);return{updated:e.slice(0,t),activated:e.slice(t),deactivated:n.slice(t)}}(this.current.matched,n.matched),d=p.updated,u=p.deactivated,m=p.activated,h=[].concat(function(n){return Ii(n,"beforeRouteLeave",Si,!0)}(u),this.router.beforeHooks,function(n){return Ii(n,"beforeRouteUpdate",Si)}(d),m.map((function(n){return n.beforeEnter})),wi(m)),g=function(e,t){if(r.pending!==n)return s(ki(a,n));try{e(n,a,(function(e){!1===e?(r.ensureURL(!0),s(function(n,e){return yi(n,e,vi.aborted,'Navigation aborted from "'+n.fullPath+'" to "'+e.fullPath+'" via a navigation guard.')}(a,n))):_i(e)?(r.ensureURL(!0),s(e)):"string"==typeof e||"object"==typeof e&&("string"==typeof e.path||"string"==typeof e.name)?(s(bi(a,n)),"object"==typeof e&&e.replace?r.replace(e):r.push(e)):t(e)}))}catch(n){s(n)}};fi(h,g,(function(){fi(function(n){return Ii(n,"beforeRouteEnter",(function(n,e,t,r){return function(n,e,t){return function(r,a,o){return n(r,a,(function(n){"function"==typeof n&&(e.enteredCbs[t]||(e.enteredCbs[t]=[]),e.enteredCbs[t].push(n)),o(n)}))}}(n,t,r)}))}(m).concat(r.router.resolveHooks),g,(function(){if(r.pending!==n)return s(ki(a,n));r.pending=null,e(n),r.router.app&&r.router.app.$nextTick((function(){bo(n)}))}))}))},Pi.prototype.updateRoute=function(n){this.current=n,this.cb&&this.cb(n)},Pi.prototype.setupListeners=function(){},Pi.prototype.teardown=function(){this.listeners.forEach((function(n){n()})),this.listeners=[],this.current=mo,this.pending=null};var zi=function(n){function e(e,t){n.call(this,e,t),this._startLocation=Di(this.base)}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router,t=e.options.scrollBehavior,r=mi&&t;r&&this.listeners.push(ri());var a=function(){var t=n.current,a=Di(n.base);n.current===mo&&a===n._startLocation||n.transitionTo(a,(function(n){r&&ai(e,n,t,!0)}))};window.addEventListener("popstate",a),this.listeners.push((function(){window.removeEventListener("popstate",a)}))}},e.prototype.go=function(n){window.history.go(n)},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){hi(_o(r.base+n.fullPath)),ai(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){gi(_o(r.base+n.fullPath)),ai(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.ensureURL=function(n){if(Di(this.base)!==this.current.fullPath){var e=_o(this.base+this.current.fullPath);n?hi(e):gi(e)}},e.prototype.getCurrentLocation=function(){return Di(this.base)},e}(Pi);function Di(n){var e=window.location.pathname,t=e.toLowerCase(),r=n.toLowerCase();return!n||t!==r&&0!==t.indexOf(_o(r+"/"))||(e=e.slice(n.length)),(e||"/")+window.location.search+window.location.hash}var Oi=function(n){function e(e,t,r){n.call(this,e,t),r&&function(n){var e=Di(n);if(!/^\/#/.test(e))return window.location.replace(_o(n+"/#"+e)),!0}(this.base)||ji()}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.setupListeners=function(){var n=this;if(!(this.listeners.length>0)){var e=this.router.options.scrollBehavior,t=mi&&e;t&&this.listeners.push(ri());var r=function(){var e=n.current;ji()&&n.transitionTo(qi(),(function(r){t&&ai(n.router,r,e,!0),mi||Fi(r.fullPath)}))},a=mi?"popstate":"hashchange";window.addEventListener(a,r),this.listeners.push((function(){window.removeEventListener(a,r)}))}},e.prototype.push=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Mi(n.fullPath),ai(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this,a=this.current;this.transitionTo(n,(function(n){Fi(n.fullPath),ai(r.router,n,a,!1),e&&e(n)}),t)},e.prototype.go=function(n){window.history.go(n)},e.prototype.ensureURL=function(n){var e=this.current.fullPath;qi()!==e&&(n?Mi(e):Fi(e))},e.prototype.getCurrentLocation=function(){return qi()},e}(Pi);function ji(){var n=qi();return"/"===n.charAt(0)||(Fi("/"+n),!1)}function qi(){var n=window.location.href,e=n.indexOf("#");return e<0?"":n=n.slice(e+1)}function $i(n){var e=window.location.href,t=e.indexOf("#");return(t>=0?e.slice(0,t):e)+"#"+n}function Mi(n){mi?hi($i(n)):window.location.hash=n}function Fi(n){mi?gi($i(n)):window.location.replace($i(n))}var Ui=function(n){function e(e,t){n.call(this,e,t),this.stack=[],this.index=-1}return n&&(e.__proto__=n),e.prototype=Object.create(n&&n.prototype),e.prototype.constructor=e,e.prototype.push=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index+1).concat(n),r.index++,e&&e(n)}),t)},e.prototype.replace=function(n,e,t){var r=this;this.transitionTo(n,(function(n){r.stack=r.stack.slice(0,r.index).concat(n),e&&e(n)}),t)},e.prototype.go=function(n){var e=this,t=this.index+n;if(!(t<0||t>=this.stack.length)){var r=this.stack[t];this.confirmTransition(r,(function(){var n=e.current;e.index=t,e.updateRoute(r),e.router.afterHooks.forEach((function(e){e&&e(r,n)}))}),(function(n){xi(n,vi.duplicated)&&(e.index=t)}))}},e.prototype.getCurrentLocation=function(){var n=this.stack[this.stack.length-1];return n?n.fullPath:"/"},e.prototype.ensureURL=function(){},e}(Pi),Ri=function(n){void 0===n&&(n={}),this.app=null,this.apps=[],this.options=n,this.beforeHooks=[],this.resolveHooks=[],this.afterHooks=[],this.matcher=Wo(n.routes||[],this);var e=n.mode||"hash";switch(this.fallback="history"===e&&!mi&&!1!==n.fallback,this.fallback&&(e="hash"),Vo||(e="abstract"),this.mode=e,e){case"history":this.history=new zi(this,n.base);break;case"hash":this.history=new Oi(this,n.base,this.fallback);break;case"abstract":this.history=new Ui(this,n.base);break;default:0}},Li={currentRoute:{configurable:!0}};function Ni(n,e){return n.push(e),function(){var t=n.indexOf(e);t>-1&&n.splice(t,1)}}Ri.prototype.match=function(n,e,t){return this.matcher.match(n,e,t)},Li.currentRoute.get=function(){return this.history&&this.history.current},Ri.prototype.init=function(n){var e=this;if(this.apps.push(n),n.$once("hook:destroyed",(function(){var t=e.apps.indexOf(n);t>-1&&e.apps.splice(t,1),e.app===n&&(e.app=e.apps[0]||null),e.app||e.history.teardown()})),!this.app){this.app=n;var t=this.history;if(t instanceof zi||t instanceof Oi){var r=function(n){t.setupListeners(),function(n){var r=t.current,a=e.options.scrollBehavior;mi&&a&&"fullPath"in n&&ai(e,n,r,!1)}(n)};t.transitionTo(t.getCurrentLocation(),r,r)}t.listen((function(n){e.apps.forEach((function(e){e._route=n}))}))}},Ri.prototype.beforeEach=function(n){return Ni(this.beforeHooks,n)},Ri.prototype.beforeResolve=function(n){return Ni(this.resolveHooks,n)},Ri.prototype.afterEach=function(n){return Ni(this.afterHooks,n)},Ri.prototype.onReady=function(n,e){this.history.onReady(n,e)},Ri.prototype.onError=function(n){this.history.onError(n)},Ri.prototype.push=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.push(n,e,t)}));this.history.push(n,e,t)},Ri.prototype.replace=function(n,e,t){var r=this;if(!e&&!t&&"undefined"!=typeof Promise)return new Promise((function(e,t){r.history.replace(n,e,t)}));this.history.replace(n,e,t)},Ri.prototype.go=function(n){this.history.go(n)},Ri.prototype.back=function(){this.go(-1)},Ri.prototype.forward=function(){this.go(1)},Ri.prototype.getMatchedComponents=function(n){var e=n?n.matched?n:this.resolve(n).route:this.currentRoute;return e?[].concat.apply([],e.matched.map((function(n){return Object.keys(n.components).map((function(e){return n.components[e]}))}))):[]},Ri.prototype.resolve=function(n,e,t){var r=Ro(n,e=e||this.history.current,t,this),a=this.match(r,e),o=a.redirectedFrom||a.fullPath;return{location:r,route:a,href:function(n,e,t){var r="hash"===t?"#"+e:e;return n?_o(n+"/"+r):r}(this.history.base,o,this.mode),normalizedTo:r,resolved:a}},Ri.prototype.getRoutes=function(){return this.matcher.getRoutes()},Ri.prototype.addRoute=function(n,e){this.matcher.addRoute(n,e),this.history.current!==mo&&this.history.transitionTo(this.history.getCurrentLocation())},Ri.prototype.addRoutes=function(n){this.matcher.addRoutes(n),this.history.current!==mo&&this.history.transitionTo(this.history.getCurrentLocation())},Object.defineProperties(Ri.prototype,Li),Ri.install=function n(e){if(!n.installed||Lo!==e){n.installed=!0,Lo=e;var t=function(n){return void 0!==n},r=function(n,e){var r=n.$options._parentVnode;t(r)&&t(r=r.data)&&t(r=r.registerRouteInstance)&&r(n,e)};e.mixin({beforeCreate:function(){t(this.$options.router)?(this._routerRoot=this,this._router=this.$options.router,this._router.init(this),e.util.defineReactive(this,"_route",this._router.history.current)):this._routerRoot=this.$parent&&this.$parent._routerRoot||this,r(this,this)},destroyed:function(){r(this)}}),Object.defineProperty(e.prototype,"$router",{get:function(){return this._routerRoot._router}}),Object.defineProperty(e.prototype,"$route",{get:function(){return this._routerRoot._route}}),e.component("RouterView",ko),e.component("RouterLink",Go);var a=e.config.optionMergeStrategies;a.beforeRouteEnter=a.beforeRouteLeave=a.beforeRouteUpdate=a.created}},Ri.version="3.5.4",Ri.isNavigationFailure=xi,Ri.NavigationFailureType=vi,Ri.START_LOCATION=mo,Vo&&window.Vue&&window.Vue.use(Ri);var Gi=Ri;t(103);t(126);var Ki={NotFound:()=>Promise.all([t.e(0),t.e(5)]).then(t.bind(null,331)),Layout:()=>Promise.all([t.e(0),t.e(2)]).then(t.bind(null,330))},Vi={"v-6ee71fe0":()=>t.e(6).then(t.bind(null,333)),"v-06a3e7f2":()=>t.e(8).then(t.bind(null,334)),"v-fc698e82":()=>t.e(7).then(t.bind(null,335)),"v-3b2b3709":()=>t.e(10).then(t.bind(null,336)),"v-3a9d6f9d":()=>t.e(9).then(t.bind(null,337)),"v-561954fe":()=>t.e(11).then(t.bind(null,332)),"v-169b12eb":()=>t.e(12).then(t.bind(null,338)),"v-be755618":()=>t.e(15).then(t.bind(null,339)),"v-132121e4":()=>t.e(14).then(t.bind(null,340)),"v-4b9555d9":()=>t.e(13).then(t.bind(null,341)),"v-26c04c03":()=>t.e(16).then(t.bind(null,342)),"v-4d3d3bec":()=>t.e(17).then(t.bind(null,343)),"v-59c6ef63":()=>t.e(18).then(t.bind(null,344)),"v-0b248a60":()=>t.e(19).then(t.bind(null,345)),"v-2f3eb2e7":()=>t.e(20).then(t.bind(null,346)),"v-1247b65b":()=>t.e(21).then(t.bind(null,347)),"v-cbe0d60a":()=>t.e(22).then(t.bind(null,348)),"v-81d98e10":()=>t.e(23).then(t.bind(null,349)),"v-16eeeecc":()=>t.e(24).then(t.bind(null,350)),"v-c5d8330a":()=>t.e(25).then(t.bind(null,351)),"v-211c03e0":()=>t.e(27).then(t.bind(null,352)),"v-6da5591e":()=>t.e(26).then(t.bind(null,353)),"v-019d3da2":()=>t.e(28).then(t.bind(null,354)),"v-3d63ec0a":()=>t.e(30).then(t.bind(null,355)),"v-185c15db":()=>t.e(29).then(t.bind(null,356)),"v-680c343b":()=>t.e(31).then(t.bind(null,357)),"v-9b6819e6":()=>t.e(32).then(t.bind(null,358)),"v-db387184":()=>t.e(33).then(t.bind(null,359)),"v-07c97ac3":()=>t.e(34).then(t.bind(null,360)),"v-335e284a":()=>t.e(35).then(t.bind(null,361)),"v-33c779e9":()=>t.e(3).then(t.bind(null,362)),"v-2e5f8162":()=>t.e(36).then(t.bind(null,363)),"v-3f9afa48":()=>t.e(37).then(t.bind(null,364)),"v-e15ee02a":()=>t.e(38).then(t.bind(null,365)),"v-3a4f35cc":()=>t.e(40).then(t.bind(null,366)),"v-50a8e3a0":()=>t.e(39).then(t.bind(null,367)),"v-77a29116":()=>t.e(41).then(t.bind(null,368)),"v-58d0a1ce":()=>t.e(42).then(t.bind(null,369)),"v-d7e2a582":()=>t.e(43).then(t.bind(null,370)),"v-7ebc8c8b":()=>t.e(44).then(t.bind(null,371)),"v-33dd887e":()=>t.e(45).then(t.bind(null,372)),"v-03d01b37":()=>t.e(46).then(t.bind(null,373)),"v-6e85c154":()=>t.e(48).then(t.bind(null,374)),"v-68efef1e":()=>t.e(47).then(t.bind(null,375)),"v-5b19c60a":()=>t.e(49).then(t.bind(null,376)),"v-e1ca0762":()=>t.e(52).then(t.bind(null,377)),"v-32d723b6":()=>t.e(51).then(t.bind(null,378)),"v-5d2403be":()=>t.e(53).then(t.bind(null,379)),"v-43971d6a":()=>t.e(50).then(t.bind(null,380)),"v-11c4c310":()=>t.e(54).then(t.bind(null,381)),"v-3b906eab":()=>t.e(55).then(t.bind(null,382)),"v-0523fe6a":()=>t.e(56).then(t.bind(null,383)),"v-31339544":()=>t.e(60).then(t.bind(null,384)),"v-7e4b3a46":()=>t.e(61).then(t.bind(null,385)),"v-be31a184":()=>t.e(62).then(t.bind(null,386)),"v-338caad2":()=>t.e(57).then(t.bind(null,387)),"v-572ce303":()=>t.e(63).then(t.bind(null,388)),"v-131bc9a5":()=>t.e(64).then(t.bind(null,389)),"v-582a5ac3":()=>t.e(58).then(t.bind(null,390)),"v-6a155cef":()=>t.e(65).then(t.bind(null,391)),"v-fa04c054":()=>t.e(67).then(t.bind(null,392)),"v-394a82c1":()=>t.e(66).then(t.bind(null,393)),"v-6c7b2800":()=>t.e(68).then(t.bind(null,394)),"v-306f5d23":()=>t.e(59).then(t.bind(null,395)),"v-0169ea0d":()=>t.e(71).then(t.bind(null,396)),"v-51cd8504":()=>t.e(70).then(t.bind(null,397)),"v-783e73dc":()=>t.e(69).then(t.bind(null,398)),"v-5b58f46b":()=>t.e(72).then(t.bind(null,399)),"v-d695f1cc":()=>t.e(74).then(t.bind(null,400)),"v-92ed690a":()=>t.e(73).then(t.bind(null,401)),"v-018b12ce":()=>t.e(75).then(t.bind(null,402)),"v-3f6d3b4e":()=>t.e(76).then(t.bind(null,403)),"v-13d7c644":()=>t.e(77).then(t.bind(null,404)),"v-080925d0":()=>t.e(80).then(t.bind(null,405)),"v-2e18135a":()=>t.e(79).then(t.bind(null,406)),"v-a2c6b924":()=>t.e(81).then(t.bind(null,407)),"v-4a20ad90":()=>t.e(78).then(t.bind(null,408)),"v-51e55098":()=>t.e(83).then(t.bind(null,409)),"v-20df4130":()=>t.e(82).then(t.bind(null,410)),"v-1efcbbda":()=>t.e(84).then(t.bind(null,411)),"v-09ac84c7":()=>t.e(85).then(t.bind(null,412)),"v-7d5d8b2d":()=>t.e(87).then(t.bind(null,413)),"v-4ed9e4ca":()=>t.e(86).then(t.bind(null,414)),"v-6202dee6":()=>t.e(88).then(t.bind(null,415)),"v-18dfbaf2":()=>t.e(89).then(t.bind(null,416)),"v-994f98d2":()=>t.e(90).then(t.bind(null,417)),"v-ea545412":()=>t.e(91).then(t.bind(null,418)),"v-1d3069d2":()=>t.e(92).then(t.bind(null,419)),"v-0c8b6730":()=>t.e(93).then(t.bind(null,420))};function Hi(n){const e=Object.create(null);return function(t){return e[t]||(e[t]=n(t))}}const Zi=/-(\w)/g,Wi=Hi(n=>n.replace(Zi,(n,e)=>e?e.toUpperCase():"")),Xi=/\B([A-Z])/g,Yi=Hi(n=>n.replace(Xi,"-$1").toLowerCase()),Qi=Hi(n=>n.charAt(0).toUpperCase()+n.slice(1));function Ji(n,e){if(!e)return;if(n(e))return n(e);return e.includes("-")?n(Qi(Wi(e))):n(Qi(e))||n(Yi(e))}const ns=Object.assign({},Ki,Vi),es=n=>ns[n],ts=n=>Vi[n],rs=n=>Ki[n],as=n=>Kt.component(n);function os(n){return Ji(ts,n)}function is(n){return Ji(rs,n)}function ss(n){return Ji(es,n)}function cs(n){return Ji(as,n)}function ls(...n){return Promise.all(n.filter(n=>n).map(async n=>{if(!cs(n)&&ss(n)){const e=await ss(n)();Kt.component(n,e.default)}}))}function ps(n,e){"undefined"!=typeof window&&window.__VUEPRESS__&&(window.__VUEPRESS__[n]=e)}var ds=t(92),us=t.n(ds),ms=t(93),hs=t.n(ms),gs={created(){if(this.siteMeta=this.$site.headTags.filter(([n])=>"meta"===n).map(([n,e])=>e),this.$ssrContext){const e=this.getMergedMetaTags();this.$ssrContext.title=this.$title,this.$ssrContext.lang=this.$lang,this.$ssrContext.pageMeta=(n=e)?n.map(n=>{let e="<meta";return Object.keys(n).forEach(t=>{e+=` ${t}="${hs()(n[t])}"`}),e+">"}).join("\n    "):"",this.$ssrContext.canonicalLink=vs(this.$canonicalUrl)}var n},mounted(){this.currentMetaTags=[...document.querySelectorAll("meta")],this.updateMeta(),this.updateCanonicalLink()},methods:{updateMeta(){document.title=this.$title,document.documentElement.lang=this.$lang;const n=this.getMergedMetaTags();this.currentMetaTags=bs(n,this.currentMetaTags)},getMergedMetaTags(){const n=this.$page.frontmatter.meta||[];return us()([{name:"description",content:this.$description}],n,this.siteMeta,ks)},updateCanonicalLink(){fs(),this.$canonicalUrl&&document.head.insertAdjacentHTML("beforeend",vs(this.$canonicalUrl))}},watch:{$page(){this.updateMeta(),this.updateCanonicalLink()}},beforeDestroy(){bs(null,this.currentMetaTags),fs()}};function fs(){const n=document.querySelector("link[rel='canonical']");n&&n.remove()}function vs(n=""){return n?`<link href="${n}" rel="canonical" />`:""}function bs(n,e){if(e&&[...e].filter(n=>n.parentNode===document.head).forEach(n=>document.head.removeChild(n)),n)return n.map(n=>{const e=document.createElement("meta");return Object.keys(n).forEach(t=>{e.setAttribute(t,n[t])}),document.head.appendChild(e),e})}function ks(n){for(const e of["name","property","itemprop"])if(n.hasOwnProperty(e))return n[e]+e;return JSON.stringify(n)}var ys=t(49),Es={mounted(){window.addEventListener("scroll",this.onScroll)},methods:{onScroll:t.n(ys)()((function(){this.setActiveHash()}),300),setActiveHash(){const n=[].slice.call(document.querySelectorAll(".sidebar-link")),e=[].slice.call(document.querySelectorAll(".header-anchor")).filter(e=>n.some(n=>n.hash===e.hash)),t=Math.max(window.pageYOffset,document.documentElement.scrollTop,document.body.scrollTop),r=Math.max(document.documentElement.scrollHeight,document.body.scrollHeight),a=window.innerHeight+t;for(let n=0;n<e.length;n++){const o=e[n],i=e[n+1],s=0===n&&0===t||t>=o.parentElement.offsetTop+10&&(!i||t<i.parentElement.offsetTop-10),c=decodeURIComponent(this.$route.hash);if(s&&c!==decodeURIComponent(o.hash)){const t=o;if(a===r)for(let t=n+1;t<e.length;t++)if(c===decodeURIComponent(e[t].hash))return;return this.$vuepress.$set("disableScrollBehavior",!0),void this.$router.replace(decodeURIComponent(t.hash),()=>{this.$nextTick(()=>{this.$vuepress.$set("disableScrollBehavior",!1)})})}}}},beforeDestroy(){window.removeEventListener("scroll",this.onScroll)}},_s=t(23),xs=t.n(_s),ws={mounted(){xs.a.configure({showSpinner:!1}),this.$router.beforeEach((n,e,t)=>{n.path===e.path||Kt.component(n.name)||xs.a.start(),t()}),this.$router.afterEach(()=>{xs.a.done(),this.isSidebarOpen=!1})}};t(233),t(234);class As{constructor(){this.containerEl=document.getElementById("message-container"),this.containerEl||(this.containerEl=document.createElement("div"),this.containerEl.id="message-container",document.body.appendChild(this.containerEl))}show({text:n="",duration:e=3e3}){let t=document.createElement("div");t.className="message move-in",t.innerHTML=`\n      <i style="fill: #06a35a;font-size: 14px;display:inline-flex;align-items: center;">\n        <svg style="fill: #06a35a;font-size: 14px;" t="1572421810237" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2323" width="16" height="16"><path d="M822.811993 824.617989c-83.075838 81.99224-188.546032 124.613757-316.049383 127.86455-122.085362-3.250794-223.943563-45.87231-305.935802-127.86455s-124.613757-184.21164-127.86455-305.935802c3.250794-127.503351 45.87231-232.973545 127.86455-316.049383 81.99224-83.075838 184.21164-126.058554 305.935802-129.309347 127.503351 3.250794 232.973545 46.23351 316.049383 129.309347 83.075838 83.075838 126.058554 188.546032 129.309347 316.049383C949.231746 640.406349 905.887831 742.62575 822.811993 824.617989zM432.716755 684.111464c3.973192 3.973192 8.307584 5.779189 13.364374 6.140388 5.05679 0.361199 9.752381-1.444797 13.364374-5.417989l292.571429-287.514638c3.973192-3.973192 5.779189-8.307584 5.779189-13.364374 0-5.05679-1.805996-9.752381-5.779189-13.364374l1.805996 1.805996c-3.973192-3.973192-8.668783-5.779189-14.086772-6.140388-5.417989-0.361199-10.47478 1.444797-14.809171 5.417989l-264.397884 220.33157c-3.973192 3.250794-8.668783 4.695591-14.447972 4.695591-5.779189 0-10.835979-1.444797-15.53157-3.973192l-94.273016-72.962257c-4.334392-3.250794-9.391182-4.334392-14.447972-3.973192s-9.391182 3.250794-12.641975 7.585185l-2.889594 3.973192c-3.250794 4.334392-4.334392 9.391182-3.973192 14.809171 0.722399 5.417989 2.528395 10.11358 5.779189 14.086772L432.716755 684.111464z" p-id="2324"></path></svg>\n      </i>\n      <div class="text">${n}</div>\n    `,this.containerEl.appendChild(t),e>0&&setTimeout(()=>{this.close(t)},e)}close(n){n.className=n.className.replace("move-in",""),n.className+="move-out",n.addEventListener("animationend",()=>{n.remove()})}}var Cs={mounted(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},updated(){!!/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)||this.updateCopy()},methods:{updateCopy(){setTimeout(()=>{(['div[class*="language-"] pre','div[class*="aside-code"] aside']instanceof Array||Array.isArray(['div[class*="language-"] pre','div[class*="aside-code"] aside']))&&['div[class*="language-"] pre','div[class*="aside-code"] aside'].forEach(n=>{document.querySelectorAll(n).forEach(this.generateCopyButton)})},1e3)},generateCopyButton(n){if(n.classList.contains("codecopy-enabled"))return;const e=document.createElement("i");e.className="code-copy",e.innerHTML='<svg  style="color:#aaa;font-size:14px" t="1572422231464" class="icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="3201" width="14" height="14"><path d="M866.461538 39.384615H354.461538c-43.323077 0-78.769231 35.446154-78.76923 78.769231v39.384616h472.615384c43.323077 0 78.769231 35.446154 78.769231 78.76923v551.384616h39.384615c43.323077 0 78.769231-35.446154 78.769231-78.769231V118.153846c0-43.323077-35.446154-78.769231-78.769231-78.769231z m-118.153846 275.692308c0-43.323077-35.446154-78.769231-78.76923-78.769231H157.538462c-43.323077 0-78.769231 35.446154-78.769231 78.769231v590.769231c0 43.323077 35.446154 78.769231 78.769231 78.769231h512c43.323077 0 78.769231-35.446154 78.76923-78.769231V315.076923z m-354.461538 137.846154c0 11.815385-7.876923 19.692308-19.692308 19.692308h-157.538461c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h157.538461c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z m157.538461 315.076923c0 11.815385-7.876923 19.692308-19.692307 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h315.076923c11.815385 0 19.692308 7.876923 19.692307 19.692308v39.384615z m78.769231-157.538462c0 11.815385-7.876923 19.692308-19.692308 19.692308H216.615385c-11.815385 0-19.692308-7.876923-19.692308-19.692308v-39.384615c0-11.815385 7.876923-19.692308 19.692308-19.692308h393.846153c11.815385 0 19.692308 7.876923 19.692308 19.692308v39.384615z" p-id="3202"></path></svg>',e.title="Copy to clipboard",e.addEventListener("click",()=>{this.copyToClipboard(n.innerText)}),n.appendChild(e),n.classList.add("codecopy-enabled")},copyToClipboard(n){const e=document.createElement("textarea");e.value=n,e.setAttribute("readonly",""),e.style.position="absolute",e.style.left="-9999px",document.body.appendChild(e);const t=document.getSelection().rangeCount>0&&document.getSelection().getRangeAt(0);e.select(),document.execCommand("copy");(new As).show({text:"复制成功 🎉",duration:1e3}),document.body.removeChild(e),t&&(document.getSelection().removeAllRanges(),document.getSelection().addRange(t))}}};!function(n,e){void 0===e&&(e={});var t=e.insertAt;if(n&&"undefined"!=typeof document){var r=document.head||document.getElementsByTagName("head")[0],a=document.createElement("style");a.type="text/css","top"===t&&r.firstChild?r.insertBefore(a,r.firstChild):r.appendChild(a),a.styleSheet?a.styleSheet.cssText=n:a.appendChild(document.createTextNode(n))}}("@media (max-width: 1000px) {\n  .vuepress-plugin-demo-block__h_code {\n    display: none;\n  }\n  .vuepress-plugin-demo-block__app {\n    margin-left: auto !important;\n    margin-right: auto !important;\n  }\n}\n.vuepress-plugin-demo-block__wrapper {\n  margin-top: 10px;\n  border: 1px solid #ebebeb;\n  border-radius: 4px;\n  transition: all 0.2s;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display {\n  height: 400px;\n  display: flex;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__app {\n  width: 300px;\n  border: 1px solid #ebebeb;\n  box-shadow: 1px 1px 3px #ebebeb;\n  margin-right: 5px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code {\n  flex: 1;\n  overflow: auto;\n  height: 100%;\n}\n.vuepress-plugin-demo-block__wrapper.vuepress-plugin-demo-block__horizontal .vuepress-plugin-demo-block__display .vuepress-plugin-demo-block__h_code > pre {\n  overflow: visible;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  max-height: 400px;\n  overflow: auto;\n}\n.vuepress-plugin-demo-block__wrapper div {\n  box-sizing: border-box;\n}\n.vuepress-plugin-demo-block__wrapper:hover {\n  box-shadow: 0 0 11px rgba(33, 33, 33, 0.2);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code {\n  overflow: hidden;\n  height: 0;\n  padding: 0 !important;\n  background-color: #282c34;\n  border-radius: 0 !important;\n  transition: height 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__code pre {\n  margin: 0 !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__display {\n  padding: 20px;\n  border-bottom: 1px solid #ebebeb;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer {\n  position: relative;\n  text-align: center;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__codepen {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer.vuepress-plugin-demo-block__show-link .vuepress-plugin-demo-block__expand::before {\n  border-top: none;\n  border-right: 6px solid transparent;\n  border-bottom: 6px solid #ccc;\n  border-left: 6px solid transparent;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__codepen,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand span,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand {\n  opacity: 1;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover .vuepress-plugin-demo-block__expand::before {\n  border-top-color: #3eaf7c !important;\n  border-bottom-color: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer:hover svg {\n  fill: #3eaf7c !important;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand-text {\n  transition: all 0.5s;\n  opacity: 0;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:nth-last-child(2) {\n  right: 50px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer form:last-child {\n  right: 10px;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button {\n  border-color: transparent;\n  background-color: transparent;\n  font-size: 14px;\n  color: #3eaf7c;\n  cursor: pointer;\n  outline: none;\n  margin: 0;\n  width: 46px;\n  position: relative;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::before {\n  content: attr(data-tip);\n  white-space: nowrap;\n  position: absolute;\n  top: -30px;\n  left: 50%;\n  color: #eee;\n  line-height: 1;\n  z-index: 1000;\n  border-radius: 4px;\n  padding: 6px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  background-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button:hover::after {\n  content: '' !important;\n  display: block;\n  position: absolute;\n  left: 50%;\n  top: -5px;\n  -webkit-transform: translateX(-50%);\n          transform: translateX(-50%);\n  border: 5px solid transparent;\n  border-top-color: rgba(0, 0, 0, 0.8);\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__button svg {\n  width: 34px;\n  height: 20px;\n  fill: #ccc;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__jsfiddle,\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__codepen {\n  position: absolute;\n  top: 10px;\n  transition: all 0.5s;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand {\n  position: relative;\n  width: 100px;\n  height: 40px;\n  margin: 0;\n  color: #3eaf7c;\n  font-size: 14px;\n  background-color: transparent;\n  border-color: transparent;\n  outline: none;\n  transition: all 0.5s;\n  cursor: pointer;\n}\n.vuepress-plugin-demo-block__wrapper .vuepress-plugin-demo-block__footer .vuepress-plugin-demo-block__expand::before {\n  content: \"\";\n  position: absolute;\n  top: 50%;\n  left: 50%;\n  width: 0;\n  height: 0;\n  border-top: 6px solid #ccc;\n  border-right: 6px solid transparent;\n  border-left: 6px solid transparent;\n  -webkit-transform: translate(-50%, -50%);\n          transform: translate(-50%, -50%);\n}\n");var Bs={jsLib:[],cssLib:[],jsfiddle:!0,codepen:!0,codepenLayout:"left",codepenJsProcessor:"babel",codepenEditors:"101",horizontal:!1,vue:"https://cdn.jsdelivr.net/npm/vue/dist/vue.min.js",react:"https://cdn.jsdelivr.net/npm/react/umd/react.production.min.js",reactDOM:"https://cdn.jsdelivr.net/npm/react-dom/umd/react-dom.production.min.js"},Ts={},Ps=function(n){return'<div id="app">\n'.concat(n,"\n</div>")},Is=function(n){return window.$VUEPRESS_DEMO_BLOCK&&void 0!==window.$VUEPRESS_DEMO_BLOCK[n]?window.$VUEPRESS_DEMO_BLOCK[n]:Bs[n]},Ss=function n(e,t,r){var a=document.createElement(e);return t&&Object.keys(t).forEach((function(n){if(n.indexOf("data"))a[n]=t[n];else{var e=n.replace("data","");a.dataset[e]=t[n]}})),r&&r.forEach((function(e){var t=e.tag,r=e.attrs,o=e.children;a.appendChild(n(t,r,o))})),a},zs=function(n,e,t){var r,a=(r=n.querySelectorAll(".".concat(e)),Array.prototype.slice.call(r));return 1!==a.length||t?a:a[0]},Ds=function(n,e){var t,r,a=n.match(/<style>([\s\S]+)<\/style>/),o=n.match(/<template>([\s\S]+)<\/template>/),i=n.match(/<script>([\s\S]+)<\/script>/),s={css:a&&a[1].replace(/^\n|\n$/g,""),html:o&&o[1].replace(/^\n|\n$/g,""),js:i&&i[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};s.htmlTpl=Ps(s.html),s.jsTpl=(t=s.js,r=t.replace(/export\s+default\s*?\{\n*/,"").replace(/\n*\}\s*$/,"").trim(),"new Vue({\n  el: '#app',\n  ".concat(r,"\n})")),s.script=function(n,e){var t=n.split(/export\s+default/),r="(function() {".concat(t[0]," ; return ").concat(t[1],"})()"),a=window.Babel?window.Babel.transform(r,{presets:["es2015"]}).code:r,o=[eval][0](a);return o.template=e,o}(s.js,s.html);var c=Is("vue");return s.jsLib.unshift(c),s},Os=function(n,e){var t,r=n.match(/<style>([\s\S]+)<\/style>/),a=n.match(/<html>([\s\S]+)<\/html>/),o=n.match(/<script>([\s\S]+)<\/script>/),i={css:r&&r[1].replace(/^\n|\n$/g,""),html:a&&a[1].replace(/^\n|\n$/g,""),js:o&&o[1].replace(/^\n|\n$/g,""),jsLib:e.jsLib||[],cssLib:e.cssLib||[]};return i.htmlTpl=i.html,i.jsTpl=i.js,i.script=(t=i.js,window.Babel?window.Babel.transform(t,{presets:["es2015"]}).code:t),i},js=function(n){return n=n.replace("export default ","").replace(/App\.__style__(\s*)=(\s*)`([\s\S]*)?`/,""),n+='ReactDOM.render(React.createElement(App), document.getElementById("app"))'};function qs(){var n=zs(document,"vuepress-plugin-demo-block__wrapper",!0);n.length?n.forEach((function(n){if("true"!==n.dataset.created){n.style.display="block";var e=zs(n,"vuepress-plugin-demo-block__code"),t=zs(n,"vuepress-plugin-demo-block__display"),r=zs(n,"vuepress-plugin-demo-block__footer"),a=zs(t,"vuepress-plugin-demo-block__app"),o=decodeURIComponent(n.dataset.code),i=decodeURIComponent(n.dataset.config),s=decodeURIComponent(n.dataset.type);i=i?JSON.parse(i):{};var c=e.querySelector("div").clientHeight,l="react"===s?function(n,e){var t=(0,window.Babel.transform)(n,{presets:["es2015","react"]}).code,r="(function(exports){var module={};module.exports=exports;".concat(t,";return module.exports.__esModule?module.exports.default:module.exports;})({})"),a=new Function("return ".concat(r))(),o={js:a,css:a.__style__||"",jsLib:e.jsLib||[],cssLib:e.cssLib||[],jsTpl:js(n),htmlTpl:Ps("")},i=Is("react"),s=Is("reactDOM");return o.jsLib.unshift(i,s),o}(o,i):"vanilla"===s?Os(o,i):Ds(o,i),p=Ss("button",{className:"".concat("vuepress-plugin-demo-block__expand")});if(r.appendChild(p),p.addEventListener("click",$s.bind(null,p,c,e,r)),Is("jsfiddle")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,a=n.jsLib,o=n.cssLib,i=a.concat(o).concat(Is("cssLib")).concat(Is("jsLib")).join(",");return Ss("form",{className:"vuepress-plugin-demo-block__jsfiddle",target:"_blank",action:"https://jsfiddle.net/api/post/library/pure/",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"css",value:e}},{tag:"input",attrs:{type:"hidden",name:"html",value:t}},{tag:"input",attrs:{type:"hidden",name:"js",value:r}},{tag:"input",attrs:{type:"hidden",name:"panel_js",value:3}},{tag:"input",attrs:{type:"hidden",name:"wrap",value:1}},{tag:"input",attrs:{type:"hidden",name:"resources",value:i}},{tag:"button",attrs:{type:"submit",className:"vuepress-plugin-demo-block__button",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088289967" class="icon" style="" viewBox="0 0 1170 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1952" xmlns:xlink="http://www.w3.org/1999/xlink" width="228.515625" height="200"><defs><style type="text/css"></style></defs><path d="M1028.571429 441.142857q63.428571 26.285714 102.571428 83.142857T1170.285714 650.857143q0 93.714286-67.428571 160.285714T940 877.714286q-2.285714 0-6.571429-0.285715t-6-0.285714H232q-97.142857-5.714286-164.571429-71.714286T0 645.142857q0-62.857143 31.428571-116t84-84q-6.857143-22.285714-6.857142-46.857143 0-65.714286 46.857142-112t113.714286-46.285714q54.285714 0 98.285714 33.142857 42.857143-88 127.142858-141.714286t186.571428-53.714285q94.857143 0 174.857143 46T982.571429 248.571429t46.571428 172q0 3.428571-0.285714 10.285714t-0.285714 10.285714zM267.428571 593.142857q0 69.714286 48 110.285714t118.857143 40.571429q78.285714 0 137.142857-56.571429-9.142857-11.428571-27.142857-32.285714T519.428571 626.285714q-38.285714 37.142857-82.285714 37.142857-31.428571 0-53.428571-19.142857T361.714286 594.285714q0-30.285714 22-49.714285t52.285714-19.428572q25.142857 0 48.285714 12t41.714286 31.428572 37.142857 42.857142 39.428572 46.857143 44 42.857143 55.428571 31.428572 69.428571 12q69.142857 0 116.857143-40.857143T936 594.857143q0-69.142857-48-109.714286t-118.285714-40.571428q-81.714286 0-137.714286 55.428571l53.142857 61.714286q37.714286-36.571429 81.142857-36.571429 29.714286 0 52.571429 18.857143t22.857143 48q0 32.571429-21.142857 52.285714t-53.714286 19.714286q-24.571429 0-47.142857-12t-41.142857-31.428571-37.428572-42.857143-39.714286-46.857143-44.285714-42.857143-55.142857-31.428571T434.285714 444.571429q-69.714286 0-118.285714 40.285714T267.428571 593.142857z" p-id="1953"></path></svg>',datatip:"JSFiddle"}}])}(l)),Is("codepen")&&r.appendChild(function(n){var e=n.css,t=n.htmlTpl,r=n.jsTpl,a=n.jsLib,o=n.cssLib,i=JSON.stringify({css:e,html:t,js:r,js_external:a.concat(Is("jsLib")).join(";"),css_external:o.concat(Is("cssLib")).join(";"),layout:Is("codepenLayout"),js_pre_processor:Is("codepenJsProcessor"),editors:Is("codepenEditors")});return Ss("form",{className:"vuepress-plugin-demo-block__codepen",target:"_blank",action:"https://codepen.io/pen/define",method:"post"},[{tag:"input",attrs:{type:"hidden",name:"data",value:i}},{tag:"button",attrs:{type:"submit",innerHTML:'<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg t="1547088271207" class="icon" style="" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="1737" xmlns:xlink="http://www.w3.org/1999/xlink" width="200" height="200"><defs><style type="text/css"></style></defs><path d="M123.428571 668l344.571429 229.714286v-205.142857L277.142857 565.142857z m-35.428571-82.285714l110.285714-73.714286-110.285714-73.714286v147.428572z m468 312l344.571429-229.714286-153.714286-102.857143-190.857143 127.428572v205.142857z m-44-281.714286l155.428571-104-155.428571-104-155.428571 104zM277.142857 458.857143l190.857143-127.428572V126.285714L123.428571 356z m548.571429 53.142857l110.285714 73.714286V438.285714z m-78.857143-53.142857l153.714286-102.857143-344.571429-229.714286v205.142857z m277.142857-102.857143v312q0 23.428571-19.428571 36.571429l-468 312q-12 7.428571-24.571429 7.428571t-24.571429-7.428571L19.428571 704.571429q-19.428571-13.142857-19.428571-36.571429V356q0-23.428571 19.428571-36.571429L487.428571 7.428571q12-7.428571 24.571429-7.428571t24.571429 7.428571l468 312q19.428571 13.142857 19.428571 36.571429z" p-id="1738"></path></svg>',className:"vuepress-plugin-demo-block__button",datatip:"Codepen"}}])}(l)),void 0!==i.horizontal?i.horizontal:Is("horizontal")){n.classList.add("vuepress-plugin-demo-block__horizontal");var d=e.firstChild.cloneNode(!0);d.classList.add("vuepress-plugin-demo-block__h_code"),t.appendChild(d)}if(l.css&&function(n){if(!Ts[n]){var e=Ss("style",{innerHTML:n});document.body.appendChild(e),Ts[n]=!0}}(l.css),"react"===s)ReactDOM.render(React.createElement(l.js),a);else if("vue"===s){var u=(new(Vue.extend(l.script))).$mount();a.appendChild(u.$el)}else"vanilla"===s&&(a.innerHTML=l.html,new Function("return (function(){".concat(l.script,"})()"))());n.dataset.created="true"}})):setTimeout((function(n){qs()}),300)}function $s(n,e,t,r){var a="1"!==n.dataset.isExpand;t.style.height=a?"".concat(e,"px"):0,a?r.classList.add("vuepress-plugin-demo-block__show-link"):r.classList.remove("vuepress-plugin-demo-block__show-link"),n.dataset.isExpand=a?"1":"0"}var Ms={mounted:function(){window.$VUEPRESS_DEMO_BLOCK={jsfiddle:!1,codepen:!0,horizontal:!1},qs()},updated:function(){qs()}},Fs="auto",Us="zoom-in",Rs="zoom-out",Ls="grab",Ns="move";function Gs(n,e,t){var r=!(arguments.length>3&&void 0!==arguments[3])||arguments[3],a={passive:!1};r?n.addEventListener(e,t,a):n.removeEventListener(e,t,a)}function Ks(n,e){if(n){var t=new Image;t.onload=function(){e&&e(t)},t.src=n}}function Vs(n){return n.dataset.original?n.dataset.original:"A"===n.parentNode.tagName?n.parentNode.getAttribute("href"):null}function Hs(n,e,t){!function(n){var e=Zs,t=Ws;if(n.transition){var r=n.transition;delete n.transition,n[e]=r}if(n.transform){var a=n.transform;delete n.transform,n[t]=a}}(e);var r=n.style,a={};for(var o in e)t&&(a[o]=r[o]||""),r[o]=e[o];return a}var Zs="transition",Ws="transform",Xs="transform",Ys="transitionend";var Qs=function(){},Js={enableGrab:!0,preloadImage:!1,closeOnWindowResize:!0,transitionDuration:.4,transitionTimingFunction:"cubic-bezier(0.4, 0, 0, 1)",bgColor:"rgb(255, 255, 255)",bgOpacity:1,scaleBase:1,scaleExtra:.5,scrollThreshold:40,zIndex:998,customSize:null,onOpen:Qs,onClose:Qs,onGrab:Qs,onMove:Qs,onRelease:Qs,onBeforeOpen:Qs,onBeforeClose:Qs,onBeforeGrab:Qs,onBeforeRelease:Qs,onImageLoading:Qs,onImageLoaded:Qs},nc={init:function(n){var e,t;e=this,t=n,Object.getOwnPropertyNames(Object.getPrototypeOf(e)).forEach((function(n){e[n]=e[n].bind(t)}))},click:function(n){if(n.preventDefault(),tc(n))return window.open(this.target.srcOriginal||n.currentTarget.src,"_blank");this.shown?this.released?this.close():this.release():this.open(n.currentTarget)},scroll:function(){var n=document.documentElement||document.body.parentNode||document.body,e=window.pageXOffset||n.scrollLeft,t=window.pageYOffset||n.scrollTop;null===this.lastScrollPosition&&(this.lastScrollPosition={x:e,y:t});var r=this.lastScrollPosition.x-e,a=this.lastScrollPosition.y-t,o=this.options.scrollThreshold;(Math.abs(a)>=o||Math.abs(r)>=o)&&(this.lastScrollPosition=null,this.close())},keydown:function(n){(function(n){return"Escape"===(n.key||n.code)||27===n.keyCode})(n)&&(this.released?this.close():this.release(this.close))},mousedown:function(n){if(ec(n)&&!tc(n)){n.preventDefault();var e=n.clientX,t=n.clientY;this.pressTimer=setTimeout(function(){this.grab(e,t)}.bind(this),200)}},mousemove:function(n){this.released||this.move(n.clientX,n.clientY)},mouseup:function(n){ec(n)&&!tc(n)&&(clearTimeout(this.pressTimer),this.released?this.close():this.release())},touchstart:function(n){n.preventDefault();var e=n.touches[0],t=e.clientX,r=e.clientY;this.pressTimer=setTimeout(function(){this.grab(t,r)}.bind(this),200)},touchmove:function(n){if(!this.released){var e=n.touches[0],t=e.clientX,r=e.clientY;this.move(t,r)}},touchend:function(n){(function(n){n.targetTouches.length})(n)||(clearTimeout(this.pressTimer),this.released?this.close():this.release())},clickOverlay:function(){this.close()},resizeWindow:function(){this.close()}};function ec(n){return 0===n.button}function tc(n){return n.metaKey||n.ctrlKey}var rc={init:function(n){this.el=document.createElement("div"),this.instance=n,this.parent=document.body,Hs(this.el,{position:"fixed",top:0,left:0,right:0,bottom:0,opacity:0}),this.updateStyle(n.options),Gs(this.el,"click",n.handler.clickOverlay.bind(n))},updateStyle:function(n){Hs(this.el,{zIndex:n.zIndex,backgroundColor:n.bgColor,transition:"opacity\n        "+n.transitionDuration+"s\n        "+n.transitionTimingFunction})},insert:function(){this.parent.appendChild(this.el)},remove:function(){this.parent.removeChild(this.el)},fadeIn:function(){this.el.offsetWidth,this.el.style.opacity=this.instance.options.bgOpacity},fadeOut:function(){this.el.style.opacity=0}},ac="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(n){return typeof n}:function(n){return n&&"function"==typeof Symbol&&n.constructor===Symbol&&n!==Symbol.prototype?"symbol":typeof n},oc=function(){function n(n,e){for(var t=0;t<e.length;t++){var r=e[t];r.enumerable=r.enumerable||!1,r.configurable=!0,"value"in r&&(r.writable=!0),Object.defineProperty(n,r.key,r)}}return function(e,t,r){return t&&n(e.prototype,t),r&&n(e,r),e}}(),ic=Object.assign||function(n){for(var e=1;e<arguments.length;e++){var t=arguments[e];for(var r in t)Object.prototype.hasOwnProperty.call(t,r)&&(n[r]=t[r])}return n},sc={init:function(n,e){this.el=n,this.instance=e,this.srcThumbnail=this.el.getAttribute("src"),this.srcset=this.el.getAttribute("srcset"),this.srcOriginal=Vs(this.el),this.rect=this.el.getBoundingClientRect(),this.translate=null,this.scale=null,this.styleOpen=null,this.styleClose=null},zoomIn:function(){var n=this.instance.options,e=n.zIndex,t=n.enableGrab,r=n.transitionDuration,a=n.transitionTimingFunction;this.translate=this.calculateTranslate(),this.scale=this.calculateScale(),this.styleOpen={position:"relative",zIndex:e+1,cursor:t?Ls:Rs,transition:Xs+"\n        "+r+"s\n        "+a,transform:"translate3d("+this.translate.x+"px, "+this.translate.y+"px, 0px)\n        scale("+this.scale.x+","+this.scale.y+")",height:this.rect.height+"px",width:this.rect.width+"px"},this.el.offsetWidth,this.styleClose=Hs(this.el,this.styleOpen,!0)},zoomOut:function(){this.el.offsetWidth,Hs(this.el,{transform:"none"})},grab:function(n,e,t){var r=cc(),a=r.x-n,o=r.y-e;Hs(this.el,{cursor:Ns,transform:"translate3d(\n        "+(this.translate.x+a)+"px, "+(this.translate.y+o)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},move:function(n,e,t){var r=cc(),a=r.x-n,o=r.y-e;Hs(this.el,{transition:Xs,transform:"translate3d(\n        "+(this.translate.x+a)+"px, "+(this.translate.y+o)+"px, 0px)\n        scale("+(this.scale.x+t)+","+(this.scale.y+t)+")"})},restoreCloseStyle:function(){Hs(this.el,this.styleClose)},restoreOpenStyle:function(){Hs(this.el,this.styleOpen)},upgradeSource:function(){if(this.srcOriginal){var n=this.el.parentNode;this.srcset&&this.el.removeAttribute("srcset");var e=this.el.cloneNode(!1);e.setAttribute("src",this.srcOriginal),e.style.position="fixed",e.style.visibility="hidden",n.appendChild(e),setTimeout(function(){this.el.setAttribute("src",this.srcOriginal),n.removeChild(e)}.bind(this),50)}},downgradeSource:function(){this.srcOriginal&&(this.srcset&&this.el.setAttribute("srcset",this.srcset),this.el.setAttribute("src",this.srcThumbnail))},calculateTranslate:function(){var n=cc(),e=this.rect.left+this.rect.width/2,t=this.rect.top+this.rect.height/2;return{x:n.x-e,y:n.y-t}},calculateScale:function(){var n=this.el.dataset,e=n.zoomingHeight,t=n.zoomingWidth,r=this.instance.options,a=r.customSize,o=r.scaleBase;if(!a&&e&&t)return{x:t/this.rect.width,y:e/this.rect.height};if(a&&"object"===(void 0===a?"undefined":ac(a)))return{x:a.width/this.rect.width,y:a.height/this.rect.height};var i=this.rect.width/2,s=this.rect.height/2,c=cc(),l={x:c.x-i,y:c.y-s},p=l.x/i,d=l.y/s,u=o+Math.min(p,d);if(a&&"string"==typeof a){var m=t||this.el.naturalWidth,h=e||this.el.naturalHeight,g=parseFloat(a)*m/(100*this.rect.width),f=parseFloat(a)*h/(100*this.rect.height);if(u>g||u>f)return{x:g,y:f}}return{x:u,y:u}}};function cc(){var n=document.documentElement;return{x:Math.min(n.clientWidth,window.innerWidth)/2,y:Math.min(n.clientHeight,window.innerHeight)/2}}function lc(n,e,t){["mousedown","mousemove","mouseup","touchstart","touchmove","touchend"].forEach((function(r){Gs(n,r,e[r],t)}))}var pc=function(){function n(e){!function(n,e){if(!(n instanceof e))throw new TypeError("Cannot call a class as a function")}(this,n),this.target=Object.create(sc),this.overlay=Object.create(rc),this.handler=Object.create(nc),this.body=document.body,this.shown=!1,this.lock=!1,this.released=!0,this.lastScrollPosition=null,this.pressTimer=null,this.options=ic({},Js,e),this.overlay.init(this),this.handler.init(this)}return oc(n,[{key:"listen",value:function(n){if("string"==typeof n)for(var e=document.querySelectorAll(n),t=e.length;t--;)this.listen(e[t]);else"IMG"===n.tagName&&(n.style.cursor=Us,Gs(n,"click",this.handler.click),this.options.preloadImage&&Ks(Vs(n)));return this}},{key:"config",value:function(n){return n?(ic(this.options,n),this.overlay.updateStyle(this.options),this):this.options}},{key:"open",value:function(n){var e=this,t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:this.options.onOpen;if(!this.shown&&!this.lock){var r="string"==typeof n?document.querySelector(n):n;if("IMG"===r.tagName){if(this.options.onBeforeOpen(r),this.target.init(r,this),!this.options.preloadImage){var a=this.target.srcOriginal;null!=a&&(this.options.onImageLoading(r),Ks(a,this.options.onImageLoaded))}this.shown=!0,this.lock=!0,this.target.zoomIn(),this.overlay.insert(),this.overlay.fadeIn(),Gs(document,"scroll",this.handler.scroll),Gs(document,"keydown",this.handler.keydown),this.options.closeOnWindowResize&&Gs(window,"resize",this.handler.resizeWindow);var o=function n(){Gs(r,Ys,n,!1),e.lock=!1,e.target.upgradeSource(),e.options.enableGrab&&lc(document,e.handler,!0),t(r)};return Gs(r,Ys,o),this}}}},{key:"close",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onClose;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeClose(t),this.lock=!0,this.body.style.cursor=Fs,this.overlay.fadeOut(),this.target.zoomOut(),Gs(document,"scroll",this.handler.scroll,!1),Gs(document,"keydown",this.handler.keydown,!1),this.options.closeOnWindowResize&&Gs(window,"resize",this.handler.resizeWindow,!1);var r=function r(){Gs(t,Ys,r,!1),n.shown=!1,n.lock=!1,n.target.downgradeSource(),n.options.enableGrab&&lc(document,n.handler,!1),n.target.restoreCloseStyle(),n.overlay.remove(),e(t)};return Gs(t,Ys,r),this}}},{key:"grab",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onGrab;if(this.shown&&!this.lock){var a=this.target.el;this.options.onBeforeGrab(a),this.released=!1,this.target.grab(n,e,t);var o=function n(){Gs(a,Ys,n,!1),r(a)};return Gs(a,Ys,o),this}}},{key:"move",value:function(n,e){var t=arguments.length>2&&void 0!==arguments[2]?arguments[2]:this.options.scaleExtra,r=arguments.length>3&&void 0!==arguments[3]?arguments[3]:this.options.onMove;if(this.shown&&!this.lock){this.released=!1,this.body.style.cursor=Ns,this.target.move(n,e,t);var a=this.target.el,o=function n(){Gs(a,Ys,n,!1),r(a)};return Gs(a,Ys,o),this}}},{key:"release",value:function(){var n=this,e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:this.options.onRelease;if(this.shown&&!this.lock){var t=this.target.el;this.options.onBeforeRelease(t),this.lock=!0,this.body.style.cursor=Fs,this.target.restoreOpenStyle();var r=function r(){Gs(t,Ys,r,!1),n.lock=!1,n.released=!0,e(t)};return Gs(t,Ys,r),this}}}]),n}();const dc=JSON.parse('{"bgColor":"rgba(0,0,0,0.6)"}'),uc=Number("500");class mc{constructor(){this.instance=new pc(dc)}update(n=".theme-vdoing-content img:not(.no-zoom)"){"undefined"!=typeof window&&this.instance.listen(n)}updateDelay(n=".theme-vdoing-content img:not(.no-zoom)",e=uc){setTimeout(()=>this.update(n),e)}}var hc=[gs,Es,ws,Cs,Ms,{watch:{"$page.path"(){void 0!==this.$vuepress.zooming&&this.$vuepress.zooming.updateDelay()}},mounted(){this.$vuepress.zooming=new mc,this.$vuepress.zooming.updateDelay()}}],gc={name:"GlobalLayout",computed:{layout(){const n=this.getLayout();return ps("layout",n),Kt.component(n)}},methods:{getLayout(){if(this.$page.path){const n=this.$page.frontmatter.layout;return n&&(this.$vuepress.getLayoutAsyncComponent(n)||this.$vuepress.getVueComponent(n))?n:"Layout"}return"NotFound"}}},fc=t(0),vc=Object(fc.a)(gc,(function(){return(0,this._self._c)(this.layout,{tag:"component"})}),[],!1,null,null,null).exports;!function(n,e,t){switch(e){case"components":n[e]||(n[e]={}),Object.assign(n[e],t);break;case"mixins":n[e]||(n[e]=[]),n[e].push(...t);break;default:throw new Error("Unknown option name.")}}(vc,"mixins",hc);const bc=[{name:"v-6ee71fe0",path:"/tech/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-6ee71fe0").then(t)}},{path:"/tech/index.html",redirect:"/tech/"},{path:"/00.目录页/01.技术杂谈.html",redirect:"/tech/"},{name:"v-06a3e7f2",path:"/pages/yxcypz/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-06a3e7f2").then(t)}},{path:"/pages/yxcypz/index.html",redirect:"/pages/yxcypz/"},{path:"/01.技术杂谈/01.常用总结/01.一些常用配置.html",redirect:"/pages/yxcypz/"},{name:"v-fc698e82",path:"/life/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-fc698e82").then(t)}},{path:"/life/index.html",redirect:"/life/"},{path:"/00.目录页/02.生活随写.html",redirect:"/life/"},{name:"v-3b2b3709",path:"/pages/yxgjaz/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-3b2b3709").then(t)}},{path:"/pages/yxgjaz/index.html",redirect:"/pages/yxgjaz/"},{path:"/01.技术杂谈/01.常用总结/03.一些工具安装.html",redirect:"/pages/yxgjaz/"},{name:"v-3a9d6f9d",path:"/pages/yxgjwz/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-3a9d6f9d").then(t)}},{path:"/pages/yxgjwz/index.html",redirect:"/pages/yxgjwz/"},{path:"/01.技术杂谈/01.常用总结/02.一些工具网站.html",redirect:"/pages/yxgjwz/"},{name:"v-561954fe",path:"/pages/markdown/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-561954fe").then(t)}},{path:"/pages/markdown/index.html",redirect:"/pages/markdown/"},{path:"/01.技术杂谈/01.常用总结/04.markdown常用语法组件.html",redirect:"/pages/markdown/"},{name:"v-169b12eb",path:"/pages/2022ckjl/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-169b12eb").then(t)}},{path:"/pages/2022ckjl/index.html",redirect:"/pages/2022ckjl/"},{path:"/01.技术杂谈/02.踩坑记录/01.2022踩坑记录.html",redirect:"/pages/2022ckjl/"},{name:"v-be755618",path:"/pages/k8s03/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-be755618").then(t)}},{path:"/pages/k8s03/index.html",redirect:"/pages/k8s03/"},{path:"/01.技术杂谈/03.kubernetes/03.k8s网络.html",redirect:"/pages/k8s03/"},{name:"v-132121e4",path:"/pages/k8s02/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-132121e4").then(t)}},{path:"/pages/k8s02/index.html",redirect:"/pages/k8s02/"},{path:"/01.技术杂谈/03.kubernetes/02.k8s存储.html",redirect:"/pages/k8s02/"},{name:"v-4b9555d9",path:"/pages/k8s01/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-4b9555d9").then(t)}},{path:"/pages/k8s01/index.html",redirect:"/pages/k8s01/"},{path:"/01.技术杂谈/03.kubernetes/01.k8s基础.html",redirect:"/pages/k8s01/"},{name:"v-26c04c03",path:"/pages/k8s04/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-26c04c03").then(t)}},{path:"/pages/k8s04/index.html",redirect:"/pages/k8s04/"},{path:"/01.技术杂谈/03.kubernetes/04.pod cgroup和资源限制.html",redirect:"/pages/k8s04/"},{name:"v-4d3d3bec",path:"/pages/k8s05/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-4d3d3bec").then(t)}},{path:"/pages/k8s05/index.html",redirect:"/pages/k8s05/"},{path:"/01.技术杂谈/03.kubernetes/05.流量限制.html",redirect:"/pages/k8s05/"},{name:"v-59c6ef63",path:"/pages/k8s06/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-59c6ef63").then(t)}},{path:"/pages/k8s06/index.html",redirect:"/pages/k8s06/"},{path:"/01.技术杂谈/03.kubernetes/06.网络策略calico.html",redirect:"/pages/k8s06/"},{name:"v-0b248a60",path:"/pages/k8s07/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-0b248a60").then(t)}},{path:"/pages/k8s07/index.html",redirect:"/pages/k8s07/"},{path:"/01.技术杂谈/03.kubernetes/07.grafana和promuthues.html",redirect:"/pages/k8s07/"},{name:"v-2f3eb2e7",path:"/pages/k8s08/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-2f3eb2e7").then(t)}},{path:"/pages/k8s08/index.html",redirect:"/pages/k8s08/"},{path:"/01.技术杂谈/03.kubernetes/08.etcd节点down机数据恢复.html",redirect:"/pages/k8s08/"},{name:"v-1247b65b",path:"/pages/k8s09/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-1247b65b").then(t)}},{path:"/pages/k8s09/index.html",redirect:"/pages/k8s09/"},{path:"/01.技术杂谈/03.kubernetes/09.ceph.html",redirect:"/pages/k8s09/"},{name:"v-cbe0d60a",path:"/pages/k8s10/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-cbe0d60a").then(t)}},{path:"/pages/k8s10/index.html",redirect:"/pages/k8s10/"},{path:"/01.技术杂谈/03.kubernetes/10.chrony.html",redirect:"/pages/k8s10/"},{name:"v-81d98e10",path:"/pages/k8s11/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-81d98e10").then(t)}},{path:"/pages/k8s11/index.html",redirect:"/pages/k8s11/"},{path:"/01.技术杂谈/03.kubernetes/11.crd operator.html",redirect:"/pages/k8s11/"},{name:"v-16eeeecc",path:"/pages/k8s12/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-16eeeecc").then(t)}},{path:"/pages/k8s12/index.html",redirect:"/pages/k8s12/"},{path:"/01.技术杂谈/03.kubernetes/12.cri之containerd shimv2.html",redirect:"/pages/k8s12/"},{name:"v-c5d8330a",path:"/pages/k8s13/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-c5d8330a").then(t)}},{path:"/pages/k8s13/index.html",redirect:"/pages/k8s13/"},{path:"/01.技术杂谈/03.kubernetes/13.harbor.html",redirect:"/pages/k8s13/"},{name:"v-211c03e0",path:"/pages/k8s15/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-211c03e0").then(t)}},{path:"/pages/k8s15/index.html",redirect:"/pages/k8s15/"},{path:"/01.技术杂谈/03.kubernetes/15.Loongnix mips64.html",redirect:"/pages/k8s15/"},{name:"v-6da5591e",path:"/pages/k8s14/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-6da5591e").then(t)}},{path:"/pages/k8s14/index.html",redirect:"/pages/k8s14/"},{path:"/01.技术杂谈/03.kubernetes/14.helm chart.html",redirect:"/pages/k8s14/"},{name:"v-019d3da2",path:"/pages/k8s16/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-019d3da2").then(t)}},{path:"/pages/k8s16/index.html",redirect:"/pages/k8s16/"},{path:"/01.技术杂谈/03.kubernetes/16.openebs-lvm-localpv.html",redirect:"/pages/k8s16/"},{name:"v-3d63ec0a",path:"/pages/devops/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-3d63ec0a").then(t)}},{path:"/pages/devops/index.html",redirect:"/pages/devops/"},{path:"/01.技术杂谈/03.kubernetes/18.DevOps.html",redirect:"/pages/devops/"},{name:"v-185c15db",path:"/pages/ingressroute/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-185c15db").then(t)}},{path:"/pages/ingressroute/index.html",redirect:"/pages/ingressroute/"},{path:"/01.技术杂谈/03.kubernetes/17.traefik-ingressroute.html",redirect:"/pages/ingressroute/"},{name:"v-680c343b",path:"/pages/serverless/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-680c343b").then(t)}},{path:"/pages/serverless/index.html",redirect:"/pages/serverless/"},{path:"/01.技术杂谈/03.kubernetes/19.serverless.html",redirect:"/pages/serverless/"},{name:"v-9b6819e6",path:"/pages/k8s20/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-9b6819e6").then(t)}},{path:"/pages/k8s20/index.html",redirect:"/pages/k8s20/"},{path:"/01.技术杂谈/03.kubernetes/20.k8s容器故障处理.html",redirect:"/pages/k8s20/"},{name:"v-db387184",path:"/pages/k8smianshi1/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-db387184").then(t)}},{path:"/pages/k8smianshi1/index.html",redirect:"/pages/k8smianshi1/"},{path:"/01.技术杂谈/03.kubernetes/301.k8s面试/01.1.html",redirect:"/pages/k8smianshi1/"},{name:"v-07c97ac3",path:"/pages/kubevirtyuanli/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-07c97ac3").then(t)}},{path:"/pages/kubevirtyuanli/index.html",redirect:"/pages/kubevirtyuanli/"},{path:"/01.技术杂谈/03.kubernetes/302.kubevirt/01.kubevirt原理.html",redirect:"/pages/kubevirtyuanli/"},{name:"v-335e284a",path:"/pages/kubevirtdeploy/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-335e284a").then(t)}},{path:"/pages/kubevirtdeploy/index.html",redirect:"/pages/kubevirtdeploy/"},{path:"/01.技术杂谈/03.kubernetes/302.kubevirt/02.kubevirt部署.html",redirect:"/pages/kubevirtdeploy/"},{name:"v-33c779e9",path:"/pages/kata1/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-33c779e9").then(t)}},{path:"/pages/kata1/index.html",redirect:"/pages/kata1/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/01.kata基本原理与架构.html",redirect:"/pages/kata1/"},{name:"v-2e5f8162",path:"/pages/kata2/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-2e5f8162").then(t)}},{path:"/pages/kata2/index.html",redirect:"/pages/kata2/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/02.kata网络和存储文件系统分析.html",redirect:"/pages/kata2/"},{name:"v-3f9afa48",path:"/pages/kata3/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-3f9afa48").then(t)}},{path:"/pages/kata3/index.html",redirect:"/pages/kata3/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/03.kata cgroup及资源限制.html",redirect:"/pages/kata3/"},{name:"v-e15ee02a",path:"/pages/kata4/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-e15ee02a").then(t)}},{path:"/pages/kata4/index.html",redirect:"/pages/kata4/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/04.guest kernel和guestos.html",redirect:"/pages/kata4/"},{name:"v-3a4f35cc",path:"/pages/kata6/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-3a4f35cc").then(t)}},{path:"/pages/kata6/index.html",redirect:"/pages/kata6/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/06.kata使用限制.html",redirect:"/pages/kata6/"},{name:"v-50a8e3a0",path:"/pages/kata5/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-50a8e3a0").then(t)}},{path:"/pages/kata5/index.html",redirect:"/pages/kata5/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/05.kata-monitor监控.html",redirect:"/pages/kata5/"},{name:"v-77a29116",path:"/pages/kata7/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-77a29116").then(t)}},{path:"/pages/kata7/index.html",redirect:"/pages/kata7/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/07.其他特性.html",redirect:"/pages/kata7/"},{name:"v-58d0a1ce",path:"/pages/kata8/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-58d0a1ce").then(t)}},{path:"/pages/kata8/index.html",redirect:"/pages/kata8/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/08.一个kata容器的创建示例.html",redirect:"/pages/kata8/"},{name:"v-d7e2a582",path:"/pages/kata0201/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-d7e2a582").then(t)}},{path:"/pages/kata0201/index.html",redirect:"/pages/kata0201/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/02.kata部署/01.kata-deploy部署、卸载与升级.html",redirect:"/pages/kata0201/"},{name:"v-7ebc8c8b",path:"/pages/kata0202/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-7ebc8c8b").then(t)}},{path:"/pages/kata0202/index.html",redirect:"/pages/kata0202/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/02.kata部署/02.kata-deploy分析.html",redirect:"/pages/kata0202/"},{name:"v-33dd887e",path:"/pages/kata0401/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-33dd887e").then(t)}},{path:"/pages/kata0401/index.html",redirect:"/pages/kata0401/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/01.常用命令.html",redirect:"/pages/kata0401/"},{name:"v-03d01b37",path:"/pages/kata0402/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-03d01b37").then(t)}},{path:"/pages/kata0402/index.html",redirect:"/pages/kata0402/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/02.kata使用问题汇总.html",redirect:"/pages/kata0402/"},{name:"v-6e85c154",path:"/pages/kata0404/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-6e85c154").then(t)}},{path:"/pages/kata0404/index.html",redirect:"/pages/kata0404/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/04.kata debug与日志.html",redirect:"/pages/kata0404/"},{name:"v-68efef1e",path:"/pages/kata0403/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-68efef1e").then(t)}},{path:"/pages/kata0403/index.html",redirect:"/pages/kata0403/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/03.kata相关配置及路径.html",redirect:"/pages/kata0403/"},{name:"v-5b19c60a",path:"/pages/kata0501/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-5b19c60a").then(t)}},{path:"/pages/kata0501/index.html",redirect:"/pages/kata0501/"},{path:"/01.技术杂谈/03.kubernetes/303.kata-containers/05.kataV3.0/01.kata v3.0.html",redirect:"/pages/kata0501/"},{name:"v-e1ca0762",path:"/pages/docker03/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-e1ca0762").then(t)}},{path:"/pages/docker03/index.html",redirect:"/pages/docker03/"},{path:"/01.技术杂谈/03.kubernetes/304.docker/03.docker镜像.html",redirect:"/pages/docker03/"},{name:"v-32d723b6",path:"/pages/docker02/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-32d723b6").then(t)}},{path:"/pages/docker02/index.html",redirect:"/pages/docker02/"},{path:"/01.技术杂谈/03.kubernetes/304.docker/02.dockerfile改源.html",redirect:"/pages/docker02/"},{name:"v-5d2403be",path:"/pages/docker04/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-5d2403be").then(t)}},{path:"/pages/docker04/index.html",redirect:"/pages/docker04/"},{path:"/01.技术杂谈/03.kubernetes/304.docker/04.docker镜像优化.html",redirect:"/pages/docker04/"},{name:"v-43971d6a",path:"/pages/docker01/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-43971d6a").then(t)}},{path:"/pages/docker01/index.html",redirect:"/pages/docker01/"},{path:"/01.技术杂谈/03.kubernetes/304.docker/01.buildx多平台构建.html",redirect:"/pages/docker01/"},{name:"v-11c4c310",path:"/pages/docker05/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-11c4c310").then(t)}},{path:"/pages/docker05/index.html",redirect:"/pages/docker05/"},{path:"/01.技术杂谈/03.kubernetes/304.docker/05.在Docker中设置时区.html",redirect:"/pages/docker05/"},{name:"v-3b906eab",path:"/pages/docker06/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-3b906eab").then(t)}},{path:"/pages/docker06/index.html",redirect:"/pages/docker06/"},{path:"/01.技术杂谈/03.kubernetes/304.docker/06.docker基础.html",redirect:"/pages/docker06/"},{name:"v-0523fe6a",path:"/pages/rzcjfa/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-0523fe6a").then(t)}},{path:"/pages/rzcjfa/index.html",redirect:"/pages/rzcjfa/"},{path:"/01.技术杂谈/03.kubernetes/305.日志采集/01.日志采集方案.html",redirect:"/pages/rzcjfa/"},{name:"v-31339544",path:"/pages/loki/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-31339544").then(t)}},{path:"/pages/loki/index.html",redirect:"/pages/loki/"},{path:"/01.技术杂谈/03.kubernetes/305.日志采集/05.loki.html",redirect:"/pages/loki/"},{name:"v-7e4b3a46",path:"/pages/gpu01/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-7e4b3a46").then(t)}},{path:"/pages/gpu01/index.html",redirect:"/pages/gpu01/"},{path:"/01.技术杂谈/03.kubernetes/306.GPU/01.nvidia-device-plugins.html",redirect:"/pages/gpu01/"},{name:"v-be31a184",path:"/pages/4paradigm/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-be31a184").then(t)}},{path:"/pages/4paradigm/index.html",redirect:"/pages/4paradigm/"},{path:"/01.技术杂谈/03.kubernetes/306.GPU/02.第四范式vGPU.html",redirect:"/pages/4paradigm/"},{name:"v-338caad2",path:"/pages/fluentd-log/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-338caad2").then(t)}},{path:"/pages/fluentd-log/index.html",redirect:"/pages/fluentd-log/"},{path:"/01.技术杂谈/03.kubernetes/305.日志采集/02.fluentd配置.html",redirect:"/pages/fluentd-log/"},{name:"v-572ce303",path:"/pages/tencnt-cpu-manager/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-572ce303").then(t)}},{path:"/pages/tencnt-cpu-manager/index.html",redirect:"/pages/tencnt-cpu-manager/"},{path:"/01.技术杂谈/03.kubernetes/306.GPU/03.腾讯gpu-manager.html",redirect:"/pages/tencnt-cpu-manager/"},{name:"v-131bc9a5",path:"/pages/ali-gpushare/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-131bc9a5").then(t)}},{path:"/pages/ali-gpushare/index.html",redirect:"/pages/ali-gpushare/"},{path:"/01.技术杂谈/03.kubernetes/306.GPU/04.阿里gpu-share.html",redirect:"/pages/ali-gpushare/"},{name:"v-582a5ac3",path:"/pages/fadb16/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-582a5ac3").then(t)}},{path:"/pages/fadb16/index.html",redirect:"/pages/fadb16/"},{path:"/01.技术杂谈/03.kubernetes/305.日志采集/03.events持久化.html",redirect:"/pages/fadb16/"},{name:"v-6a155cef",path:"/pages/nvidiadevice/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-6a155cef").then(t)}},{path:"/pages/nvidiadevice/index.html",redirect:"/pages/nvidiadevice/"},{path:"/01.技术杂谈/03.kubernetes/306.GPU/05.英伟达驱动安装.html",redirect:"/pages/nvidiadevice/"},{name:"v-fa04c054",path:"/pages/golang01/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-fa04c054").then(t)}},{path:"/pages/golang01/index.html",redirect:"/pages/golang01/"},{path:"/01.技术杂谈/04.golang/01.常用计算.html",redirect:"/pages/golang01/"},{name:"v-394a82c1",path:"/pages/qgpu/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-394a82c1").then(t)}},{path:"/pages/qgpu/index.html",redirect:"/pages/qgpu/"},{path:"/01.技术杂谈/03.kubernetes/306.GPU/06.腾讯云qGPU.html",redirect:"/pages/qgpu/"},{name:"v-6c7b2800",path:"/pages/golang02/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-6c7b2800").then(t)}},{path:"/pages/golang02/index.html",redirect:"/pages/golang02/"},{path:"/01.技术杂谈/04.golang/02.golang面试问题.html",redirect:"/pages/golang02/"},{name:"v-306f5d23",path:"/pages/alert-log/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-306f5d23").then(t)}},{path:"/pages/alert-log/index.html",redirect:"/pages/alert-log/"},{path:"/01.技术杂谈/03.kubernetes/305.日志采集/04.alertmanager持久化.html",redirect:"/pages/alert-log/"},{name:"v-0169ea0d",path:"/pages/golang05/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-0169ea0d").then(t)}},{path:"/pages/golang05/index.html",redirect:"/pages/golang05/"},{path:"/01.技术杂谈/04.golang/05.go-封装继承和多态.html",redirect:"/pages/golang05/"},{name:"v-51cd8504",path:"/pages/golang04/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-51cd8504").then(t)}},{path:"/pages/golang04/index.html",redirect:"/pages/golang04/"},{path:"/01.技术杂谈/04.golang/04.go embed.html",redirect:"/pages/golang04/"},{name:"v-783e73dc",path:"/pages/golang03/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-783e73dc").then(t)}},{path:"/pages/golang03/index.html",redirect:"/pages/golang03/"},{path:"/01.技术杂谈/04.golang/03.go-指针.html",redirect:"/pages/golang03/"},{name:"v-5b58f46b",path:"/pages/golang06/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-5b58f46b").then(t)}},{path:"/pages/golang06/index.html",redirect:"/pages/golang06/"},{path:"/01.技术杂谈/04.golang/06.go-文件操作.html",redirect:"/pages/golang06/"},{name:"v-d695f1cc",path:"/pages/golang08/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-d695f1cc").then(t)}},{path:"/pages/golang08/index.html",redirect:"/pages/golang08/"},{path:"/01.技术杂谈/04.golang/08.go-slice切片.html",redirect:"/pages/golang08/"},{name:"v-92ed690a",path:"/pages/golang07/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-92ed690a").then(t)}},{path:"/pages/golang07/index.html",redirect:"/pages/golang07/"},{path:"/01.技术杂谈/04.golang/07.go-json.html",redirect:"/pages/golang07/"},{name:"v-018b12ce",path:"/pages/golang09/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-018b12ce").then(t)}},{path:"/pages/golang09/index.html",redirect:"/pages/golang09/"},{path:"/01.技术杂谈/04.golang/09.gin框架使用sockjs-go.html",redirect:"/pages/golang09/"},{name:"v-3f6d3b4e",path:"/pages/b5149c/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-3f6d3b4e").then(t)}},{path:"/pages/b5149c/index.html",redirect:"/pages/b5149c/"},{path:"/01.技术杂谈/06.计算机网络基础/01.关于cgroup.html",redirect:"/pages/b5149c/"},{name:"v-13d7c644",path:"/pages/95ef75/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-13d7c644").then(t)}},{path:"/pages/95ef75/index.html",redirect:"/pages/95ef75/"},{path:"/01.技术杂谈/06.计算机网络基础/02.关于cpu内存.html",redirect:"/pages/95ef75/"},{name:"v-080925d0",path:"/pages/33705b/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-080925d0").then(t)}},{path:"/pages/33705b/index.html",redirect:"/pages/33705b/"},{path:"/01.技术杂谈/07.虚拟化/03.centos使用kvm创建虚拟机.html",redirect:"/pages/33705b/"},{name:"v-2e18135a",path:"/pages/697e48/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-2e18135a").then(t)}},{path:"/pages/697e48/index.html",redirect:"/pages/697e48/"},{path:"/01.技术杂谈/07.虚拟化/02.虚拟化基础概念.html",redirect:"/pages/697e48/"},{name:"v-a2c6b924",path:"/pages/yhsjff/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-a2c6b924").then(t)}},{path:"/pages/yhsjff/index.html",redirect:"/pages/yhsjff/"},{path:"/01.技术杂谈/08.运维脚本/01.Linux系统下的用户审计方法.html",redirect:"/pages/yhsjff/"},{name:"v-4a20ad90",path:"/pages/6f3d25/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-4a20ad90").then(t)}},{path:"/pages/6f3d25/index.html",redirect:"/pages/6f3d25/"},{path:"/01.技术杂谈/07.虚拟化/01.开启硬件虚拟化.html",redirect:"/pages/6f3d25/"},{name:"v-51e55098",path:"/pages/ythx/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-51e55098").then(t)}},{path:"/pages/ythx/index.html",redirect:"/pages/ythx/"},{path:"/02.生活随写/01.养桃日记/01.养桃花销.html",redirect:"/pages/ythx/"},{name:"v-20df4130",path:"/pages/jqdd/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-20df4130").then(t)}},{path:"/pages/jqdd/index.html",redirect:"/pages/jqdd/"},{path:"/01.技术杂谈/09.软考高项/01.敬请等待.html",redirect:"/pages/jqdd/"},{name:"v-1efcbbda",path:"/pages/2bb179/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-1efcbbda").then(t)}},{path:"/pages/2bb179/index.html",redirect:"/pages/2bb179/"},{path:"/02.生活随写/01.养桃日记/02.养猫劝退.html",redirect:"/pages/2bb179/"},{name:"v-09ac84c7",path:"/pages/b5e483/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-09ac84c7").then(t)}},{path:"/pages/b5e483/index.html",redirect:"/pages/b5e483/"},{path:"/02.生活随写/01.养桃日记/03.养桃笔记.html",redirect:"/pages/b5e483/"},{name:"v-7d5d8b2d",path:"/books/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-7d5d8b2d").then(t)}},{path:"/books/index.html",redirect:"/books/"},{path:"/04.阅读/01.书单.html",redirect:"/books/"},{name:"v-4ed9e4ca",path:"/about/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-4ed9e4ca").then(t)}},{path:"/about/index.html",redirect:"/about/"},{path:"/03.关于/01.关于.html",redirect:"/about/"},{name:"v-6202dee6",path:"/pages/yzbook/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-6202dee6").then(t)}},{path:"/pages/yzbook/index.html",redirect:"/pages/yzbook/"},{path:"/04.阅读/02.优质博客.html",redirect:"/pages/yzbook/"},{name:"v-18dfbaf2",path:"/pages/yzgihub/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-18dfbaf2").then(t)}},{path:"/pages/yzgihub/index.html",redirect:"/pages/yzgihub/"},{path:"/04.阅读/03.优质开源项目.html",redirect:"/pages/yzgihub/"},{name:"v-994f98d2",path:"/archives/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-994f98d2").then(t)}},{path:"/archives/index.html",redirect:"/archives/"},{path:"/@pages/archivesPage.html",redirect:"/archives/"},{name:"v-ea545412",path:"/categories/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-ea545412").then(t)}},{path:"/categories/index.html",redirect:"/categories/"},{path:"/@pages/categoriesPage.html",redirect:"/categories/"},{name:"v-1d3069d2",path:"/tags/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-1d3069d2").then(t)}},{path:"/tags/index.html",redirect:"/tags/"},{path:"/@pages/tagsPage.html",redirect:"/tags/"},{name:"v-0c8b6730",path:"/",component:vc,beforeEnter:(n,e,t)=>{ls("Layout","v-0c8b6730").then(t)}},{path:"/index.html",redirect:"/"},{path:"*",component:vc}],kc={title:"hff",description:"https://fangfenghuang.github.io/",base:"/",headTags:[["link",{rel:"icon",href:"/img/logo.ico"}],["meta",{name:"keywords",content:"go,python,c,c++,vue,shell,php"}],["meta",{name:"baidu-site-verification",content:"code-LTKHwOecxI"}],["meta",{name:"theme-color",content:"#11a8cd"}],["meta",{name:"referrer",content:"no-referrer-when-downgrade"}],["link",{rel:"stylesheet",href:"https://at.alicdn.com/t/font_3114978_qe0b39no76.css"}],["script",{language:"javascript",type:"text/javascript",src:"/js/pgmanor-self.js"}]],pages:[{title:"技术杂谈",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"01.技术杂谈",imgUrl:"/img/tech.png",description:"学习、工作"}},title:"技术杂谈",date:"2020-03-11T21:50:53.000Z",permalink:"/tech/",sidebar:!1,article:!1,comment:!1,editLink:!1,author:{name:"fangfenghuang",link:"https://github.com/fangfenghuang"},titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"技术杂谈"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88.html"},{property:"og:type",content:"article"},{property:"og:title",content:"技术杂谈"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2020-03-11T21:50:53.000Z"},{itemprop:"name",content:"技术杂谈"},{itemprop:"description",content:""}]},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88.html",relativePath:"00.目录页/01.技术杂谈.md",key:"v-6ee71fe0",path:"/tech/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/27, 18:59:09",lastUpdatedTimestamp:1658919549e3},{title:"一些常用配置",frontmatter:{title:"一些常用配置",date:"2021-11-02T09:51:37.000Z",permalink:"/pages/yxcypz/",categories:["技术杂谈","常用总结"],tags:["常用","配置"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"一些常用配置"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/01.%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"一些常用配置"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/01.%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2021-11-02T09:51:37.000Z"},{property:"article:tag",content:"常用"},{property:"article:tag",content:"配置"},{itemprop:"name",content:"一些常用配置"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/01.%E4%B8%80%E4%BA%9B%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE.html",relativePath:"01.技术杂谈/01.常用总结/01.一些常用配置.md",key:"v-06a3e7f2",path:"/pages/yxcypz/",headers:[{level:2,title:"hosts",slug:"hosts",normalizedTitle:"hosts",charIndex:2},{level:2,title:"winscp",slug:"winscp",normalizedTitle:"winscp",charIndex:46}],headersStr:"hosts winscp",content:"# hosts\n\nC:\\Windows\\System32\\drivers\\etc\\\n\n\n# winscp\n\nsudo su -c /usr/libexec/openssh/sftp-server",normalizedContent:"# hosts\n\nc:\\windows\\system32\\drivers\\etc\\\n\n\n# winscp\n\nsudo su -c /usr/libexec/openssh/sftp-server",charsets:{},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"生活随写",frontmatter:{pageComponent:{name:"Catalogue",data:{path:"02.生活随写",imgUrl:"/img/life.png",description:"个人、随笔"}},title:"生活随写",date:"2020-03-11T21:50:54.000Z",permalink:"/life/",sidebar:!1,article:!1,comment:!1,editLink:!1,author:{name:"fangfenghuang",link:"https://github.com/fangfenghuang"},titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"生活随写"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99.html"},{property:"og:type",content:"article"},{property:"og:title",content:"生活随写"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2020-03-11T21:50:54.000Z"},{itemprop:"name",content:"生活随写"},{itemprop:"description",content:""}]},regularPath:"/00.%E7%9B%AE%E5%BD%95%E9%A1%B5/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99.html",relativePath:"00.目录页/02.生活随写.md",key:"v-fc698e82",path:"/life/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/27, 18:59:09",lastUpdatedTimestamp:1658919549e3},{title:"一些工具安装",frontmatter:{title:"一些工具安装",date:"2021-11-02T09:51:37.000Z",permalink:"/pages/yxgjaz/",categories:["技术杂谈","常用总结"],tags:["常用","工具"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"一些工具安装"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/03.%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85.html"},{property:"og:type",content:"article"},{property:"og:title",content:"一些工具安装"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/03.%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2021-11-02T09:51:37.000Z"},{property:"article:tag",content:"常用"},{property:"article:tag",content:"工具"},{itemprop:"name",content:"一些工具安装"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/03.%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7%E5%AE%89%E8%A3%85.html",relativePath:"01.技术杂谈/01.常用总结/03.一些工具安装.md",key:"v-3b2b3709",path:"/pages/yxgjaz/",headers:[{level:2,title:"sysbench安装",slug:"sysbench安装",normalizedTitle:"sysbench安装",charIndex:2},{level:2,title:"centos安装fio和gfio（图形界面）",slug:"centos安装fio和gfio-图形界面",normalizedTitle:"centos安装fio和gfio（图形界面）",charIndex:210},{level:2,title:"go 安装",slug:"go-安装",normalizedTitle:"go 安装",charIndex:1180},{level:2,title:"apt安装docker",slug:"apt安装docker",normalizedTitle:"apt安装docker",charIndex:1608},{level:2,title:"docker安装",slug:"docker安装",normalizedTitle:"docker安装",charIndex:1999},{level:2,title:"centos7安装iperf：",slug:"centos7安装iperf",normalizedTitle:"centos7安装iperf：",charIndex:3478}],headersStr:"sysbench安装 centos安装fio和gfio（图形界面） go 安装 apt安装docker docker安装 centos7安装iperf：",content:"# sysbench安装\n\nhttps://github.com/akopytov/sysbench#rhelcentos%E8%8E%B7%E5%8F%96 curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash sudo yum -y install sysbench\n\n\n# centos安装fio和gfio（图形界面）\n\nyum install gcc yum install libaio-devel (必须先安装，否则卸载fio后重新执行) yum install gtk2-devel glib2-devel\n\n下载fio压缩包，解压fio压缩文件 ##wget https://github.com/axboe/fio/archive/refs/tags/fio-2.2.10.tar.gz\n\ntar -zxvf fio-2.1.10.tar.gz\n\ncd fio-2.2.10\n\n./configure --enable-gfio\n\nmake fio\n\nmake gfio\n\nmake install\n\nln -s /usr/local/bin/fio /usr/bin/fio ln -s /usr/local/bin/gfio /usr/bin/gfio\n\n进入server模式：./fio -S\n\n使用gfio图形化测试：gfio\n\n问题：\n\n 1. 远程使用图形化界面时出错：MoTTY X11 proxy: Unsupported authorisation protocol http://t.zoukankan.com/create-serenditipy-p-15407983.html\n\n普通用户报错，root用户不报错的解决方法： cp /root/.Xauthority /home/xxx/\n\n普通用户不报错，root用户报错的解决方法： cp /home/xxx/.Xauthority /root/\n\n 2. MoTTY X11 proxy: Authorisation not recognised https://blog.csdn.net/u014780310/article/details/118966628\n\n1、cd ~/ 2、xauth list 3、根据前面提示的cannot open localhost：10.0以及上面列出来的unix:10，执行如下命令: xauth add bluedon-PC/unix:10 MIT-MAGIC-COOKIE-1 fd2c21d2294dd751801469e960799ab7 4、退出终端，重新登录\n\n\n# go 安装\n\n$ wget -c https://studygolang.com/dl/golang/go1.18.linux-amd64.tar.gz\n$ tar -C /usr/local -xzf go1.18.linux-amd64.tar.gz\n# 注意升级需要先删除/usr/local/go后再解压\n\n$ vi /root/.bashrc\nexport GOROOT=/usr/local/go\nexport GOPATH=/root/go\nexport PATH=$PATH:$GOPATH/bin:$GOROOT/bin\nexport GOBIN=/root/go/bin\nexport GO111MODULE=on\nexport GOPROXY=https://goproxy.cn,direct\n\n$ source /root/.bashrc\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# apt安装docker\n\n更新数据源 apt-get update apt-get -y install apt-transport-https ca-certificates curl software-properties-common curl -fsSL https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" apt-get update && apt-get install -y docker-ce 验证安装 docker version\n\n\n# docker安装\n\n# 卸载旧版本Docker软件\n## 以YUM方式安装的Docker卸载\nyum remove docker \\\n           docker-client \\\n           docker-client-latest \\\n           docker-common \\\n           docker-latest \\\n           docker-latest-logrotate \\\n           docker-logrotate \\\n           docker-selinux \\\n           docker-engine-selinux \\\n           docker-engine \\\n           container*\n## 以RPM方式安装的Docker卸载\n### 先查询安装了哪些Docker相关的包\n[root@mvxl7365 ~]# rpm -qa|grep docker\ndocker-ce-17.03.2.ce-1.el7.centos.x86_64\ndocker-ce-selinux-17.03.2.ce-1.el7.centos.noarch\n### 逐一进行卸载\n[root@mvxl7365 ~]# rpm -e docker-ce-17.03.2.ce-1.el7.centos.x86_64\n[root@mvxl7365 ~]# rpm -e docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch\n### 检查是否卸载干净\n[root@mvxl7365 ~]# rpm -qa|grep docker\n\n3、使用curl升级到最新版\n命令：\ncurl -fsSL https://get.docker.com/ | sh\n\n4、重启Docker\n命令：\nsystemctl restart docker\n\n5、设置Docker开机自启\n命令：\nsystemctl enable docker\n\n6、查看Docker版本信息\n命令：\ndocker version\n\n7、查看Docker系统信息，包括镜像和容器数…\n命令：\ndocker info\n\n8、使用docker images命令查看自己之前的镜像是否存在\n命令：\ndocker images\n\n9、查看容器\n命令：\ndocker ps\n如果此时容器列表显示为空，或者重启容器报如下提示：\nError response from daemon: Unknown runtime specified docker-runc\nError: failed to start containers: yapi\n可执行以下命令：\ngrep -rl 'docker-runc' /var/lib/docker/containers/ | xargs sed -i 's/docker-runc/runc/g'\n然后重启docker，命令如下：\nsystemctl restart docker\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n\n\n\n# centos7安装iperf：\n\nyum install -y iperf3",normalizedContent:"# sysbench安装\n\nhttps://github.com/akopytov/sysbench#rhelcentos%e8%8e%b7%e5%8f%96 curl -s https://packagecloud.io/install/repositories/akopytov/sysbench/script.rpm.sh | sudo bash sudo yum -y install sysbench\n\n\n# centos安装fio和gfio（图形界面）\n\nyum install gcc yum install libaio-devel (必须先安装，否则卸载fio后重新执行) yum install gtk2-devel glib2-devel\n\n下载fio压缩包，解压fio压缩文件 ##wget https://github.com/axboe/fio/archive/refs/tags/fio-2.2.10.tar.gz\n\ntar -zxvf fio-2.1.10.tar.gz\n\ncd fio-2.2.10\n\n./configure --enable-gfio\n\nmake fio\n\nmake gfio\n\nmake install\n\nln -s /usr/local/bin/fio /usr/bin/fio ln -s /usr/local/bin/gfio /usr/bin/gfio\n\n进入server模式：./fio -s\n\n使用gfio图形化测试：gfio\n\n问题：\n\n 1. 远程使用图形化界面时出错：motty x11 proxy: unsupported authorisation protocol http://t.zoukankan.com/create-serenditipy-p-15407983.html\n\n普通用户报错，root用户不报错的解决方法： cp /root/.xauthority /home/xxx/\n\n普通用户不报错，root用户报错的解决方法： cp /home/xxx/.xauthority /root/\n\n 2. motty x11 proxy: authorisation not recognised https://blog.csdn.net/u014780310/article/details/118966628\n\n1、cd ~/ 2、xauth list 3、根据前面提示的cannot open localhost：10.0以及上面列出来的unix:10，执行如下命令: xauth add bluedon-pc/unix:10 mit-magic-cookie-1 fd2c21d2294dd751801469e960799ab7 4、退出终端，重新登录\n\n\n# go 安装\n\n$ wget -c https://studygolang.com/dl/golang/go1.18.linux-amd64.tar.gz\n$ tar -c /usr/local -xzf go1.18.linux-amd64.tar.gz\n# 注意升级需要先删除/usr/local/go后再解压\n\n$ vi /root/.bashrc\nexport goroot=/usr/local/go\nexport gopath=/root/go\nexport path=$path:$gopath/bin:$goroot/bin\nexport gobin=/root/go/bin\nexport go111module=on\nexport goproxy=https://goproxy.cn,direct\n\n$ source /root/.bashrc\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# apt安装docker\n\n更新数据源 apt-get update apt-get -y install apt-transport-https ca-certificates curl software-properties-common curl -fssl https://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\" apt-get update && apt-get install -y docker-ce 验证安装 docker version\n\n\n# docker安装\n\n# 卸载旧版本docker软件\n## 以yum方式安装的docker卸载\nyum remove docker \\\n           docker-client \\\n           docker-client-latest \\\n           docker-common \\\n           docker-latest \\\n           docker-latest-logrotate \\\n           docker-logrotate \\\n           docker-selinux \\\n           docker-engine-selinux \\\n           docker-engine \\\n           container*\n## 以rpm方式安装的docker卸载\n### 先查询安装了哪些docker相关的包\n[root@mvxl7365 ~]# rpm -qa|grep docker\ndocker-ce-17.03.2.ce-1.el7.centos.x86_64\ndocker-ce-selinux-17.03.2.ce-1.el7.centos.noarch\n### 逐一进行卸载\n[root@mvxl7365 ~]# rpm -e docker-ce-17.03.2.ce-1.el7.centos.x86_64\n[root@mvxl7365 ~]# rpm -e docker-ce-selinux-17.03.2.ce-1.el7.centos.noarch\n### 检查是否卸载干净\n[root@mvxl7365 ~]# rpm -qa|grep docker\n\n3、使用curl升级到最新版\n命令：\ncurl -fssl https://get.docker.com/ | sh\n\n4、重启docker\n命令：\nsystemctl restart docker\n\n5、设置docker开机自启\n命令：\nsystemctl enable docker\n\n6、查看docker版本信息\n命令：\ndocker version\n\n7、查看docker系统信息，包括镜像和容器数…\n命令：\ndocker info\n\n8、使用docker images命令查看自己之前的镜像是否存在\n命令：\ndocker images\n\n9、查看容器\n命令：\ndocker ps\n如果此时容器列表显示为空，或者重启容器报如下提示：\nerror response from daemon: unknown runtime specified docker-runc\nerror: failed to start containers: yapi\n可执行以下命令：\ngrep -rl 'docker-runc' /var/lib/docker/containers/ | xargs sed -i 's/docker-runc/runc/g'\n然后重启docker，命令如下：\nsystemctl restart docker\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n\n\n\n# centos7安装iperf：\n\nyum install -y iperf3",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"一些工具网站",frontmatter:{title:"一些工具网站",date:"2021-11-02T09:51:37.000Z",permalink:"/pages/yxgjwz/",categories:["技术杂谈","常用总结"],tags:["常用","工具"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"一些工具网站"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/02.%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7%E7%BD%91%E7%AB%99.html"},{property:"og:type",content:"article"},{property:"og:title",content:"一些工具网站"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/02.%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7%E7%BD%91%E7%AB%99.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2021-11-02T09:51:37.000Z"},{property:"article:tag",content:"常用"},{property:"article:tag",content:"工具"},{itemprop:"name",content:"一些工具网站"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/02.%E4%B8%80%E4%BA%9B%E5%B7%A5%E5%85%B7%E7%BD%91%E7%AB%99.html",relativePath:"01.技术杂谈/01.常用总结/02.一些工具网站.md",key:"v-3a9d6f9d",path:"/pages/yxgjwz/",headers:[{level:2,title:"搜索引擎",slug:"搜索引擎",normalizedTitle:"搜索引擎",charIndex:2},{level:2,title:"一些工具网站",slug:"一些工具网站",normalizedTitle:"一些工具网站",charIndex:83},{level:2,title:"一些插件",slug:"一些插件",normalizedTitle:"一些插件",charIndex:166},{level:2,title:"一些常用查询网站",slug:"一些常用查询网站",normalizedTitle:"一些常用查询网站",charIndex:258},{level:2,title:"其他",slug:"其他",normalizedTitle:"其他",charIndex:352}],headersStr:"搜索引擎 一些工具网站 一些插件 一些常用查询网站 其他",content:"# 搜索引擎\n\nhttps://www.google.com https://www.google.com.hk/ https://cn.bing.com/\n\n\n# 一些工具网站\n\nhttp://www.pdman.cn/#/ 数据库建模\n\nhttps://app.diagrams.net/ 画图工具 docker镜像仓\n\n\n# 一些插件\n\n[chrome md]插件(https://blog.csdn.net/twingao/article/details/105170034) google vpn\n\n\n# 一些常用查询网站\n\n学历查询 https://www.iprdb.com/ 专利查询 http://www2.soopat.com/Home/IIndex 专利查询 （qq邮箱）\n\n\n# 其他\n\n查找适合自己当前网络环境的优选Cloudflare Anycast IP",normalizedContent:"# 搜索引擎\n\nhttps://www.google.com https://www.google.com.hk/ https://cn.bing.com/\n\n\n# 一些工具网站\n\nhttp://www.pdman.cn/#/ 数据库建模\n\nhttps://app.diagrams.net/ 画图工具 docker镜像仓\n\n\n# 一些插件\n\n[chrome md]插件(https://blog.csdn.net/twingao/article/details/105170034) google vpn\n\n\n# 一些常用查询网站\n\n学历查询 https://www.iprdb.com/ 专利查询 http://www2.soopat.com/home/iindex 专利查询 （qq邮箱）\n\n\n# 其他\n\n查找适合自己当前网络环境的优选cloudflare anycast ip",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"markdown常用语法组件",frontmatter:{title:"markdown常用语法组件",date:"2022-08-26T09:51:37.000Z",permalink:"/pages/markdown/",categories:["技术杂谈","常用总结"],tags:["常用","工具"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"",meta:[{name:"image",content:"https://pic4.zhimg.com/80/v2-a47051e92cf74930bedd7469978e6c08_hd.png"},{name:"twitter:title",content:"markdown常用语法组件"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://pic4.zhimg.com/80/v2-a47051e92cf74930bedd7469978e6c08_hd.png"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/04.markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E7%BB%84%E4%BB%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"markdown常用语法组件"},{property:"og:description",content:""},{property:"og:image",content:"https://pic4.zhimg.com/80/v2-a47051e92cf74930bedd7469978e6c08_hd.png"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/04.markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E7%BB%84%E4%BB%B6.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-26T09:51:37.000Z"},{property:"article:tag",content:"常用"},{property:"article:tag",content:"工具"},{itemprop:"name",content:"markdown常用语法组件"},{itemprop:"description",content:""},{itemprop:"image",content:"https://pic4.zhimg.com/80/v2-a47051e92cf74930bedd7469978e6c08_hd.png"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/01.%E5%B8%B8%E7%94%A8%E6%80%BB%E7%BB%93/04.markdown%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E7%BB%84%E4%BB%B6.html",relativePath:"01.技术杂谈/01.常用总结/04.markdown常用语法组件.md",key:"v-561954fe",path:"/pages/markdown/",headers:[{level:2,title:"目录导航",slug:"目录导航",normalizedTitle:"目录导航",charIndex:2},{level:2,title:"字体",slug:"字体",normalizedTitle:"字体",charIndex:124},{level:2,title:"分隔线",slug:"分隔线",normalizedTitle:"分隔线",charIndex:241},{level:2,title:"列表",slug:"列表",normalizedTitle:"列表",charIndex:459},{level:2,title:"区块",slug:"区块",normalizedTitle:"区块",charIndex:648},{level:2,title:"代码框",slug:"代码框",normalizedTitle:"代码框",charIndex:812},{level:2,title:"链接",slug:"链接",normalizedTitle:"链接",charIndex:1028},{level:2,title:"图片",slug:"图片",normalizedTitle:"图片",charIndex:1075},{level:2,title:"表格",slug:"表格",normalizedTitle:"表格",charIndex:1084},{level:2,title:"换行",slug:"换行",normalizedTitle:"换行",charIndex:1204},{level:2,title:"流程图",slug:"流程图",normalizedTitle:"流程图",charIndex:1297},{level:2,title:"数学公式",slug:"数学公式",normalizedTitle:"数学公式",charIndex:1305},{level:2,title:"Todo List",slug:"todo-list",normalizedTitle:"todo list",charIndex:1359},{level:2,title:"脚注",slug:"脚注",normalizedTitle:"脚注",charIndex:1402}],headersStr:"目录导航 字体 分隔线 列表 区块 代码框 链接 图片 表格 换行 流程图 数学公式 Todo List 脚注",content:'# 目录导航\n\n[TOC]\n\n[TOC=2] // 提取H1到H2的内容显示 [TOC=3] // 提取H1到H3的内容显示 [TOC=2,3] // 提取H2到H3的内容显示\n\n注意：[TOC] 后面必须增加一个空行才能正确显示目录结构\n\n\n# 字体\n\n斜体文字 斜体文字 粗体文字 粗体文字 粗斜体文字 粗斜体文字 ==背景高亮== 此处被删除\n\n格式化文本 加粗 加粗 小号文本 倾斜 倾斜 下划线 下划线 删除线 删除线 AAA下标 AAA上标 高亮 带下划线文本\n\n\n# 分隔线\n\n----------------------------------------\n\n----------------------------------------\n\n----------------------------------------\n\n----------------------------------------\n\n----------------------------------------\n\n\n# 列表\n\n * 第一项\n * 第二项\n * 第三项\n\n * 第一项\n * 第二项\n * 第三项\n\n * 第一项\n * 第二项\n * 第三项\n\n列表嵌套只需在子列表的选项前添加四个空格即可：\n\n 1. 第一项：\n    * 第一项嵌套的第一个元素\n    * 第一项嵌套的第二个元素\n 2. 第二项：\n    * 第二项嵌套的第一个元素\n    * 第二项嵌套的第二个元素\n\n\n# 区块\n\n> 区块引用\n\n> 最外层\n> \n> > 第一层嵌套\n> > \n> > > 第二层嵌套\n\n> 区块中使用列表\n> \n>  1. 第一项\n>  2. 第二项\n> \n>  * 第一项\n>  * 第二项\n>  * 第三项\n\n * 第一项\n   \n   > Markdown教程 学的不仅是技术更是梦想\n\n * 第二项\n\n\n# 代码框\n\na = 1\n\nThere is a literal backtick (`) here.\n\n//四个空格缩进表示代码块\nimport os\nprint("hello world")\ndef show_time():\nreturn time.time()\n\n\nimport os\nprint("hello world")\ndef show_time():\nreturn time.time()\n\n\n1\n2\n3\n4\n\n\n\n# 链接\n\n这是一个链接 新浪新闻\n\nhttps://news.sina.com.cn/\n\n\n# 图片\n\n\n\n\n# 表格\n\n-: 设置内容或标题栏右对齐 :- 设置内容或标题栏左对齐 :-: 设置内容或标题栏居中对齐\n\n左对齐     居中对齐    右对齐\n单元格11   单元格12   单元格13\n单元格21   单元格22   单元格23\n\n\n# 换行\n\n在行的末尾添加至少两个空格，然后再接Enter另起一行； 第2种方式是在需要换行的两行内容之间空一行； 第3种方式是在需要换行的内容末尾添加一个换行标签，也就是\n标签。\n\n\n# 流程图\n\n\n# 数学公式\n\n推荐一个常用的数学公式在线编译网站：https://www.latexlive.com\n\n\n# Todo List\n\n * [ ] 待办事项\n * [x] 已完成的待办事项\n\n\n# 脚注\n\n在文档末尾写上[+^+数字+]:+文字内容 声明一个脚注 然后就跟文献引用一样，在要引用该脚注的文字后插入[+^+数字+]即可\n\n该方法根据实验证明有效[^1] [^1]:文章链接',normalizedContent:'# 目录导航\n\n[toc]\n\n[toc=2] // 提取h1到h2的内容显示 [toc=3] // 提取h1到h3的内容显示 [toc=2,3] // 提取h2到h3的内容显示\n\n注意：[toc] 后面必须增加一个空行才能正确显示目录结构\n\n\n# 字体\n\n斜体文字 斜体文字 粗体文字 粗体文字 粗斜体文字 粗斜体文字 ==背景高亮== 此处被删除\n\n格式化文本 加粗 加粗 小号文本 倾斜 倾斜 下划线 下划线 删除线 删除线 aaa下标 aaa上标 高亮 带下划线文本\n\n\n# 分隔线\n\n----------------------------------------\n\n----------------------------------------\n\n----------------------------------------\n\n----------------------------------------\n\n----------------------------------------\n\n\n# 列表\n\n * 第一项\n * 第二项\n * 第三项\n\n * 第一项\n * 第二项\n * 第三项\n\n * 第一项\n * 第二项\n * 第三项\n\n列表嵌套只需在子列表的选项前添加四个空格即可：\n\n 1. 第一项：\n    * 第一项嵌套的第一个元素\n    * 第一项嵌套的第二个元素\n 2. 第二项：\n    * 第二项嵌套的第一个元素\n    * 第二项嵌套的第二个元素\n\n\n# 区块\n\n> 区块引用\n\n> 最外层\n> \n> > 第一层嵌套\n> > \n> > > 第二层嵌套\n\n> 区块中使用列表\n> \n>  1. 第一项\n>  2. 第二项\n> \n>  * 第一项\n>  * 第二项\n>  * 第三项\n\n * 第一项\n   \n   > markdown教程 学的不仅是技术更是梦想\n\n * 第二项\n\n\n# 代码框\n\na = 1\n\nthere is a literal backtick (`) here.\n\n//四个空格缩进表示代码块\nimport os\nprint("hello world")\ndef show_time():\nreturn time.time()\n\n\nimport os\nprint("hello world")\ndef show_time():\nreturn time.time()\n\n\n1\n2\n3\n4\n\n\n\n# 链接\n\n这是一个链接 新浪新闻\n\nhttps://news.sina.com.cn/\n\n\n# 图片\n\n\n\n\n# 表格\n\n-: 设置内容或标题栏右对齐 :- 设置内容或标题栏左对齐 :-: 设置内容或标题栏居中对齐\n\n左对齐     居中对齐    右对齐\n单元格11   单元格12   单元格13\n单元格21   单元格22   单元格23\n\n\n# 换行\n\n在行的末尾添加至少两个空格，然后再接enter另起一行； 第2种方式是在需要换行的两行内容之间空一行； 第3种方式是在需要换行的内容末尾添加一个换行标签，也就是\n标签。\n\n\n# 流程图\n\n\n# 数学公式\n\n推荐一个常用的数学公式在线编译网站：https://www.latexlive.com\n\n\n# todo list\n\n * [ ] 待办事项\n * [x] 已完成的待办事项\n\n\n# 脚注\n\n在文档末尾写上[+^+数字+]:+文字内容 声明一个脚注 然后就跟文献引用一样，在要引用该脚注的文字后插入[+^+数字+]即可\n\n该方法根据实验证明有效[^1] [^1]:文章链接',charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"2022踩坑记录",frontmatter:{title:"2022踩坑记录",date:"2022-01-02T09:51:37.000Z",permalink:"/pages/2022ckjl/",categories:["技术杂谈","常用总结"],tags:["踩坑"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"2022踩坑记录"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/02.%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/01.2022%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"2022踩坑记录"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/02.%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/01.2022%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-01-02T09:51:37.000Z"},{property:"article:tag",content:"踩坑"},{itemprop:"name",content:"2022踩坑记录"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/02.%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/01.2022%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95.html",relativePath:"01.技术杂谈/02.踩坑记录/01.2022踩坑记录.md",key:"v-169b12eb",path:"/pages/2022ckjl/",headers:[{level:2,title:"cordns域名解析alpine镜像不兼容问题",slug:"cordns域名解析alpine镜像不兼容问题",normalizedTitle:"cordns域名解析alpine镜像不兼容问题",charIndex:2},{level:2,title:"kata-monitor宿主机服务对kata-deploy的影响",slug:"kata-monitor宿主机服务对kata-deploy的影响",normalizedTitle:"kata-monitor宿主机服务对kata-deploy的影响",charIndex:353},{level:2,title:"containerd重启不影响容器进程；docker也可以",slug:"containerd重启不影响容器进程-docker也可以",normalizedTitle:"containerd重启不影响容器进程；docker也可以",charIndex:414},{level:2,title:"重启服务器containerd启动超时问题",slug:"重启服务器containerd启动超时问题",normalizedTitle:"重启服务器containerd启动超时问题",charIndex:448},{level:2,title:"golang mkdir 777 权限问题",slug:"golang-mkdir-777-权限问题",normalizedTitle:"golang mkdir 777 权限问题",charIndex:528},{level:2,title:"k8s nodename指定节点时资源不足导致failed pod不断创建，如cpu/mem/gpu资源不足",slug:"k8s-nodename指定节点时资源不足导致failed-pod不断创建-如cpu-mem-gpu资源不足",normalizedTitle:"k8s nodename指定节点时资源不足导致failed pod不断创建，如cpu/mem/gpu资源不足",charIndex:635}],headersStr:"cordns域名解析alpine镜像不兼容问题 kata-monitor宿主机服务对kata-deploy的影响 containerd重启不影响容器进程；docker也可以 重启服务器containerd启动超时问题 golang mkdir 777 权限问题 k8s nodename指定节点时资源不足导致failed pod不断创建，如cpu/mem/gpu资源不足",content:"# cordns域名解析alpine镜像不兼容问题\n\n> 20220622\n\nalpine版本兼容性问题会导致backend pod里cordns解析失败 docker镜像是使用alpine作为底包，如果版本不匹配会导致域名解析问题 https://stackoverflow.com/questions/65181012/does-alpine-have-known-dns-issue-within-kubernetes https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/dns-debugging-resolution/ https://github.com/kubernetes-sigs/kind/issues/2418\n\n\n# kata-monitor宿主机服务对kata-deploy的影响\n\n重启服务器会导致kata-deploy起不来\n\n\n# containerd重启不影响容器进程；docker也可以\n\n\n# 重启服务器containerd启动超时问题\n\nhttps://github.com/containerd/containerd/issues/5597\n\n\n# golang mkdir 777 权限问题\n\nhttps://github.com/golang/go/issues/15210 https://zhuanlan.zhihu.com/p/33692995\n\n\n# k8s nodename指定节点时资源不足导致failed pod不断创建，如cpu/mem/gpu资源不足\n\npod.spec.nodeName将Pod直接调度到指定的Node节点上，会【跳过Scheduler的调度策略】，该匹配规则是【强制】匹配。可以越过Taints污点进行调度。\n\nNode didn't have enough resource: cpu, requested: 100000, used: 1440, capacity: 7800\n\nEvents:\n  Type     Reason    Age    From             Message\n  ----     ------    ----   ----             -------\n  Warning  OutOfcpu  4m19s  kubelet, tztest  Node didn't have enough resource: cpu, requested: 100000, used: 1440, capacity: 7800\n\n[root@tztest kbuser]# kubectl get pod -n hff\nNAME                        READY   STATUS     RESTARTS   AGE\nhff-sts-0                   1/1     Running    0          53d\nweb-demo-799fccc7dd-295bk   0/1     OutOfcpu   0          7s\nweb-demo-799fccc7dd-7z6fm   0/1     OutOfcpu   0          11s\nweb-demo-799fccc7dd-n6jzz   0/1     OutOfcpu   0          5s\nweb-demo-799fccc7dd-ph4vt   0/1     OutOfcpu   0          18s\nweb-demo-799fccc7dd-rqhk5   0/1     OutOfcpu   0          3s\nweb-demo-799fccc7dd-t74r7   0/1     OutOfcpu   0          13s\nweb-demo-799fccc7dd-tqhv5   0/1     OutOfcpu   0          9s\nweb-demo-799fccc7dd-xcldr   0/1     OutOfcpu   0          15s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n",normalizedContent:"# cordns域名解析alpine镜像不兼容问题\n\n> 20220622\n\nalpine版本兼容性问题会导致backend pod里cordns解析失败 docker镜像是使用alpine作为底包，如果版本不匹配会导致域名解析问题 https://stackoverflow.com/questions/65181012/does-alpine-have-known-dns-issue-within-kubernetes https://kubernetes.io/zh-cn/docs/tasks/administer-cluster/dns-debugging-resolution/ https://github.com/kubernetes-sigs/kind/issues/2418\n\n\n# kata-monitor宿主机服务对kata-deploy的影响\n\n重启服务器会导致kata-deploy起不来\n\n\n# containerd重启不影响容器进程；docker也可以\n\n\n# 重启服务器containerd启动超时问题\n\nhttps://github.com/containerd/containerd/issues/5597\n\n\n# golang mkdir 777 权限问题\n\nhttps://github.com/golang/go/issues/15210 https://zhuanlan.zhihu.com/p/33692995\n\n\n# k8s nodename指定节点时资源不足导致failed pod不断创建，如cpu/mem/gpu资源不足\n\npod.spec.nodename将pod直接调度到指定的node节点上，会【跳过scheduler的调度策略】，该匹配规则是【强制】匹配。可以越过taints污点进行调度。\n\nnode didn't have enough resource: cpu, requested: 100000, used: 1440, capacity: 7800\n\nevents:\n  type     reason    age    from             message\n  ----     ------    ----   ----             -------\n  warning  outofcpu  4m19s  kubelet, tztest  node didn't have enough resource: cpu, requested: 100000, used: 1440, capacity: 7800\n\n[root@tztest kbuser]# kubectl get pod -n hff\nname                        ready   status     restarts   age\nhff-sts-0                   1/1     running    0          53d\nweb-demo-799fccc7dd-295bk   0/1     outofcpu   0          7s\nweb-demo-799fccc7dd-7z6fm   0/1     outofcpu   0          11s\nweb-demo-799fccc7dd-n6jzz   0/1     outofcpu   0          5s\nweb-demo-799fccc7dd-ph4vt   0/1     outofcpu   0          18s\nweb-demo-799fccc7dd-rqhk5   0/1     outofcpu   0          3s\nweb-demo-799fccc7dd-t74r7   0/1     outofcpu   0          13s\nweb-demo-799fccc7dd-tqhv5   0/1     outofcpu   0          9s\nweb-demo-799fccc7dd-xcldr   0/1     outofcpu   0          15s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"k8s网络",frontmatter:{title:"k8s网络",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s03/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"容器网络发端于 Docker 的网络。Docker 使用了一个比较简单的网络模型，即内部的网桥加内部的保留 IP。",meta:[{name:"twitter:title",content:"k8s网络"},{name:"twitter:description",content:"容器网络发端于 Docker 的网络。Docker 使用了一个比较简单的网络模型，即内部的网桥加内部的保留 IP。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/03.k8s%E7%BD%91%E7%BB%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s网络"},{property:"og:description",content:"容器网络发端于 Docker 的网络。Docker 使用了一个比较简单的网络模型，即内部的网桥加内部的保留 IP。"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/03.k8s%E7%BD%91%E7%BB%9C.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"k8s网络"},{itemprop:"description",content:"容器网络发端于 Docker 的网络。Docker 使用了一个比较简单的网络模型，即内部的网桥加内部的保留 IP。"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/03.k8s%E7%BD%91%E7%BB%9C.html",relativePath:"01.技术杂谈/03.kubernetes/03.k8s网络.md",key:"v-be755618",path:"/pages/k8s03/",headers:[{level:2,title:"docker网络",slug:"docker网络",normalizedTitle:"docker网络",charIndex:2},{level:2,title:"k8s网络",slug:"k8s网络",normalizedTitle:"k8s网络",charIndex:489},{level:3,title:"docker0:",slug:"docker0",normalizedTitle:"docker0:",charIndex:499},{level:3,title:"calico网络",slug:"calico网络",normalizedTitle:"calico网络",charIndex:1130},{level:4,title:"Calico主要由Felix、Orchestrator Plugin、etcd、BIRD和BGP Router Reflector等组件组成。",slug:"calico主要由felix、orchestrator-plugin、etcd、bird和bgp-router-reflector等组件组成。",normalizedTitle:"calico主要由felix、orchestrator plugin、etcd、bird和bgp router reflector等组件组成。",charIndex:1142},{level:4,title:"BGP: Pod 1跨节点访问Pod 2大致流程如下：",slug:"bgp-pod-1跨节点访问pod-2大致流程如下",normalizedTitle:"bgp: pod 1跨节点访问pod 2大致流程如下：",charIndex:1444},{level:4,title:"Calico Route Reflector模式（RR）（路由器反射）",slug:"calico-route-reflector模式-rr-路由器反射",normalizedTitle:"calico route reflector模式（rr）（路由器反射）",charIndex:1677},{level:4,title:"IPIP: Pod 1访问Pod 2大致流程如下：",slug:"ipip-pod-1访问pod-2大致流程如下",normalizedTitle:"ipip: pod 1访问pod 2大致流程如下：",charIndex:1763}],headersStr:"docker网络 k8s网络 docker0: calico网络 Calico主要由Felix、Orchestrator Plugin、etcd、BIRD和BGP Router Reflector等组件组成。 BGP: Pod 1跨节点访问Pod 2大致流程如下： Calico Route Reflector模式（RR）（路由器反射） IPIP: Pod 1访问Pod 2大致流程如下：",content:"# docker网络\n\n容器网络发端于 Docker 的网络。Docker 使用了一个比较简单的网络模型，即内部的网桥加内部的保留 IP。\n\ndocker0：Docker服务会在它所在的机器上创建一个名为docker0的网桥。 docker0的IP地址为172.17.0.1，子网掩码为255.255.0.0。\n\n[root@rqy-k8s-2 kbuser]# docker network ls NETWORK ID NAME DRIVER SCOPE e29e51f3f12a bridge bridge local b70c41f7568e host host local 3a890954cce6 none null local\n\nDocker容器在启动时，如果没有显式指定加入任何网络，就会默认加入到名为bridge的网络。而这个bridge网络就是基于docker0实现的。 加入host网络的容器，可以实现和Docker daemon守护进程（也就是Docker服务）所在的宿主机网络环境进行直接通信 none网络，则表示容器在启动时不带任何网络设备。\n\n\n# k8s网络\n\n\n# docker0:\n\n 1. 同一Pod内的容器间通信: 因为pause容器提供pod内网络共享，所以容器直接可以使用localhost(lo)访问其他容器\n\n 2. 各Pod彼此之间的通信(两个pod在一台主机上面, 两个pod分布在不同主机之上) 1)两个pod在一台主机上面: 通过docker默认的docker网桥互连容器(docker0), ifconfig 查了docker0 2)两个pod分布在不同主机之上: 通过CNI插件实现，eg: flannel,calico\n\n 3. Pod与Service间的通信 Service分配的ip叫cluster ip是一个虚拟ip（相对固定，除非删除service），这个ip只能在k8s集群内部使用， 如果service需要对外提供，只能使用Nodeport方式映射到主机上，使用主机的ip和端口对外提供服务。 节点上面有个kube-proxy进程，这个进程从master apiserver获取信息，感知service和endpoint的创建，然后做两个事： 1.为每个service 在集群中每个节点上面创建一个随机端口，任何该端口上面的连接会代理到相应的pod 2.集群中每个节点安装iptables/ipvs规则，用于clusterip + port路由到上一步定义的随机端口上面， 所以集群中每个node上面都有service的转发规则:iptables -L -n -t filter\n\n\n# calico网络\n\n# Calico主要由Felix、Orchestrator Plugin、etcd、BIRD和BGP Router Reflector等组件组成。\n\n * Felix：Calico Agent，运行于每个节点。\n * Orchestrator Plugi：编排系统（如 Kubernetes 、 OpenStack 等）以将 Calico整合进系统中的插件，例如Kubernetes的CNI。\n * etcd：持久存储Calico数据的存储管理系统。\n * BIRD：用于分发路由信息的BGP客户端。\n * BGP Route Reflector：BGP路由反射器，可选组件，用于较大规模的网络场景。\n\n# BGP: Pod 1跨节点访问Pod 2大致流程如下：\n\n 1. 数据包从容器1出到达Veth Pair另一端（宿主机上，以cali前缀开头）；\n 2. 宿主机根据路由规则，将数据包转发给下一跳（网关）；\n 3. 到达Node2，根据路由规则将数据包转发给cali设备，从而到达容器2。 这里最核心的“下一跳”路由规则，就是由Calico的Felix进程负责维护的。这些路由规则信息，则是通过BGP Client也就是BIRD组件，使用BGP协议传输而来的。\n\n# Calico Route Reflector模式（RR）（路由器反射）\n\nCalico维护的网络在默认是（Node-to-Node Mesh）全互联模式（mesh）\n\n# IPIP: Pod 1访问Pod 2大致流程如下：\n\n 1. 数据包从容器1出到达Veth Pair另一端（宿主机上，以cali前缀开头）；\n 2. 进入IP隧道设备（tunl0），由Linux内核IPIP驱动封装在宿主机网络的IP包中（新的IP包目的地之是原IP包的下一跳地址，即192.168.31.63），这样，就成了Node1到Node2的数据包；\n 3. 数据包经过路由器三层转发到Node2；\n 4. Node2收到数据包后，网络协议栈会使用IPIP驱动进行解包，从中拿到原始IP包；\n 5. 然后根据路由规则，根据路由规则将数据包转发给cali设备，从而到达容器2。",normalizedContent:"# docker网络\n\n容器网络发端于 docker 的网络。docker 使用了一个比较简单的网络模型，即内部的网桥加内部的保留 ip。\n\ndocker0：docker服务会在它所在的机器上创建一个名为docker0的网桥。 docker0的ip地址为172.17.0.1，子网掩码为255.255.0.0。\n\n[root@rqy-k8s-2 kbuser]# docker network ls network id name driver scope e29e51f3f12a bridge bridge local b70c41f7568e host host local 3a890954cce6 none null local\n\ndocker容器在启动时，如果没有显式指定加入任何网络，就会默认加入到名为bridge的网络。而这个bridge网络就是基于docker0实现的。 加入host网络的容器，可以实现和docker daemon守护进程（也就是docker服务）所在的宿主机网络环境进行直接通信 none网络，则表示容器在启动时不带任何网络设备。\n\n\n# k8s网络\n\n\n# docker0:\n\n 1. 同一pod内的容器间通信: 因为pause容器提供pod内网络共享，所以容器直接可以使用localhost(lo)访问其他容器\n\n 2. 各pod彼此之间的通信(两个pod在一台主机上面, 两个pod分布在不同主机之上) 1)两个pod在一台主机上面: 通过docker默认的docker网桥互连容器(docker0), ifconfig 查了docker0 2)两个pod分布在不同主机之上: 通过cni插件实现，eg: flannel,calico\n\n 3. pod与service间的通信 service分配的ip叫cluster ip是一个虚拟ip（相对固定，除非删除service），这个ip只能在k8s集群内部使用， 如果service需要对外提供，只能使用nodeport方式映射到主机上，使用主机的ip和端口对外提供服务。 节点上面有个kube-proxy进程，这个进程从master apiserver获取信息，感知service和endpoint的创建，然后做两个事： 1.为每个service 在集群中每个节点上面创建一个随机端口，任何该端口上面的连接会代理到相应的pod 2.集群中每个节点安装iptables/ipvs规则，用于clusterip + port路由到上一步定义的随机端口上面， 所以集群中每个node上面都有service的转发规则:iptables -l -n -t filter\n\n\n# calico网络\n\n# calico主要由felix、orchestrator plugin、etcd、bird和bgp router reflector等组件组成。\n\n * felix：calico agent，运行于每个节点。\n * orchestrator plugi：编排系统（如 kubernetes 、 openstack 等）以将 calico整合进系统中的插件，例如kubernetes的cni。\n * etcd：持久存储calico数据的存储管理系统。\n * bird：用于分发路由信息的bgp客户端。\n * bgp route reflector：bgp路由反射器，可选组件，用于较大规模的网络场景。\n\n# bgp: pod 1跨节点访问pod 2大致流程如下：\n\n 1. 数据包从容器1出到达veth pair另一端（宿主机上，以cali前缀开头）；\n 2. 宿主机根据路由规则，将数据包转发给下一跳（网关）；\n 3. 到达node2，根据路由规则将数据包转发给cali设备，从而到达容器2。 这里最核心的“下一跳”路由规则，就是由calico的felix进程负责维护的。这些路由规则信息，则是通过bgp client也就是bird组件，使用bgp协议传输而来的。\n\n# calico route reflector模式（rr）（路由器反射）\n\ncalico维护的网络在默认是（node-to-node mesh）全互联模式（mesh）\n\n# ipip: pod 1访问pod 2大致流程如下：\n\n 1. 数据包从容器1出到达veth pair另一端（宿主机上，以cali前缀开头）；\n 2. 进入ip隧道设备（tunl0），由linux内核ipip驱动封装在宿主机网络的ip包中（新的ip包目的地之是原ip包的下一跳地址，即192.168.31.63），这样，就成了node1到node2的数据包；\n 3. 数据包经过路由器三层转发到node2；\n 4. node2收到数据包后，网络协议栈会使用ipip驱动进行解包，从中拿到原始ip包；\n 5. 然后根据路由规则，根据路由规则将数据包转发给cali设备，从而到达容器2。",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"k8s存储",frontmatter:{title:"k8s存储",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s02/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"docker支持多种graphDriver，包括vfs、devicemapper、overlay、overlay2、aufs等等",meta:[{name:"twitter:title",content:"k8s存储"},{name:"twitter:description",content:"docker支持多种graphDriver，包括vfs、devicemapper、overlay、overlay2、aufs等等"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/02.k8s%E5%AD%98%E5%82%A8.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s存储"},{property:"og:description",content:"docker支持多种graphDriver，包括vfs、devicemapper、overlay、overlay2、aufs等等"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/02.k8s%E5%AD%98%E5%82%A8.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"k8s存储"},{itemprop:"description",content:"docker支持多种graphDriver，包括vfs、devicemapper、overlay、overlay2、aufs等等"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/02.k8s%E5%AD%98%E5%82%A8.html",relativePath:"01.技术杂谈/03.kubernetes/02.k8s存储.md",key:"v-132121e4",path:"/pages/k8s02/",headers:[{level:2,title:"Docker 镜像存储原理",slug:"docker-镜像存储原理",normalizedTitle:"docker 镜像存储原理",charIndex:2},{level:3,title:"overlay2",slug:"overlay2",normalizedTitle:"overlay2",charIndex:66},{level:4,title:"新增一个镜像",slug:"新增一个镜像",normalizedTitle:"新增一个镜像",charIndex:1476},{level:4,title:"写时复制",slug:"写时复制",normalizedTitle:"写时复制",charIndex:4157},{level:3,title:"查看docker镜像、容器、数据卷所占用的空间",slug:"查看docker镜像、容器、数据卷所占用的空间",normalizedTitle:"查看docker镜像、容器、数据卷所占用的空间",charIndex:4386},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:4920}],headersStr:"Docker 镜像存储原理 overlay2 新增一个镜像 写时复制 查看docker镜像、容器、数据卷所占用的空间 参考资料",content:'# Docker 镜像存储原理\n\ndocker支持多种graphDriver，包括vfs、devicemapper、overlay、overlay2、aufs等等\n\n\n# overlay2\n\nLinux 内核在 4.0 版本对overlay做了很多必要的改进，此时的 OverlayFS 被称之为overlay2\n\n * 要想使用overlay2，Docker 版本必须高于 17.06.02。\n * 如果你的操作系统是 RHEL 或 CentOS，Linux 内核版本必须使用 3.10.0-514 或者更高版本，其他 Linux 发行版的内核版本必须高于 4.0（例如 Ubuntu 或 Debian）\n * overlay2最好搭配 xfs 文件系统使用，并且使用 xfs 作为底层文件系统时，d_type必须开启，可以使用以下命令验证 d_type 是否开启：\n\n$ xfs_info /var/lib/docker | grep ftype\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\n\n\n1\n2\n\n\nverlay2 是这样储存文件的： overlay2将镜像层和容器层都放在单独的目录，并且有唯一 ID，每一层仅存储发生变化的文件，最终使用联合挂载技术将容器层和镜像层的所有文件统一挂载到容器中，使得容器中看到完整的系统文件。\n\n[root@localhost ~]# docker info | grep Storage\n Storage Driver: overlay2\n\n\n1\n2\n\n\nOverlay驱动的镜像只有两层：一个upper文件系统和一个lower文件系统，分别代表Docker的镜像层和容器层\n\nmerged层是lower层和upper层的统一视图\n\n当需要修改一个文件时，使用CoW将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。\n\n在Docker中，底下的只读层就是image，可写层就是Container。voerlay2驱动存储位置为/var/lib/docker/（/app/docker）\n\n[root@tztest kbuser]# ls /app/docker/\nbuilder  buildkit  containerd  containers  image  kubelet  network  overlay2  plugins  runtimes  swarm  tmp  trust  volumes\n[root@tztest kbuser]# ls /app/docker/overlay2/7e32a486c4dc7a52d0685b7fb3e4f6fb4eb7b9ae963f0820285c3659e3f361ca\ncommitted  diff  link  lower  work\n[root@tztest kbuser]# ls /app/docker/image/overlay2\ndistribution  imagedb  layerdb  repositories.json\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n * overlay2目录，存储镜像和容器的层信息\n\n * image目录，存储镜像元相关信息\n\n * repositories.json就是存储镜像信息，主要是name和image id的对应，digest和image id的对应\n\n# 新增一个镜像\n\n[root@tztest kbuser]# docker images | grep web-demo\nweb-demo_c7cac94                    dev-1648826415118                          df2b573855e0        12 days ago         17.7MB\n[root@tztest kbuser]# ls /app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0\ncommitted  diff  link  lower  work\n\n（可能新增多个镜像层目录文件）\n\n\n//允许一个容器\n[root@tztest kbuser]# docker run --name hfftest -it  df2b573855e0 sh\n[root@tztest kbuser]#  docker ps | grep hfftest\n1e73601f56d9        df2b573855e0                                          "sh"                     34 seconds ago      Up 32 seconds       80/tcp, 8080/tcp         hfftest\n\n\n[root@tztest kbuser]# ls /app/docker/overlay2/ -tl\n总用量 3900\ndrwx------ 5 root root  4096 4月  14 16:42 4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0\ndrwx------ 4 root root  4096 4月  14 16:42 4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0-init\ndrwx------ 2 root root 69632 4月  14 16:42 l\ndrwx------ 4 root root  4096 4月   1 23:22 d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0\n//多了两个目录（4695d98...108d41eb0）和一个l目录\n\nl目录是一堆软连接，把一些较短的随机串软连到镜像层的 diff 文件夹下，这样做是为了避免达到mount命令参数的长度限制。\n\n\n[root@tztest kbuser]# docker inspect df2b573855e0 | grep Dir\n\n"LowerDir": "/app/docker/overlay2/d90eefdee868034a568195793cd1c269664a8e459f773cef20cefe5fc81f9e1b/diff:/app/docker/overlay2/b1789038611adaa88789bc8600ff21ebf28d0f4437ae720bfea03b34d50cc689/diff:/app/docker/overlay2/9c3ce321c132b4e638a2187c58d6af6dff58f74c3f49780df8ee4eb80b0dc5f2/diff:/app/docker/overlay2/198313ba0d321e9efa1205820408780b4edb07027456cfcd89cc660bbfa92953/diff",\n"MergedDir": "/app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0/merged",\n"UpperDir": "/app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0/diff",\n"WorkDir": "/app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0/work"\n\nLowerDir：对应的是容器的只读镜像层，在新生成目录2c...74-init下；\nUpperDir：为容器的可读写层，在新生成目录2c...74下；\nMergedDir：为底层只读镜像层和上层可读写容器层的统一视图\n\n//写入一个文件：\n[root@tztest kbuser]# docker run --name hfftest -it  df2b573855e0 sh\n/app # touch hfftest0414\n/app # echo 111 > hfftest0414\n\n[root@tztest kbuser]# find / -name  hfftest0414\n/app/docker/overlay2/4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0/diff/app/hfftest0414\n/app/docker/overlay2/4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0/merged/app/hfftest0414\n//写入文件在UpperDir和MergedDir中\n\n//停止容器后，创建的文件仍然存在（diff,merge不在了）。当容器被删除后，两个新增目录及其相关文件被删除\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n\n\n# 写时复制\n\noverlay2 对文件的修改采用的是写时复制的工作机制：\n\n * 第一次修改文件：当我们第一次在容器中修改某个文件时，overlay2 会触发写时复制操作，overlay2 首先从镜像层复制文件到容器层，然后在容器层执行对应的文件修改操作。\n * 删除文件或目录：当文件或目录被删除时，overlay2 并不会真正从镜像中删除它，因为镜像层是只读的，overlay2 会创建一个特殊的文件或目录，这种特殊的文件或目录会阻止容器的访问。\n\n\n# 查看docker镜像、容器、数据卷所占用的空间\n\n[root@tztest kbuser]# docker system df\nTYPE                TOTAL               ACTIVE              SIZE                RECLAIMABLE\nImages              117                 51                  18.52GB             11.19GB (60%)\nContainers          203                 100                 2.842GB             1.446GB (50%)\nLocal Volumes       13                  12                  30.42MB             0B (0%)\nBuild Cache         0                   0                   0B                  0B\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 参考资料\n\nhttps://www.modb.pro/db/127388',normalizedContent:'# docker 镜像存储原理\n\ndocker支持多种graphdriver，包括vfs、devicemapper、overlay、overlay2、aufs等等\n\n\n# overlay2\n\nlinux 内核在 4.0 版本对overlay做了很多必要的改进，此时的 overlayfs 被称之为overlay2\n\n * 要想使用overlay2，docker 版本必须高于 17.06.02。\n * 如果你的操作系统是 rhel 或 centos，linux 内核版本必须使用 3.10.0-514 或者更高版本，其他 linux 发行版的内核版本必须高于 4.0（例如 ubuntu 或 debian）\n * overlay2最好搭配 xfs 文件系统使用，并且使用 xfs 作为底层文件系统时，d_type必须开启，可以使用以下命令验证 d_type 是否开启：\n\n$ xfs_info /var/lib/docker | grep ftype\nnaming   =version 2              bsize=4096   ascii-ci=0 ftype=1\n\n\n1\n2\n\n\nverlay2 是这样储存文件的： overlay2将镜像层和容器层都放在单独的目录，并且有唯一 id，每一层仅存储发生变化的文件，最终使用联合挂载技术将容器层和镜像层的所有文件统一挂载到容器中，使得容器中看到完整的系统文件。\n\n[root@localhost ~]# docker info | grep storage\n storage driver: overlay2\n\n\n1\n2\n\n\noverlay驱动的镜像只有两层：一个upper文件系统和一个lower文件系统，分别代表docker的镜像层和容器层\n\nmerged层是lower层和upper层的统一视图\n\n当需要修改一个文件时，使用cow将文件从只读的lower复制到可写的upper进行修改，结果也保存在upper层。\n\n在docker中，底下的只读层就是image，可写层就是container。voerlay2驱动存储位置为/var/lib/docker/（/app/docker）\n\n[root@tztest kbuser]# ls /app/docker/\nbuilder  buildkit  containerd  containers  image  kubelet  network  overlay2  plugins  runtimes  swarm  tmp  trust  volumes\n[root@tztest kbuser]# ls /app/docker/overlay2/7e32a486c4dc7a52d0685b7fb3e4f6fb4eb7b9ae963f0820285c3659e3f361ca\ncommitted  diff  link  lower  work\n[root@tztest kbuser]# ls /app/docker/image/overlay2\ndistribution  imagedb  layerdb  repositories.json\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n * overlay2目录，存储镜像和容器的层信息\n\n * image目录，存储镜像元相关信息\n\n * repositories.json就是存储镜像信息，主要是name和image id的对应，digest和image id的对应\n\n# 新增一个镜像\n\n[root@tztest kbuser]# docker images | grep web-demo\nweb-demo_c7cac94                    dev-1648826415118                          df2b573855e0        12 days ago         17.7mb\n[root@tztest kbuser]# ls /app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0\ncommitted  diff  link  lower  work\n\n（可能新增多个镜像层目录文件）\n\n\n//允许一个容器\n[root@tztest kbuser]# docker run --name hfftest -it  df2b573855e0 sh\n[root@tztest kbuser]#  docker ps | grep hfftest\n1e73601f56d9        df2b573855e0                                          "sh"                     34 seconds ago      up 32 seconds       80/tcp, 8080/tcp         hfftest\n\n\n[root@tztest kbuser]# ls /app/docker/overlay2/ -tl\n总用量 3900\ndrwx------ 5 root root  4096 4月  14 16:42 4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0\ndrwx------ 4 root root  4096 4月  14 16:42 4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0-init\ndrwx------ 2 root root 69632 4月  14 16:42 l\ndrwx------ 4 root root  4096 4月   1 23:22 d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0\n//多了两个目录（4695d98...108d41eb0）和一个l目录\n\nl目录是一堆软连接，把一些较短的随机串软连到镜像层的 diff 文件夹下，这样做是为了避免达到mount命令参数的长度限制。\n\n\n[root@tztest kbuser]# docker inspect df2b573855e0 | grep dir\n\n"lowerdir": "/app/docker/overlay2/d90eefdee868034a568195793cd1c269664a8e459f773cef20cefe5fc81f9e1b/diff:/app/docker/overlay2/b1789038611adaa88789bc8600ff21ebf28d0f4437ae720bfea03b34d50cc689/diff:/app/docker/overlay2/9c3ce321c132b4e638a2187c58d6af6dff58f74c3f49780df8ee4eb80b0dc5f2/diff:/app/docker/overlay2/198313ba0d321e9efa1205820408780b4edb07027456cfcd89cc660bbfa92953/diff",\n"mergeddir": "/app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0/merged",\n"upperdir": "/app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0/diff",\n"workdir": "/app/docker/overlay2/d1142002c8d33580ab1213fff5746027a174d763e37885039df98b7108d41eb0/work"\n\nlowerdir：对应的是容器的只读镜像层，在新生成目录2c...74-init下；\nupperdir：为容器的可读写层，在新生成目录2c...74下；\nmergeddir：为底层只读镜像层和上层可读写容器层的统一视图\n\n//写入一个文件：\n[root@tztest kbuser]# docker run --name hfftest -it  df2b573855e0 sh\n/app # touch hfftest0414\n/app # echo 111 > hfftest0414\n\n[root@tztest kbuser]# find / -name  hfftest0414\n/app/docker/overlay2/4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0/diff/app/hfftest0414\n/app/docker/overlay2/4695d98d682387009f6ab5c84d86599fe35460dae36aea7d00e1561042d630e0/merged/app/hfftest0414\n//写入文件在upperdir和mergeddir中\n\n//停止容器后，创建的文件仍然存在（diff,merge不在了）。当容器被删除后，两个新增目录及其相关文件被删除\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n\n\n# 写时复制\n\noverlay2 对文件的修改采用的是写时复制的工作机制：\n\n * 第一次修改文件：当我们第一次在容器中修改某个文件时，overlay2 会触发写时复制操作，overlay2 首先从镜像层复制文件到容器层，然后在容器层执行对应的文件修改操作。\n * 删除文件或目录：当文件或目录被删除时，overlay2 并不会真正从镜像中删除它，因为镜像层是只读的，overlay2 会创建一个特殊的文件或目录，这种特殊的文件或目录会阻止容器的访问。\n\n\n# 查看docker镜像、容器、数据卷所占用的空间\n\n[root@tztest kbuser]# docker system df\ntype                total               active              size                reclaimable\nimages              117                 51                  18.52gb             11.19gb (60%)\ncontainers          203                 100                 2.842gb             1.446gb (50%)\nlocal volumes       13                  12                  30.42mb             0b (0%)\nbuild cache         0                   0                   0b                  0b\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 参考资料\n\nhttps://www.modb.pro/db/127388',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"k8s基础",frontmatter:{title:"k8s基础",date:"2021-11-02T09:51:37.000Z",permalink:"/pages/k8s01/",categories:["k8s"],tags:["k8s"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"kubectl api-versions\n`",meta:[{name:"twitter:title",content:"k8s基础"},{name:"twitter:description",content:"kubectl api-versions\n`"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/01.k8s%E5%9F%BA%E7%A1%80.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s基础"},{property:"og:description",content:"kubectl api-versions\n`"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/01.k8s%E5%9F%BA%E7%A1%80.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2021-11-02T09:51:37.000Z"},{property:"article:tag",content:"k8s"},{itemprop:"name",content:"k8s基础"},{itemprop:"description",content:"kubectl api-versions\n`"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/01.k8s%E5%9F%BA%E7%A1%80.html",relativePath:"01.技术杂谈/03.kubernetes/01.k8s基础.md",key:"v-4b9555d9",path:"/pages/k8s01/",headers:[{level:2,title:"apiVersion",slug:"apiversion",normalizedTitle:"apiversion",charIndex:2},{level:2,title:"resourceVersion",slug:"resourceversion",normalizedTitle:"resourceversion",charIndex:1054},{level:2,title:"Patch 机制",slug:"patch-机制",normalizedTitle:"patch 机制",charIndex:1361},{level:2,title:"externalTrafficPolicy，跳过SNAT",slug:"externaltrafficpolicy-跳过snat",normalizedTitle:"externaltrafficpolicy，跳过snat",charIndex:1784},{level:2,title:"存储空间资源限制ephemeral-storage",slug:"存储空间资源限制ephemeral-storage",normalizedTitle:"存储空间资源限制ephemeral-storage",charIndex:2066},{level:3,title:"使用限制：",slug:"使用限制",normalizedTitle:"使用限制：",charIndex:2394},{level:3,title:"效果",slug:"效果",normalizedTitle:"效果",charIndex:2549},{level:2,title:"Qos 服务质量等级",slug:"qos-服务质量等级",normalizedTitle:"qos 服务质量等级",charIndex:2605},{level:2,title:"ResourceVersion",slug:"resourceversion-2",normalizedTitle:"resourceversion",charIndex:2998},{level:3,title:"调优建议",slug:"调优建议",normalizedTitle:"调优建议",charIndex:4188},{level:2,title:"主机网络hostNetwork",slug:"主机网络hostnetwork",normalizedTitle:"主机网络hostnetwork",charIndex:4439},{level:2,title:"pod的重启策略",slug:"pod的重启策略",normalizedTitle:"pod的重启策略",charIndex:4698},{level:2,title:"删除一个Pod会发生什么事情？",slug:"删除一个pod会发生什么事情",normalizedTitle:"删除一个pod会发生什么事情？",charIndex:4767},{level:2,title:"镜像拉取策略 ImagePullPolicy",slug:"镜像拉取策略-imagepullpolicy",normalizedTitle:"镜像拉取策略 imagepullpolicy",charIndex:5071},{level:2,title:"为容器配置hosts",slug:"为容器配置hosts",normalizedTitle:"为容器配置hosts",charIndex:5176},{level:2,title:"容器修改hostname",slug:"容器修改hostname",normalizedTitle:"容器修改hostname",charIndex:5392},{level:2,title:"kubernetes 指定节点nodeName与NodeSelector",slug:"kubernetes-指定节点nodename与nodeselector",normalizedTitle:"kubernetes 指定节点nodename与nodeselector",charIndex:5611},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:0}],headersStr:"apiVersion resourceVersion Patch 机制 externalTrafficPolicy，跳过SNAT 存储空间资源限制ephemeral-storage 使用限制： 效果 Qos 服务质量等级 ResourceVersion 调优建议 主机网络hostNetwork pod的重启策略 删除一个Pod会发生什么事情？ 镜像拉取策略 ImagePullPolicy 为容器配置hosts 容器修改hostname kubernetes 指定节点nodeName与NodeSelector ",content:'# apiVersion\n\nkubectl api-versions\n\n\n1\n\n\n * alpha 名称中带有alpha的API版本是进入Kubernetes的新功能的早期候选版本。这些可能包含错误，并且不保证将来可以使用。\n\n * beta API版本名称中的beta表示测试已经超过了alpha级别，并且该功能最终将包含在Kubernetes中。 虽然它的工作方式可能会改变，并且对象的定义方式可能会完全改变，但该特征本身很可能以某种形式将其变为Kubernetes。\n\n * stable 稳定的apiVersion这些名称中不包含alpha或beta。 它们可以安全使用。\n\n * v1 这是Kubernetes API的第一个稳定版本。 它包含许多核心对象。\n\n * apps/v1 apps是Kubernetes中最常见的API组，其中包含许多核心对象和v1。 它包括与在Kubernetes上运行应用程序相关的功能，如Deployments，RollingUpdates和ReplicaSets。\n\n * autoscaling/v1 此API版本允许根据不同的资源使用指标自动调整容器。此稳定版本仅支持CPU扩展，但未来的alpha和beta版本将允许您根据内存使用情况和自定义指标进行扩展。\n\n * batch/v1 batchAPI组包含与批处理和类似作业的任务相关的对象（而不是像应用程序一样的任务，如无限期地运行Web服务器）。 这个apiVersion是这些API对象的第一个稳定版本。\n\n * batch/v1beta1 Kubernetes中批处理对象的新功能测试版，特别是包括允许您在特定时间或周期运行作业的CronJobs。\n\n * certificates.k8s.io/v1beta1 此API版本添加了验证网络证书的功能，以便在群集中进行安全通信。 您可以在官方文档上阅读更多内容。\n\n * extensions/v1beta1 此版本的API包含许多新的常用Kubernetes功能。 部署，DaemonSets，ReplicaSet和Ingresses都在此版本中收到了重大更改。\n\n * policy/v1beta1 此apiVersion增加了设置pod中断预算和pod安全性新规则的功能\n\n * rbac.authorization.k8s.io/v1 此apiVersion包含Kubernetes基于角色的访问控制的额外功能。这有助于您保护群集\n\n\n# resourceVersion\n\n这个版本号是一个 K8s 的内部机制，用户不应该假设它是一个数字或者通过比较两个版本号大小来确定资源对象的新旧，唯一能做的就是通过比较版本号相等来确定对象是否是同一个版本（即是否发生了变化）。而 resourceVersion 一个重要的用处，就是来做 update 请求的版本控制。 kube-apiserver 会校验用户 update 请求提交对象中的 resourceVersion 一定要和当前 K8s 中这个对象最新的 resourceVersion 一致，才能接受本次 update。否则，K8s 会拒绝请求，并告诉用户发生了版本冲突（Conflict）。\n\n\n# Patch 机制\n\n * json patch 在 json patch 中我们要指定操作类型，比如 add 新增还是 replace 替换，另外在修改 containers 列表时要通过元素序号来指定容器。\n\n * merge patch（默认） merge patch 无法单独更新一个列表中的某个元素，因此不管我们是要在 containers 里新增容器、还是修改已有容器的 image、env 等字段，都要用整个 containers 列表来提交 patch：\n\n * strategic merge patch 在我们 patch 更新 containers 不再需要指定下标序号了，而是指定 name 来修改，K8s 会把 name 作为 key 来计算 merge。 目前 strategic 策略只能用于原生 K8s 资源以及 Aggregated API 方式的自定义资源，对于 CRD 定义的资源对象，是无法使用的。\n\n\n# externalTrafficPolicy，跳过SNAT\n\n对于Service, 如果指定类型为 NodePort, 那么这个端口会在集群的所有 Node 上打开，即使这个Node 上面没有这个pod\n\nKube-proxy转发时会保留源IP。即：容器收到的报文，看到源IP地址还是用户的。\n\n缺点是负载均衡可能不是很好，因为一旦容器实例分布在多个节点上，它只转发给本机，不跨节点转发流量。当然，少了一次转发，性能会相对好一丢丢。\n\n注：这种模式下的Service类型只能为外部流量，即：LoadBalancer 或者 NodePort 两种，否则会报错\n\n\n# 存储空间资源限制ephemeral-storage\n\n在每个Kubernetes的节点上，kubelet的根目录(默认是/var/lib/kubelet)和日志目录(/var/log)保存在节点的主分区上，这个分区同时也会被Pod的EmptyDir类型的volume、容器日志、镜像的层、容器的可写层所占用。\n\nresources:\n  requests:\n    cpu: 1\n    memory: 2048Mi\n    ephemeral-storage: 2Gi\n  limits:\n    cpu: 2\n    memory: 2048Mi\n    ephemeral-storage: 5Gi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 使用限制：\n\n * 只要Root Dir和kubelet --root-dir在一个分区，就能起作用\n * 如果运行时指定了别的独立的分区，比如修改了docker的镜像层和容器可写层的存储位置(默认是/var/lib/docker)所在的分区，将不再将其计入ephemeral-storage的消耗。\n\n\n# 效果\n\n在容器写入超过存储限制时就会被驱逐掉 teststorage 0/1 Evicted 0 1m\n\n\n# Qos 服务质量等级\n\nGuaranteed：Pod 里的每个容器都必须有内存/CPU 限制和请求，而且值必须相等。 Burstable：Pod 里至少有一个容器有内存或者 CPU 请求且不满足 Guarantee 等级的要求，即内存/CPU 的值设置的不同。 BestEffort：容器必须没有任何内存或者 CPU 的限制或请求。\n\n三个级别的优先级从低到高的顺序是： BestEffort pods -> Burstable pods -> Guaranteed pods\n\n可压缩资源：如CPU，即使cpu 超配，也可以划分时间片运行，只是运行变慢，进程不会挂。 不可压缩资源：Memory/Storage，内存不同于CPU，系统内存不足时，会触发 OOM杀死进程，按照oom score 来确定先kill谁，oom_score_adj值越高，被kill 的优先级越高。\n\n\n# ResourceVersion\n\n绝大部分情况下，apiserver 直接从本地缓存提供服务（因为它缓存了集群全量数据）； 某些特殊情况，例如， 客户端明确要求从 etcd 读数据（追求最高的数据准确性） apiserver 本地缓存还没建好 对于非结构化的数据存储系统来说，LIST操作通常都是非常重量级的，不仅占用大量的 磁盘 IO、网络带宽和 CPU。K8s的LIST请求大部分都应该被apiserver挡住，从它的本地缓存提供服务，但如果使用不当，就会跳过缓存直接到达 etcd，有很大的稳定性风险。\n\nGet请求：GetOptions{}与ListOption{}一样，不设置ResourceVersion=0会导致 apiserver去etcd拿数据，应该尽量避免。\n\nWhen specified with a watch call, shows changes that occur after that particular version of a resource. Defaults to changes from the beginning of history. \nWhen specified for list: \n\n\n1\n2\n\n * if unset, then the result is returned from remote storage based on quorum-read flag;\n * if it\'s 0, then we simply return what we currently have in cache, no guarantee;\n * if set to non zero, then the result is at least as fresh as given rv. 未指定ResourceVersion，获取最新数据；ApiServer收到这个类型的读请求后，会向Etcd发出线性读请求获取etcd最新数据 ResourceVersion=“0”,获取ApiServer的缓存数据，有可能是过期数据。 ResouceVersion为非0的字符串，获取不小于该version的数据。 默认是未指定ResouceVersion。 如果客户端没传ListOption，则初始化一个默认值，其中的ResourceVersion设置为空字符串， 这将使apiserver从etcd拉取数据来返回给客户端，而不使用本地缓存（除非本地缓存还没有建好）。 resourceVersion=0将导致limit被忽略，也就是说， 虽然指定了limit，但请求会返回全量数据。 从 v1.19 版本开始，Kubernetes API 服务器支持 list 请求的 resourceVersionMatch 参数\n\n\n# 调优建议\n\nList 请求默认设置 ResourceVersion=0 优先使用 namespaced API 通过label/field selector做过滤\n\nhttp://arthurchiao.art/blog/k8s-reliability-list-data-zh https://www.pudn.com/news/62c14ac49f2d63494a8b7887.html https://kubernetes.io/zh-cn/docs/reference/_print/\n\n\n# 主机网络hostNetwork\n\n * Pod使用主机网络只需要在配置中添加hostNetwork: true即可\n * 部署后可以看到Pod的IP与节点的IP相同，说明Pod直接使用了主机网络。\n * Pod直接使用主机的网络会占用宿主机的端口，Pod的IP就是宿主机的IP，使用时需要考虑是否与主机上的端口冲突\n * 由于占用主机端口，使用Deployment部署hostNetwork类型Pod时，要注意Pod的副本数不要超过节点数量，否则会导致一个节点上调度了多个Pod，Pod启动时端口冲突无法创建\n\n\n# pod的重启策略\n\nAlways：但凡pod对象终止就重启，此为默认策略。\n\nOnFailure：仅在pod对象出现错误时才重启\n\n\n# 删除一个Pod会发生什么事情？\n\nKube-apiserver会接受到用户的删除指令，默认有30秒时间等待优雅退出，超过30秒会被标记为死亡状态，此时Pod的状态Terminating，kubelet看到pod标记为Terminating就开始了关闭Pod的工作；\n\n关闭流程如下： 1、 pod从service的endpoint列表中被移除； 2、 如果该pod定义了一个停止前的钩子，其会在pod内部被调用，停止钩子一般定义了如何优雅的结束进程； 3、 进程被发送TERM信号（kill -14） 4、 当超过优雅退出的时间后，Pod中的所有进程都会被发送SIGKILL信号（kill -9）。\n\n\n# 镜像拉取策略 ImagePullPolicy\n\nAlways：不管镜像是否存在都会进行一次拉取 Never：不管镜像是否存在都不会进行拉取 IfNotPresent：只有镜像不存在时，才会进行镜像拉取\n\n\n# 为容器配置hosts\n\n\n# 配置在二级ipsec下，和cointariners同级\n\nspec:\n   ...\n    spec:\n      hostAliases:\n      - ip: "172.16.0.12"\n        hostnames:\n        - "api.cc.pro"\n      containers:\n      - name: cc-x\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 容器修改hostname\n\nspec:\n  hostname: busybox-1\n  subdomain: busybox-subdomain\n\n\n1\n2\n3\n\n\n因为pod的访问域名是hostname.custom-subdomain.default.svc.cluster.local\n\n所以该 Pod 的域名是 busybox-1.busybox-subdomain.default.svc.cluster.local。\n\n\n# kubernetes 指定节点nodeName与NodeSelector\n\nPod.spec.nodeName用于强制约束将Pod调度到指定的Node节点上，这里说是“调度”，但其实指定了nodeName的Pod会直接跳过Scheduler的调度逻辑，直接写入PodList列表，该匹配规则是强制匹配。 Pod.spec.nodeSelector是通过kubernetes的label-selector机制进行节点选择，由scheduler调度策略MatchNodeSelector进行label匹配，调度pod到目标节点，该匹配规则是强制约束。启用节点选择器的步骤为：Node添加label标记>Pod定义中添加nodeSelector\n\n\n#',normalizedContent:'# apiversion\n\nkubectl api-versions\n\n\n1\n\n\n * alpha 名称中带有alpha的api版本是进入kubernetes的新功能的早期候选版本。这些可能包含错误，并且不保证将来可以使用。\n\n * beta api版本名称中的beta表示测试已经超过了alpha级别，并且该功能最终将包含在kubernetes中。 虽然它的工作方式可能会改变，并且对象的定义方式可能会完全改变，但该特征本身很可能以某种形式将其变为kubernetes。\n\n * stable 稳定的apiversion这些名称中不包含alpha或beta。 它们可以安全使用。\n\n * v1 这是kubernetes api的第一个稳定版本。 它包含许多核心对象。\n\n * apps/v1 apps是kubernetes中最常见的api组，其中包含许多核心对象和v1。 它包括与在kubernetes上运行应用程序相关的功能，如deployments，rollingupdates和replicasets。\n\n * autoscaling/v1 此api版本允许根据不同的资源使用指标自动调整容器。此稳定版本仅支持cpu扩展，但未来的alpha和beta版本将允许您根据内存使用情况和自定义指标进行扩展。\n\n * batch/v1 batchapi组包含与批处理和类似作业的任务相关的对象（而不是像应用程序一样的任务，如无限期地运行web服务器）。 这个apiversion是这些api对象的第一个稳定版本。\n\n * batch/v1beta1 kubernetes中批处理对象的新功能测试版，特别是包括允许您在特定时间或周期运行作业的cronjobs。\n\n * certificates.k8s.io/v1beta1 此api版本添加了验证网络证书的功能，以便在群集中进行安全通信。 您可以在官方文档上阅读更多内容。\n\n * extensions/v1beta1 此版本的api包含许多新的常用kubernetes功能。 部署，daemonsets，replicaset和ingresses都在此版本中收到了重大更改。\n\n * policy/v1beta1 此apiversion增加了设置pod中断预算和pod安全性新规则的功能\n\n * rbac.authorization.k8s.io/v1 此apiversion包含kubernetes基于角色的访问控制的额外功能。这有助于您保护群集\n\n\n# resourceversion\n\n这个版本号是一个 k8s 的内部机制，用户不应该假设它是一个数字或者通过比较两个版本号大小来确定资源对象的新旧，唯一能做的就是通过比较版本号相等来确定对象是否是同一个版本（即是否发生了变化）。而 resourceversion 一个重要的用处，就是来做 update 请求的版本控制。 kube-apiserver 会校验用户 update 请求提交对象中的 resourceversion 一定要和当前 k8s 中这个对象最新的 resourceversion 一致，才能接受本次 update。否则，k8s 会拒绝请求，并告诉用户发生了版本冲突（conflict）。\n\n\n# patch 机制\n\n * json patch 在 json patch 中我们要指定操作类型，比如 add 新增还是 replace 替换，另外在修改 containers 列表时要通过元素序号来指定容器。\n\n * merge patch（默认） merge patch 无法单独更新一个列表中的某个元素，因此不管我们是要在 containers 里新增容器、还是修改已有容器的 image、env 等字段，都要用整个 containers 列表来提交 patch：\n\n * strategic merge patch 在我们 patch 更新 containers 不再需要指定下标序号了，而是指定 name 来修改，k8s 会把 name 作为 key 来计算 merge。 目前 strategic 策略只能用于原生 k8s 资源以及 aggregated api 方式的自定义资源，对于 crd 定义的资源对象，是无法使用的。\n\n\n# externaltrafficpolicy，跳过snat\n\n对于service, 如果指定类型为 nodeport, 那么这个端口会在集群的所有 node 上打开，即使这个node 上面没有这个pod\n\nkube-proxy转发时会保留源ip。即：容器收到的报文，看到源ip地址还是用户的。\n\n缺点是负载均衡可能不是很好，因为一旦容器实例分布在多个节点上，它只转发给本机，不跨节点转发流量。当然，少了一次转发，性能会相对好一丢丢。\n\n注：这种模式下的service类型只能为外部流量，即：loadbalancer 或者 nodeport 两种，否则会报错\n\n\n# 存储空间资源限制ephemeral-storage\n\n在每个kubernetes的节点上，kubelet的根目录(默认是/var/lib/kubelet)和日志目录(/var/log)保存在节点的主分区上，这个分区同时也会被pod的emptydir类型的volume、容器日志、镜像的层、容器的可写层所占用。\n\nresources:\n  requests:\n    cpu: 1\n    memory: 2048mi\n    ephemeral-storage: 2gi\n  limits:\n    cpu: 2\n    memory: 2048mi\n    ephemeral-storage: 5gi\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 使用限制：\n\n * 只要root dir和kubelet --root-dir在一个分区，就能起作用\n * 如果运行时指定了别的独立的分区，比如修改了docker的镜像层和容器可写层的存储位置(默认是/var/lib/docker)所在的分区，将不再将其计入ephemeral-storage的消耗。\n\n\n# 效果\n\n在容器写入超过存储限制时就会被驱逐掉 teststorage 0/1 evicted 0 1m\n\n\n# qos 服务质量等级\n\nguaranteed：pod 里的每个容器都必须有内存/cpu 限制和请求，而且值必须相等。 burstable：pod 里至少有一个容器有内存或者 cpu 请求且不满足 guarantee 等级的要求，即内存/cpu 的值设置的不同。 besteffort：容器必须没有任何内存或者 cpu 的限制或请求。\n\n三个级别的优先级从低到高的顺序是： besteffort pods -> burstable pods -> guaranteed pods\n\n可压缩资源：如cpu，即使cpu 超配，也可以划分时间片运行，只是运行变慢，进程不会挂。 不可压缩资源：memory/storage，内存不同于cpu，系统内存不足时，会触发 oom杀死进程，按照oom score 来确定先kill谁，oom_score_adj值越高，被kill 的优先级越高。\n\n\n# resourceversion\n\n绝大部分情况下，apiserver 直接从本地缓存提供服务（因为它缓存了集群全量数据）； 某些特殊情况，例如， 客户端明确要求从 etcd 读数据（追求最高的数据准确性） apiserver 本地缓存还没建好 对于非结构化的数据存储系统来说，list操作通常都是非常重量级的，不仅占用大量的 磁盘 io、网络带宽和 cpu。k8s的list请求大部分都应该被apiserver挡住，从它的本地缓存提供服务，但如果使用不当，就会跳过缓存直接到达 etcd，有很大的稳定性风险。\n\nget请求：getoptions{}与listoption{}一样，不设置resourceversion=0会导致 apiserver去etcd拿数据，应该尽量避免。\n\nwhen specified with a watch call, shows changes that occur after that particular version of a resource. defaults to changes from the beginning of history. \nwhen specified for list: \n\n\n1\n2\n\n * if unset, then the result is returned from remote storage based on quorum-read flag;\n * if it\'s 0, then we simply return what we currently have in cache, no guarantee;\n * if set to non zero, then the result is at least as fresh as given rv. 未指定resourceversion，获取最新数据；apiserver收到这个类型的读请求后，会向etcd发出线性读请求获取etcd最新数据 resourceversion=“0”,获取apiserver的缓存数据，有可能是过期数据。 resouceversion为非0的字符串，获取不小于该version的数据。 默认是未指定resouceversion。 如果客户端没传listoption，则初始化一个默认值，其中的resourceversion设置为空字符串， 这将使apiserver从etcd拉取数据来返回给客户端，而不使用本地缓存（除非本地缓存还没有建好）。 resourceversion=0将导致limit被忽略，也就是说， 虽然指定了limit，但请求会返回全量数据。 从 v1.19 版本开始，kubernetes api 服务器支持 list 请求的 resourceversionmatch 参数\n\n\n# 调优建议\n\nlist 请求默认设置 resourceversion=0 优先使用 namespaced api 通过label/field selector做过滤\n\nhttp://arthurchiao.art/blog/k8s-reliability-list-data-zh https://www.pudn.com/news/62c14ac49f2d63494a8b7887.html https://kubernetes.io/zh-cn/docs/reference/_print/\n\n\n# 主机网络hostnetwork\n\n * pod使用主机网络只需要在配置中添加hostnetwork: true即可\n * 部署后可以看到pod的ip与节点的ip相同，说明pod直接使用了主机网络。\n * pod直接使用主机的网络会占用宿主机的端口，pod的ip就是宿主机的ip，使用时需要考虑是否与主机上的端口冲突\n * 由于占用主机端口，使用deployment部署hostnetwork类型pod时，要注意pod的副本数不要超过节点数量，否则会导致一个节点上调度了多个pod，pod启动时端口冲突无法创建\n\n\n# pod的重启策略\n\nalways：但凡pod对象终止就重启，此为默认策略。\n\nonfailure：仅在pod对象出现错误时才重启\n\n\n# 删除一个pod会发生什么事情？\n\nkube-apiserver会接受到用户的删除指令，默认有30秒时间等待优雅退出，超过30秒会被标记为死亡状态，此时pod的状态terminating，kubelet看到pod标记为terminating就开始了关闭pod的工作；\n\n关闭流程如下： 1、 pod从service的endpoint列表中被移除； 2、 如果该pod定义了一个停止前的钩子，其会在pod内部被调用，停止钩子一般定义了如何优雅的结束进程； 3、 进程被发送term信号（kill -14） 4、 当超过优雅退出的时间后，pod中的所有进程都会被发送sigkill信号（kill -9）。\n\n\n# 镜像拉取策略 imagepullpolicy\n\nalways：不管镜像是否存在都会进行一次拉取 never：不管镜像是否存在都不会进行拉取 ifnotpresent：只有镜像不存在时，才会进行镜像拉取\n\n\n# 为容器配置hosts\n\n\n# 配置在二级ipsec下，和cointariners同级\n\nspec:\n   ...\n    spec:\n      hostaliases:\n      - ip: "172.16.0.12"\n        hostnames:\n        - "api.cc.pro"\n      containers:\n      - name: cc-x\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 容器修改hostname\n\nspec:\n  hostname: busybox-1\n  subdomain: busybox-subdomain\n\n\n1\n2\n3\n\n\n因为pod的访问域名是hostname.custom-subdomain.default.svc.cluster.local\n\n所以该 pod 的域名是 busybox-1.busybox-subdomain.default.svc.cluster.local。\n\n\n# kubernetes 指定节点nodename与nodeselector\n\npod.spec.nodename用于强制约束将pod调度到指定的node节点上，这里说是“调度”，但其实指定了nodename的pod会直接跳过scheduler的调度逻辑，直接写入podlist列表，该匹配规则是强制匹配。 pod.spec.nodeselector是通过kubernetes的label-selector机制进行节点选择，由scheduler调度策略matchnodeselector进行label匹配，调度pod到目标节点，该匹配规则是强制约束。启用节点选择器的步骤为：node添加label标记>pod定义中添加nodeselector\n\n\n#',charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"pod cgroup和资源限制",frontmatter:{title:"pod cgroup和资源限制",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s04/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"Cgroups 是 Control Groups 的缩写，由 Linux内核提供。用于限制、记录和隔离进程组使用的物理资源（CPU、内存、i/o）。",meta:[{name:"twitter:title",content:"pod cgroup和资源限制"},{name:"twitter:description",content:"Cgroups 是 Control Groups 的缩写，由 Linux内核提供。用于限制、记录和隔离进程组使用的物理资源（CPU、内存、i/o）。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/04.pod%20cgroup%E5%92%8C%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"pod cgroup和资源限制"},{property:"og:description",content:"Cgroups 是 Control Groups 的缩写，由 Linux内核提供。用于限制、记录和隔离进程组使用的物理资源（CPU、内存、i/o）。"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/04.pod%20cgroup%E5%92%8C%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"pod cgroup和资源限制"},{itemprop:"description",content:"Cgroups 是 Control Groups 的缩写，由 Linux内核提供。用于限制、记录和隔离进程组使用的物理资源（CPU、内存、i/o）。"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/04.pod%20cgroup%E5%92%8C%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6.html",relativePath:"01.技术杂谈/03.kubernetes/04.pod cgroup和资源限制.md",key:"v-26c04c03",path:"/pages/k8s04/",headers:[{level:2,title:"K8s中的Cgroups",slug:"k8s中的cgroups",normalizedTitle:"k8s中的cgroups",charIndex:1589},{level:3,title:"容器级别的Cgroup",slug:"容器级别的cgroup",normalizedTitle:"容器级别的cgroup",charIndex:1936},{level:3,title:"Pod级别的Cgroup",slug:"pod级别的cgroup",normalizedTitle:"pod级别的cgroup",charIndex:2119},{level:3,title:"QoS级别的Cgroup",slug:"qos级别的cgroup",normalizedTitle:"qos级别的cgroup",charIndex:2635},{level:3,title:"节点Node级别的Cgroup",slug:"节点node级别的cgroup",normalizedTitle:"节点node级别的cgroup",charIndex:3026},{level:2,title:"资源限制",slug:"资源限制",normalizedTitle:"资源限制",charIndex:3145},{level:3,title:"Eviction",slug:"eviction",normalizedTitle:"eviction",charIndex:3723},{level:2,title:"容器是一个“单进程”模型",slug:"容器是一个-单进程-模型",normalizedTitle:"容器是一个“单进程”模型",charIndex:4226}],headersStr:"K8s中的Cgroups 容器级别的Cgroup Pod级别的Cgroup QoS级别的Cgroup 节点Node级别的Cgroup 资源限制 Eviction 容器是一个“单进程”模型",content:"Cgroups 是 Control Groups 的缩写，由 Linux内核提供。用于限制、记录和隔离进程组使用的物理资源（CPU、内存、i/o）。\n\n[root@localhost ~]# mount -t cgroup\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\ncpuset、cpu、 memory子系统\n\ncfs_period和cfs_quota:限制进程在长度为cfs_period的一段时间内，只能被分配到总量为cfs_quota的CPU时间,CPU quota默认没有任何限制（即：-1）,CPU period默认100 ms（100000 us）\n\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/docker/cpu.cfs_period_us\n100000\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/docker/cpu.cfs_quota_us\n-1\n\n\n1\n2\n3\n4\n\n\n注： 可压缩资源：cpu等(当可压缩资源不足时，Pod只会“饥饿”，但不会退出) 非可压缩资源： mem(当不可压缩资源不足时，Pod就会因为OOM（Out-Of-Memory）被内核杀掉。)\n\n\n# K8s中的Cgroups\n\nkubelet启动时，它会根据需要创建一个4层的cgroup树。\n\n * Node(root) cgroup\n * QoS cgroup\n * Pod cgroup\n * Container cgroup\n\nKubelet运行在Kubernetes集群的工作节点上，管理pod的生命周期，连接到CRI、CNI、CSI等运行时接口，通过cgroup按照配置向pod提供资源，并在使用超过时删除或OOMKilled pod。\n\nkubelet中的所有cgroup操作都是由其内部的containerManager模块实现的，该模块通过cgroup(从下到上)对资源使用进行逐层限制\n\n> container-> pod-> qos -> node(root)。\n\n\n# 容器级别的Cgroup\n\n * 如果容器超出其内存限制，则可能终止该容器。如果它是可重新启动的，kubelet将重新启动它，就像处理任何其他类型的运行时故障一样。\n * 如果容器超出了它的内存请求，那么每当节点耗尽内存时，它的Pod很可能会被逐出。\n * 容器可能被允许，也可能不被允许在较长时间内超过其CPU限制。但是，它不会因为CPU占用过多而被杀死。\n\n\n# Pod级别的Cgroup\n\n每个pod都有一定的开销资源，比如由sandbox容器或docker containerd-shim(在1.22中删除)使用的资源。另外，pod在指定内存类型的卷时也会占用内存资源。\n\n * 计算所有pod容器的CPU请求/限制和内存限制，并将CPU请求/限制转换为cpuhares和cpuQuota。\n\n> pod/cpu.shares = sum(pod.spec.containers.resources.requests[cpu]) pod/cpu.cfs_quota_us = sum(pod.spec.containers.resources.limits[cpu]) pod/memory.limit_in_bytes = sum(pod.spec.containers.resources.limits[memory])\n\n * 只有pod cgroup的cpu。如果其中一个容器只指定请求而不指定限制，则将设置共享值，而不设置其限制值。\n\n * 只设置cpu。当无容器指定请求值或限制值时共享，即pod在资源空闲时使用所有节点资源，在资源受限时不获取任何资源，符合低优先级原则\n\n\n# QoS级别的Cgroup\n\n * Guaranteed(保证型)::由请求设置的值等于由限制设置的值。 当Pod里的每一个Container都同时设置了requests和limits，并且requests和limits值相等的时候，这个Pod就属于Guaranteed类别\n * Burstable(突增型):请求设置的值小于限制设置的值，但是!= 0。 而当Pod不满足Guaranteed的条件，但至少有一个Container设置了requests。那么这个Pod就会被划分到Burstable类别\n * BestEffort(尽力而为型):请求和限制设置的值都是0。 优先级是 而如果一个Pod既没有设置requests，也没有设置limits，那么它的QoS类别就是BestEffort\n\n> Guaranteed > Burstable > BestEffort\n\n\n# 节点Node级别的Cgroup\n\n * 业务流程使用的资源，即pod使用的资源。\n * Kubernetes组件使用的资源，如kubelet和docker。\n * 系统组件使用的资源，如logind、journald和其他进程。\n\n\n# 资源限制\n\n在调度的时候，kube-scheduler只会按照requests的值进行计算。而在真正设置Cgroups限制的时候，kubelet则会按照limits的值来进行设置。\n\n * 当你指定了requests.cpu=250m之后，相当于将Cgroups的cpu.shares的值设置为(250/1000)*1024。而当你没有设置requests.cpu的时候，cpu.shares默认则是1024\n\n * 如果你指定了limits.cpu=500m之后，则相当于将Cgroups的cpu.cfs_quota_us的值设置为(500/1000)*100ms，而cpu.cfs_period_us的值始终是100ms。这样，Kubernetes就为你设置了这个容器只能用到CPU的50%。\n\n * 对于内存来说，当你指定了limits.memory=128Mi之后，相当于将Cgroups的memory.limit_in_bytes设置为128 * 1024 * 1024。\n\n> Kubernetes这种对CPU和内存资源限额的设计，实际上参考了Borg论文中对“动态资源边界”的定义，既：容器化作业在提交时所设置的资源边界，并不一定是调度系统所必须严格遵守的，这是因为在实际场景中，大多数作业使用到的资源其实远小于它所请求的资源限额。\n\n\n# Eviction\n\n目前，Kubernetes为你设置的Eviction的默认阈值如下所示：\n\nmemory.available<100Mi nodefs.available<10% nodefs.inodesFree<5% imagefs.available<15% 当然，上述各个触发条件在kubelet里都是可配置的。比如下面这个例子：\n\nkubelet --eviction-hard=imagefs.available<10%,memory.available<500Mi,nodefs.available<5%,nodefs.inodesFree<5% --eviction-soft=imagefs.available<30%,nodefs.available<10% --eviction-soft-grace-period=imagefs.available=2m,nodefs.available=2m --eviction-max-pod-grace-period=600 在这个配置中，你可以看到Eviction在Kubernetes里其实分为Soft和Hard两种模式。\n\n\n# 容器是一个“单进程”模型",normalizedContent:"cgroups 是 control groups 的缩写，由 linux内核提供。用于限制、记录和隔离进程组使用的物理资源（cpu、内存、i/o）。\n\n[root@localhost ~]# mount -t cgroup\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent=/usr/lib/systemd/systemd-cgroups-agent,name=systemd)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)\ncgroup on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\ncpuset、cpu、 memory子系统\n\ncfs_period和cfs_quota:限制进程在长度为cfs_period的一段时间内，只能被分配到总量为cfs_quota的cpu时间,cpu quota默认没有任何限制（即：-1）,cpu period默认100 ms（100000 us）\n\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/docker/cpu.cfs_period_us\n100000\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/docker/cpu.cfs_quota_us\n-1\n\n\n1\n2\n3\n4\n\n\n注： 可压缩资源：cpu等(当可压缩资源不足时，pod只会“饥饿”，但不会退出) 非可压缩资源： mem(当不可压缩资源不足时，pod就会因为oom（out-of-memory）被内核杀掉。)\n\n\n# k8s中的cgroups\n\nkubelet启动时，它会根据需要创建一个4层的cgroup树。\n\n * node(root) cgroup\n * qos cgroup\n * pod cgroup\n * container cgroup\n\nkubelet运行在kubernetes集群的工作节点上，管理pod的生命周期，连接到cri、cni、csi等运行时接口，通过cgroup按照配置向pod提供资源，并在使用超过时删除或oomkilled pod。\n\nkubelet中的所有cgroup操作都是由其内部的containermanager模块实现的，该模块通过cgroup(从下到上)对资源使用进行逐层限制\n\n> container-> pod-> qos -> node(root)。\n\n\n# 容器级别的cgroup\n\n * 如果容器超出其内存限制，则可能终止该容器。如果它是可重新启动的，kubelet将重新启动它，就像处理任何其他类型的运行时故障一样。\n * 如果容器超出了它的内存请求，那么每当节点耗尽内存时，它的pod很可能会被逐出。\n * 容器可能被允许，也可能不被允许在较长时间内超过其cpu限制。但是，它不会因为cpu占用过多而被杀死。\n\n\n# pod级别的cgroup\n\n每个pod都有一定的开销资源，比如由sandbox容器或docker containerd-shim(在1.22中删除)使用的资源。另外，pod在指定内存类型的卷时也会占用内存资源。\n\n * 计算所有pod容器的cpu请求/限制和内存限制，并将cpu请求/限制转换为cpuhares和cpuquota。\n\n> pod/cpu.shares = sum(pod.spec.containers.resources.requests[cpu]) pod/cpu.cfs_quota_us = sum(pod.spec.containers.resources.limits[cpu]) pod/memory.limit_in_bytes = sum(pod.spec.containers.resources.limits[memory])\n\n * 只有pod cgroup的cpu。如果其中一个容器只指定请求而不指定限制，则将设置共享值，而不设置其限制值。\n\n * 只设置cpu。当无容器指定请求值或限制值时共享，即pod在资源空闲时使用所有节点资源，在资源受限时不获取任何资源，符合低优先级原则\n\n\n# qos级别的cgroup\n\n * guaranteed(保证型)::由请求设置的值等于由限制设置的值。 当pod里的每一个container都同时设置了requests和limits，并且requests和limits值相等的时候，这个pod就属于guaranteed类别\n * burstable(突增型):请求设置的值小于限制设置的值，但是!= 0。 而当pod不满足guaranteed的条件，但至少有一个container设置了requests。那么这个pod就会被划分到burstable类别\n * besteffort(尽力而为型):请求和限制设置的值都是0。 优先级是 而如果一个pod既没有设置requests，也没有设置limits，那么它的qos类别就是besteffort\n\n> guaranteed > burstable > besteffort\n\n\n# 节点node级别的cgroup\n\n * 业务流程使用的资源，即pod使用的资源。\n * kubernetes组件使用的资源，如kubelet和docker。\n * 系统组件使用的资源，如logind、journald和其他进程。\n\n\n# 资源限制\n\n在调度的时候，kube-scheduler只会按照requests的值进行计算。而在真正设置cgroups限制的时候，kubelet则会按照limits的值来进行设置。\n\n * 当你指定了requests.cpu=250m之后，相当于将cgroups的cpu.shares的值设置为(250/1000)*1024。而当你没有设置requests.cpu的时候，cpu.shares默认则是1024\n\n * 如果你指定了limits.cpu=500m之后，则相当于将cgroups的cpu.cfs_quota_us的值设置为(500/1000)*100ms，而cpu.cfs_period_us的值始终是100ms。这样，kubernetes就为你设置了这个容器只能用到cpu的50%。\n\n * 对于内存来说，当你指定了limits.memory=128mi之后，相当于将cgroups的memory.limit_in_bytes设置为128 * 1024 * 1024。\n\n> kubernetes这种对cpu和内存资源限额的设计，实际上参考了borg论文中对“动态资源边界”的定义，既：容器化作业在提交时所设置的资源边界，并不一定是调度系统所必须严格遵守的，这是因为在实际场景中，大多数作业使用到的资源其实远小于它所请求的资源限额。\n\n\n# eviction\n\n目前，kubernetes为你设置的eviction的默认阈值如下所示：\n\nmemory.available<100mi nodefs.available<10% nodefs.inodesfree<5% imagefs.available<15% 当然，上述各个触发条件在kubelet里都是可配置的。比如下面这个例子：\n\nkubelet --eviction-hard=imagefs.available<10%,memory.available<500mi,nodefs.available<5%,nodefs.inodesfree<5% --eviction-soft=imagefs.available<30%,nodefs.available<10% --eviction-soft-grace-period=imagefs.available=2m,nodefs.available=2m --eviction-max-pod-grace-period=600 在这个配置中，你可以看到eviction在kubernetes里其实分为soft和hard两种模式。\n\n\n# 容器是一个“单进程”模型",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"流量限制",frontmatter:{title:"流量限制",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s05/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:'[root@localhost ~]# cat /etc/cni/net.d/10-calico.conflist | grep bandwidth\n    { "type": "bandwidth", "capabilities": { "bandwidth": true } }\n`',meta:[{name:"twitter:title",content:"流量限制"},{name:"twitter:description",content:'[root@localhost ~]# cat /etc/cni/net.d/10-calico.conflist | grep bandwidth\n    { "type": "bandwidth", "capabilities": { "bandwidth": true } }\n`'},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/05.%E6%B5%81%E9%87%8F%E9%99%90%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"流量限制"},{property:"og:description",content:'[root@localhost ~]# cat /etc/cni/net.d/10-calico.conflist | grep bandwidth\n    { "type": "bandwidth", "capabilities": { "bandwidth": true } }\n`'},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/05.%E6%B5%81%E9%87%8F%E9%99%90%E5%88%B6.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"流量限制"},{itemprop:"description",content:'[root@localhost ~]# cat /etc/cni/net.d/10-calico.conflist | grep bandwidth\n    { "type": "bandwidth", "capabilities": { "bandwidth": true } }\n`'}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/05.%E6%B5%81%E9%87%8F%E9%99%90%E5%88%B6.html",relativePath:"01.技术杂谈/03.kubernetes/05.流量限制.md",key:"v-4d3d3bec",path:"/pages/k8s05/",headers:[{level:2,title:"流量限制验证",slug:"流量限制验证",normalizedTitle:"流量限制验证",charIndex:313}],headersStr:"流量限制验证",content:'# kubelet启动参数：\n\n> --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin --network-plugin=cni\n\nsystemctl cat kubelet | grep network-plugin\n\n\n1\n\n\n\n# calico配置\n\n[root@localhost ~]# cat /etc/cni/net.d/10-calico.conflist | grep bandwidth\n    { "type": "bandwidth", "capabilities": { "bandwidth": true } }\n\n\n1\n2\n\n\n\n# 流量限制验证\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: netperf-server\n  annotations:\n    kubernetes.io/egress-bandwidth: 1M\n    kubernetes.io/ingress-bandwidth: 1M\nspec:\n  containers:\n  - image: sirot/netperf-latest\n    command: ["/bin/sh","-c","netserver -p 4444 -4; iperf3 -s -i 1;"]\n    imagePullPolicy: IfNotPresent\n    name: netperf\n    ports:\n    - name: netperf-port\n      containerPort: 4444\n    - name: iperf-port\n      containerPort: 5210\n  restartPolicy: Always\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n> 注： pod创建后修改annotation无效，需要重启pod才生效 如果不是docker而是使用containerd作为runtime，需要containerd 1.4版本才能支持。\n\n tc qdisc show\n\n...\n\nqdisc tbf 1: dev cali90ab6b94883 root refcnt 2 rate 1000Kbit burst 27917286b lat 1924.2s\n\nqdisc ingress ffff: dev cali90ab6b94883 parent ffff:fff1 ----------------\n\nqdisc tbf 1: dev 31b3 root refcnt 2 rate 1000Kbit burst 27917286b lat 1924.2s\n\nroot@netperf-server:/# iperf3 -c 10.19.0.13\n\nConnecting to host 10.19.0.13, port 5201\n\n[  4] local 10.242.235.108 port 46514 connected to 10.19.0.13 port 5201\n\n[ ID] Interval           Transfer     Bandwidth       Retr  Cwnd\n\n[  4]   0.00-1.00   sec  26.2 MBytes   220 Mbits/sec    1    274 KBytes\n\n[  4]   1.00-2.00   sec  0.00 Bytes  0.00 bits/sec    0    275 KBytes\n\n[  4]   2.00-3.00   sec  0.00 Bytes  0.00 bits/sec    0    278 KBytes\n\n[  4]   3.00-4.00   sec   331 KBytes  2.71 Mbits/sec    0    285 KBytes\n\n[  4]   4.00-5.00   sec  0.00 Bytes  0.00 bits/sec    0    295 KBytes\n\n[  4]   5.00-6.00   sec   382 KBytes  3.13 Mbits/sec    0    312 KBytes\n\n[  4]   6.00-7.00   sec  0.00 Bytes  0.00 bits/sec    0    332 KBytes\n\n[  4]   7.00-8.00   sec  0.00 Bytes  0.00 bits/sec    0    361 KBytes\n\n[  4]   8.00-9.00   sec   446 KBytes  3.65 Mbits/sec    0    389 KBytes\n\n^C[  4]   9.00-9.55   sec  0.00 Bytes  0.00 bits/sec    0    405 KBytes\n\n- - - - - - - - - - - - - - - - - - - - - - - - -\n\n[ ID] Interval           Transfer     Bandwidth       Retr\n\n[  4]   0.00-9.55   sec  27.4 MBytes  24.1 Mbits/sec    1             sender\n\n[  4]   0.00-9.55   sec  0.00 Bytes  0.00 bits/sec                  receiver\n\niperf3: interrupt - the client has terminated\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n',normalizedContent:'# kubelet启动参数：\n\n> --cni-conf-dir=/etc/cni/net.d --cni-bin-dir=/opt/cni/bin --network-plugin=cni\n\nsystemctl cat kubelet | grep network-plugin\n\n\n1\n\n\n\n# calico配置\n\n[root@localhost ~]# cat /etc/cni/net.d/10-calico.conflist | grep bandwidth\n    { "type": "bandwidth", "capabilities": { "bandwidth": true } }\n\n\n1\n2\n\n\n\n# 流量限制验证\n\napiversion: v1\nkind: pod\nmetadata:\n  name: netperf-server\n  annotations:\n    kubernetes.io/egress-bandwidth: 1m\n    kubernetes.io/ingress-bandwidth: 1m\nspec:\n  containers:\n  - image: sirot/netperf-latest\n    command: ["/bin/sh","-c","netserver -p 4444 -4; iperf3 -s -i 1;"]\n    imagepullpolicy: ifnotpresent\n    name: netperf\n    ports:\n    - name: netperf-port\n      containerport: 4444\n    - name: iperf-port\n      containerport: 5210\n  restartpolicy: always\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\n> 注： pod创建后修改annotation无效，需要重启pod才生效 如果不是docker而是使用containerd作为runtime，需要containerd 1.4版本才能支持。\n\n tc qdisc show\n\n...\n\nqdisc tbf 1: dev cali90ab6b94883 root refcnt 2 rate 1000kbit burst 27917286b lat 1924.2s\n\nqdisc ingress ffff: dev cali90ab6b94883 parent ffff:fff1 ----------------\n\nqdisc tbf 1: dev 31b3 root refcnt 2 rate 1000kbit burst 27917286b lat 1924.2s\n\nroot@netperf-server:/# iperf3 -c 10.19.0.13\n\nconnecting to host 10.19.0.13, port 5201\n\n[  4] local 10.242.235.108 port 46514 connected to 10.19.0.13 port 5201\n\n[ id] interval           transfer     bandwidth       retr  cwnd\n\n[  4]   0.00-1.00   sec  26.2 mbytes   220 mbits/sec    1    274 kbytes\n\n[  4]   1.00-2.00   sec  0.00 bytes  0.00 bits/sec    0    275 kbytes\n\n[  4]   2.00-3.00   sec  0.00 bytes  0.00 bits/sec    0    278 kbytes\n\n[  4]   3.00-4.00   sec   331 kbytes  2.71 mbits/sec    0    285 kbytes\n\n[  4]   4.00-5.00   sec  0.00 bytes  0.00 bits/sec    0    295 kbytes\n\n[  4]   5.00-6.00   sec   382 kbytes  3.13 mbits/sec    0    312 kbytes\n\n[  4]   6.00-7.00   sec  0.00 bytes  0.00 bits/sec    0    332 kbytes\n\n[  4]   7.00-8.00   sec  0.00 bytes  0.00 bits/sec    0    361 kbytes\n\n[  4]   8.00-9.00   sec   446 kbytes  3.65 mbits/sec    0    389 kbytes\n\n^c[  4]   9.00-9.55   sec  0.00 bytes  0.00 bits/sec    0    405 kbytes\n\n- - - - - - - - - - - - - - - - - - - - - - - - -\n\n[ id] interval           transfer     bandwidth       retr\n\n[  4]   0.00-9.55   sec  27.4 mbytes  24.1 mbits/sec    1             sender\n\n[  4]   0.00-9.55   sec  0.00 bytes  0.00 bits/sec                  receiver\n\niperf3: interrupt - the client has terminated\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"网络策略calico",frontmatter:{title:"网络策略calico",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s06/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"https://kubernetes.io/docs/concepts/services-networking/network-policies/",meta:[{name:"twitter:title",content:"网络策略calico"},{name:"twitter:description",content:"https://kubernetes.io/docs/concepts/services-networking/network-policies/"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/06.%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5calico.html"},{property:"og:type",content:"article"},{property:"og:title",content:"网络策略calico"},{property:"og:description",content:"https://kubernetes.io/docs/concepts/services-networking/network-policies/"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/06.%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5calico.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"网络策略calico"},{itemprop:"description",content:"https://kubernetes.io/docs/concepts/services-networking/network-policies/"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/06.%E7%BD%91%E7%BB%9C%E7%AD%96%E7%95%A5calico.html",relativePath:"01.技术杂谈/03.kubernetes/06.网络策略calico.md",key:"v-59c6ef63",path:"/pages/k8s06/",headers:[{level:2,title:"kubernetes NetworkPolicy",slug:"kubernetes-networkpolicy",normalizedTitle:"kubernetes networkpolicy",charIndex:2},{level:2,title:"calico NetworkPolicy",slug:"calico-networkpolicy",normalizedTitle:"calico networkpolicy",charIndex:106},{level:2,title:"网络策略隔离限制问题",slug:"网络策略隔离限制问题",normalizedTitle:"网络策略隔离限制问题",charIndex:1563},{level:3,title:"关于源地址问题：",slug:"关于源地址问题",normalizedTitle:"关于源地址问题：",charIndex:1864},{level:3,title:"建议：",slug:"建议",normalizedTitle:"建议：",charIndex:2322}],headersStr:"kubernetes NetworkPolicy calico NetworkPolicy 网络策略隔离限制问题 关于源地址问题： 建议：",content:"# kubernetes NetworkPolicy\n\nhttps://kubernetes.io/docs/concepts/services-networking/network-policies/\n\n\n# calico NetworkPolicy\n\nhttps://docs.projectcalico.org/reference/resources/globalnetworkpolicy\n\n---\napiVersion: projectcalico.org/v3\nkind: GlobalNetworkPolicy\nmetadata:\n  name: global-default\nspec:\n  egress:\n  - action: Allow\n    destination: {}\n    source: {}\n  ingress:\n  - action: Allow\n    destination: {}\n    source: {}\n  order: 9999\n  types:\n  - Ingress\n  - Egress\n---\napiVersion: projectcalico.org/v3\nkind: GlobalNetworkPolicy\nmetadata:\n  name: global-egress-deny\nspec:\n  egress:\n  - action: Deny\n    destination:\n      selector: area == 'dummy'\n    source: {}\n  namespaceSelector: (! has(privileged-namespace))\n  order: 502\n  types:\n  - Egress\n---\napiVersion: projectcalico.org/v3\nkind: GlobalNetworkPolicy\nmetadata:\n  name: global-egress-allow\nspec:\n  egress:\n  - action: Allow\n    destination:\n      nets:\n      - 127.0.0.1/32\n    source:\n      namespaceSelector: name == \"dummy\"\n  order: 501\n  types:\n  - Egress\n---\napiVersion: projectcalico.org/v3\nkind: GlobalNetworkPolicy\nmetadata:\n  name: global-privileged-namespace\nspec:\n  egress:\n  - action: Allow\n    destination: {}\n    source: {}\n  ingress:\n  - action: Allow\n    destination: {}\n    source: {}\n  namespaceSelector: has(privileged-namespace)\n  order: 500\n  types:\n  - Ingress\n  - Egress\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n\n\n\n# 网络策略隔离限制问题\n\n * 默认情况下，发送到service的数据包Type=LoadBalancer/NodePort会经过SNAT，会导致网络策略不生效\n * 网络策略不能限制主机访问，即便设置了所有网段拒绝。 (Traffic from a host to its workload endpoints (e.g. Kubernetes pods) is always allowed, despite any policy in place. This ensures that kubelet liveness and readiness probes always work.)\n\n\n# 关于源地址问题：\n\n 1. 集群内通过podip访问一定不会SNAT\n 2. 集群内通过clusterIP访问默认不会SNAT\n 3. nodeport和LB默认会SNAT （网络策略可能会无法命中）\n\n * externalTrafficPolicy: Cluster （默认） nodeport: 在集群内访问看到的IP是请求的节点IP，ep是轮训的 在集群外访问看到的IP是请求的节点IP，ep是轮训的 LB: 集群内访问看到的都是当前pod所在节点IP，ep是轮训的 集群外请求三次都是看到的节点1（固定）的IP，ep是轮训的\n * externalTrafficPolicy: local nodeport: 集群内访问请求IP与当前pod节点一致时看到的是podIP，否则是当前pod所在节点IP，ep同节点 (??????) 在集群外访问看到的是真实的IP,ep对应请求的节点IP LB: 集群内访问看到的都是真实的IP（当前podIP），ep同节点 集群外请求三次都是真实的IP，ep同节点\n\n\n# 建议：\n\n建议在服务配置中将 spec.externalTrafficPolicy 设置为 local，以便数据包的源地址保持不变，即数据包的源地址就是客户端的源地址。",normalizedContent:"# kubernetes networkpolicy\n\nhttps://kubernetes.io/docs/concepts/services-networking/network-policies/\n\n\n# calico networkpolicy\n\nhttps://docs.projectcalico.org/reference/resources/globalnetworkpolicy\n\n---\napiversion: projectcalico.org/v3\nkind: globalnetworkpolicy\nmetadata:\n  name: global-default\nspec:\n  egress:\n  - action: allow\n    destination: {}\n    source: {}\n  ingress:\n  - action: allow\n    destination: {}\n    source: {}\n  order: 9999\n  types:\n  - ingress\n  - egress\n---\napiversion: projectcalico.org/v3\nkind: globalnetworkpolicy\nmetadata:\n  name: global-egress-deny\nspec:\n  egress:\n  - action: deny\n    destination:\n      selector: area == 'dummy'\n    source: {}\n  namespaceselector: (! has(privileged-namespace))\n  order: 502\n  types:\n  - egress\n---\napiversion: projectcalico.org/v3\nkind: globalnetworkpolicy\nmetadata:\n  name: global-egress-allow\nspec:\n  egress:\n  - action: allow\n    destination:\n      nets:\n      - 127.0.0.1/32\n    source:\n      namespaceselector: name == \"dummy\"\n  order: 501\n  types:\n  - egress\n---\napiversion: projectcalico.org/v3\nkind: globalnetworkpolicy\nmetadata:\n  name: global-privileged-namespace\nspec:\n  egress:\n  - action: allow\n    destination: {}\n    source: {}\n  ingress:\n  - action: allow\n    destination: {}\n    source: {}\n  namespaceselector: has(privileged-namespace)\n  order: 500\n  types:\n  - ingress\n  - egress\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n\n\n\n# 网络策略隔离限制问题\n\n * 默认情况下，发送到service的数据包type=loadbalancer/nodeport会经过snat，会导致网络策略不生效\n * 网络策略不能限制主机访问，即便设置了所有网段拒绝。 (traffic from a host to its workload endpoints (e.g. kubernetes pods) is always allowed, despite any policy in place. this ensures that kubelet liveness and readiness probes always work.)\n\n\n# 关于源地址问题：\n\n 1. 集群内通过podip访问一定不会snat\n 2. 集群内通过clusterip访问默认不会snat\n 3. nodeport和lb默认会snat （网络策略可能会无法命中）\n\n * externaltrafficpolicy: cluster （默认） nodeport: 在集群内访问看到的ip是请求的节点ip，ep是轮训的 在集群外访问看到的ip是请求的节点ip，ep是轮训的 lb: 集群内访问看到的都是当前pod所在节点ip，ep是轮训的 集群外请求三次都是看到的节点1（固定）的ip，ep是轮训的\n * externaltrafficpolicy: local nodeport: 集群内访问请求ip与当前pod节点一致时看到的是podip，否则是当前pod所在节点ip，ep同节点 (??????) 在集群外访问看到的是真实的ip,ep对应请求的节点ip lb: 集群内访问看到的都是真实的ip（当前podip），ep同节点 集群外请求三次都是真实的ip，ep同节点\n\n\n# 建议：\n\n建议在服务配置中将 spec.externaltrafficpolicy 设置为 local，以便数据包的源地址保持不变，即数据包的源地址就是客户端的源地址。",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"grafana和promuthues",frontmatter:{title:"grafana和promuthues",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s07/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"grafana和promuthues"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/07.grafana%E5%92%8Cpromuthues.html"},{property:"og:type",content:"article"},{property:"og:title",content:"grafana和promuthues"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/07.grafana%E5%92%8Cpromuthues.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"grafana和promuthues"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/07.grafana%E5%92%8Cpromuthues.html",relativePath:"01.技术杂谈/03.kubernetes/07.grafana和promuthues.md",key:"v-0b248a60",path:"/pages/k8s07/",headers:[{level:2,title:"组件",slug:"组件",normalizedTitle:"组件",charIndex:2},{level:2,title:"curl",slug:"curl",normalizedTitle:"curl",charIndex:406},{level:2,title:"热加载",slug:"热加载",normalizedTitle:"热加载",charIndex:755},{level:2,title:"pushgateway",slug:"pushgateway",normalizedTitle:"pushgateway",charIndex:807},{level:2,title:"Grafana",slug:"grafana",normalizedTitle:"grafana",charIndex:823},{level:2,title:"指标",slug:"指标",normalizedTitle:"指标",charIndex:835},{level:3,title:"指标类型",slug:"指标类型",normalizedTitle:"指标类型",charIndex:842},{level:3,title:"计算表达式：",slug:"计算表达式",normalizedTitle:"计算表达式：",charIndex:923},{level:3,title:"指标命名规范",slug:"指标命名规范",normalizedTitle:"指标命名规范",charIndex:1099}],headersStr:"组件 curl 热加载 pushgateway Grafana 指标 指标类型 计算表达式： 指标命名规范",content:"# 组件\n\n * Prometheus Server: 用于收集和存储时间序列数据。\n * Client Library: 客户端库，为需要监控的服务生成相应的 metrics 并暴露给 Prometheus server。当Prometheus server 来 pull 时，直接返回实时状态的 metrics。对于机器层面的 metrices，需要使用 node exporter。\n * Push Gateway: 主要用于短期的 jobs。\n * Exporters: 用于暴露已有的第三方服务的 metrics 给 Prometheus。\n * Alertmanager: 从 Prometheus server 端接收到 alerts 后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。常见的接收方式有：电子邮件，pagerduty，OpsGenie, webhook 等。\n\n\n# curl\n\necho \"hfftest 111\" |curl --data-binary @- http://10.19.0.13:9091/metrics/job/schedulerStatus/instance/tztest\n\ncurl -X POST -g 'http://127.0.0.1:9090/api/v1/admin/tsdb/delete_series?match[]=scheduler_effective_dynamic_schedule_count'\n\ncurl -X POST -g 'http://10.19.0.13:9090/api/v1/admin/tsdb/delete_series?match[]={job=\"schedulerStatus\"}'\n\n\n# 热加载\n\ncurl -XPOST <prometheus-url>/-/reload\n\n\n1\n\n\n\n# pushgateway\n\n\n# Grafana\n\n\n# 指标\n\n\n# 指标类型\n\nCounter（计数器）对数据只增不减 Gauage（仪表盘）可增可减 Histogram（直方图）,Summary（摘要）提供更多的统计信\n\n\n# 计算表达式：\n\nPrometheus为不同的数据提供了非常多的计算函数，其中有个小技巧就是遇到counter数据类型，在做任何操作之前，先套上一个rate()或者increase()函数\n\n> 100-avg(irate(node_cpu_seconds_total{mode='idle'}[5m])) by (node_name)*100\n\n\n# 指标命名规范\n\n一个指标名称： • 必须符合有效字符的数据模型。 • 应该具有与指标所属域相关的（单个词汇）应用程序前缀。前缀有时被客户端库称为命名空间。对于特定于应用程序的指标，前缀通常是应用程序名称本身。然而，有时候指标更通用，比如客户端库导出的标准化指标。例如： ○ prometheus_notifications_total （针对Prometheus 服务器） ○ process_cpu_seconds_total （由客户端库导出） ○ http_request_duration_seconds （用于所有HTTP请求） • 必须有一个单一的单位（即，不要把秒与毫秒，或秒与字节混用）。 • 应该使用基本单位（如秒、字节、米——而不是毫秒、兆字节、公里）。参见下面的基本单位列表。 • 应以复数形式用后缀来描述单位。请注意，累计计数以total作为后缀，附加在单位之后。 ○ http_request_duration_seconds ○ node_memory_usage_bytes ○ http_requests_total （用于无单位的累计计数） ○ process_cpu_seconds_total （用于有单位的累计计数） ○ foobar_build_info （用于提供关于正在运行的二进制文件的元数据的伪指标） • 应该在所有的标签维度中表示相同的监控逻辑。 ○ 请求持久时长 ○ 传输的数据字节数 ○ 瞬时资源使用百分比",normalizedContent:"# 组件\n\n * prometheus server: 用于收集和存储时间序列数据。\n * client library: 客户端库，为需要监控的服务生成相应的 metrics 并暴露给 prometheus server。当prometheus server 来 pull 时，直接返回实时状态的 metrics。对于机器层面的 metrices，需要使用 node exporter。\n * push gateway: 主要用于短期的 jobs。\n * exporters: 用于暴露已有的第三方服务的 metrics 给 prometheus。\n * alertmanager: 从 prometheus server 端接收到 alerts 后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。常见的接收方式有：电子邮件，pagerduty，opsgenie, webhook 等。\n\n\n# curl\n\necho \"hfftest 111\" |curl --data-binary @- http://10.19.0.13:9091/metrics/job/schedulerstatus/instance/tztest\n\ncurl -x post -g 'http://127.0.0.1:9090/api/v1/admin/tsdb/delete_series?match[]=scheduler_effective_dynamic_schedule_count'\n\ncurl -x post -g 'http://10.19.0.13:9090/api/v1/admin/tsdb/delete_series?match[]={job=\"schedulerstatus\"}'\n\n\n# 热加载\n\ncurl -xpost <prometheus-url>/-/reload\n\n\n1\n\n\n\n# pushgateway\n\n\n# grafana\n\n\n# 指标\n\n\n# 指标类型\n\ncounter（计数器）对数据只增不减 gauage（仪表盘）可增可减 histogram（直方图）,summary（摘要）提供更多的统计信\n\n\n# 计算表达式：\n\nprometheus为不同的数据提供了非常多的计算函数，其中有个小技巧就是遇到counter数据类型，在做任何操作之前，先套上一个rate()或者increase()函数\n\n> 100-avg(irate(node_cpu_seconds_total{mode='idle'}[5m])) by (node_name)*100\n\n\n# 指标命名规范\n\n一个指标名称： • 必须符合有效字符的数据模型。 • 应该具有与指标所属域相关的（单个词汇）应用程序前缀。前缀有时被客户端库称为命名空间。对于特定于应用程序的指标，前缀通常是应用程序名称本身。然而，有时候指标更通用，比如客户端库导出的标准化指标。例如： ○ prometheus_notifications_total （针对prometheus 服务器） ○ process_cpu_seconds_total （由客户端库导出） ○ http_request_duration_seconds （用于所有http请求） • 必须有一个单一的单位（即，不要把秒与毫秒，或秒与字节混用）。 • 应该使用基本单位（如秒、字节、米——而不是毫秒、兆字节、公里）。参见下面的基本单位列表。 • 应以复数形式用后缀来描述单位。请注意，累计计数以total作为后缀，附加在单位之后。 ○ http_request_duration_seconds ○ node_memory_usage_bytes ○ http_requests_total （用于无单位的累计计数） ○ process_cpu_seconds_total （用于有单位的累计计数） ○ foobar_build_info （用于提供关于正在运行的二进制文件的元数据的伪指标） • 应该在所有的标签维度中表示相同的监控逻辑。 ○ 请求持久时长 ○ 传输的数据字节数 ○ 瞬时资源使用百分比",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"etcd节点down机数据恢复",frontmatter:{title:"etcd节点down机数据恢复",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s08/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"(1) 移出该节点：etcdctl member remove xx（可以通过member list获取XX）",meta:[{name:"twitter:title",content:"etcd节点down机数据恢复"},{name:"twitter:description",content:"(1) 移出该节点：etcdctl member remove xx（可以通过member list获取XX）"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/08.etcd%E8%8A%82%E7%82%B9down%E6%9C%BA%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D.html"},{property:"og:type",content:"article"},{property:"og:title",content:"etcd节点down机数据恢复"},{property:"og:description",content:"(1) 移出该节点：etcdctl member remove xx（可以通过member list获取XX）"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/08.etcd%E8%8A%82%E7%82%B9down%E6%9C%BA%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"etcd节点down机数据恢复"},{itemprop:"description",content:"(1) 移出该节点：etcdctl member remove xx（可以通过member list获取XX）"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/08.etcd%E8%8A%82%E7%82%B9down%E6%9C%BA%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D.html",relativePath:"01.技术杂谈/03.kubernetes/08.etcd节点down机数据恢复.md",key:"v-2f3eb2e7",path:"/pages/k8s08/",headersStr:null,content:"(1) 移出该节点：etcdctl member remove xx（可以通过member list获取XX）\n\n(2) 停止etcd服务\n\n(3) 需要将配置中的 cluster_state改为：existing，因为是加入已有集群，不能用 new 修复机器问题，删除旧的数据目录，重新启动 etcd 服务\n\n(4) 加入 memeber： etcdctl member add xxx –peer-urls=https://x.x.x.x:2380\n\n(5) 验证：etcdctl endpoint status",normalizedContent:"(1) 移出该节点：etcdctl member remove xx（可以通过member list获取xx）\n\n(2) 停止etcd服务\n\n(3) 需要将配置中的 cluster_state改为：existing，因为是加入已有集群，不能用 new 修复机器问题，删除旧的数据目录，重新启动 etcd 服务\n\n(4) 加入 memeber： etcdctl member add xxx –peer-urls=https://x.x.x.x:2380\n\n(5) 验证：etcdctl endpoint status",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"ceph",frontmatter:{title:"ceph",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s09/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"rbd不支持ReadWriteMany\n在同一个节点中,是可以支持多个pod共享rbd image运行的",meta:[{name:"twitter:title",content:"ceph"},{name:"twitter:description",content:"rbd不支持ReadWriteMany\n在同一个节点中,是可以支持多个pod共享rbd image运行的"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/09.ceph.html"},{property:"og:type",content:"article"},{property:"og:title",content:"ceph"},{property:"og:description",content:"rbd不支持ReadWriteMany\n在同一个节点中,是可以支持多个pod共享rbd image运行的"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/09.ceph.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"ceph"},{itemprop:"description",content:"rbd不支持ReadWriteMany\n在同一个节点中,是可以支持多个pod共享rbd image运行的"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/09.ceph.html",relativePath:"01.技术杂谈/03.kubernetes/09.ceph.md",key:"v-1247b65b",path:"/pages/k8s09/",headers:[{level:2,title:"挂载点查询",slug:"挂载点查询",normalizedTitle:"挂载点查询",charIndex:2},{level:2,title:"rbd vs cephfs",slug:"rbd-vs-cephfs",normalizedTitle:"rbd vs cephfs",charIndex:12}],headersStr:"挂载点查询 rbd vs cephfs",content:"# 挂载点查询\n\n\n# rbd vs cephfs\n\nrbd不支持ReadWriteMany 在同一个节点中,是可以支持多个pod共享rbd image运行的",normalizedContent:"# 挂载点查询\n\n\n# rbd vs cephfs\n\nrbd不支持readwritemany 在同一个节点中,是可以支持多个pod共享rbd image运行的",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"chrony",frontmatter:{title:"chrony",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s10/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"chrony"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/10.chrony.html"},{property:"og:type",content:"article"},{property:"og:title",content:"chrony"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/10.chrony.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"chrony"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/10.chrony.html",relativePath:"01.技术杂谈/03.kubernetes/10.chrony.md",key:"v-cbe0d60a",path:"/pages/k8s10/",headers:[{level:2,title:"一、Chrony简述",slug:"一、chrony简述",normalizedTitle:"一、chrony简述",charIndex:2},{level:2,title:"二、部署版本：",slug:"二、部署版本",normalizedTitle:"二、部署版本：",charIndex:376},{level:2,title:"三、环境配置：",slug:"三、环境配置",normalizedTitle:"三、环境配置：",charIndex:398},{level:2,title:"四、NTP/Chrony对比：",slug:"四、ntp-chrony对比",normalizedTitle:"四、ntp/chrony对比：",charIndex:481},{level:3,title:"chrony的优势包括以下几点:",slug:"chrony的优势包括以下几点",normalizedTitle:"chrony的优势包括以下几点:",charIndex:635},{level:3,title:"ntp能做，chrony做不到的：",slug:"ntp能做-chrony做不到的",normalizedTitle:"ntp能做，chrony做不到的：",charIndex:915},{level:3,title:"chrony可以比ntp做得更好：",slug:"chrony可以比ntp做得更好",normalizedTitle:"chrony可以比ntp做得更好：",charIndex:1204},{level:2,title:"五、chrony服务安装的文件：",slug:"五、chrony服务安装的文件",normalizedTitle:"五、chrony服务安装的文件：",charIndex:1892},{level:2,title:"六、Chrony配置chrony.conf",slug:"六、chrony配置chrony-conf",normalizedTitle:"六、chrony配置chrony.conf",charIndex:2984},{level:3,title:"常用配置项：",slug:"常用配置项",normalizedTitle:"常用配置项：",charIndex:3010},{level:3,title:"建议配置项：",slug:"建议配置项",normalizedTitle:"建议配置项：",charIndex:4453},{level:3,title:"NTP Server(master节点)",slug:"ntp-server-master节点",normalizedTitle:"ntp server(master节点)",charIndex:4655},{level:3,title:"NTP Client(普通node节点)",slug:"ntp-client-普通node节点",normalizedTitle:"ntp client(普通node节点)",charIndex:4835},{level:2,title:"七、部署:",slug:"七、部署",normalizedTitle:"七、部署:",charIndex:5031},{level:2,title:"八、常用chrony命令：",slug:"八、常用chrony命令",normalizedTitle:"八、常用chrony命令：",charIndex:5222},{level:2,title:"九、问题定位思路",slug:"九、问题定位思路",normalizedTitle:"九、问题定位思路",charIndex:5528},{level:2,title:"十、参考资料：",slug:"十、参考资料",normalizedTitle:"十、参考资料：",charIndex:5651}],headersStr:"一、Chrony简述 二、部署版本： 三、环境配置： 四、NTP/Chrony对比： chrony的优势包括以下几点: ntp能做，chrony做不到的： chrony可以比ntp做得更好： 五、chrony服务安装的文件： 六、Chrony配置chrony.conf 常用配置项： 建议配置项： NTP Server(master节点) NTP Client(普通node节点) 七、部署: 八、常用chrony命令： 九、问题定位思路 十、参考资料：",content:"# 一、Chrony简述\n\nchrony是网络时间协议(NTP)的另一种实现,与网络时间协议后台程序(ntpd)不同,它可以更快地且更准确地同步系统时钟，请注意，ntpd仍然包含其中以供需要运行NTP服务的客户使用。 两个主要程序：chronyd和chronyc\n\n * chronyd：后台运行的守护进程，用于调整内核中运行的系统时钟和时钟服务器同步。它确定计算机增减时间的比率，并对此进行补偿\n * chronyc：命令行用户工具，用于监控性能并进行多样化的配置。它可以在chronyd实例控制的计算机上工作，也可在一台不同的远程计算机上工作\n\n> 服务unit文件： /usr/lib/systemd/system/chronyd.service 监听端口： 323/udp，123/udp 配置文件： /etc/chrony.conf\n\n\n# 二、部署版本：\n\n官方版本：3.4\n\n\n# 三、环境配置：\n\n1、关闭firewalld防火墙 2、关闭SELinux 3、chrony与ntp都是时间同步软件，两个软件不能够同时开启，会出现时间冲突\n\n\n# 四、NTP/Chrony对比：\n\n使用chronyd服务平滑同步时间的方式要优于crontab + ntpdate，因为ntpdate同步时间会造成时间的跳跃，对一些依赖时间的程序和服务会造成影响，例如：sleep、timer等，且chronyd服务可以在修正时间的过程中同时修正CPU tick。\n\n\n# chrony的优势包括以下几点:\n\n1.更快的同步只需要数分钟而非数小时时间，从而最大程度减少时间和频率误差，这对于并非全天24小时的运行的台式计算机或系统而言非常有用； 2.能够更好地响应时钟频率的快速变化，这对于具备不稳定时钟的虚拟机或导致赛事中频率发生比变化的节能技术; 3.在初始同步后，它不会停止时钟，以防对需要系统时间保持单调的应用程序造成影响; 4.在应对临时非对称延迟时(例如大规模下载造成链接饱和等情况)提供了更好的稳定性; 5.无需对时间服务器进行定期轮询，因此具备间歇性网络连接(如网络不稳定的场景)的系统仍然可以快速同步时钟。\n\n\n# ntp能做，chrony做不到的：\n\nntp支持RFC 5905的所有操作模式，包括广播、多播和manycast服务器/客户端。然而，广播和多播模式本质上不如普通的服务器/客户机模式准确和安全（即使有身份验证），通常应该避免。 ntp支持自动密钥协议（RFC 5906）来使用公钥加密对服务器进行身份验证。请注意，该协议已被证明是不安全的，并且已被NTS（RFC 8915）淘汰。 ntp已经被移植到更多的操作系统中。 ntp包含大量用于各种硬件参考时钟的驱动程序。chrony需要其他程序（如gpsd或ntp refclock）通过SHM或SOCK接口提供参考时间。\n\n\n# chrony可以比ntp做得更好：\n\nchrony可以在访问时间参考是断断续续的环境中有效地执行。ntp需要定期对引用进行轮询才能正常工作。 chrony通常可以更快地同步时钟，并具有更好的时间精度。 chrony快速适应时钟速率的突然变化（例如，由于晶体振荡器的温度变化）。ntp可能需要很长时间才能重新安定下来。 chrony即使在网络拥塞时间较长的情况下也能表现良好。 默认配置中的chrony从不占用时间来不打乱其他正在运行的程序。ntp也可以配置为从不步进时间，但是在这种情况下，它必须使用不同的方法来调整时钟（daemon循环而不是内核规程），这可能会对时钟的准确性产生负面影响。 chrony可以在更大的范围内调整时钟的速率，这使得它甚至可以在时钟中断或不稳定的机器上运行（例如在某些虚拟机中）。 chrony更小，占用的内存更少，只有在需要时才会唤醒CPU，这样更省电。 chrony可以做ntp做不到的事情： chrony支持网络时间安全（NTS）认证机制。 chrony在Linux上支持硬件时间戳，这允许在本地网络中进行非常稳定和准确的同步。 chrony为独立网络提供支持，无论时间校正的唯一方法是手动输入（例如，由管理员查看时钟）。chrony可以查看在不同更新时更正的错误，计算出计算机获得或丢失时间的速率，并使用此估计值来随后调整计算机时钟。 chrony支持计算实时时钟的增益或丢失率，即在计算机关闭时保持时间的时钟。当系统引导时，它可以使用这些数据从实时时钟的修正版本设置系统时间。到目前为止，这些实时时钟工具仅在Linux上可用。\n\n\n# 五、chrony服务安装的文件：\n\n[root@master200.yinzhengjie.org.cn ~]# rpm -ql chrony\n/etc/NetworkManager/dispatcher.d/20-chrony\n/etc/chrony.conf　　　　　　　　#chrony的主配置文件\n/etc/chrony.keys\n/etc/dhcp/dhclient.d/chrony.sh\n/etc/logrotate.d/chrony\n/etc/sysconfig/chronyd\n/usr/bin/chronyc　　　　　　　　#chronyc是一个命令行交互式接口程序，可用于监视chronyd的性能，并在运行时更改各种操作参数。\n/usr/lib/systemd/ntp-units.d/50-chronyd.list\n/usr/lib/systemd/system/chrony-dnssrv@.service\n/usr/lib/systemd/system/chrony-dnssrv@.timer\n/usr/lib/systemd/system/chrony-wait.service\n/usr/lib/systemd/system/chronyd.service　　　　　　#CentOS 7.x版本对应的unit file\n/usr/libexec/chrony-helper\n/usr/sbin/chronyd              #chronyd是一个可以在启动时启动的守护程序，它既可以充当服务端进程也可以充当服务端进程\n/usr/share/doc/chrony-3.4\n/usr/share/doc/chrony-3.4/COPYING\n/usr/share/doc/chrony-3.4/FAQ\n/usr/share/doc/chrony-3.4/NEWS\n/usr/share/doc/chrony-3.4/README\n/usr/share/man/man1/chronyc.1.gz\n/usr/share/man/man5/chrony.conf.5.gz\n/usr/share/man/man8/chronyd.8.gz\n/var/lib/chrony\n/var/lib/chrony/drift\n/var/lib/chrony/rtc\n/var/log/chrony\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 六、Chrony配置chrony.conf\n\n\n# 常用配置项：\n\nPool 10.210.116.60                       #此指令的语法与server指令的语法类似，只是它用于指定NTP服务器池，而不是单个NTP服务器。池名称需要解析为多个地址，这些地址可能会随着时间的推移而改变。\nserver 0.centos.pool.ntp.org iburst          #server可用于时钟服务器；iburst，当服务器可达时，发送一个八个数据包而不是通常的一个数据包，包间隔通常为2秒，可加快初始同步速度; iburst 是参数, 一般用此参数即可。该参数的含义是在头四次 NTP 请求以 2s 或者更短的间隔，而不是以 minpoll x 指定的最小间隔，这样的设置可以让 chronyd 启动时快速进行一次同步。\n其他的参数有 minpoll x 默认值是 6，代表 64s。maxpoll x 默认值是 9，代表 512s。\nserver 1.centos.pool.ntp.org iburst          #N.centos.pool.ntp.org：这个是地址池，是ntp服务的虚拟集群，这里可以写成集群地址，也可以写指定的某服务器\npeer 10.210.116.160     #同ntp, 对等体模式\ndriftfile /var/lib/chrony/drift              #根据实际时间计算出计算机增减时间的比率，讲它记录到一个文件中，会在重启后为系统时钟做出补偿\nmakestep 1.0 3                         #当头三次校时，如果时间相差 1.0s, 则跳跃式校时\nrtcsync                                #启用内核模式，系统时钟每11分钟会拷贝到实时时钟（RTC）\n#allow 192.168.0.0/16                   #allow/deny：仅允许/拒绝192.168.2.0/24网络的主机可以访问此时间服务器 deny all拒绝所有客户端\n#local stratum 10                       #即使server指令中时间服务器不可用，也允许讲本地时间做为标准时间授时给其它客户端\nstratumweight 0.05                      # 让chronyd在选择源时忽略源的层级\n#hwtimestamp *                        #通过使用 hwtimestamp 指令启用硬件时间戳\n#minsources 2                          #增加调整所需的可选择源的最小数量\n#keyfile /etc/chrony.keys                 # 指定包含NTP验证密钥的文件。\nlogdir /var/log/chrony                   # 指定日志文件的目录。\nlogchange 0.5                          # 如果时钟调整大于0.5秒，则向系统日志发送消息\n#log measurements statistics tracking      #选择日志文件要记录的信息\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 建议配置项：\n\n 1. 当前节点设置成server:127.127.0.1\n 2. 三个master节点作为其他普通节点的时间服务器（配置成pool）\n 3. 三个master节点互为peer(同原ntp)\n 4. 如果有外部时钟源配置，则设置成pool\n 5. 如果时间超过10min，则允许第一次跳跃 （与之前沟通需求保持一致，可修改策略）\n 6. 最多3个外部时钟源，可以不设置外部时钟源\n\n\n# NTP Server(master节点)\n\nserver 127.127.0.1 pool 外部时钟源1 pool外部时钟源2 peer master2节点IP peer master3节点IP driftfile /var/lib/chrony/drift makestep 600 1 rtcsync logdir /var/log/chrony\n\n\n# NTP Client(普通node节点)\n\nserver 127.127.0.1 pool外部时钟源1 pool外部时钟源2 pool master1节点IP pool master2节点IP pool master3节点IP driftfile /var/lib/chrony/drift makestep 600 1 rtcsync logdir /var/log/chrony\n\n\n# 七、部署:\n\nenable chrony， disable ntpd\n\n 1. Stop/disable ntpd\n 2. configure chrony.conf(master/node)\n 3. systemctl start/enable chronyd.service\n 4. systemctl restart chronyd.service (notify)\n\n\n# 八、常用chrony命令：\n\n1、 chronyd -q 'server ntp.ntsc.ac.cn iburst' 临时同步时间 2、 chronyc -n sources -v 查看时间同步服务器列表 3、 accheck - 检查NTP访问是否对特定主机可用 4、 activity - 该命令会显示有多少NTP源在线/离线 5、 add server - 手动添加一台新的NTP服务器。 6、 clients - 在客户端报告已访问到服务器 7、 delete - 手动移除NTP服务器或对等服务器 8、 settime - 手动设置守护进程时间 9、 tracking - 显示系统时间信息\n\n\n# 九、问题定位思路\n\n1.检查chrony服务是否正常：chrony activity 2.检查ntpd服务是否启动：systemctl is-active ntpd 3.检查时间同步服务器列表：chronyc -n sources -v\n\n\n# 十、参考资料：\n\nhttps://chrony.tuxfamily.org/documentation.html",normalizedContent:"# 一、chrony简述\n\nchrony是网络时间协议(ntp)的另一种实现,与网络时间协议后台程序(ntpd)不同,它可以更快地且更准确地同步系统时钟，请注意，ntpd仍然包含其中以供需要运行ntp服务的客户使用。 两个主要程序：chronyd和chronyc\n\n * chronyd：后台运行的守护进程，用于调整内核中运行的系统时钟和时钟服务器同步。它确定计算机增减时间的比率，并对此进行补偿\n * chronyc：命令行用户工具，用于监控性能并进行多样化的配置。它可以在chronyd实例控制的计算机上工作，也可在一台不同的远程计算机上工作\n\n> 服务unit文件： /usr/lib/systemd/system/chronyd.service 监听端口： 323/udp，123/udp 配置文件： /etc/chrony.conf\n\n\n# 二、部署版本：\n\n官方版本：3.4\n\n\n# 三、环境配置：\n\n1、关闭firewalld防火墙 2、关闭selinux 3、chrony与ntp都是时间同步软件，两个软件不能够同时开启，会出现时间冲突\n\n\n# 四、ntp/chrony对比：\n\n使用chronyd服务平滑同步时间的方式要优于crontab + ntpdate，因为ntpdate同步时间会造成时间的跳跃，对一些依赖时间的程序和服务会造成影响，例如：sleep、timer等，且chronyd服务可以在修正时间的过程中同时修正cpu tick。\n\n\n# chrony的优势包括以下几点:\n\n1.更快的同步只需要数分钟而非数小时时间，从而最大程度减少时间和频率误差，这对于并非全天24小时的运行的台式计算机或系统而言非常有用； 2.能够更好地响应时钟频率的快速变化，这对于具备不稳定时钟的虚拟机或导致赛事中频率发生比变化的节能技术; 3.在初始同步后，它不会停止时钟，以防对需要系统时间保持单调的应用程序造成影响; 4.在应对临时非对称延迟时(例如大规模下载造成链接饱和等情况)提供了更好的稳定性; 5.无需对时间服务器进行定期轮询，因此具备间歇性网络连接(如网络不稳定的场景)的系统仍然可以快速同步时钟。\n\n\n# ntp能做，chrony做不到的：\n\nntp支持rfc 5905的所有操作模式，包括广播、多播和manycast服务器/客户端。然而，广播和多播模式本质上不如普通的服务器/客户机模式准确和安全（即使有身份验证），通常应该避免。 ntp支持自动密钥协议（rfc 5906）来使用公钥加密对服务器进行身份验证。请注意，该协议已被证明是不安全的，并且已被nts（rfc 8915）淘汰。 ntp已经被移植到更多的操作系统中。 ntp包含大量用于各种硬件参考时钟的驱动程序。chrony需要其他程序（如gpsd或ntp refclock）通过shm或sock接口提供参考时间。\n\n\n# chrony可以比ntp做得更好：\n\nchrony可以在访问时间参考是断断续续的环境中有效地执行。ntp需要定期对引用进行轮询才能正常工作。 chrony通常可以更快地同步时钟，并具有更好的时间精度。 chrony快速适应时钟速率的突然变化（例如，由于晶体振荡器的温度变化）。ntp可能需要很长时间才能重新安定下来。 chrony即使在网络拥塞时间较长的情况下也能表现良好。 默认配置中的chrony从不占用时间来不打乱其他正在运行的程序。ntp也可以配置为从不步进时间，但是在这种情况下，它必须使用不同的方法来调整时钟（daemon循环而不是内核规程），这可能会对时钟的准确性产生负面影响。 chrony可以在更大的范围内调整时钟的速率，这使得它甚至可以在时钟中断或不稳定的机器上运行（例如在某些虚拟机中）。 chrony更小，占用的内存更少，只有在需要时才会唤醒cpu，这样更省电。 chrony可以做ntp做不到的事情： chrony支持网络时间安全（nts）认证机制。 chrony在linux上支持硬件时间戳，这允许在本地网络中进行非常稳定和准确的同步。 chrony为独立网络提供支持，无论时间校正的唯一方法是手动输入（例如，由管理员查看时钟）。chrony可以查看在不同更新时更正的错误，计算出计算机获得或丢失时间的速率，并使用此估计值来随后调整计算机时钟。 chrony支持计算实时时钟的增益或丢失率，即在计算机关闭时保持时间的时钟。当系统引导时，它可以使用这些数据从实时时钟的修正版本设置系统时间。到目前为止，这些实时时钟工具仅在linux上可用。\n\n\n# 五、chrony服务安装的文件：\n\n[root@master200.yinzhengjie.org.cn ~]# rpm -ql chrony\n/etc/networkmanager/dispatcher.d/20-chrony\n/etc/chrony.conf　　　　　　　　#chrony的主配置文件\n/etc/chrony.keys\n/etc/dhcp/dhclient.d/chrony.sh\n/etc/logrotate.d/chrony\n/etc/sysconfig/chronyd\n/usr/bin/chronyc　　　　　　　　#chronyc是一个命令行交互式接口程序，可用于监视chronyd的性能，并在运行时更改各种操作参数。\n/usr/lib/systemd/ntp-units.d/50-chronyd.list\n/usr/lib/systemd/system/chrony-dnssrv@.service\n/usr/lib/systemd/system/chrony-dnssrv@.timer\n/usr/lib/systemd/system/chrony-wait.service\n/usr/lib/systemd/system/chronyd.service　　　　　　#centos 7.x版本对应的unit file\n/usr/libexec/chrony-helper\n/usr/sbin/chronyd              #chronyd是一个可以在启动时启动的守护程序，它既可以充当服务端进程也可以充当服务端进程\n/usr/share/doc/chrony-3.4\n/usr/share/doc/chrony-3.4/copying\n/usr/share/doc/chrony-3.4/faq\n/usr/share/doc/chrony-3.4/news\n/usr/share/doc/chrony-3.4/readme\n/usr/share/man/man1/chronyc.1.gz\n/usr/share/man/man5/chrony.conf.5.gz\n/usr/share/man/man8/chronyd.8.gz\n/var/lib/chrony\n/var/lib/chrony/drift\n/var/lib/chrony/rtc\n/var/log/chrony\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n# 六、chrony配置chrony.conf\n\n\n# 常用配置项：\n\npool 10.210.116.60                       #此指令的语法与server指令的语法类似，只是它用于指定ntp服务器池，而不是单个ntp服务器。池名称需要解析为多个地址，这些地址可能会随着时间的推移而改变。\nserver 0.centos.pool.ntp.org iburst          #server可用于时钟服务器；iburst，当服务器可达时，发送一个八个数据包而不是通常的一个数据包，包间隔通常为2秒，可加快初始同步速度; iburst 是参数, 一般用此参数即可。该参数的含义是在头四次 ntp 请求以 2s 或者更短的间隔，而不是以 minpoll x 指定的最小间隔，这样的设置可以让 chronyd 启动时快速进行一次同步。\n其他的参数有 minpoll x 默认值是 6，代表 64s。maxpoll x 默认值是 9，代表 512s。\nserver 1.centos.pool.ntp.org iburst          #n.centos.pool.ntp.org：这个是地址池，是ntp服务的虚拟集群，这里可以写成集群地址，也可以写指定的某服务器\npeer 10.210.116.160     #同ntp, 对等体模式\ndriftfile /var/lib/chrony/drift              #根据实际时间计算出计算机增减时间的比率，讲它记录到一个文件中，会在重启后为系统时钟做出补偿\nmakestep 1.0 3                         #当头三次校时，如果时间相差 1.0s, 则跳跃式校时\nrtcsync                                #启用内核模式，系统时钟每11分钟会拷贝到实时时钟（rtc）\n#allow 192.168.0.0/16                   #allow/deny：仅允许/拒绝192.168.2.0/24网络的主机可以访问此时间服务器 deny all拒绝所有客户端\n#local stratum 10                       #即使server指令中时间服务器不可用，也允许讲本地时间做为标准时间授时给其它客户端\nstratumweight 0.05                      # 让chronyd在选择源时忽略源的层级\n#hwtimestamp *                        #通过使用 hwtimestamp 指令启用硬件时间戳\n#minsources 2                          #增加调整所需的可选择源的最小数量\n#keyfile /etc/chrony.keys                 # 指定包含ntp验证密钥的文件。\nlogdir /var/log/chrony                   # 指定日志文件的目录。\nlogchange 0.5                          # 如果时钟调整大于0.5秒，则向系统日志发送消息\n#log measurements statistics tracking      #选择日志文件要记录的信息\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 建议配置项：\n\n 1. 当前节点设置成server:127.127.0.1\n 2. 三个master节点作为其他普通节点的时间服务器（配置成pool）\n 3. 三个master节点互为peer(同原ntp)\n 4. 如果有外部时钟源配置，则设置成pool\n 5. 如果时间超过10min，则允许第一次跳跃 （与之前沟通需求保持一致，可修改策略）\n 6. 最多3个外部时钟源，可以不设置外部时钟源\n\n\n# ntp server(master节点)\n\nserver 127.127.0.1 pool 外部时钟源1 pool外部时钟源2 peer master2节点ip peer master3节点ip driftfile /var/lib/chrony/drift makestep 600 1 rtcsync logdir /var/log/chrony\n\n\n# ntp client(普通node节点)\n\nserver 127.127.0.1 pool外部时钟源1 pool外部时钟源2 pool master1节点ip pool master2节点ip pool master3节点ip driftfile /var/lib/chrony/drift makestep 600 1 rtcsync logdir /var/log/chrony\n\n\n# 七、部署:\n\nenable chrony， disable ntpd\n\n 1. stop/disable ntpd\n 2. configure chrony.conf(master/node)\n 3. systemctl start/enable chronyd.service\n 4. systemctl restart chronyd.service (notify)\n\n\n# 八、常用chrony命令：\n\n1、 chronyd -q 'server ntp.ntsc.ac.cn iburst' 临时同步时间 2、 chronyc -n sources -v 查看时间同步服务器列表 3、 accheck - 检查ntp访问是否对特定主机可用 4、 activity - 该命令会显示有多少ntp源在线/离线 5、 add server - 手动添加一台新的ntp服务器。 6、 clients - 在客户端报告已访问到服务器 7、 delete - 手动移除ntp服务器或对等服务器 8、 settime - 手动设置守护进程时间 9、 tracking - 显示系统时间信息\n\n\n# 九、问题定位思路\n\n1.检查chrony服务是否正常：chrony activity 2.检查ntpd服务是否启动：systemctl is-active ntpd 3.检查时间同步服务器列表：chronyc -n sources -v\n\n\n# 十、参考资料：\n\nhttps://chrony.tuxfamily.org/documentation.html",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"crd operator",frontmatter:{title:"crd operator",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s11/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"自定义资源的描述(Custom Resource Definition)",meta:[{name:"twitter:title",content:"crd operator"},{name:"twitter:description",content:"自定义资源的描述(Custom Resource Definition)"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/11.crd%20operator.html"},{property:"og:type",content:"article"},{property:"og:title",content:"crd operator"},{property:"og:description",content:"自定义资源的描述(Custom Resource Definition)"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/11.crd%20operator.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"crd operator"},{itemprop:"description",content:"自定义资源的描述(Custom Resource Definition)"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/11.crd%20operator.html",relativePath:"01.技术杂谈/03.kubernetes/11.crd operator.md",key:"v-81d98e10",path:"/pages/k8s11/",headers:[{level:2,title:"CRD",slug:"crd",normalizedTitle:"crd",charIndex:2},{level:2,title:"Operator",slug:"operator",normalizedTitle:"operator",charIndex:48}],headersStr:"CRD Operator",content:"# CRD\n\n自定义资源的描述(Custom Resource Definition)\n\n\n# Operator\n\nOperator的工作原理，实际上是利用了Kubernetes的自定义API资源（CRD），来描述我们想要部署的“有状态应用”；然后在自定义控制器里，根据自定义API对象的变化，来完成具体的部署和运维工作。",normalizedContent:"# crd\n\n自定义资源的描述(custom resource definition)\n\n\n# operator\n\noperator的工作原理，实际上是利用了kubernetes的自定义api资源（crd），来描述我们想要部署的“有状态应用”；然后在自定义控制器里，根据自定义api对象的变化，来完成具体的部署和运维工作。",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"cri之containerd shimv2",frontmatter:{title:"cri之containerd shimv2",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s12/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"https://www.infoq.cn/article/r*ikOvovTHhADAWw1Hb1 CRI Shimv2：一种 Kubernetes 集成容器运行时的新思路（张磊）",meta:[{name:"twitter:title",content:"cri之containerd shimv2"},{name:"twitter:description",content:"https://www.infoq.cn/article/r*ikOvovTHhADAWw1Hb1 CRI Shimv2：一种 Kubernetes 集成容器运行时的新思路（张磊）"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/12.cri%E4%B9%8Bcontainerd%20shimv2.html"},{property:"og:type",content:"article"},{property:"og:title",content:"cri之containerd shimv2"},{property:"og:description",content:"https://www.infoq.cn/article/r*ikOvovTHhADAWw1Hb1 CRI Shimv2：一种 Kubernetes 集成容器运行时的新思路（张磊）"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/12.cri%E4%B9%8Bcontainerd%20shimv2.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"cri之containerd shimv2"},{itemprop:"description",content:"https://www.infoq.cn/article/r*ikOvovTHhADAWw1Hb1 CRI Shimv2：一种 Kubernetes 集成容器运行时的新思路（张磊）"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/12.cri%E4%B9%8Bcontainerd%20shimv2.html",relativePath:"01.技术杂谈/03.kubernetes/12.cri之containerd shimv2.md",key:"v-16eeeecc",path:"/pages/k8s12/",headers:[{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:2}],headersStr:"参考资料",content:"# 参考资料\n\nhttps://www.infoq.cn/article/r*ikOvovTHhADAWw1Hb1 CRI Shimv2：一种 Kubernetes 集成容器运行时的新思路（张磊）",normalizedContent:"# 参考资料\n\nhttps://www.infoq.cn/article/r*ikovovthhadaww1hb1 cri shimv2：一种 kubernetes 集成容器运行时的新思路（张磊）",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"harbor",frontmatter:{title:"harbor",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s13/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"harbor"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/13.harbor.html"},{property:"og:type",content:"article"},{property:"og:title",content:"harbor"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/13.harbor.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"harbor"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/13.harbor.html",relativePath:"01.技术杂谈/03.kubernetes/13.harbor.md",key:"v-c5d8330a",path:"/pages/k8s13/",headers:[{level:2,title:"harbor升级数据库迁移及回滚",slug:"harbor升级数据库迁移及回滚",normalizedTitle:"harbor升级数据库迁移及回滚",charIndex:2},{level:3,title:"harbor安装",slug:"harbor安装",normalizedTitle:"harbor安装",charIndex:23},{level:3,title:"harbor升级（大于v1.10.x到更新版本）",slug:"harbor升级-大于v1-10-x到更新版本",normalizedTitle:"harbor升级（大于v1.10.x到更新版本）",charIndex:141},{level:3,title:"harbor回滚",slug:"harbor回滚",normalizedTitle:"harbor回滚",charIndex:566},{level:3,title:"harbor数据库迁移及golang-migrate",slug:"harbor数据库迁移及golang-migrate",normalizedTitle:"harbor数据库迁移及golang-migrate",charIndex:662}],headersStr:"harbor升级数据库迁移及回滚 harbor安装 harbor升级（大于v1.10.x到更新版本） harbor回滚 harbor数据库迁移及golang-migrate",content:"# harbor升级数据库迁移及回滚\n\n\n# harbor安装\n\n 1. 下载docker-compose\n 2. 下载，解压Harbor离线包\n 3. 修改配置harbor.yml.tmpl>harbor.yml及生成证书等\n 4. 安装并启动：./install.sh\n\n\n# harbor升级（大于v1.10.x到更新版本）\n\nharbor不同阶段的升级方式不同，存在兼容性问题，有些版本无法直接跨版本升级，需要多阶段升级方式达到最终升级目的 自harborv2起，迁移工具全部转移到了 goharbor/prepare 这个镜像中\n\n 1. 到github下载2.4.2版本的离线包（包含镜像goharbor/prepare）\n 2. 准备迁移工具镜像goharbor/prepare\n 3. 停止harbor\n 4. 备份数据库和安装目录\n 5. 解压离线包到安装目录\n 6. 移动旧的配置文件到新的安装目录下\n 7. 数据迁移：docker run -it --rm -v /:/hostfs goharbor/prepare:v2.4.2 migrate -i /opt/harbor/harbor.yml （此更新包括数据库模式（schema）和配置文件数据）\n 8. 安装并启动：./install.sh\n\n\n# harbor回滚\n\n 1. 停止harbor\n 2. 删除安装目录和数据库文件\n 3. 将备份目录和备份数据库还原回安装目录和数据库目录\n 4. 安装并启动：./install.sh\n\n\n# harbor数据库迁移及golang-migrate\n\n数据库升级是自动完成的，用户手动执行升级配置文件的命令行工具包。此工具包与Harbor一同发布，被包含在goharbor/prepare镜像中。\n\n每次启动Harbor实例时，它的数据库模式都是自动升级的，其原理为：Harbor在每次启动时都会调用第三方库 “golang-migrate”，它会检测当前数据库模式的版本，如果实例的版本比当前数据库的版本更高，则会自动升级。\n\n$ docker run -v /:/hostfs goharbor/prepare:v2.0.0 migrate -i ${harbor.yml路径}\n\n\n1\n",normalizedContent:"# harbor升级数据库迁移及回滚\n\n\n# harbor安装\n\n 1. 下载docker-compose\n 2. 下载，解压harbor离线包\n 3. 修改配置harbor.yml.tmpl>harbor.yml及生成证书等\n 4. 安装并启动：./install.sh\n\n\n# harbor升级（大于v1.10.x到更新版本）\n\nharbor不同阶段的升级方式不同，存在兼容性问题，有些版本无法直接跨版本升级，需要多阶段升级方式达到最终升级目的 自harborv2起，迁移工具全部转移到了 goharbor/prepare 这个镜像中\n\n 1. 到github下载2.4.2版本的离线包（包含镜像goharbor/prepare）\n 2. 准备迁移工具镜像goharbor/prepare\n 3. 停止harbor\n 4. 备份数据库和安装目录\n 5. 解压离线包到安装目录\n 6. 移动旧的配置文件到新的安装目录下\n 7. 数据迁移：docker run -it --rm -v /:/hostfs goharbor/prepare:v2.4.2 migrate -i /opt/harbor/harbor.yml （此更新包括数据库模式（schema）和配置文件数据）\n 8. 安装并启动：./install.sh\n\n\n# harbor回滚\n\n 1. 停止harbor\n 2. 删除安装目录和数据库文件\n 3. 将备份目录和备份数据库还原回安装目录和数据库目录\n 4. 安装并启动：./install.sh\n\n\n# harbor数据库迁移及golang-migrate\n\n数据库升级是自动完成的，用户手动执行升级配置文件的命令行工具包。此工具包与harbor一同发布，被包含在goharbor/prepare镜像中。\n\n每次启动harbor实例时，它的数据库模式都是自动升级的，其原理为：harbor在每次启动时都会调用第三方库 “golang-migrate”，它会检测当前数据库模式的版本，如果实例的版本比当前数据库的版本更高，则会自动升级。\n\n$ docker run -v /:/hostfs goharbor/prepare:v2.0.0 migrate -i ${harbor.yml路径}\n\n\n1\n",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"Loongnix mips64",frontmatter:{title:"Loongnix mips64",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s15/",categories:["技术杂谈","kubernetes"],tags:["mips"],titleTag:"原创",readingShow:"top",description:"Loongnix-20.loongarch64桌面系统\n  Loongnix-server-20.loongarch64服务器系统",meta:[{name:"twitter:title",content:"Loongnix mips64"},{name:"twitter:description",content:"Loongnix-20.loongarch64桌面系统\n  Loongnix-server-20.loongarch64服务器系统"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/15.Loongnix%20mips64.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Loongnix mips64"},{property:"og:description",content:"Loongnix-20.loongarch64桌面系统\n  Loongnix-server-20.loongarch64服务器系统"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/15.Loongnix%20mips64.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:"mips"},{itemprop:"name",content:"Loongnix mips64"},{itemprop:"description",content:"Loongnix-20.loongarch64桌面系统\n  Loongnix-server-20.loongarch64服务器系统"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/15.Loongnix%20mips64.html",relativePath:"01.技术杂谈/03.kubernetes/15.Loongnix mips64.md",key:"v-211c03e0",path:"/pages/k8s15/",headers:[{level:2,title:"龙芯mips64",slug:"龙芯mips64",normalizedTitle:"龙芯mips64",charIndex:2},{level:2,title:"社区适配情况：",slug:"社区适配情况",normalizedTitle:"社区适配情况：",charIndex:15},{level:2,title:"源：",slug:"源",normalizedTitle:"源：",charIndex:323},{level:3,title:"yum源修改：",slug:"yum源修改",normalizedTitle:"yum源修改：",charIndex:330},{level:3,title:"apt源：",slug:"apt源",normalizedTitle:"apt源：",charIndex:826},{level:3,title:"Loongnix-20.mips64el系统源地址",slug:"loongnix-20-mips64el系统源地址",normalizedTitle:"loongnix-20.mips64el系统源地址",charIndex:1367},{level:3,title:"龙芯NPM源",slug:"龙芯npm源",normalizedTitle:"龙芯npm源",charIndex:1712},{level:2,title:"harbor",slug:"harbor",normalizedTitle:"harbor",charIndex:1795},{level:2,title:"参考资料",slug:"参考资料",normalizedTitle:"参考资料",charIndex:2105}],headersStr:"龙芯mips64 社区适配情况： 源： yum源修改： apt源： Loongnix-20.mips64el系统源地址 龙芯NPM源 harbor 参考资料",content:'# 龙芯mips64\n\n\n# 社区适配情况：\n\n龙芯平台已适配了MIPS下的loongnix-Server以及Debian10对应的版本：nodejs-v12.16.3，LoongArch下的Loongnix-20.loongarch64桌面系统以及Loongnix-server-20.loongarch64服务器系统对应的版本: nodejs-v14.16.1，并将持续维护，力争为用户提供好用的开发环境。\n\n * mips: loongnix-Server Debian10\n * LoongArch: Loongnix-20.loongarch64桌面系统 Loongnix-server-20.loongarch64服务器系统\n\n\n# 源：\n\n\n# yum源修改：\n\nyum install epel-release -y\n\nvi  /etc/yum.repos.d/Loongnix-Base.repo\norg>cn\nsed -i \'s/org/cn/g\' /etc/yum.repos.d/Loongnix-Base.repo \nyum clean all \nyum makecache\n\nyum install epel-release -y && cp /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel-test.repo && sed -i s/ftp.loongnix.org/10.2.5.28/g /etc/yum.repos.d/epel-test.repo && yum makecache && yum install git which gcc g++ libatomic gpg tar openssl11 -y\n\nyum install epel-release -y && yum makecache\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# apt源：\n\necho "deb http://os.loongnix.org/mirrors/debian/debian/ buster main" >> /etc/apt/sources.list\n\necho "deb http://mirrors.163.com/debian/ buster main contrib non-free" > /etc/apt/sources.list && echo "deb http://mirrors.163.com/debian/ buster-updates main contrib non-free" >> /etc/apt/sources.list && echo "deb http://mirrors.163.com/debian/ buster-backports main contrib non-free" >> /etc/apt/sources.list && echo "deb http://mirrors.163.com/debian-security buster/updates main contrib non-free" >> /etc/apt/sources.list\n\n\n1\n2\n3\n\n\n\n# Loongnix-20.mips64el系统源地址\n\ndeb [trusted=yes] http://ftp.loongnix.org/os/loongnix/20/mips64el/ DaoXiangHu-testing main contrib non-free \ndeb-src [trusted=yes] http://ftp.loongnix.org/os/loongnix/20/mips64el/ DaoXiangHu-testing main contrib non-free\nLoongnix-server-1.7.2007 服务器系统源地址\nhttp://ftp.loongnix.org/os/loongnix-server/1.7/\n\n\n1\n2\n3\n4\n\n\n\n# 龙芯NPM源\n\n源地址1：http://npm.loongnix.cn:4873 源地址2：http://registry.loongnix.cn:4873\n\n\n# harbor\n\n执行以下命令编辑/etc/docker/daemon.json，增加insecure-registries的配置，重新加载并重启docker使配置生效\n\nmkdir -p /etc/docker/\ntee /etc/docker/daemon.json <<-‘EOF’\n{\n“insecure-registries”:[“harbor.loongnix.cn”]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl enable docker\nsudo systemctl restart docker\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 参考资料\n\nhttp://doc.loongnix.cn/web/#/50?page_id=146 龙芯Docker安装手册 http://ftp.loongnix.cn/ 龙芯开源社区ftp下载站点 http://www.loongnix.cn/index.php/Container-Registry Loongarch架构的软件仓库站点 http://ask.loongnix.cn/?/search/q-bm9kZWpz#all',normalizedContent:'# 龙芯mips64\n\n\n# 社区适配情况：\n\n龙芯平台已适配了mips下的loongnix-server以及debian10对应的版本：nodejs-v12.16.3，loongarch下的loongnix-20.loongarch64桌面系统以及loongnix-server-20.loongarch64服务器系统对应的版本: nodejs-v14.16.1，并将持续维护，力争为用户提供好用的开发环境。\n\n * mips: loongnix-server debian10\n * loongarch: loongnix-20.loongarch64桌面系统 loongnix-server-20.loongarch64服务器系统\n\n\n# 源：\n\n\n# yum源修改：\n\nyum install epel-release -y\n\nvi  /etc/yum.repos.d/loongnix-base.repo\norg>cn\nsed -i \'s/org/cn/g\' /etc/yum.repos.d/loongnix-base.repo \nyum clean all \nyum makecache\n\nyum install epel-release -y && cp /etc/yum.repos.d/epel.repo /etc/yum.repos.d/epel-test.repo && sed -i s/ftp.loongnix.org/10.2.5.28/g /etc/yum.repos.d/epel-test.repo && yum makecache && yum install git which gcc g++ libatomic gpg tar openssl11 -y\n\nyum install epel-release -y && yum makecache\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# apt源：\n\necho "deb http://os.loongnix.org/mirrors/debian/debian/ buster main" >> /etc/apt/sources.list\n\necho "deb http://mirrors.163.com/debian/ buster main contrib non-free" > /etc/apt/sources.list && echo "deb http://mirrors.163.com/debian/ buster-updates main contrib non-free" >> /etc/apt/sources.list && echo "deb http://mirrors.163.com/debian/ buster-backports main contrib non-free" >> /etc/apt/sources.list && echo "deb http://mirrors.163.com/debian-security buster/updates main contrib non-free" >> /etc/apt/sources.list\n\n\n1\n2\n3\n\n\n\n# loongnix-20.mips64el系统源地址\n\ndeb [trusted=yes] http://ftp.loongnix.org/os/loongnix/20/mips64el/ daoxianghu-testing main contrib non-free \ndeb-src [trusted=yes] http://ftp.loongnix.org/os/loongnix/20/mips64el/ daoxianghu-testing main contrib non-free\nloongnix-server-1.7.2007 服务器系统源地址\nhttp://ftp.loongnix.org/os/loongnix-server/1.7/\n\n\n1\n2\n3\n4\n\n\n\n# 龙芯npm源\n\n源地址1：http://npm.loongnix.cn:4873 源地址2：http://registry.loongnix.cn:4873\n\n\n# harbor\n\n执行以下命令编辑/etc/docker/daemon.json，增加insecure-registries的配置，重新加载并重启docker使配置生效\n\nmkdir -p /etc/docker/\ntee /etc/docker/daemon.json <<-‘eof’\n{\n“insecure-registries”:[“harbor.loongnix.cn”]\n}\neof\nsudo systemctl daemon-reload\nsudo systemctl enable docker\nsudo systemctl restart docker\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 参考资料\n\nhttp://doc.loongnix.cn/web/#/50?page_id=146 龙芯docker安装手册 http://ftp.loongnix.cn/ 龙芯开源社区ftp下载站点 http://www.loongnix.cn/index.php/container-registry loongarch架构的软件仓库站点 http://ask.loongnix.cn/?/search/q-bm9kzwpz#all',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"helm chart",frontmatter:{title:"helm chart",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s14/",categories:["技术杂谈","kubernetes"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"helm chart"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/14.helm%20chart.html"},{property:"og:type",content:"article"},{property:"og:title",content:"helm chart"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/14.helm%20chart.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"helm chart"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/14.helm%20chart.html",relativePath:"01.技术杂谈/03.kubernetes/14.helm chart.md",key:"v-6da5591e",path:"/pages/k8s14/",headers:[{level:2,title:"helm命令：",slug:"helm命令",normalizedTitle:"helm命令：",charIndex:2},{level:2,title:"examples/",slug:"examples",normalizedTitle:"examples/",charIndex:185}],headersStr:"helm命令： examples/",content:"# helm命令：\n\nhelm create myservice helm install . helm install myservice --name myservice --namespace hfftest helm list helm package .\n\nhelm ls --all hfftest helm del --purge hfftest\n\n\n# examples/\n\nChart.yaml # Yaml文件，用于描述Chart的基本信息，包括名称版本等 LICENSE # [可选] 协议 README.md # [可选] 当前Chart的介绍 values.yaml # Chart的默认配置文件 requirements.yaml # [可选] 用于存放当前Chart依赖的其它Chart的说明文件 charts/ # [可选]: 该目录中放置当前Chart依赖的其它Chart templates/ # [可选]: 部署文件模版目录，模版使用的值来自values.yaml和由Tiller提供的值 templates/NOTES.txt # [可选]: 放置Chart的使用指南",normalizedContent:"# helm命令：\n\nhelm create myservice helm install . helm install myservice --name myservice --namespace hfftest helm list helm package .\n\nhelm ls --all hfftest helm del --purge hfftest\n\n\n# examples/\n\nchart.yaml # yaml文件，用于描述chart的基本信息，包括名称版本等 license # [可选] 协议 readme.md # [可选] 当前chart的介绍 values.yaml # chart的默认配置文件 requirements.yaml # [可选] 用于存放当前chart依赖的其它chart的说明文件 charts/ # [可选]: 该目录中放置当前chart依赖的其它chart templates/ # [可选]: 部署文件模版目录，模版使用的值来自values.yaml和由tiller提供的值 templates/notes.txt # [可选]: 放置chart的使用指南",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"openebs-lvm-localpv",frontmatter:{title:"openebs-lvm-localpv",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/k8s16/",categories:["技术杂谈","kubernetes"],tags:["csi"],titleTag:"原创",readingShow:"top",description:"https://github.com/openebs/lvm-localpv",meta:[{name:"twitter:title",content:"openebs-lvm-localpv"},{name:"twitter:description",content:"https://github.com/openebs/lvm-localpv"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/16.openebs-lvm-localpv.html"},{property:"og:type",content:"article"},{property:"og:title",content:"openebs-lvm-localpv"},{property:"og:description",content:"https://github.com/openebs/lvm-localpv"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/16.openebs-lvm-localpv.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:"csi"},{itemprop:"name",content:"openebs-lvm-localpv"},{itemprop:"description",content:"https://github.com/openebs/lvm-localpv"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/16.openebs-lvm-localpv.html",relativePath:"01.技术杂谈/03.kubernetes/16.openebs-lvm-localpv.md",key:"v-019d3da2",path:"/pages/k8s16/",headers:[{level:2,title:"pv",slug:"pv",normalizedTitle:"pv",charIndex:36},{level:3,title:"创建pv",slug:"创建pv",normalizedTitle:"创建pv",charIndex:50},{level:3,title:"创建vg",slug:"创建vg",normalizedTitle:"创建vg",charIndex:141},{level:2,title:"deploy",slug:"deploy",normalizedTitle:"deploy",charIndex:246}],headersStr:"pv 创建pv 创建vg deploy",content:'https://github.com/openebs/lvm-localpv\n\n\n# pv\n\n\n# 创建pv\n\npvname=${disk}1\n\nsgdisk -n 1:2048 ${disk} pvcreate ${pvname} pvdisplay ${pvname}\n\n\n# 创建vg\n\nvgcreate ${vgname} ${pvname} vgextend ${vgname} ${pvname} pvdisplay ${pvname} | grep ${vgname}\n\n\n# deploy\n\n$ kubectl apply -f https://openebs.github.io/charts/lvm-operator.yaml\n\n\n# 应用\n\napiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: openebs-lvmpv\nallowVolumeExpansion: true\nparameters:\n  storage: "lvm"\n  volgroup: "lvmvg"\nprovisioner: local.csi.openebs.io\nallowedTopologies:\n- matchLabelExpressions:\n  - key: kubernetes.io/hostname\n    values:\n      - lvmpv-node1\n      - lvmpv-node2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\nvolgroup：选择vg allowedTopologies: 选择节点\n\n\n# disk回收\n\npvname=${disk}1\n\nvgremove ${vgname} 或 vgreduce ${vgname} ${pvname}\n\npvremove ${pvname}\n\npvdisplay ${pvname}\n\nsgdisk --zap-all --clear --mbrtogpt ${disk}',normalizedContent:'https://github.com/openebs/lvm-localpv\n\n\n# pv\n\n\n# 创建pv\n\npvname=${disk}1\n\nsgdisk -n 1:2048 ${disk} pvcreate ${pvname} pvdisplay ${pvname}\n\n\n# 创建vg\n\nvgcreate ${vgname} ${pvname} vgextend ${vgname} ${pvname} pvdisplay ${pvname} | grep ${vgname}\n\n\n# deploy\n\n$ kubectl apply -f https://openebs.github.io/charts/lvm-operator.yaml\n\n\n# 应用\n\napiversion: storage.k8s.io/v1\nkind: storageclass\nmetadata:\n  name: openebs-lvmpv\nallowvolumeexpansion: true\nparameters:\n  storage: "lvm"\n  volgroup: "lvmvg"\nprovisioner: local.csi.openebs.io\nallowedtopologies:\n- matchlabelexpressions:\n  - key: kubernetes.io/hostname\n    values:\n      - lvmpv-node1\n      - lvmpv-node2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\nvolgroup：选择vg allowedtopologies: 选择节点\n\n\n# disk回收\n\npvname=${disk}1\n\nvgremove ${vgname} 或 vgreduce ${vgname} ${pvname}\n\npvremove ${pvname}\n\npvdisplay ${pvname}\n\nsgdisk --zap-all --clear --mbrtogpt ${disk}',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"DevOps",frontmatter:{title:"DevOps",date:"2022-08-24T16:38:55.000Z",permalink:"/pages/devops/",categories:["技术杂谈","kubernetes"],tags:["DevOps"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"DevOps"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/18.DevOps.html"},{property:"og:type",content:"article"},{property:"og:title",content:"DevOps"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/18.DevOps.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-24T16:38:55.000Z"},{property:"article:tag",content:"DevOps"},{itemprop:"name",content:"DevOps"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/18.DevOps.html",relativePath:"01.技术杂谈/03.kubernetes/18.DevOps.md",key:"v-3d63ec0a",path:"/pages/devops/",headers:[{level:2,title:"CI/CD流水线",slug:"ci-cd流水线",normalizedTitle:"ci/cd流水线",charIndex:172},{level:3,title:"Jenkins",slug:"jenkins",normalizedTitle:"jenkins",charIndex:267}],headersStr:"CI/CD流水线 Jenkins",content:"DevOps是一套完整的运维开发流程，可以实现快速的构建、测试和发布软件，整个流程包括敏捷开发-持续集成-持续交付-持续部署-DevOps。\n\n * CI(Continued integrate 持续集成)\n * CD(Continued Delivery 持续交付)\n * CD(Continued Deployment 持续部署)\n\n\n# CI/CD流水线\n\n * 多SCM支持：GitLab/GitHub/BitBucket/SVN等\n * 图形界面\n * sonarQube\n * 支持缓存\n * 自动发布：更新镜像\n\n\n# Jenkins\n\nJenkins是一个开源的、提供友好操作界面的持续集成（CI）工具，起源于Hudson，主要用于持续、自动的构建/测试软件项目、监控外部任务的运行。",normalizedContent:"devops是一套完整的运维开发流程，可以实现快速的构建、测试和发布软件，整个流程包括敏捷开发-持续集成-持续交付-持续部署-devops。\n\n * ci(continued integrate 持续集成)\n * cd(continued delivery 持续交付)\n * cd(continued deployment 持续部署)\n\n\n# ci/cd流水线\n\n * 多scm支持：gitlab/github/bitbucket/svn等\n * 图形界面\n * sonarqube\n * 支持缓存\n * 自动发布：更新镜像\n\n\n# jenkins\n\njenkins是一个开源的、提供友好操作界面的持续集成（ci）工具，起源于hudson，主要用于持续、自动的构建/测试软件项目、监控外部任务的运行。",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"traefik-IngressRoute",frontmatter:{title:"traefik-IngressRoute",date:"2022-08-24T16:38:55.000Z",permalink:"/pages/ingressroute/",categories:["技术杂谈","kubernetes"],tags:["网络"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"traefik-IngressRoute"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/17.traefik-ingressroute.html"},{property:"og:type",content:"article"},{property:"og:title",content:"traefik-IngressRoute"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/17.traefik-ingressroute.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-24T16:38:55.000Z"},{property:"article:tag",content:"网络"},{itemprop:"name",content:"traefik-IngressRoute"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/17.traefik-ingressroute.html",relativePath:"01.技术杂谈/03.kubernetes/17.traefik-ingressroute.md",key:"v-185c15db",path:"/pages/ingressroute/",headers:[{level:2,title:"路由匹配规则",slug:"路由匹配规则",normalizedTitle:"路由匹配规则",charIndex:553},{level:2,title:"中间件",slug:"中间件",normalizedTitle:"中间件",charIndex:1086},{level:2,title:"https配置",slug:"https配置",normalizedTitle:"https配置",charIndex:1283}],headersStr:"路由匹配规则 中间件 https配置",content:"IngressRoute是traefik编写的一个自定义资源(CRD),可以更好的配置traefik所需的路由信息 https://doc.traefik.io/traefik/reference/dynamic-configuration/kubernetes-crd/#resources\n\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: nginx-test\n  namespace: kube-ops\nspec:\n  entryPoints:\n    # 指定入口点为web。这里的web就是traefik静态配置(启动参数)中的 --entryPoints.web.address=:8000,通过仪表盘也可以看到\n    - web\n  routes:\n    - kind: Rule\n      match: Host(`test.com`) # 匹配规则,第三部分说明\n      services:\n        - name: nginx-test\n          port: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# 路由匹配规则\n\n * Headers(key, value): 判断请求头是否存在，key是请求头名称，value是值\n * HeadersRegexp(key, regexp): 同上,可以使用正则来匹配\n * Host(example.com, ...): 检查请求Host请求头,判断其值是否为给定之一\n * HostHeader(example.com, ...): 同上\n * HostRegexp(example.com, {subdomain:[a-z]+}.example.com, ...): 同上，可以使用正则\n * Method(GET, ...): 检查请求方法是否为给定的一个methods（GET，POST，PUT，DELETE，PATCH）\n * Path(/path, /articles/{cat:[a-z]+}/{id:[0-9]+}, ...): 匹配确切的请求路径。接受正则表达式\n * PathPrefix(/products/, /articles/{cat:[a-z]+}/{id:[0-9]+}): 匹配请求前缀路径。接受正则表达式\n * Query(foo=bar, bar=baz): 匹配查询字符串参数\n\n\n# 中间件\n\napiVersion: traefik.containo.us/v1alpha1\nkind: Middleware\nmetadata:\n  name: stripprefix-test\n  namespace: test\nspec:\n  stripPrefix:\n    prefixes:\n    - /test/\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# https配置\n\n * 生成证书secret\n\nkubectl create secret tls nginx-test --cert=tls.crt --key=tls.key\n\n * 修改之前的IngressRoute\n\napiVersion: traefik.containo.us/v1alpha1\nkind: IngressRoute\nmetadata:\n  name: nginx-test\n  namespace: kube-ops\nspec:\n  entryPoints:\n    # 指定入口点为web。这里的web就是traefik静态配置(启动参数)中的 --entryPoints.web.address=:8000,通过仪表盘也可以看到\n    - web\n  routes:\n    - kind: Rule\n      match: Host(`test.com`) # 匹配规则,第三部分说明\n      services:\n        - name: nginx-test\n          port: 80\n  tls:\n    secretName: nginx-test\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n",normalizedContent:"ingressroute是traefik编写的一个自定义资源(crd),可以更好的配置traefik所需的路由信息 https://doc.traefik.io/traefik/reference/dynamic-configuration/kubernetes-crd/#resources\n\napiversion: traefik.containo.us/v1alpha1\nkind: ingressroute\nmetadata:\n  name: nginx-test\n  namespace: kube-ops\nspec:\n  entrypoints:\n    # 指定入口点为web。这里的web就是traefik静态配置(启动参数)中的 --entrypoints.web.address=:8000,通过仪表盘也可以看到\n    - web\n  routes:\n    - kind: rule\n      match: host(`test.com`) # 匹配规则,第三部分说明\n      services:\n        - name: nginx-test\n          port: 80\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# 路由匹配规则\n\n * headers(key, value): 判断请求头是否存在，key是请求头名称，value是值\n * headersregexp(key, regexp): 同上,可以使用正则来匹配\n * host(example.com, ...): 检查请求host请求头,判断其值是否为给定之一\n * hostheader(example.com, ...): 同上\n * hostregexp(example.com, {subdomain:[a-z]+}.example.com, ...): 同上，可以使用正则\n * method(get, ...): 检查请求方法是否为给定的一个methods（get，post，put，delete，patch）\n * path(/path, /articles/{cat:[a-z]+}/{id:[0-9]+}, ...): 匹配确切的请求路径。接受正则表达式\n * pathprefix(/products/, /articles/{cat:[a-z]+}/{id:[0-9]+}): 匹配请求前缀路径。接受正则表达式\n * query(foo=bar, bar=baz): 匹配查询字符串参数\n\n\n# 中间件\n\napiversion: traefik.containo.us/v1alpha1\nkind: middleware\nmetadata:\n  name: stripprefix-test\n  namespace: test\nspec:\n  stripprefix:\n    prefixes:\n    - /test/\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# https配置\n\n * 生成证书secret\n\nkubectl create secret tls nginx-test --cert=tls.crt --key=tls.key\n\n * 修改之前的ingressroute\n\napiversion: traefik.containo.us/v1alpha1\nkind: ingressroute\nmetadata:\n  name: nginx-test\n  namespace: kube-ops\nspec:\n  entrypoints:\n    # 指定入口点为web。这里的web就是traefik静态配置(启动参数)中的 --entrypoints.web.address=:8000,通过仪表盘也可以看到\n    - web\n  routes:\n    - kind: rule\n      match: host(`test.com`) # 匹配规则,第三部分说明\n      services:\n        - name: nginx-test\n          port: 80\n  tls:\n    secretname: nginx-test\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"Serverless",frontmatter:{title:"Serverless",date:"2022-08-24T16:38:55.000Z",permalink:"/pages/serverless/",categories:["技术杂谈","kubernetes"],tags:["Serverless"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"Serverless"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/19.serverless.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Serverless"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/19.serverless.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-24T16:38:55.000Z"},{property:"article:tag",content:"Serverless"},{itemprop:"name",content:"Serverless"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/19.serverless.html",relativePath:"01.技术杂谈/03.kubernetes/19.serverless.md",key:"v-680c343b",path:"/pages/serverless/",headers:[{level:2,title:"典型应用场景",slug:"典型应用场景",normalizedTitle:"典型应用场景",charIndex:324},{level:2,title:"问题",slug:"问题",normalizedTitle:"问题",charIndex:463}],headersStr:"典型应用场景 问题",content:"从单词角度理解,server译为服务，less译为少，Serverless可以理解为无服务器计算。\n\n从语义角度理解，之所以叫无服务器计算，是因为和传统的PaaS(平台即服务)相比，用户不需要关心服务器的部署与配置。但这并不意味着不需要服务器，只是这些东西皆由云平台来提供。\n\n从架构角度理解，Serverless=FaaS+事件驱动+BaaS=无服务器计算(Serverless computing)\n\n> FaaS: Function as a Service,函数即服务 事件驱动：通过事件触发的形式去完成函数的调用，处理请求和响应（如定时任务/http请求...） BaaS: Backend as a Service 后端即服务\n\n\n# 典型应用场景\n\nServerless 适用于事件触发的场景。当某个事件发生时，拉起并调用 Serverless 云函数，比如文件上传、消息队列中的消息事件、定时器事件，也可以是 IoT 设备的某个事件。还可以用于一些文件处理，比如图像处理、音视频处理和日志分析等场景。\n\n\n# 问题",normalizedContent:"从单词角度理解,server译为服务，less译为少，serverless可以理解为无服务器计算。\n\n从语义角度理解，之所以叫无服务器计算，是因为和传统的paas(平台即服务)相比，用户不需要关心服务器的部署与配置。但这并不意味着不需要服务器，只是这些东西皆由云平台来提供。\n\n从架构角度理解，serverless=faas+事件驱动+baas=无服务器计算(serverless computing)\n\n> faas: function as a service,函数即服务 事件驱动：通过事件触发的形式去完成函数的调用，处理请求和响应（如定时任务/http请求...） baas: backend as a service 后端即服务\n\n\n# 典型应用场景\n\nserverless 适用于事件触发的场景。当某个事件发生时，拉起并调用 serverless 云函数，比如文件上传、消息队列中的消息事件、定时器事件，也可以是 iot 设备的某个事件。还可以用于一些文件处理，比如图像处理、音视频处理和日志分析等场景。\n\n\n# 问题",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"k8s容器故障处理",frontmatter:{title:"k8s容器故障处理",date:"2022-08-24T16:38:55.000Z",permalink:"/pages/k8s20/",categories:["技术杂谈","kubernetes"],tags:["Serverless"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"k8s容器故障处理"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/20.k8s%E5%AE%B9%E5%99%A8%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"k8s容器故障处理"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/20.k8s%E5%AE%B9%E5%99%A8%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-24T16:38:55.000Z"},{property:"article:tag",content:"Serverless"},{itemprop:"name",content:"k8s容器故障处理"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/20.k8s%E5%AE%B9%E5%99%A8%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86.html",relativePath:"01.技术杂谈/03.kubernetes/20.k8s容器故障处理.md",key:"v-9b6819e6",path:"/pages/k8s20/",headers:[{level:2,title:"Kubelet 使用的目录所在磁盘爆满",slug:"kubelet-使用的目录所在磁盘爆满",normalizedTitle:"kubelet 使用的目录所在磁盘爆满",charIndex:2},{level:2,title:"查看文件io是否高",slug:"查看文件io是否高",normalizedTitle:"查看文件io是否高",charIndex:880},{level:2,title:"容器抓包",slug:"容器抓包",normalizedTitle:"容器抓包",charIndex:1247}],headersStr:"Kubelet 使用的目录所在磁盘爆满 查看文件io是否高 容器抓包",content:'# Kubelet 使用的目录所在磁盘爆满\n\nkubelet 默认使用的目录 /var/lib/kubelet ：通过 kubelet 的 --root-dir 参数指定，用于存储插件信息、Pod 相关的状态以及挂载的 volume（例如， emptyDir 、 ConfigMap 及 Secret ）。\n\n现象： 新建 Pod 时无法成功进行 mkdir，导致 Sandbox 也无法创建成功\n\nWarning UnexpectedAdmissionError 44m kubelet, 172.22.0.44 Update plugin resources failed d\nue to failed to write checkpoint file "kubelet_internal_checkpoint": write /var/lib/kubelet/deviceplugins/.728425055: no space left on device, which is unexpected.\n\n\n1\n2\n\n\n处理方式：\n\n 1. 手动删除 docker 的部分 log 文件或可写层文件。通常删除 log 文件，示例如下：\n\n$ cd /var/lib/docker/containers\n$ du -sh * # 找到比较大的目录\n$ cd dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c\n$ cat /dev/null > dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de74\n3c-json.log.9 # 删除log文件\n\n\n1\n2\n3\n4\n5\n\n 2. 执行以下命令，将该 Node 标记为不可调度，并将其已有的 Pod 驱逐到其它节点。 kubectl drain\n 3. systemctl restart dockerd\n 4. kubectl uncordon\n\n\n# 查看文件io是否高\n\n有时节点在低 cpu ‘us’ (user) 、高 cpu ‘id’ (idle) 的条件下，仍会出现负载很高的情况。通常是由于文件 IO 性能达到瓶颈，导致 IO Wait 过多，使节点整体负载升高，影响其它进程的性能。 本文以 top、atop 及 iotop 工具为例，来判断磁盘 I/O 是否正在降低应用性能。\n\ntop:可查看核的 wa 值，wa（wait）表示 IO WAIT 的 CPU 占用。默认显示所有核的平均值，按 1查看每个核的 wa 值。如 wa 通常为0%，如果经常浮动在1%之上，说明存储设备的速度已经太慢，无法跟上 CPU 的处理速 度。 atop:查看 busy， 继续在该界面按 d，可查看哪些进程正在使用磁盘 IO。 iotop -oPa：查看哪些进程占用磁盘 IO\n\n\n# 容器抓包',normalizedContent:'# kubelet 使用的目录所在磁盘爆满\n\nkubelet 默认使用的目录 /var/lib/kubelet ：通过 kubelet 的 --root-dir 参数指定，用于存储插件信息、pod 相关的状态以及挂载的 volume（例如， emptydir 、 configmap 及 secret ）。\n\n现象： 新建 pod 时无法成功进行 mkdir，导致 sandbox 也无法创建成功\n\nwarning unexpectedadmissionerror 44m kubelet, 172.22.0.44 update plugin resources failed d\nue to failed to write checkpoint file "kubelet_internal_checkpoint": write /var/lib/kubelet/deviceplugins/.728425055: no space left on device, which is unexpected.\n\n\n1\n2\n\n\n处理方式：\n\n 1. 手动删除 docker 的部分 log 文件或可写层文件。通常删除 log 文件，示例如下：\n\n$ cd /var/lib/docker/containers\n$ du -sh * # 找到比较大的目录\n$ cd dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de743c\n$ cat /dev/null > dda02c9a7491fa797ab730c1568ba06cba74cecd4e4a82e9d90d00fa11de74\n3c-json.log.9 # 删除log文件\n\n\n1\n2\n3\n4\n5\n\n 2. 执行以下命令，将该 node 标记为不可调度，并将其已有的 pod 驱逐到其它节点。 kubectl drain\n 3. systemctl restart dockerd\n 4. kubectl uncordon\n\n\n# 查看文件io是否高\n\n有时节点在低 cpu ‘us’ (user) 、高 cpu ‘id’ (idle) 的条件下，仍会出现负载很高的情况。通常是由于文件 io 性能达到瓶颈，导致 io wait 过多，使节点整体负载升高，影响其它进程的性能。 本文以 top、atop 及 iotop 工具为例，来判断磁盘 i/o 是否正在降低应用性能。\n\ntop:可查看核的 wa 值，wa（wait）表示 io wait 的 cpu 占用。默认显示所有核的平均值，按 1查看每个核的 wa 值。如 wa 通常为0%，如果经常浮动在1%之上，说明存储设备的速度已经太慢，无法跟上 cpu 的处理速 度。 atop:查看 busy， 继续在该界面按 d，可查看哪些进程正在使用磁盘 io。 iotop -opa：查看哪些进程占用磁盘 io\n\n\n# 容器抓包',charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"1",frontmatter:{title:1,date:"2022-07-27T14:56:54.000Z",permalink:"/pages/k8smianshi1/",categories:["技术杂谈","kubernetes","k8s面试"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"1"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/301.k8s%E9%9D%A2%E8%AF%95/01.1.html"},{property:"og:type",content:"article"},{property:"og:title",content:"1"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/301.k8s%E9%9D%A2%E8%AF%95/01.1.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"1"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/301.k8s%E9%9D%A2%E8%AF%95/01.1.html",relativePath:"01.技术杂谈/03.kubernetes/301.k8s面试/01.1.md",key:"v-db387184",path:"/pages/k8smianshi1/",headers:[{level:2,title:"简要说下Kubernetes有哪些核心组件以及这些组件负责什么工作？(8大组件)",slug:"简要说下kubernetes有哪些核心组件以及这些组件负责什么工作-8大组件",normalizedTitle:"简要说下kubernetes有哪些核心组件以及这些组件负责什么工作？(8大组件)",charIndex:2},{level:2,title:"kubenetes针对pod资源对象的健康监测机制",slug:"kubenetes针对pod资源对象的健康监测机制",normalizedTitle:"kubenetes针对pod资源对象的健康监测机制",charIndex:804},{level:2,title:"参考：",slug:"参考",normalizedTitle:"参考：",charIndex:1425}],headersStr:"简要说下Kubernetes有哪些核心组件以及这些组件负责什么工作？(8大组件) kubenetes针对pod资源对象的健康监测机制 参考：",content:"# 简要说下Kubernetes有哪些核心组件以及这些组件负责什么工作？(8大组件)\n\netcd：提供数据库服务保存了整个集群的状态\n\nkube-apiserver：提供了资源操作的唯一入口，并提供认证、授权、访问控制、API注册和发现等机制\n\nkube-controller-manager：负责维护集群的状态，比如故障检测、自动扩展、滚动更新等\n\ncloud-controller-manager：是与底层云计算服务商交互的控制器\n\nkub-scheduler：负责资源的调度，按照预定的调度策略将Pod调度到相应的机器上\n\nkubelet：负责维护容器的生命周期，同时也负责Volume和网络的管理，运行在每个计算节点上，作为agent，接收分配该节点的Pods任务及管理容器，周期性获取容器状态，反馈给kube-apiserver。\n\nkube-proxy：负责为Service提供内部的服务发现和负载均衡，并维护网络规则。运行在每个计算节点上，负责Pod网络代理。定时从etcd获取到service信息来做相应的策略。\n\ncontainer-runtime：是负责管理运行容器的软件，比如docker\n\nkubectl:客户端命令行工具，作为整个系统的操作入口。\n\nkube-controller-manager:执行整个系统的后台任务，包括节点状态状况、Pod个数、Pods和Service的关联等。\n\nkube-scheduler:负责节点资源管理，接收来自kube-apiserver创建Pods任务，并分配到某个节点。\n\nkube-dns：一个可选的DNS服务，用于为每个Service对象创建DNS记录，这样所有的Pod就可以通过DNS访问服务了。\n\nIngress Controller 为服务提供外网入口\n\nHeapster 提供资源监控\n\nDashboard 提供 GUI\n\n\n# kubenetes针对pod资源对象的健康监测机制\n\n1） livenessProbe探针 可以根据用户自定义规则来判定pod是否健康，如果livenessProbe探针探测到容器不健康，则kubelet会根据其重启策略来决定是否重启，如果一个容器不包含livenessProbe探针，则kubelet会认为容器的livenessProbe探针的返回值永远成功。\n\n2） ReadinessProbe探针 同样是可以根据用户自定义规则来判断pod是否健康，如果探测失败，控制器会将此pod从对应service的endpoint列表中移除，从此不再将任何请求调度到此Pod上，直到下次探测成功。\n\n3） startupProbe探针 启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉，这个问题也可以换另一种方式解决，就是定义上面两类探针机制时，初始化时间定义的长一些即可。\n\n每种探测方法能支持以下几个相同的检查参数，用于设置控制检查时间：\n\ninitialDelaySeconds：初始第一次探测间隔，用于应用启动的时间，防止应用还没启动而健康检查失败 periodSeconds：检查间隔，多久执行probe检查，默认为10s； timeoutSeconds：检查超时时长，探测应用timeout后为失败； successThreshold：成功探测阈值，表示探测多少次为健康正常，默认探测1次。\n\n\n# 参考：\n\nhttps://zhuangxiaoyan.blog.csdn.net/article/details/120679513",normalizedContent:"# 简要说下kubernetes有哪些核心组件以及这些组件负责什么工作？(8大组件)\n\netcd：提供数据库服务保存了整个集群的状态\n\nkube-apiserver：提供了资源操作的唯一入口，并提供认证、授权、访问控制、api注册和发现等机制\n\nkube-controller-manager：负责维护集群的状态，比如故障检测、自动扩展、滚动更新等\n\ncloud-controller-manager：是与底层云计算服务商交互的控制器\n\nkub-scheduler：负责资源的调度，按照预定的调度策略将pod调度到相应的机器上\n\nkubelet：负责维护容器的生命周期，同时也负责volume和网络的管理，运行在每个计算节点上，作为agent，接收分配该节点的pods任务及管理容器，周期性获取容器状态，反馈给kube-apiserver。\n\nkube-proxy：负责为service提供内部的服务发现和负载均衡，并维护网络规则。运行在每个计算节点上，负责pod网络代理。定时从etcd获取到service信息来做相应的策略。\n\ncontainer-runtime：是负责管理运行容器的软件，比如docker\n\nkubectl:客户端命令行工具，作为整个系统的操作入口。\n\nkube-controller-manager:执行整个系统的后台任务，包括节点状态状况、pod个数、pods和service的关联等。\n\nkube-scheduler:负责节点资源管理，接收来自kube-apiserver创建pods任务，并分配到某个节点。\n\nkube-dns：一个可选的dns服务，用于为每个service对象创建dns记录，这样所有的pod就可以通过dns访问服务了。\n\ningress controller 为服务提供外网入口\n\nheapster 提供资源监控\n\ndashboard 提供 gui\n\n\n# kubenetes针对pod资源对象的健康监测机制\n\n1） livenessprobe探针 可以根据用户自定义规则来判定pod是否健康，如果livenessprobe探针探测到容器不健康，则kubelet会根据其重启策略来决定是否重启，如果一个容器不包含livenessprobe探针，则kubelet会认为容器的livenessprobe探针的返回值永远成功。\n\n2） readinessprobe探针 同样是可以根据用户自定义规则来判断pod是否健康，如果探测失败，控制器会将此pod从对应service的endpoint列表中移除，从此不再将任何请求调度到此pod上，直到下次探测成功。\n\n3） startupprobe探针 启动检查机制，应用一些启动缓慢的业务，避免业务长时间启动而被上面两类探针kill掉，这个问题也可以换另一种方式解决，就是定义上面两类探针机制时，初始化时间定义的长一些即可。\n\n每种探测方法能支持以下几个相同的检查参数，用于设置控制检查时间：\n\ninitialdelayseconds：初始第一次探测间隔，用于应用启动的时间，防止应用还没启动而健康检查失败 periodseconds：检查间隔，多久执行probe检查，默认为10s； timeoutseconds：检查超时时长，探测应用timeout后为失败； successthreshold：成功探测阈值，表示探测多少次为健康正常，默认探测1次。\n\n\n# 参考：\n\nhttps://zhuangxiaoyan.blog.csdn.net/article/details/120679513",charsets:{cjk:!0}},{title:"kubevirt原理",frontmatter:{title:"kubevirt原理",date:"2022-10-09T17:56:54.000Z",permalink:"/pages/kubevirtyuanli/",categories:["技术杂谈","kubernetes","kubevirt"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"kubevirt原理"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/302.kubevirt/01.kubevirt%E5%8E%9F%E7%90%86.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kubevirt原理"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/302.kubevirt/01.kubevirt%E5%8E%9F%E7%90%86.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T17:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kubevirt原理"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/302.kubevirt/01.kubevirt%E5%8E%9F%E7%90%86.html",relativePath:"01.技术杂谈/03.kubernetes/302.kubevirt/01.kubevirt原理.md",key:"v-07c97ac3",path:"/pages/kubevirtyuanli/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"kubevirt部署",frontmatter:{title:"kubevirt部署",date:"2022-10-09T17:56:54.000Z",permalink:"/pages/kubevirtdeploy/",categories:["技术杂谈","kubernetes","kubevirt"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"kubevirt部署"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/302.kubevirt/02.kubevirt%E9%83%A8%E7%BD%B2.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kubevirt部署"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/302.kubevirt/02.kubevirt%E9%83%A8%E7%BD%B2.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T17:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kubevirt部署"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/302.kubevirt/02.kubevirt%E9%83%A8%E7%BD%B2.html",relativePath:"01.技术杂谈/03.kubernetes/302.kubevirt/02.kubevirt部署.md",key:"v-335e284a",path:"/pages/kubevirtdeploy/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"kata基本原理与架构",frontmatter:{title:"kata基本原理与架构",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata1/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:"​\t\tKata Containers项目来自于2017年12月合并的两个项目“IntelClear Containers”和“Hyper runV”，其目标是构建极其轻量级的VM，它们像容器一样执行，但提供工作负载隔离和添加虚拟机层的安全优势。",meta:[{name:"image",content:"https://fangfenghuang.github.io/../images/20220330151918.png"},{name:"twitter:title",content:"kata基本原理与架构"},{name:"twitter:description",content:"​\t\tKata Containers项目来自于2017年12月合并的两个项目“IntelClear Containers”和“Hyper runV”，其目标是构建极其轻量级的VM，它们像容器一样执行，但提供工作负载隔离和添加虚拟机层的安全优势。"},{name:"twitter:card",content:"summary_large_image"},{name:"twitter:image",content:"https://fangfenghuang.github.io/../images/20220330151918.png"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/01.kata%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata基本原理与架构"},{property:"og:description",content:"​\t\tKata Containers项目来自于2017年12月合并的两个项目“IntelClear Containers”和“Hyper runV”，其目标是构建极其轻量级的VM，它们像容器一样执行，但提供工作负载隔离和添加虚拟机层的安全优势。"},{property:"og:image",content:"https://fangfenghuang.github.io/../images/20220330151918.png"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/01.kata%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata基本原理与架构"},{itemprop:"description",content:"​\t\tKata Containers项目来自于2017年12月合并的两个项目“IntelClear Containers”和“Hyper runV”，其目标是构建极其轻量级的VM，它们像容器一样执行，但提供工作负载隔离和添加虚拟机层的安全优势。"},{itemprop:"image",content:"https://fangfenghuang.github.io/../images/20220330151918.png"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/01.kata%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86%E4%B8%8E%E6%9E%B6%E6%9E%84.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/01.kata基本原理与架构.md",key:"v-33c779e9",path:"/pages/kata1/",headers:[{level:2,title:"The speed of containers, the security of VMs",slug:"the-speed-of-containers-the-security-of-vms",normalizedTitle:"the speed of containers, the security of vms",charIndex:498},{level:2,title:"项目思路：",slug:"项目思路",normalizedTitle:"项目思路：",charIndex:766},{level:2,title:"安全隔离",slug:"安全隔离",normalizedTitle:"安全隔离",charIndex:1046},{level:2,title:"kata隔离效益",slug:"kata隔离效益",normalizedTitle:"kata隔离效益",charIndex:1151},{level:2,title:"减少虚拟化开销",slug:"减少虚拟化开销",normalizedTitle:"减少虚拟化开销",charIndex:1543},{level:2,title:"怎样接上容器的生态",slug:"怎样接上容器的生态",normalizedTitle:"怎样接上容器的生态",charIndex:1716},{level:2,title:"和传统的runC的区别",slug:"和传统的runc的区别",normalizedTitle:"和传统的runc的区别",charIndex:1896},{level:2,title:"使用场景",slug:"使用场景",normalizedTitle:"使用场景",charIndex:2036},{level:2,title:"Kata Containers 2.x vs 1.x",slug:"kata-containers-2-x-vs-1-x",normalizedTitle:"kata containers 2.x vs 1.x",charIndex:2686},{level:2,title:"kata Runtime (shimv2)",slug:"kata-runtime-shimv2",normalizedTitle:"kata runtime (shimv2)",charIndex:3249},{level:2,title:"kata-agent",slug:"kata-agent",normalizedTitle:"kata-agent",charIndex:3767},{level:2,title:"虚拟化技术",slug:"虚拟化技术",normalizedTitle:"虚拟化技术",charIndex:3974},{level:3,title:"hypervisor",slug:"hypervisor",normalizedTitle:"hypervisor",charIndex:4182},{level:4,title:"qemu-system-x86_64",slug:"qemu-system-x86-64",normalizedTitle:"qemu-system-x86_64",charIndex:4502},{level:3,title:"cgroup",slug:"cgroup",normalizedTitle:"cgroup",charIndex:4555},{level:3,title:"客户机内核和镜像",slug:"客户机内核和镜像",normalizedTitle:"客户机内核和镜像",charIndex:4583},{level:3,title:"网络和存储",slug:"网络和存储",normalizedTitle:"网络和存储",charIndex:4622},{level:3,title:"CPU和内存",slug:"cpu和内存",normalizedTitle:"cpu和内存",charIndex:4653},{level:3,title:"VSOCK",slug:"vsock",normalizedTitle:"vsock",charIndex:2013},{level:3,title:"kata monitor",slug:"kata-monitor",normalizedTitle:"kata monitor",charIndex:4698},{level:2,title:"技术要点总结",slug:"技术要点总结",normalizedTitle:"技术要点总结",charIndex:4737},{level:2,title:"部署组件：",slug:"部署组件",normalizedTitle:"部署组件：",charIndex:5153},{level:2,title:"容器创建流程",slug:"容器创建流程",normalizedTitle:"容器创建流程",charIndex:5443},{level:2,title:"环境要求：",slug:"环境要求",normalizedTitle:"环境要求：",charIndex:5823},{level:2,title:"对资源管理的一些影响",slug:"对资源管理的一些影响",normalizedTitle:"对资源管理的一些影响",charIndex:5908},{level:2,title:"存储限制：",slug:"存储限制",normalizedTitle:"存储限制：",charIndex:6115},{level:2,title:"主机资源共享问题",slug:"主机资源共享问题",normalizedTitle:"主机资源共享问题",charIndex:6316},{level:3,title:"Privileged containers",slug:"privileged-containers",normalizedTitle:"privileged containers",charIndex:6455},{level:2,title:"docker切换成containerd的使用影响",slug:"docker切换成containerd的使用影响",normalizedTitle:"docker切换成containerd的使用影响",charIndex:6947},{level:2,title:"镜像：",slug:"镜像",normalizedTitle:"镜像：",charIndex:6976},{level:2,title:"网络限制",slug:"网络限制",normalizedTitle:"网络限制",charIndex:7334},{level:2,title:"资源约束管理",slug:"资源约束管理",normalizedTitle:"资源约束管理",charIndex:7688},{level:2,title:"内存相关问题：",slug:"内存相关问题",normalizedTitle:"内存相关问题：",charIndex:7820},{level:2,title:"runc、runtime、docker、containerd、cri-o一些名词解释",slug:"runc、runtime、docker、containerd、cri-o一些名词解释",normalizedTitle:"runc、runtime、docker、containerd、cri-o一些名词解释",charIndex:7891},{level:2,title:"Sandbox与Container",slug:"sandbox与container",normalizedTitle:"sandbox与container",charIndex:8296},{level:2,title:"k8s和docker分道扬镳的故事(v1.23之后)",slug:"k8s和docker分道扬镳的故事-v1-23之后",normalizedTitle:"k8s和docker分道扬镳的故事(v1.23之后)",charIndex:8471},{level:2,title:"docker vs containerd",slug:"docker-vs-containerd",normalizedTitle:"docker vs containerd",charIndex:8948},{level:2,title:"Kata Containers 与 gVisor",slug:"kata-containers-与-gvisor",normalizedTitle:"kata containers 与 gvisor",charIndex:9332},{level:2,title:"runc容器的安全性（隔离）问题",slug:"runc容器的安全性-隔离-问题",normalizedTitle:"runc容器的安全性（隔离）问题",charIndex:9839},{level:2,title:"理想的多租户状态",slug:"理想的多租户状态",normalizedTitle:"理想的多租户状态",charIndex:10085},{level:2,title:"k8s的原生多租户解决方案",slug:"k8s的原生多租户解决方案",normalizedTitle:"k8s的原生多租户解决方案",charIndex:10328},{level:2,title:"kata vs container",slug:"kata-vs-container",normalizedTitle:"kata vs container",charIndex:10503},{level:2,title:"kata vs VM（openstack）",slug:"kata-vs-vm-openstack",normalizedTitle:"kata vs vm（openstack）",charIndex:10527},{level:2,title:"kata vs kubevirt",slug:"kata-vs-kubevirt",normalizedTitle:"kata vs kubevirt",charIndex:10555}],headersStr:"The speed of containers, the security of VMs 项目思路： 安全隔离 kata隔离效益 减少虚拟化开销 怎样接上容器的生态 和传统的runC的区别 使用场景 Kata Containers 2.x vs 1.x kata Runtime (shimv2) kata-agent 虚拟化技术 hypervisor qemu-system-x86_64 cgroup 客户机内核和镜像 网络和存储 CPU和内存 VSOCK kata monitor 技术要点总结 部署组件： 容器创建流程 环境要求： 对资源管理的一些影响 存储限制： 主机资源共享问题 Privileged containers docker切换成containerd的使用影响 镜像： 网络限制 资源约束管理 内存相关问题： runc、runtime、docker、containerd、cri-o一些名词解释 Sandbox与Container k8s和docker分道扬镳的故事(v1.23之后) docker vs containerd Kata Containers 与 gVisor runc容器的安全性（隔离）问题 理想的多租户状态 k8s的原生多租户解决方案 kata vs container kata vs VM（openstack） kata vs kubevirt",content:'# 安全容器-Kata containers\n\n安全容器4类方案：\n\n * 传统OS容器配合安全机制（runc + SELinux, AppArmor, … + rootless mode）\n * 用户态内核的容器（Google的gVisor）\n * Library OS（UniKernel、Nabla Containers）\n * 轻量虚拟化的容器（Kata Containers、Firecracker）。\n\nKata Containers项目来自于2017年12月合并的两个项目“IntelClear Containers”和“Hyper runV”，其目标是构建极其轻量级的VM，它们像容器一样执行，但提供工作负载隔离和添加虚拟机层的安全优势。\n\nKataContainers社区于2018年5月发布了第一版1.0。由于Kata容器运行时兼容OCI，它可以无缝地插入Docker引擎和任何其他容器管理平台，如Kubernetes和Open-Stack，只需简单地将RUNC替换为Kata-runtime。\n\nKata Containers 的本质就是一个精简后的轻量级虚拟机。\n\n\n# The speed of containers, the security of VMs\n\n安全体现在:\n\n在专用内核中运行，提供网络、I/O 和内存的隔离，并且可以利用硬件强制隔离和虚拟化 VT 扩展。\n\n容器体现在：\n\n兼容性上：支持OCI以及CRI接口，和容器一样操作。 性能上：启动速度达到百毫秒级，接近容器。 开销上：内存开销小，类似容器。 与Kubernetes和Docker无缝衔接，并且是runc的替代品 开源基础设施基金会下的开源治理项目 多架构支持：x86、ARM、IBM Power、IBM s/390x\n\n\n# 项目思路：\n\n 1. 操作系统本身的容器机制没办法解决安全性问题，需要一个隔离层；\n 2. 虚拟机是一个现成的隔离层，AWS这样的云服务已经让全世界相信，对户来说，"secure of VM" 是可以满足需求的；\n 3. 虚机里面只要有个内核，就可以支持 OCI 规范的语义，在内核上跑个 Linux 应用这并不太难实现；\n 4. 虚机可能不够快，阻碍了它在容器环境的应用，那么可不可以拥有 "speed of container" 呢？ 现在，如果最后一个问题可以解决，那么它就是我们要的“安全的容器”了——这就是 Kata Containers。\n\n\n# 安全隔离\n\n安全性问题90%以上可以归结为隔离性问题\n\n * Docker安全隔离问题\n\n * 在Kata Containers中，每个容器都有自己的轻量级虚拟机和小内核，通过硬件虚拟化提供容器隔离。\n\n\n# kata隔离效益\n\nkata 实际上是通过创建轻量级虚拟机实现容器之间的资源隔离，再在虚拟机中运行容器运行时，这样就使容器在专用内核中运行，提供网络，I / O和内存的隔离，并可以通过虚拟化VT扩展利用硬件强制隔离。\n\n传统的操作系统容器技术是内核进程管理的一个延伸，容器进程本身是一组关联的进程，对于宿主机的调度器来说是完全可见的，一个 Pod 里的所有容器或进程，同时也都被宿主机调度和管理。这就意味着，在有大量容器的环境下，宿主机内核的负担很重。而采纳安全容器之后，从宿主机上是看不到这些完整的信息的，隔离层同时也降低了宿主机的调度开销，减少了维护负担，避免了容器之间、容器和宿主机之间的服务质量干扰。\n\n安全容器作为一道屏障，可以让宿主机的运维管理操作不能直接访问到应用的数据，这样，把用户的应用数据直接保护在沙箱里就可以降低对用户的授权要求，保障用户的数据私密性。\n\n\n# 减少虚拟化开销\n\n * 通过“少用不必要的内存”和“共享能共享的内存”来降低内存的开销，更小的内存不仅开销更小，启动也更轻快\n\n * 最关键的性能优化来自Intel Clear Containers。\n\n * 最关键的优化其实就是VM的启动时间进行裁剪，优化。\n\n * 使用特定的Linux内核，使用简化的initrd以及rootfs。\n\n\n# 怎样接上容器的生态\n\nkata-containers它本质上就一个容器的runtime。只要实现了OCI的接口就可以接上那些容器管理工具，只要实现了CRI接口，就可以接上k8s。\n\n所以kata-containers与OCI运行时规范兼容，可以通过CRI-O和Containerd实现与 Kubernetes CRI进行无缝协作。（Shim API）\n\n\n# 和传统的runC的区别\n\n最大的区别就在于container是放在虚拟机里面运行的，中间多了一层kernel后，外面的容器管理软件就无法管理，监控里面的进程、容器，也无法和里面通信。 解决方案就是在VM里面放了一个agent，内外通过VSOCK通信，这样子内外就打通了。\n\n\n# 使用场景\n\n * 主要使用场景是在公有云模式\n\n * 裸金属基础设施\n\n * 混合工作负载生产环境\n\n * 监管和敏感的生产环境\n\n * 多租户容器集群\n\n * 具有内核相关功能的遗留的依赖内核的工作负载\n\n\n# 架构（Kata2.0）\n\narchitecture\n\n\n\n\n\n整个kata生态系统分为 3 部分：\n\n * 容器调度系统（如 K8s）\n * 上层 runtime，这一层主要是实现了 CRI 接口，然后使用下层 runtime 对容器进行管理。上层 runtime 典型代表有 containerd 和 CRI-O。\n * 下层 runtime，这一层才会直接负责容器的管理，典型代表为 runc 和 Kata Containers。\n\n对 Kata Containers 来说，Kata Containers 会接收来自上层 runtime 的请求，实现容器的创建、删除等管理工作。\n\n同时，上图中也有 3 个通信协议存在：\n\n * CRI： 容器运行时接口，这是 k8s（实际上是 kubelet）和 上层 runtime 之间的通信接口\n * shim v2：上层 runtime （如 containerd ）和 下层 runtime（如 Kata Containers ） 之间的通信接口\n * agent 协议：这是 Kata Containers 内部的协议，用于 Kata Containers 的 shim 进程和 guest 内的 agent 之间的通信。\n\n\n# Kata Containers 2.x vs 1.x\n\n2.x 在开发上主要有以下几个重大的变更点：\n\n * agent 使用 Rust 重写\n\n * 只支持 shimv2，因此少了 proxy 和 shim 组件, shimv2 提供了 Containerd Runtime V2 (Shim API) 的 Kata 实现，从而使得 Kubernetes 场景下能够实现每个 Pod 一个 shim 进程 – shimv2。\n\n * 在 Kata Containers 2.x 中，核心组件只剩下两个：runtime 和agent ，且都在 kata-containers 这个 repo 下。\n\n在kata1.x， kata-container可以当做docker的一个插件，启动kata-container可以通过docker命令，但是kata2.x之后，kata去掉了docker的cli，不能通过docker启动kata runtime容器。\n\n在 Kata 1.x 中，面向用户的主要组件是运行时（kata-runtime）。对于 Kata 2.0，主要组件是 Kata containerd shim v2。 对“ Kata 运行时”的任何提及均应指代 Kata containerd shim v2。\n\n\n# kata Runtime (shimv2)\n\nruntime 为运行在宿主机上的、支持 shim v2 协议的进程。在这系列文章中，多数情况下可以将 runtime 、shimv2 视为同一内容。\n\n整个 Runtime ，其可执行程序为 containerd-shim-kata-v2，也即 shim 进程，这也是 Kata Containers 的入口点。Runtime 对上接受 containerd 的请求（通过 shimv2 “协议”），对 guest 来说，通过 guest 内的 agent 来控制 guest 内容器的创建、删除等管理。\n\nRuntime 和 agent 之间的采用了 ttrpc 协议通信，这是一个使用了 protocol buffer 编解码方式的类似 gRPC 的通信方式。该协议由 containerd 创建，用于 containered 和底层 runtime 之间的通信。在 Kata Containers 中， runtime 和 agent 也通过 ttrpc 通信。\n\nhttp://liubin.org/kata-dev-book/src/runtime-arch.html\n\n\n# kata-agent\n\nagent 可以作为 guest init 进程启动，也可以使用 systemd 等作为 init ，agent 作为普通进程启动。 http://liubin.org/kata-dev-book/src/agent-arch.html\n\nhttps://github.com/kata-containers/kata-containers/tree/main/src/agent\n\n\n# 虚拟化技术\n\nkata sanbox/vm的接口 在虚拟机中，我们需要提供以下virtio设备：(qemu)\n\n * 存储(virtio-fs)\n * 网络(tap): 基于性能考虑，qemu默认为vhost-net作为virtio-net 后端，默认配置还在评估中。\n * 控制（virtio-vsock）\n * 设备驱动（vfio）:设备直通\n * 动态资源管理(acpi): CPU、内存和设备热插拔\n\n\n# hypervisor\n\nKata Containers 支持多个ypervisor\n\n * QEMU 是一个成熟而复杂的管理程序。\n\n * Firecracker 是AWS 为无服务器场景开发的轻量级hypervisor。它只支持有限的虚拟设备。\n\n * Cloud-Hypervisor 是英特尔针对云原生场景设计的另一款轻量级hypervisor。\n\n * ACRN 是针对边缘场景开发的hypervisor。\n\n[root@localhost ~]#  kata-runtime kata-env | awk -v RS= \'/\\[Hypervisor\\]/\' | grep Path\n  Path = "/opt/kata/bin/qemu-system-x86_64"\n\n\n1\n2\n\n\n# qemu-system-x86_64\n\n\n# cgroup\n\n[[kata cgroup]]\n\n\n# 客户机内核和镜像\n\n[[guest kernel和guestos]]\n\n\n# 网络和存储\n\n[[kata网络和存储文件系统分析]]\n\n\n# CPU和内存\n\n[[kata CPU和内存]]\n\n\n# VSOCK\n\nVsock\n\n\n# kata monitor\n\n[[kata-monitor监控指标]]\n\n\n# 技术要点总结\n\n * VM作为安全沙箱\n\n * 支持多种虚拟化方案，qemu、firecracker、cloud-hypervisor等\n\n * vm中agent负责直接创建、更新、销毁容器\n\n * 使用vsock作为shim v2进程与agent的通信信道\n\n * 使用tc规则/macvtap连接veth和tap，来打通CNI和VM网络\n\n * 通过virtio-9p、virtio-fs将host上镜像挂载到vm中\n\n * 通过块设备透传，将host上块设备作为容器rootfs\n\n主要解决的问题：现有容器网络模型与现有虚拟机网络模型不匹配的问题，将CNI网络和虚机网络对接weth和tap连通方案：\n\n 1. tcfilter：使用tc rules将veth的ingress和egress队列分别对接tap的egress和ingress队列实现veth和tap的直连\n\n 2. macvtap：现有虚拟网卡连通技术\n\n\n# 部署组件：\n\n部署在主机上的：\n\n * cloud-hypervisor, firecracker, qemu, 和支持的二进制文件\n\n * containerd-shim-kata-v2\n\n * kata-collect-data.sh\n\n * kata-runtime\n\n镜像:\n\n * kata-containers.img和kata-containers-initrd.img：从 Kata GitHub 发布页面中提取\n\n * vmlinuz.container和vmlinuz-virtiofs.container：从 Kata GitHub 发布页面中提取\n\n\n# 容器创建流程\n\n * 用户创建容器\n\n * 容器管理器（containerd）创建kata runtime\n\n * kata-runtime加载配置文件，调用shimv2 API\n\n * kata-runtime运行hypervisor\n\n * hypervisor创建和开启虚拟机VM（创建容器根环境rootfs）\n\n * proxy作为 VM 引导的一部分启动\n\n * 运行时调用proxy的CreateSandboxAPI 请求proxy创建容器\n\n * 容器管理器将容器的控制权返回给运行ctr命令的用户\n\n[[一个kata容器的创建示例]]\n\n\n# 限制与约束:\n\n参考资料：\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/Limitations.md\n\n\n# 环境要求：\n\n * Kata Containers 需要嵌套虚拟化或裸机\n\n * 不支持k8s使用docker运行时，需要切换成containerd或cri-o\n\n\n# 对资源管理的一些影响\n\n * 无法进行container级别的控制 首先虚拟机本身就是host上的一个进程，仍然受host上的cgroup控制。所以仍然可以监控整个pod的资源使用数据，并控制pod的资源使用。 但是我们无法拿到container级别的数据，也无法直接通过host的cgroup来控制pod里面container的资源使用。\n\n * 虚拟化技术的一些影响\n\n * 虚拟化的overhead\n\n\n# 存储限制：\n\nKata 不支持 k8s subPath (emptydir?)\n\nhttps://github.com/kata-containers/runtime/issues/2812\n\nhttps://github.com/kata-containers/kata-containers/issues/1728\n\n实测configmap没有问题，可能只对于emptydir使用有问题?\n\n\n# 主机资源共享问题\n\nRUNC可以启动一个容器以特权模式访问主机设备，而Kata-runtime也支持此选项，但在这种情况下，获得对客户VM设备的完全访问。尽管这个选项被视为一种限制，但从安全性的角度来看，它确实是一种优势，因为在容器的根升级的情况下，不会毒害主机内核。\n\n\n# Privileged containers\n\nhttps://github.com/kata-containers/documentation/blob/master/Limitations.md#docker-run---privileged\n\nhttps://github.com/kata-containers/runtime/issues/1568\n\nhttps://github.com/kata-containers/documentation/blob/master/how-to/privileged.md\n\nrunc Kata 中的特权支持与容器有本质的不同。容器在来宾中以提升的功能运行，并被授予访问用户设备而不是主机设备的权限。securityContext privileged=true与 Kubernetes一起使用也是如此。\n\n在 runc 中，“--privileged”会将主机 dev 的功能转换为容器。\n\n在 Kata 中，“--privileged”意味着 Kata VM 中的容器可以访问 Kata guest VM 中的所有设备。\n\n\n# docker切换成containerd的使用影响\n\n\n# 镜像：\n\n * 镜像不复用：\n\ncontainerd采用自己的方式管理容器镜像，不能公用docker已有镜像，并且containerd镜像使用了命名空间进行了隔离，cri默认命名空间是k8s.io，containerd默认存储命名空间是default。\n\n * 镜像构建\n\n切换到 containerd 之后，需要注意 docker.sock 不再可用，也就意味着不能再在容器里面执行 docker 命令来构建镜像了，docker build 构建镜像的应用需要切换到无需 Dockerd 就可以构建镜像的工具，如 docker buildx、buildah、kaniko\n\n * 日志配置\n\ndocker 和 containerd 除了在常用命令上有些区别外，在容器日志及相关参数配置方面也存在一些差异。\n\n\n# 网络限制\n\n * kata不支持host网络\n\n一些使用主机网络的k8s组件和应用无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。\n\n * Kata Containers 不支持网络命名空间共享\n\nDocker 支持容器使用docker run --net=containers语法加入另一个容器命名空间的能力。这允许多个容器共享一个公共网络命名空间和放置在网络命名空间中的网络接口。Kata Containers 不支持网络命名空间共享。如果将 Kata 容器设置为共享runc容器的网络命名空间，则运行时会有效地接管分配给命名空间的所有网络接口并将它们绑定到 VM。因此，runc容器失去其网络连接。\n\n\n# 资源约束管理\n\nRUNC只使用控制组(cgroups)来限制、优先化、控制和计算资源，而对于kat-runtime，由于双安全层，为了得到相同的结果，可能有必要将约束应用到多个级别。因此，资源约束管理在RUNC中是粗粒度的，而在kata运行时是细粒度的。\n\n\n# 内存相关问题：\n\n虚拟机也应用了一些内存管理技术：KSM，balloon，这些可能也会对内存管理有一些影响。\n\n\n# 一些知识扩展：\n\n\n# runc、runtime、docker、containerd、cri-o一些名词解释\n\nrunC是一个根据OCI标准创建并运行容器的命令行工具（CLI tool）(low-level runtime)。\n\nDocker就是基于runC创建的，简单地说，runC就是docker中最为核心的部分\n\ncontainerd是容器技术标准化之后的产物，为了能够兼容OCI标准，将容器运行时及其管理功能从Docker Daemon剥离。理论上，即使不运行dockerd，也能够直接通过containerd来管理容器。（当然，containerd本身也只是一个守护进程，容器的实际运行时由后面介绍的runC控制。）\n\nKubelet 是一个CRI客户端，并期望CRI实现来处理接口的服务端。CRI-O和Containerd是依赖OCI兼容运行时来管理容器实例的CRI实现（high level runtime）。\n\n\n# Sandbox与Container\n\nSandbox是一个统一、基本的隔离空间，一个虚拟机中只有一个Sandbox，但是该Sandbox内可以有多个容器，这就对应了Kubernetes Pod的模型；对于Docker来说，一般一个Sandbox内只运行一个Container。无论是哪种情况，Sandbox的ID与内部第一个容器的ID相同。\n\n\n# k8s和docker分道扬镳的故事(v1.23之后)\n\nhttps://github.com/kubernetes/kubernetes/blob/master/CHANGELOG/CHANGELOG-1.20.md#dockershim-deprecation\n\nhttps://kubernetes.io/zh/blog/2020/12/02/dont-panic-kubernetes-and-docker/\n\ndocker是一个完整的技术堆栈，是一个用户友好的抽象层，但是，对于k8s来说，并不是设计用来嵌入到 Kubernetes的（非CRI容器运行时接口），实际上k8s需要的是containerd（docker中的一个高级运行时功能），由于Docker 不兼容 CRI，Kubernetes 集群不得不引入一个叫做 Dockershim 的工具来访问它真正需要的 containerd。（增加运维成本，容易出错）。\n\n于是k8s决定不再支持Dockershim，用户应该将容器运行时从 Docker 切换到其他受支持的容器运行时。\n\n\n# docker vs containerd\n\ndocker由 docker-client ,dockerd,containerd,docker-shim,runc组成，所以containerd是docker的基础组件之一\n\n从k8s的角度看，可以选择 containerd 或 docker 作为运行时组件：Containerd 调用链更短，组件更少，更稳定，占用节点资源更少\n\n调用链\n\nDocker 作为 k8s 容器运行时，调用关系如下：\n\nkubelet --\x3e docker shim （在 kubelet 进程中） --\x3e dockerd --\x3e containerd\n\nContainerd 作为 k8s 容器运行时，调用关系如下：\n\nkubelet --\x3e cri plugin（在 containerd 进程中） --\x3e containerd\n\n\n# Kata Containers 与 gVisor\n\n在2018年，Google 公司则发布了一个名叫 gVisor 的项目。gVisor 项目给容器进程配置一个用 Go 语言实现的、运行在用户态的、极小的“独立内核”。这个内核对容器进程暴露 Linux 内核 ABI，扮演着“Guest Kernel”的角色，从而达到了将容器和宿主机隔离开的目的。\n\nkata和gvisor的本质，都是给进程分配了一个独立的操作系统内核，从而避免了让容器共享宿主机的内核。这样，容器进程能够看到的攻击面，就从整个宿主机内核变成了一个极小的、独立的、以容器为单位的内核，从而有效解决了容器进程发生“逃逸”或者夺取整个宿主机的控制权的问题。\n\n而它们的区别在于，Kata Containers 使用的是传统的虚拟化技术，通过虚拟硬件模拟出了一台“小虚拟机”，然后在这个小虚拟机里安装了一个裁剪后的 Linux 内核来实现强隔离。\n\n而 gVisor 的做法则更加激进，Google 的工程师直接用 Go 语言“模拟”出了一个运行在用户态的操作系统内核，然后通过这个模拟的内核来代替容器进程向宿主机发起有限的、可控的系统调用。\n\n\n# runc容器的安全性（隔离）问题\n\nDocker的安全问题本质上就是容器技术的安全性问题：基于软件隔离，这包括共用内核问题以及Namespace还不够完善的限制：\n\n 1. /proc、/sys等未完全隔离\n 2. Top, free, iostat等命令展示的信息未隔离\n 3. Root用户未隔离\n 4. /dev设备未隔离\n 5. 内核模块未隔离\n 6. SELinux、time、syslog等所有现有Namespace之外的信息都未隔离 镜像本身不安全也会导致安全性问题。\n\n\n# 理想的多租户状态\n\n理想来说，平台的各个租户（tenant）之间应该无法感受到彼此的存在，表现得就像每个租户独占整个平台一样。具体来说就是，我不能看到其它租户的资源，我的资源跑满了，也不能影响其它租户的资源使用。我无法从网络或内核上其它租户。\n\nKubernetes 当然做不到，其中最大的两个原因是：\n\n * kube-apiserver 是整个集群中的单例，并且没有多租户概念；\n\n * 默认的 oci-runtime 是 runc，而 runc 启动的容器是共享内核的。\n\n\n# k8s的原生多租户解决方案\n\n * 命名空间隔离√\n * RBAC权限管理√\n * 资源配额ResourceQuota√\n * Pod Security Policy\n * pod调度：绑定节点、污点容忍√\n * 网络策略限制√\n * 服务网格：Istio√\n * StorageClass存储资源隔离（感觉意义不大）\n * 多集群隔离管理\n\n\n# kata vs container\n\n\n\n\n# kata vs VM（openstack）\n\n\n\n\n# kata vs kubevirt\n\n * (kata)：在虚拟机内使用容器：可以创建一个包含多个容器的应用，并且都在虚拟机内运行；可以同时在多个虚拟机上创建/销毁容器，而虚拟机则可在使用现有虚拟机基础设施在物理服务器之间迁移。\n * (kubevirt)：在容器内使用虚拟机：利用资源管理技术；利用构建和部署工具\n * Kubevirt是借用Kubernetes的扩展性来管理VM（通过CRD管理虚拟机），你用到的是一个真正的VM；\n * KubeVirt旨在提供尽可能多的虚拟机功能\n * Kata-container是一个容器运行时，有着VM的安全性和隔离性，以容器的方式运行，有着容器的速度和特点，但不是一个真正的VM；Kata容器则试图为虚拟机提供类似容器的体验\n * Virtlet是把VM当成一个CRI来跑了，是按Pod API来定义一个VM，所以VM的很多功能比如热迁移等，Virtlet是没法满足VM的全部特性的，算是一个70%功能的VM\n\n\n# 参考资料\n\nhttps://github.com/kata-containers',normalizedContent:'# 安全容器-kata containers\n\n安全容器4类方案：\n\n * 传统os容器配合安全机制（runc + selinux, apparmor, … + rootless mode）\n * 用户态内核的容器（google的gvisor）\n * library os（unikernel、nabla containers）\n * 轻量虚拟化的容器（kata containers、firecracker）。\n\nkata containers项目来自于2017年12月合并的两个项目“intelclear containers”和“hyper runv”，其目标是构建极其轻量级的vm，它们像容器一样执行，但提供工作负载隔离和添加虚拟机层的安全优势。\n\nkatacontainers社区于2018年5月发布了第一版1.0。由于kata容器运行时兼容oci，它可以无缝地插入docker引擎和任何其他容器管理平台，如kubernetes和open-stack，只需简单地将runc替换为kata-runtime。\n\nkata containers 的本质就是一个精简后的轻量级虚拟机。\n\n\n# the speed of containers, the security of vms\n\n安全体现在:\n\n在专用内核中运行，提供网络、i/o 和内存的隔离，并且可以利用硬件强制隔离和虚拟化 vt 扩展。\n\n容器体现在：\n\n兼容性上：支持oci以及cri接口，和容器一样操作。 性能上：启动速度达到百毫秒级，接近容器。 开销上：内存开销小，类似容器。 与kubernetes和docker无缝衔接，并且是runc的替代品 开源基础设施基金会下的开源治理项目 多架构支持：x86、arm、ibm power、ibm s/390x\n\n\n# 项目思路：\n\n 1. 操作系统本身的容器机制没办法解决安全性问题，需要一个隔离层；\n 2. 虚拟机是一个现成的隔离层，aws这样的云服务已经让全世界相信，对户来说，"secure of vm" 是可以满足需求的；\n 3. 虚机里面只要有个内核，就可以支持 oci 规范的语义，在内核上跑个 linux 应用这并不太难实现；\n 4. 虚机可能不够快，阻碍了它在容器环境的应用，那么可不可以拥有 "speed of container" 呢？ 现在，如果最后一个问题可以解决，那么它就是我们要的“安全的容器”了——这就是 kata containers。\n\n\n# 安全隔离\n\n安全性问题90%以上可以归结为隔离性问题\n\n * docker安全隔离问题\n\n * 在kata containers中，每个容器都有自己的轻量级虚拟机和小内核，通过硬件虚拟化提供容器隔离。\n\n\n# kata隔离效益\n\nkata 实际上是通过创建轻量级虚拟机实现容器之间的资源隔离，再在虚拟机中运行容器运行时，这样就使容器在专用内核中运行，提供网络，i / o和内存的隔离，并可以通过虚拟化vt扩展利用硬件强制隔离。\n\n传统的操作系统容器技术是内核进程管理的一个延伸，容器进程本身是一组关联的进程，对于宿主机的调度器来说是完全可见的，一个 pod 里的所有容器或进程，同时也都被宿主机调度和管理。这就意味着，在有大量容器的环境下，宿主机内核的负担很重。而采纳安全容器之后，从宿主机上是看不到这些完整的信息的，隔离层同时也降低了宿主机的调度开销，减少了维护负担，避免了容器之间、容器和宿主机之间的服务质量干扰。\n\n安全容器作为一道屏障，可以让宿主机的运维管理操作不能直接访问到应用的数据，这样，把用户的应用数据直接保护在沙箱里就可以降低对用户的授权要求，保障用户的数据私密性。\n\n\n# 减少虚拟化开销\n\n * 通过“少用不必要的内存”和“共享能共享的内存”来降低内存的开销，更小的内存不仅开销更小，启动也更轻快\n\n * 最关键的性能优化来自intel clear containers。\n\n * 最关键的优化其实就是vm的启动时间进行裁剪，优化。\n\n * 使用特定的linux内核，使用简化的initrd以及rootfs。\n\n\n# 怎样接上容器的生态\n\nkata-containers它本质上就一个容器的runtime。只要实现了oci的接口就可以接上那些容器管理工具，只要实现了cri接口，就可以接上k8s。\n\n所以kata-containers与oci运行时规范兼容，可以通过cri-o和containerd实现与 kubernetes cri进行无缝协作。（shim api）\n\n\n# 和传统的runc的区别\n\n最大的区别就在于container是放在虚拟机里面运行的，中间多了一层kernel后，外面的容器管理软件就无法管理，监控里面的进程、容器，也无法和里面通信。 解决方案就是在vm里面放了一个agent，内外通过vsock通信，这样子内外就打通了。\n\n\n# 使用场景\n\n * 主要使用场景是在公有云模式\n\n * 裸金属基础设施\n\n * 混合工作负载生产环境\n\n * 监管和敏感的生产环境\n\n * 多租户容器集群\n\n * 具有内核相关功能的遗留的依赖内核的工作负载\n\n\n# 架构（kata2.0）\n\narchitecture\n\n\n\n\n\n整个kata生态系统分为 3 部分：\n\n * 容器调度系统（如 k8s）\n * 上层 runtime，这一层主要是实现了 cri 接口，然后使用下层 runtime 对容器进行管理。上层 runtime 典型代表有 containerd 和 cri-o。\n * 下层 runtime，这一层才会直接负责容器的管理，典型代表为 runc 和 kata containers。\n\n对 kata containers 来说，kata containers 会接收来自上层 runtime 的请求，实现容器的创建、删除等管理工作。\n\n同时，上图中也有 3 个通信协议存在：\n\n * cri： 容器运行时接口，这是 k8s（实际上是 kubelet）和 上层 runtime 之间的通信接口\n * shim v2：上层 runtime （如 containerd ）和 下层 runtime（如 kata containers ） 之间的通信接口\n * agent 协议：这是 kata containers 内部的协议，用于 kata containers 的 shim 进程和 guest 内的 agent 之间的通信。\n\n\n# kata containers 2.x vs 1.x\n\n2.x 在开发上主要有以下几个重大的变更点：\n\n * agent 使用 rust 重写\n\n * 只支持 shimv2，因此少了 proxy 和 shim 组件, shimv2 提供了 containerd runtime v2 (shim api) 的 kata 实现，从而使得 kubernetes 场景下能够实现每个 pod 一个 shim 进程 – shimv2。\n\n * 在 kata containers 2.x 中，核心组件只剩下两个：runtime 和agent ，且都在 kata-containers 这个 repo 下。\n\n在kata1.x， kata-container可以当做docker的一个插件，启动kata-container可以通过docker命令，但是kata2.x之后，kata去掉了docker的cli，不能通过docker启动kata runtime容器。\n\n在 kata 1.x 中，面向用户的主要组件是运行时（kata-runtime）。对于 kata 2.0，主要组件是 kata containerd shim v2。 对“ kata 运行时”的任何提及均应指代 kata containerd shim v2。\n\n\n# kata runtime (shimv2)\n\nruntime 为运行在宿主机上的、支持 shim v2 协议的进程。在这系列文章中，多数情况下可以将 runtime 、shimv2 视为同一内容。\n\n整个 runtime ，其可执行程序为 containerd-shim-kata-v2，也即 shim 进程，这也是 kata containers 的入口点。runtime 对上接受 containerd 的请求（通过 shimv2 “协议”），对 guest 来说，通过 guest 内的 agent 来控制 guest 内容器的创建、删除等管理。\n\nruntime 和 agent 之间的采用了 ttrpc 协议通信，这是一个使用了 protocol buffer 编解码方式的类似 grpc 的通信方式。该协议由 containerd 创建，用于 containered 和底层 runtime 之间的通信。在 kata containers 中， runtime 和 agent 也通过 ttrpc 通信。\n\nhttp://liubin.org/kata-dev-book/src/runtime-arch.html\n\n\n# kata-agent\n\nagent 可以作为 guest init 进程启动，也可以使用 systemd 等作为 init ，agent 作为普通进程启动。 http://liubin.org/kata-dev-book/src/agent-arch.html\n\nhttps://github.com/kata-containers/kata-containers/tree/main/src/agent\n\n\n# 虚拟化技术\n\nkata sanbox/vm的接口 在虚拟机中，我们需要提供以下virtio设备：(qemu)\n\n * 存储(virtio-fs)\n * 网络(tap): 基于性能考虑，qemu默认为vhost-net作为virtio-net 后端，默认配置还在评估中。\n * 控制（virtio-vsock）\n * 设备驱动（vfio）:设备直通\n * 动态资源管理(acpi): cpu、内存和设备热插拔\n\n\n# hypervisor\n\nkata containers 支持多个ypervisor\n\n * qemu 是一个成熟而复杂的管理程序。\n\n * firecracker 是aws 为无服务器场景开发的轻量级hypervisor。它只支持有限的虚拟设备。\n\n * cloud-hypervisor 是英特尔针对云原生场景设计的另一款轻量级hypervisor。\n\n * acrn 是针对边缘场景开发的hypervisor。\n\n[root@localhost ~]#  kata-runtime kata-env | awk -v rs= \'/\\[hypervisor\\]/\' | grep path\n  path = "/opt/kata/bin/qemu-system-x86_64"\n\n\n1\n2\n\n\n# qemu-system-x86_64\n\n\n# cgroup\n\n[[kata cgroup]]\n\n\n# 客户机内核和镜像\n\n[[guest kernel和guestos]]\n\n\n# 网络和存储\n\n[[kata网络和存储文件系统分析]]\n\n\n# cpu和内存\n\n[[kata cpu和内存]]\n\n\n# vsock\n\nvsock\n\n\n# kata monitor\n\n[[kata-monitor监控指标]]\n\n\n# 技术要点总结\n\n * vm作为安全沙箱\n\n * 支持多种虚拟化方案，qemu、firecracker、cloud-hypervisor等\n\n * vm中agent负责直接创建、更新、销毁容器\n\n * 使用vsock作为shim v2进程与agent的通信信道\n\n * 使用tc规则/macvtap连接veth和tap，来打通cni和vm网络\n\n * 通过virtio-9p、virtio-fs将host上镜像挂载到vm中\n\n * 通过块设备透传，将host上块设备作为容器rootfs\n\n主要解决的问题：现有容器网络模型与现有虚拟机网络模型不匹配的问题，将cni网络和虚机网络对接weth和tap连通方案：\n\n 1. tcfilter：使用tc rules将veth的ingress和egress队列分别对接tap的egress和ingress队列实现veth和tap的直连\n\n 2. macvtap：现有虚拟网卡连通技术\n\n\n# 部署组件：\n\n部署在主机上的：\n\n * cloud-hypervisor, firecracker, qemu, 和支持的二进制文件\n\n * containerd-shim-kata-v2\n\n * kata-collect-data.sh\n\n * kata-runtime\n\n镜像:\n\n * kata-containers.img和kata-containers-initrd.img：从 kata github 发布页面中提取\n\n * vmlinuz.container和vmlinuz-virtiofs.container：从 kata github 发布页面中提取\n\n\n# 容器创建流程\n\n * 用户创建容器\n\n * 容器管理器（containerd）创建kata runtime\n\n * kata-runtime加载配置文件，调用shimv2 api\n\n * kata-runtime运行hypervisor\n\n * hypervisor创建和开启虚拟机vm（创建容器根环境rootfs）\n\n * proxy作为 vm 引导的一部分启动\n\n * 运行时调用proxy的createsandboxapi 请求proxy创建容器\n\n * 容器管理器将容器的控制权返回给运行ctr命令的用户\n\n[[一个kata容器的创建示例]]\n\n\n# 限制与约束:\n\n参考资料：\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/limitations.md\n\n\n# 环境要求：\n\n * kata containers 需要嵌套虚拟化或裸机\n\n * 不支持k8s使用docker运行时，需要切换成containerd或cri-o\n\n\n# 对资源管理的一些影响\n\n * 无法进行container级别的控制 首先虚拟机本身就是host上的一个进程，仍然受host上的cgroup控制。所以仍然可以监控整个pod的资源使用数据，并控制pod的资源使用。 但是我们无法拿到container级别的数据，也无法直接通过host的cgroup来控制pod里面container的资源使用。\n\n * 虚拟化技术的一些影响\n\n * 虚拟化的overhead\n\n\n# 存储限制：\n\nkata 不支持 k8s subpath (emptydir?)\n\nhttps://github.com/kata-containers/runtime/issues/2812\n\nhttps://github.com/kata-containers/kata-containers/issues/1728\n\n实测configmap没有问题，可能只对于emptydir使用有问题?\n\n\n# 主机资源共享问题\n\nrunc可以启动一个容器以特权模式访问主机设备，而kata-runtime也支持此选项，但在这种情况下，获得对客户vm设备的完全访问。尽管这个选项被视为一种限制，但从安全性的角度来看，它确实是一种优势，因为在容器的根升级的情况下，不会毒害主机内核。\n\n\n# privileged containers\n\nhttps://github.com/kata-containers/documentation/blob/master/limitations.md#docker-run---privileged\n\nhttps://github.com/kata-containers/runtime/issues/1568\n\nhttps://github.com/kata-containers/documentation/blob/master/how-to/privileged.md\n\nrunc kata 中的特权支持与容器有本质的不同。容器在来宾中以提升的功能运行，并被授予访问用户设备而不是主机设备的权限。securitycontext privileged=true与 kubernetes一起使用也是如此。\n\n在 runc 中，“--privileged”会将主机 dev 的功能转换为容器。\n\n在 kata 中，“--privileged”意味着 kata vm 中的容器可以访问 kata guest vm 中的所有设备。\n\n\n# docker切换成containerd的使用影响\n\n\n# 镜像：\n\n * 镜像不复用：\n\ncontainerd采用自己的方式管理容器镜像，不能公用docker已有镜像，并且containerd镜像使用了命名空间进行了隔离，cri默认命名空间是k8s.io，containerd默认存储命名空间是default。\n\n * 镜像构建\n\n切换到 containerd 之后，需要注意 docker.sock 不再可用，也就意味着不能再在容器里面执行 docker 命令来构建镜像了，docker build 构建镜像的应用需要切换到无需 dockerd 就可以构建镜像的工具，如 docker buildx、buildah、kaniko\n\n * 日志配置\n\ndocker 和 containerd 除了在常用命令上有些区别外，在容器日志及相关参数配置方面也存在一些差异。\n\n\n# 网络限制\n\n * kata不支持host网络\n\n一些使用主机网络的k8s组件和应用无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。\n\n * kata containers 不支持网络命名空间共享\n\ndocker 支持容器使用docker run --net=containers语法加入另一个容器命名空间的能力。这允许多个容器共享一个公共网络命名空间和放置在网络命名空间中的网络接口。kata containers 不支持网络命名空间共享。如果将 kata 容器设置为共享runc容器的网络命名空间，则运行时会有效地接管分配给命名空间的所有网络接口并将它们绑定到 vm。因此，runc容器失去其网络连接。\n\n\n# 资源约束管理\n\nrunc只使用控制组(cgroups)来限制、优先化、控制和计算资源，而对于kat-runtime，由于双安全层，为了得到相同的结果，可能有必要将约束应用到多个级别。因此，资源约束管理在runc中是粗粒度的，而在kata运行时是细粒度的。\n\n\n# 内存相关问题：\n\n虚拟机也应用了一些内存管理技术：ksm，balloon，这些可能也会对内存管理有一些影响。\n\n\n# 一些知识扩展：\n\n\n# runc、runtime、docker、containerd、cri-o一些名词解释\n\nrunc是一个根据oci标准创建并运行容器的命令行工具（cli tool）(low-level runtime)。\n\ndocker就是基于runc创建的，简单地说，runc就是docker中最为核心的部分\n\ncontainerd是容器技术标准化之后的产物，为了能够兼容oci标准，将容器运行时及其管理功能从docker daemon剥离。理论上，即使不运行dockerd，也能够直接通过containerd来管理容器。（当然，containerd本身也只是一个守护进程，容器的实际运行时由后面介绍的runc控制。）\n\nkubelet 是一个cri客户端，并期望cri实现来处理接口的服务端。cri-o和containerd是依赖oci兼容运行时来管理容器实例的cri实现（high level runtime）。\n\n\n# sandbox与container\n\nsandbox是一个统一、基本的隔离空间，一个虚拟机中只有一个sandbox，但是该sandbox内可以有多个容器，这就对应了kubernetes pod的模型；对于docker来说，一般一个sandbox内只运行一个container。无论是哪种情况，sandbox的id与内部第一个容器的id相同。\n\n\n# k8s和docker分道扬镳的故事(v1.23之后)\n\nhttps://github.com/kubernetes/kubernetes/blob/master/changelog/changelog-1.20.md#dockershim-deprecation\n\nhttps://kubernetes.io/zh/blog/2020/12/02/dont-panic-kubernetes-and-docker/\n\ndocker是一个完整的技术堆栈，是一个用户友好的抽象层，但是，对于k8s来说，并不是设计用来嵌入到 kubernetes的（非cri容器运行时接口），实际上k8s需要的是containerd（docker中的一个高级运行时功能），由于docker 不兼容 cri，kubernetes 集群不得不引入一个叫做 dockershim 的工具来访问它真正需要的 containerd。（增加运维成本，容易出错）。\n\n于是k8s决定不再支持dockershim，用户应该将容器运行时从 docker 切换到其他受支持的容器运行时。\n\n\n# docker vs containerd\n\ndocker由 docker-client ,dockerd,containerd,docker-shim,runc组成，所以containerd是docker的基础组件之一\n\n从k8s的角度看，可以选择 containerd 或 docker 作为运行时组件：containerd 调用链更短，组件更少，更稳定，占用节点资源更少\n\n调用链\n\ndocker 作为 k8s 容器运行时，调用关系如下：\n\nkubelet --\x3e docker shim （在 kubelet 进程中） --\x3e dockerd --\x3e containerd\n\ncontainerd 作为 k8s 容器运行时，调用关系如下：\n\nkubelet --\x3e cri plugin（在 containerd 进程中） --\x3e containerd\n\n\n# kata containers 与 gvisor\n\n在2018年，google 公司则发布了一个名叫 gvisor 的项目。gvisor 项目给容器进程配置一个用 go 语言实现的、运行在用户态的、极小的“独立内核”。这个内核对容器进程暴露 linux 内核 abi，扮演着“guest kernel”的角色，从而达到了将容器和宿主机隔离开的目的。\n\nkata和gvisor的本质，都是给进程分配了一个独立的操作系统内核，从而避免了让容器共享宿主机的内核。这样，容器进程能够看到的攻击面，就从整个宿主机内核变成了一个极小的、独立的、以容器为单位的内核，从而有效解决了容器进程发生“逃逸”或者夺取整个宿主机的控制权的问题。\n\n而它们的区别在于，kata containers 使用的是传统的虚拟化技术，通过虚拟硬件模拟出了一台“小虚拟机”，然后在这个小虚拟机里安装了一个裁剪后的 linux 内核来实现强隔离。\n\n而 gvisor 的做法则更加激进，google 的工程师直接用 go 语言“模拟”出了一个运行在用户态的操作系统内核，然后通过这个模拟的内核来代替容器进程向宿主机发起有限的、可控的系统调用。\n\n\n# runc容器的安全性（隔离）问题\n\ndocker的安全问题本质上就是容器技术的安全性问题：基于软件隔离，这包括共用内核问题以及namespace还不够完善的限制：\n\n 1. /proc、/sys等未完全隔离\n 2. top, free, iostat等命令展示的信息未隔离\n 3. root用户未隔离\n 4. /dev设备未隔离\n 5. 内核模块未隔离\n 6. selinux、time、syslog等所有现有namespace之外的信息都未隔离 镜像本身不安全也会导致安全性问题。\n\n\n# 理想的多租户状态\n\n理想来说，平台的各个租户（tenant）之间应该无法感受到彼此的存在，表现得就像每个租户独占整个平台一样。具体来说就是，我不能看到其它租户的资源，我的资源跑满了，也不能影响其它租户的资源使用。我无法从网络或内核上其它租户。\n\nkubernetes 当然做不到，其中最大的两个原因是：\n\n * kube-apiserver 是整个集群中的单例，并且没有多租户概念；\n\n * 默认的 oci-runtime 是 runc，而 runc 启动的容器是共享内核的。\n\n\n# k8s的原生多租户解决方案\n\n * 命名空间隔离√\n * rbac权限管理√\n * 资源配额resourcequota√\n * pod security policy\n * pod调度：绑定节点、污点容忍√\n * 网络策略限制√\n * 服务网格：istio√\n * storageclass存储资源隔离（感觉意义不大）\n * 多集群隔离管理\n\n\n# kata vs container\n\n\n\n\n# kata vs vm（openstack）\n\n\n\n\n# kata vs kubevirt\n\n * (kata)：在虚拟机内使用容器：可以创建一个包含多个容器的应用，并且都在虚拟机内运行；可以同时在多个虚拟机上创建/销毁容器，而虚拟机则可在使用现有虚拟机基础设施在物理服务器之间迁移。\n * (kubevirt)：在容器内使用虚拟机：利用资源管理技术；利用构建和部署工具\n * kubevirt是借用kubernetes的扩展性来管理vm（通过crd管理虚拟机），你用到的是一个真正的vm；\n * kubevirt旨在提供尽可能多的虚拟机功能\n * kata-container是一个容器运行时，有着vm的安全性和隔离性，以容器的方式运行，有着容器的速度和特点，但不是一个真正的vm；kata容器则试图为虚拟机提供类似容器的体验\n * virtlet是把vm当成一个cri来跑了，是按pod api来定义一个vm，所以vm的很多功能比如热迁移等，virtlet是没法满足vm的全部特性的，算是一个70%功能的vm\n\n\n# 参考资料\n\nhttps://github.com/kata-containers',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata网络和存储文件系统分析",frontmatter:{title:"kata网络和存储文件系统分析",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata2/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:'internetworking_model="tcfilter"\nTC-filter 是默认设置，因为它允许更简单的配置、更好的 CNI 插件兼容性以及与 MACVTAP 相当的性能。',meta:[{name:"twitter:title",content:"kata网络和存储文件系统分析"},{name:"twitter:description",content:'internetworking_model="tcfilter"\nTC-filter 是默认设置，因为它允许更简单的配置、更好的 CNI 插件兼容性以及与 MACVTAP 相当的性能。'},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/02.kata%E7%BD%91%E7%BB%9C%E5%92%8C%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata网络和存储文件系统分析"},{property:"og:description",content:'internetworking_model="tcfilter"\nTC-filter 是默认设置，因为它允许更简单的配置、更好的 CNI 插件兼容性以及与 MACVTAP 相当的性能。'},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/02.kata%E7%BD%91%E7%BB%9C%E5%92%8C%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata网络和存储文件系统分析"},{itemprop:"description",content:'internetworking_model="tcfilter"\nTC-filter 是默认设置，因为它允许更简单的配置、更好的 CNI 插件兼容性以及与 MACVTAP 相当的性能。'}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/02.kata%E7%BD%91%E7%BB%9C%E5%92%8C%E5%AD%98%E5%82%A8%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%88%86%E6%9E%90.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/02.kata网络和存储文件系统分析.md",key:"v-2e5f8162",path:"/pages/kata2/",headers:[{level:2,title:"网络流量走向：",slug:"网络流量走向",normalizedTitle:"网络流量走向：",charIndex:1115},{level:2,title:"virtio-9p 和 virtio-fs 文件系统对比",slug:"virtio-9p-和-virtio-fs-文件系统对比",normalizedTitle:"virtio-9p 和 virtio-fs 文件系统对比",charIndex:4393},{level:2,title:"virtiofs",slug:"virtiofs",normalizedTitle:"virtiofs",charIndex:4373},{level:2,title:"存储路径：",slug:"存储路径",normalizedTitle:"存储路径：",charIndex:8420},{level:3,title:"virtiofsd cache",slug:"virtiofsd-cache",normalizedTitle:"virtiofsd cache",charIndex:9206},{level:3,title:"DAX(直接访问)",slug:"dax-直接访问",normalizedTitle:"dax(直接访问)",charIndex:9369},{level:3,title:"virtiofsd已知问题汇总",slug:"virtiofsd已知问题汇总",normalizedTitle:"virtiofsd已知问题汇总",charIndex:9728},{level:2,title:"containerd的Snapshotter",slug:"containerd的snapshotter",normalizedTitle:"containerd的snapshotter",charIndex:9804}],headersStr:"网络流量走向： virtio-9p 和 virtio-fs 文件系统对比 virtiofs 存储路径： virtiofsd cache DAX(直接访问) virtiofsd已知问题汇总 containerd的Snapshotter",content:'# 网络\n\n虚拟机连接容器网络接口的方式：\n\n * macvtap（早期默认）：创建了一个 MACVTAP 设备以直接连接到eth0设备\n * none(使用自定义网络，只创建一个 tap 设备，不创建 veth pair)\n * tcfilter(通过 tc filter 规则将插件提供的网络接口流量重定向到连接到 VM 的 tap 接口) （现在默认）\n * bridge：（已弃用）\n\n# Internetworking model\n# Determines how the VM should be connected to the\n# the container network interface\n# Options:\n#\n#   - macvtap\n#     Used when the Container network interface can be bridged using\n#     macvtap.\n#\n#   - none\n#     Used when customize network. Only creates a tap device. No veth pair.\n#\n#   - tcfilter\n#     Uses tc filter rules to redirect traffic from the network interface\n#     provided by plugin to a tap interface connected to the VM.\n#\ninternetworking_model="tcfilter"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nTC-filter 是默认设置，因为它允许更简单的配置、更好的 CNI 插件兼容性以及与 MACVTAP 相当的性能。\n\n * eth0属于veth-pair类型接口，一端接入cni创建的网络命名空间，一端接入宿主机\n * tap0_kata属于tap类型接口，一端接入cni创建的网络命名空间，一端接入qemu创建的hypervisor\n * 使用tc策略打通eth0网络接口和tap0_kata网络接口\n\nSandbox环境中只有eth0网络接口，这个接口是qemu和tap模拟出的接口，mac、ip、掩码都和宿主机中cni创建的网络命名空间中eth0的配置一样\n\nContainer运行在Sandbox环境中，Container采用共享宿主机网络命名空间方式创建容器，所以在container中看到的网络配置和Sandbox一样\n\n\n# 网络流量走向：\n\n流量进入宿主机后首先由物理网络通过veth pair接入到net namespace，net namespace中在使用TC filter 规则流量到tap网络接口，然后再通过tap网络接口把流量送入虚拟化环境中，最后虚拟化环境中的容器共享宿主机网络命名空间后就可以在容器中拿到网络流量\n\n[root@rqy-k8s-1 hff]# ip netns exec cni-c1dea1e8-5df7-f16e-4810-e51d8895ca20 ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n inet 127.0.0.1/8 scope host lo\n valid_lft forever preferred_lft forever\n inet6 ::1/128 scope host\n valid_lft forever preferred_lft forever\n2: tunl0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000\n link/ipip 0.0.0.0 brd 0.0.0.0\n4: eth0@if113: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc noqueue state UP group default qlen 1000\n link/ether de:95:a9:f2:89:db brd ff:ff:ff:ff:ff:ff link-netnsid 0\n inet 10.192.181.55/32 scope global eth0\n valid_lft forever preferred_lft forever\n inet6 fe80::dc95:a9ff:fef2:89db/64 scope link\n valid_lft forever preferred_lft forever\n5: tap0_kata: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc mq state UNKNOWN group default qlen 1000\n link/ether ee:32:c5:ac:30:06 brd ff:ff:ff:ff:ff:ff\n inet6 fe80::ec32:c5ff:feac:3006/64 scope link\n valid_lft forever preferred_lft forever\n[root@rqy-k8s-1 hff]# ip netns exec cni-c1dea1e8-5df7-f16e-4810-e51d8895ca20 tc -s qdisc\nqdisc noqueue 0: dev lo root refcnt 2\n Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc noqueue 0: dev eth0 root refcnt 2\n Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev eth0 parent ffff:fff1 ----------------\n Sent 468 bytes 7 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc mq 0: dev tap0_kata root\n Sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc pfifo_fast 0: dev tap0_kata parent :1 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1\n Sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev tap0_kata parent ffff:fff1 ----------------\n Sent 936 bytes 15 pkt (dropped 0, overlimits 0 requeues 0\n backlog 0b 0p requeues 0\n[root@rqy-k8s-1 kbuser]# kubectl exec -it hostpath-kata-57477fb8f7-ls6mq sh\n/ # ip addr\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000\n link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n inet 127.0.0.1/8 scope host lo\n valid_lft forever preferred_lft forever\n inet6 ::1/128 scope host\n valid_lft forever preferred_lft forever\n2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc fq qlen 1000\n link/ether de:95:a9:f2:89:db brd ff:ff:ff:ff:ff:ff\n inet 10.192.181.55/32 brd 10.192.181.55 scope global eth0\n valid_lft forever preferred_lft forever\n inet6 fe80::dc95:a9ff:fef2:89db/64 scope link\n valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n\n\n> calico网络模型网络流向： -容器流量通过veth pair到达宿主机的网络命名空间上。 -根据容器要访问的IP所在的子网CIDR和主机上的路由规则，找到下一跳要到达的宿主机IP。 -流量到达下一跳的宿主机后，根据当前宿主机上的路由规则，直接到达对端容器的veth pair插在宿主机的一端，最终进入容器。\n\n\n# 存储\n\nstorage\n\n * virtio SCSI（在基于块的图形驱动程序下使用）\n * virtio FS（默认）\n * Devicemapper（块设备）\n\n从 Kata Containers 的 2.0 版本开始，virtio-fs是默认的文件系统共享机制（后端是virtiofsd守护进程）。\n\n\n# virtio-9p 和 virtio-fs 文件系统对比\n\n 1. virtio-9p 没有针对虚拟化场景提供优化\n 2. virtio-fs 利用了 hypervisor 和虚拟机处于相同节点的优势\n 3. DAX 特性，文件内容映射到宿主机的内存窗口，客户机直接访问宿主机的 page cache\n    * 减少内存占用，因为客户机 cache 已经被绕过了\n 4. 相比 virtio-9p，virtio-fs 具有更好的 POSIX 合规性\n\n\n# virtiofs\n\n * 所有数据都要经过virtiofs，不管是镜像数据还是⽹络存储卷。虚拟机要和宿主机数据 交互，就必须要穿过qemu，virtiofs就是穿过qemu的桥梁，提供共享⽂件机制。\n * guest和host数据传输都是通过virtio-fs，包括容器镜像和容器卷，读写权限取决于virtiofsd进程的权限。\n * 数据相关的操作最终还是在宿主机上，⽐如镜像层的合并，仍然是containerd的存储层插件snapshotter完成，底层仍然是调⽤了overlayfs⽂件系统\n\n[root@localhost hff]# ps -ef | grep 55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774\nroot     28330     1  0 10:49 ?        00:00:00 /opt/kata/bin/containerd-shim-kata-v2 -namespace k8s.io -address /run/containerd/containerd.sock -publish-binary /usr/bin/containerd -id 55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774\nroot     28342 28330  0 10:49 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\nroot     28348     1  0 10:49 ?        00:00:00 /opt/kata/bin/qemu-system-x86_64 -name sandbox-55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774 -uuid 27f404fa-1887-4529-bbbb-df1525845c98 -machine q35,accel=kvm,kernel_irqchip=on,nvdimm=on -cpu host,pmu=off -qmp unix:/run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/qmp.sock,server=on,wait=off -m 2048M,slots=10,maxmem=8773M -device pci-bridge,bus=pcie.0,id=pci-bridge-0,chassis_nr=1,shpc=off,addr=2,io-reserve=4k,mem-reserve=1m,pref64-reserve=1m -device virtio-serial-pci,disable-modern=false,id=serial0 -device virtconsole,chardev=charconsole0,id=console0 -chardev socket,id=charconsole0,path=/run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/console.sock,server=on,wait=off -device nvdimm,id=nv0,memdev=mem0,unarmed=on -object memory-backend-file,id=mem0,mem-path=/opt/kata/share/kata-containers/kata-clearlinux-latest.image,size=134217728,readonly=on -device virtio-scsi-pci,id=scsi0,disable-modern=false -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -device vhost-vsock-pci,disable-modern=false,vhostfd=3,id=vsock-3099871275,guest-cid=3099871275 -chardev socket,id=char-3352582b4396a8ee,path=/run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/vhost-fs.sock -device vhost-user-fs-pci,chardev=char-3352582b4396a8ee,tag=kataShared -netdev tap,id=network-0,vhost=on,vhostfds=4,fds=5 -device driver=virtio-net-pci,netdev=network-0,mac=7e:c7:e5:c6:8c:d7,disable-modern=false,mq=on,vectors=4 -rtc base=utc,driftfix=slew,clock=host -global kvm-pit.lost_tick_policy=discard -vga none -no-user-config -nodefaults -nographic --no-reboot -daemonize -object memory-backend-file,id=dimm1,size=2048M,mem-path=/dev/shm,share=on -numa node,memdev=dimm1 -kernel /opt/kata/share/kata-containers/vmlinux-5.15.26-90 -append tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k console=hvc0 console=hvc1 cryptomgr.notests net.ifnames=0 pci=lastbus=0 root=/dev/pmem0p1 rootflags=dax,data=ordered,errors=remount-ro ro rootfstype=ext4 quiet systemd.show_status=false panic=1 nr_cpus=8 systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none -pidfile /run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/pid -smp 1,cores=1,threads=1,sockets=8,maxcpus=8\nroot     28355 28342  0 10:49 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\n\n\n1\n2\n3\n4\n5\n\n\n每⼀个 virtiofsd进程的fd参数都等于3，因为⽂件描述符是进程独⽴的，STDIO占 据了0，1和2，那么virtiofsd第⼀个可⽤的fd num就是3了\n\n\n# 存储配置\n\n\n# 存储路径：\n\n/run/kata-containers/shared/sandboxes/ /run/vc/vm/ /run/vc/sbs/\n\n[root@localhost ~]# find / -name hfftest0413-etc\n/run/kata-containers/shared/sandboxes/3b54b3b02fc7f6905d01aedfc4eb209cfb11fd9136006ed6e11e1e26c0f48562/mounts/c7c33d3c7666933c6f1c182bb49bf850c5ca99f08b4595b0f37e6f817bb52768/rootfs/etc/hfftest0413-etc\n/run/kata-containers/shared/sandboxes/3b54b3b02fc7f6905d01aedfc4eb209cfb11fd9136006ed6e11e1e26c0f48562/shared/c7c33d3c7666933c6f1c182bb49bf850c5ca99f08b4595b0f37e6f817bb52768/rootfs/etc/hfftest0413-etc\n/run/containerd/io.containerd.runtime.v2.task/k8s.io/c7c33d3c7666933c6f1c182bb49bf850c5ca99f08b4595b0f37e6f817bb52768/rootfs/etc/hfftest0413-etc\n/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/199015/fs/etc/hfftest0413-etc\n\n\n1\n2\n3\n4\n5\n\n\n\n# virtiofsd cache\n\nguest 生成时会指定内存大小，virtiofsd 会共享使用 guest 的内存。默认使用memory-backend-file 内存对象。\n\nguest 和 host 数据传输都是通过 virtio-fs，包括容器镜像和容器卷，读写权限取决于 virtiofsd 进程的权限。\n\n\n# DAX(直接访问)\n\nDAX windows 是一块虚拟内存区域，通过 PCI Bar 把文件映射到 guest 里面，并不真正的占用主机那么多内存，即使有 100 个虚拟机，设置的 DAX cache 是 1G，也不会真的使用 100G 内存。\n\n如果没有 DAX，内存使⽤量可能会⾮常⼤，因为每个 guest都有⾃⼰的⽂件缓冲区。\n\nKata Containers 官方下载的版本默认没有支持，需要编译安装 gitlab 托管的 virtio-fs qemu 项目 qemu5.0-virtiofs-dax 分支，需要单独编译qemu?qemu5.0-virtiofs-dax????\n\n * configuration.toml 设置virtio_fs_cache_size dax window ⼤⼩\n\n\n# virtiofsd已知问题汇总\n\nhttps://github.com/kata-containers/runtime/issues/2797\n\n\n# containerd的Snapshotter\n\nSnapshot为containerd实现了Snapshotter用于管理文件系统上容器镜像的快照和容器的rootfs挂载和卸载等操作功能。 snapshotter对标Docker中的graphdriver存储驱动的设计。\n\nhttps://blog.mobyproject.org/where-are-containerds-graph-drivers-145fc9b7255\n\n\n# 参考资料\n\nhttps://blog.csdn.net/u010827484/article/details/117488338 https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/networking.md http://miaoyq.com/kata-containers-share/',normalizedContent:'# 网络\n\n虚拟机连接容器网络接口的方式：\n\n * macvtap（早期默认）：创建了一个 macvtap 设备以直接连接到eth0设备\n * none(使用自定义网络，只创建一个 tap 设备，不创建 veth pair)\n * tcfilter(通过 tc filter 规则将插件提供的网络接口流量重定向到连接到 vm 的 tap 接口) （现在默认）\n * bridge：（已弃用）\n\n# internetworking model\n# determines how the vm should be connected to the\n# the container network interface\n# options:\n#\n#   - macvtap\n#     used when the container network interface can be bridged using\n#     macvtap.\n#\n#   - none\n#     used when customize network. only creates a tap device. no veth pair.\n#\n#   - tcfilter\n#     uses tc filter rules to redirect traffic from the network interface\n#     provided by plugin to a tap interface connected to the vm.\n#\ninternetworking_model="tcfilter"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\ntc-filter 是默认设置，因为它允许更简单的配置、更好的 cni 插件兼容性以及与 macvtap 相当的性能。\n\n * eth0属于veth-pair类型接口，一端接入cni创建的网络命名空间，一端接入宿主机\n * tap0_kata属于tap类型接口，一端接入cni创建的网络命名空间，一端接入qemu创建的hypervisor\n * 使用tc策略打通eth0网络接口和tap0_kata网络接口\n\nsandbox环境中只有eth0网络接口，这个接口是qemu和tap模拟出的接口，mac、ip、掩码都和宿主机中cni创建的网络命名空间中eth0的配置一样\n\ncontainer运行在sandbox环境中，container采用共享宿主机网络命名空间方式创建容器，所以在container中看到的网络配置和sandbox一样\n\n\n# 网络流量走向：\n\n流量进入宿主机后首先由物理网络通过veth pair接入到net namespace，net namespace中在使用tc filter 规则流量到tap网络接口，然后再通过tap网络接口把流量送入虚拟化环境中，最后虚拟化环境中的容器共享宿主机网络命名空间后就可以在容器中拿到网络流量\n\n[root@rqy-k8s-1 hff]# ip netns exec cni-c1dea1e8-5df7-f16e-4810-e51d8895ca20 ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n inet 127.0.0.1/8 scope host lo\n valid_lft forever preferred_lft forever\n inet6 ::1/128 scope host\n valid_lft forever preferred_lft forever\n2: tunl0@none: <noarp> mtu 1480 qdisc noop state down group default qlen 1000\n link/ipip 0.0.0.0 brd 0.0.0.0\n4: eth0@if113: <broadcast,multicast,up,lower_up> mtu 1440 qdisc noqueue state up group default qlen 1000\n link/ether de:95:a9:f2:89:db brd ff:ff:ff:ff:ff:ff link-netnsid 0\n inet 10.192.181.55/32 scope global eth0\n valid_lft forever preferred_lft forever\n inet6 fe80::dc95:a9ff:fef2:89db/64 scope link\n valid_lft forever preferred_lft forever\n5: tap0_kata: <broadcast,multicast,up,lower_up> mtu 1440 qdisc mq state unknown group default qlen 1000\n link/ether ee:32:c5:ac:30:06 brd ff:ff:ff:ff:ff:ff\n inet6 fe80::ec32:c5ff:feac:3006/64 scope link\n valid_lft forever preferred_lft forever\n[root@rqy-k8s-1 hff]# ip netns exec cni-c1dea1e8-5df7-f16e-4810-e51d8895ca20 tc -s qdisc\nqdisc noqueue 0: dev lo root refcnt 2\n sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc noqueue 0: dev eth0 root refcnt 2\n sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev eth0 parent ffff:fff1 ----------------\n sent 468 bytes 7 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc mq 0: dev tap0_kata root\n sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc pfifo_fast 0: dev tap0_kata parent :1 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1\n sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev tap0_kata parent ffff:fff1 ----------------\n sent 936 bytes 15 pkt (dropped 0, overlimits 0 requeues 0\n backlog 0b 0p requeues 0\n[root@rqy-k8s-1 kbuser]# kubectl exec -it hostpath-kata-57477fb8f7-ls6mq sh\n/ # ip addr\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue qlen 1000\n link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n inet 127.0.0.1/8 scope host lo\n valid_lft forever preferred_lft forever\n inet6 ::1/128 scope host\n valid_lft forever preferred_lft forever\n2: eth0: <broadcast,multicast,up,lower_up> mtu 1440 qdisc fq qlen 1000\n link/ether de:95:a9:f2:89:db brd ff:ff:ff:ff:ff:ff\n inet 10.192.181.55/32 brd 10.192.181.55 scope global eth0\n valid_lft forever preferred_lft forever\n inet6 fe80::dc95:a9ff:fef2:89db/64 scope link\n valid_lft forever preferred_lft forever\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n\n\n> calico网络模型网络流向： -容器流量通过veth pair到达宿主机的网络命名空间上。 -根据容器要访问的ip所在的子网cidr和主机上的路由规则，找到下一跳要到达的宿主机ip。 -流量到达下一跳的宿主机后，根据当前宿主机上的路由规则，直接到达对端容器的veth pair插在宿主机的一端，最终进入容器。\n\n\n# 存储\n\nstorage\n\n * virtio scsi（在基于块的图形驱动程序下使用）\n * virtio fs（默认）\n * devicemapper（块设备）\n\n从 kata containers 的 2.0 版本开始，virtio-fs是默认的文件系统共享机制（后端是virtiofsd守护进程）。\n\n\n# virtio-9p 和 virtio-fs 文件系统对比\n\n 1. virtio-9p 没有针对虚拟化场景提供优化\n 2. virtio-fs 利用了 hypervisor 和虚拟机处于相同节点的优势\n 3. dax 特性，文件内容映射到宿主机的内存窗口，客户机直接访问宿主机的 page cache\n    * 减少内存占用，因为客户机 cache 已经被绕过了\n 4. 相比 virtio-9p，virtio-fs 具有更好的 posix 合规性\n\n\n# virtiofs\n\n * 所有数据都要经过virtiofs，不管是镜像数据还是⽹络存储卷。虚拟机要和宿主机数据 交互，就必须要穿过qemu，virtiofs就是穿过qemu的桥梁，提供共享⽂件机制。\n * guest和host数据传输都是通过virtio-fs，包括容器镜像和容器卷，读写权限取决于virtiofsd进程的权限。\n * 数据相关的操作最终还是在宿主机上，⽐如镜像层的合并，仍然是containerd的存储层插件snapshotter完成，底层仍然是调⽤了overlayfs⽂件系统\n\n[root@localhost hff]# ps -ef | grep 55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774\nroot     28330     1  0 10:49 ?        00:00:00 /opt/kata/bin/containerd-shim-kata-v2 -namespace k8s.io -address /run/containerd/containerd.sock -publish-binary /usr/bin/containerd -id 55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774\nroot     28342 28330  0 10:49 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\nroot     28348     1  0 10:49 ?        00:00:00 /opt/kata/bin/qemu-system-x86_64 -name sandbox-55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774 -uuid 27f404fa-1887-4529-bbbb-df1525845c98 -machine q35,accel=kvm,kernel_irqchip=on,nvdimm=on -cpu host,pmu=off -qmp unix:/run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/qmp.sock,server=on,wait=off -m 2048m,slots=10,maxmem=8773m -device pci-bridge,bus=pcie.0,id=pci-bridge-0,chassis_nr=1,shpc=off,addr=2,io-reserve=4k,mem-reserve=1m,pref64-reserve=1m -device virtio-serial-pci,disable-modern=false,id=serial0 -device virtconsole,chardev=charconsole0,id=console0 -chardev socket,id=charconsole0,path=/run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/console.sock,server=on,wait=off -device nvdimm,id=nv0,memdev=mem0,unarmed=on -object memory-backend-file,id=mem0,mem-path=/opt/kata/share/kata-containers/kata-clearlinux-latest.image,size=134217728,readonly=on -device virtio-scsi-pci,id=scsi0,disable-modern=false -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -device vhost-vsock-pci,disable-modern=false,vhostfd=3,id=vsock-3099871275,guest-cid=3099871275 -chardev socket,id=char-3352582b4396a8ee,path=/run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/vhost-fs.sock -device vhost-user-fs-pci,chardev=char-3352582b4396a8ee,tag=katashared -netdev tap,id=network-0,vhost=on,vhostfds=4,fds=5 -device driver=virtio-net-pci,netdev=network-0,mac=7e:c7:e5:c6:8c:d7,disable-modern=false,mq=on,vectors=4 -rtc base=utc,driftfix=slew,clock=host -global kvm-pit.lost_tick_policy=discard -vga none -no-user-config -nodefaults -nographic --no-reboot -daemonize -object memory-backend-file,id=dimm1,size=2048m,mem-path=/dev/shm,share=on -numa node,memdev=dimm1 -kernel /opt/kata/share/kata-containers/vmlinux-5.15.26-90 -append tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k console=hvc0 console=hvc1 cryptomgr.notests net.ifnames=0 pci=lastbus=0 root=/dev/pmem0p1 rootflags=dax,data=ordered,errors=remount-ro ro rootfstype=ext4 quiet systemd.show_status=false panic=1 nr_cpus=8 systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none -pidfile /run/vc/vm/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/pid -smp 1,cores=1,threads=1,sockets=8,maxcpus=8\nroot     28355 28342  0 10:49 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/55e043c4c5eacba28c8d97a2aa96f76f153c5f9e49a1ad51f1031237002cf774/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\n\n\n1\n2\n3\n4\n5\n\n\n每⼀个 virtiofsd进程的fd参数都等于3，因为⽂件描述符是进程独⽴的，stdio占 据了0，1和2，那么virtiofsd第⼀个可⽤的fd num就是3了\n\n\n# 存储配置\n\n\n# 存储路径：\n\n/run/kata-containers/shared/sandboxes/ /run/vc/vm/ /run/vc/sbs/\n\n[root@localhost ~]# find / -name hfftest0413-etc\n/run/kata-containers/shared/sandboxes/3b54b3b02fc7f6905d01aedfc4eb209cfb11fd9136006ed6e11e1e26c0f48562/mounts/c7c33d3c7666933c6f1c182bb49bf850c5ca99f08b4595b0f37e6f817bb52768/rootfs/etc/hfftest0413-etc\n/run/kata-containers/shared/sandboxes/3b54b3b02fc7f6905d01aedfc4eb209cfb11fd9136006ed6e11e1e26c0f48562/shared/c7c33d3c7666933c6f1c182bb49bf850c5ca99f08b4595b0f37e6f817bb52768/rootfs/etc/hfftest0413-etc\n/run/containerd/io.containerd.runtime.v2.task/k8s.io/c7c33d3c7666933c6f1c182bb49bf850c5ca99f08b4595b0f37e6f817bb52768/rootfs/etc/hfftest0413-etc\n/var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/199015/fs/etc/hfftest0413-etc\n\n\n1\n2\n3\n4\n5\n\n\n\n# virtiofsd cache\n\nguest 生成时会指定内存大小，virtiofsd 会共享使用 guest 的内存。默认使用memory-backend-file 内存对象。\n\nguest 和 host 数据传输都是通过 virtio-fs，包括容器镜像和容器卷，读写权限取决于 virtiofsd 进程的权限。\n\n\n# dax(直接访问)\n\ndax windows 是一块虚拟内存区域，通过 pci bar 把文件映射到 guest 里面，并不真正的占用主机那么多内存，即使有 100 个虚拟机，设置的 dax cache 是 1g，也不会真的使用 100g 内存。\n\n如果没有 dax，内存使⽤量可能会⾮常⼤，因为每个 guest都有⾃⼰的⽂件缓冲区。\n\nkata containers 官方下载的版本默认没有支持，需要编译安装 gitlab 托管的 virtio-fs qemu 项目 qemu5.0-virtiofs-dax 分支，需要单独编译qemu?qemu5.0-virtiofs-dax????\n\n * configuration.toml 设置virtio_fs_cache_size dax window ⼤⼩\n\n\n# virtiofsd已知问题汇总\n\nhttps://github.com/kata-containers/runtime/issues/2797\n\n\n# containerd的snapshotter\n\nsnapshot为containerd实现了snapshotter用于管理文件系统上容器镜像的快照和容器的rootfs挂载和卸载等操作功能。 snapshotter对标docker中的graphdriver存储驱动的设计。\n\nhttps://blog.mobyproject.org/where-are-containerds-graph-drivers-145fc9b7255\n\n\n# 参考资料\n\nhttps://blog.csdn.net/u010827484/article/details/117488338 https://github.com/kata-containers/kata-containers/blob/main/docs/design/architecture/networking.md http://miaoyq.com/kata-containers-share/',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata cgroup及资源限制",frontmatter:{title:"kata cgroup及资源限制",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata3/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"kata cgroup及资源限制"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/03.kata%20cgroup%E5%8F%8A%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata cgroup及资源限制"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/03.kata%20cgroup%E5%8F%8A%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata cgroup及资源限制"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/03.kata%20cgroup%E5%8F%8A%E8%B5%84%E6%BA%90%E9%99%90%E5%88%B6.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/03.kata cgroup及资源限制.md",key:"v-3f9afa48",path:"/pages/kata3/",headers:[{level:2,title:"验证1： 查看cgroup大小",slug:"验证1-查看cgroup大小",normalizedTitle:"验证1： 查看cgroup大小",charIndex:1106},{level:3,title:"sandboxcgrouponly=true",slug:"sandbox-cgroup-only-true",normalizedTitle:"sandboxcgrouponly=true",charIndex:null},{level:3,title:"sandboxcgrouponly=false（结果同=true）",slug:"sandbox-cgroup-only-false-结果同-true",normalizedTitle:"sandboxcgrouponly=false（结果同=true）",charIndex:null},{level:3,title:"查看命令：",slug:"查看命令",normalizedTitle:"查看命令：",charIndex:3331},{level:2,title:"验证2：如果不设置request limit，kubepod cgroup的限制是怎样的",slug:"验证2-如果不设置request-limit-kubepod-cgroup的限制是怎样的",normalizedTitle:"验证2：如果不设置request limit，kubepod cgroup的限制是怎样的",charIndex:5356},{level:2,title:"验证3： 验证overhead是否影响业务负载",slug:"验证3-验证overhead是否影响业务负载",normalizedTitle:"验证3： 验证overhead是否影响业务负载",charIndex:6185},{level:2,title:"验证4：验证如果不设置request limit，cpu mem的使用上线",slug:"验证4-验证如果不设置request-limit-cpu-mem的使用上线",normalizedTitle:"验证4：验证如果不设置request limit，cpu mem的使用上线",charIndex:6814},{level:2,title:"验证5： 验证cpu mem小于1C 256Mi的情况（no overhead）",slug:"验证5-验证cpu-mem小于1c-256mi的情况-no-overhead",normalizedTitle:"验证5： 验证cpu mem小于1c 256mi的情况（no overhead）",charIndex:7526},{level:2,title:"验证6： 极小资源占用测试",slug:"验证6-极小资源占用测试",normalizedTitle:"验证6： 极小资源占用测试",charIndex:8677},{level:2,title:"验证7： 查看kata vm中的cgroup",slug:"验证7-查看kata-vm中的cgroup",normalizedTitle:"验证7： 查看kata vm中的cgroup",charIndex:10477},{level:2,title:"两种cgrouppath:",slug:"两种cgrouppath",normalizedTitle:"两种cgrouppath:",charIndex:14110},{level:2,title:"pod overhead",slug:"pod-overhead",normalizedTitle:"pod overhead",charIndex:489},{level:2,title:"sandboxcgrouponly",slug:"sandbox-cgroup-only",normalizedTitle:"sandboxcgrouponly",charIndex:null},{level:2,title:"default_vcpus/memory",slug:"default-vcpus-memory",normalizedTitle:"default_vcpus/memory",charIndex:716},{level:2,title:"kata资源开销",slug:"kata资源开销",normalizedTitle:"kata资源开销",charIndex:15028},{level:2,title:"kata组件进程：",slug:"kata组件进程",normalizedTitle:"kata组件进程：",charIndex:15107},{level:2,title:"不支持Cgroups V2",slug:"不支持cgroups-v2",normalizedTitle:"不支持cgroups v2",charIndex:15676},{level:2,title:"通过注释修改配置：",slug:"通过注释修改配置",normalizedTitle:"通过注释修改配置：",charIndex:17610},{level:2,title:"打开--feature-gates PodOverhead",slug:"打开-feature-gates-podoverhead",normalizedTitle:"打开--feature-gates podoverhead",charIndex:17918},{level:3,title:"启用RuntimeClass准入控制",slug:"启用runtimeclass准入控制",normalizedTitle:"启用runtimeclass准入控制",charIndex:18239},{level:3,title:"设置podOverHead",slug:"设置podoverhead",normalizedTitle:"设置podoverhead",charIndex:18437},{level:2,title:"virtio-mem内存热插拔（仅支持QEMU）",slug:"virtio-mem内存热插拔-仅支持qemu",normalizedTitle:"virtio-mem内存热插拔（仅支持qemu）",charIndex:18630}],headersStr:"验证1： 查看cgroup大小 sandboxcgrouponly=true sandboxcgrouponly=false（结果同=true） 查看命令： 验证2：如果不设置request limit，kubepod cgroup的限制是怎样的 验证3： 验证overhead是否影响业务负载 验证4：验证如果不设置request limit，cpu mem的使用上线 验证5： 验证cpu mem小于1C 256Mi的情况（no overhead） 验证6： 极小资源占用测试 验证7： 查看kata vm中的cgroup 两种cgrouppath: pod overhead sandboxcgrouponly default_vcpus/memory kata资源开销 kata组件进程： 不支持Cgroups V2 通过注释修改配置： 打开--feature-gates PodOverhead 启用RuntimeClass准入控制 设置podOverHead virtio-mem内存热插拔（仅支持QEMU）",content:'# 参考：\n\n * host-cgroups.md\n * vcpu-handling.md\n\n\n# 结论\n\n * cgroupsPath的路径根据Qos类别不同\n * kata_overhead的cpu和mem没有限制，能用到宿主机所有资源，如果不开启sandbox_cgroup_only会导致主机资源被抢占\n * kubepod cgroup限制=limit+overhead，容器业务负载就是在这个限制之内使用，然后区分sandbox_cgroup_only是否开启决定kata vm(sandbox)开销是否统计到kubepod中，如果是则业务申请cpu mem资源就必须考虑kata sandbox开销\n * 虚拟机大小=kata vm中或者说pod中看到的cpu mem（lscpu lsmem）=default+limit（见验证1）\n * kubectl describe node | grep test-kata看到的资源申请=limit+overhead（同runc）（见验证1）\n * kubectl top pod看到的是业务真正的负载开销？？\n * pod overhead会影响调度，overhead只作用于sandbox开销，不能作用于业务负载（见验证3）\n * 为了限制资源抢占问题，建议开启sandbox_cgroup_only=true,overhead建议不设置（待定），以下说明均在sandbox_cgroup_only=true前提下进行说明\n * 业务负载+sandbox开销最大能使用的资源限制=limit+overhead（overhead部分只能是额外开销用）（见验证3）\n * default_vcpus/memory，影响虚拟机的大小/启动时间，这个值官方不建议修改\n * 如果container未设置limit，则kubepod cgroup无限制（但是业务负载只能使用default设置的1G2G???暂未找到在哪做的限制）（见验证7）；如果设置了limit，则这个default则只影响虚拟机大小，但不影响kubepod cgroup限制（见验证1）\n * ~一个Pod的最小规格是1C 256M，当低于 256M 时，会重置为 2G。，支持的最大内存规格是256GB。如果用户分配的内存规格超过256GB，可能会出现未定义的错误，安全容器暂不支持超过256GB的大内存场景。~（未找到官方出处，应该只是openEuler内部做的限制）（见验证5）\n * 如果不设置request，则request的值和limit默认相等\n\n\n# 一些验证\n\n\n# 验证1： 查看cgroup大小\n\ncpu.cfs_period_us是CFS算法的一个调度周期，一般它的值是100000us，即100ms。 cpu.cfs_quota_us表示在CFS算法中，在一个调度周期里该控制组被允许的运行时间，比如这个值为50000时，就是50ms。用这个值去除以调度周期cpu.cfs_period_us，即50ms/100ms=0.5，得到的值表示该控制组被允许使用的CPU最大配额是0.5个CPU。在我的系统里，这个值是-1，为默认值，表示不限制。\n\ndefault_vcpu=1 default_memory=2Gi overhead: "podFixed":{"cpu":"250m","memory":"160Mi"} pod Qos: resources: requests: memory: "500Mi" cpu: "0.5" limits: memory: "3000Mi" cpu: "4"\n\n\n# sandbox_cgroup_only=true\n\n"cgroupsPath": "/kubepods/burstable/pod287707dd-0fda-4fab-874d-e1b00e87390a/c2bfeccb7580707e7559c00f7ee9d46e98745cc2a0d267fbb41c68da41df784f",\n\nkata_overhead-mem: ~8G（不限） kata_overhead-cpu: -1（不限） kubepods_mem: 3313500160 (~3.08G) (limit+overhead) kubepods_cpu cfs_period_us: 100000 cpu.cfs_quota_us 425000 (4.25核) （limit+overhead）\n\nlscpu: 5 (default+limit) lsmem： Memory block size: 128M Memory block size: 128M Total online memory: 5G (default+limit)\n\nkubectl describe node | grep test-kata： 750m (9%) 4250m (54%)(limit+overhead) 660Mi (10%) 3160Mi (48%)(limit+overhead) 4m54s kubectl top pod： 1002m 1Mi kubectl top node： 1306m 16% 5513Mi 84%\n\n[root@localhost ~]# systemd-cgtop | grep kata /kata_overhead - - 4.9M - - /system.slice/kata-monitor.service 1 - 27.4M - - [root@localhost ~]# systemd-cgtop | grep pod287707dd-0fda-4fab-874d-e1b00e87390a /kubepods/burstable/pod287707dd-0fda-4fab-874d-e1b00e87390a - - 193.4M - -\n\n\n# sandbox_cgroup_only=false（结果同=true）\n\n"cgroupsPath": "/kubepods/burstable/pod3a449bdd-90d5-41fd-a57a-9cfd102f9e44/87b5990ce61e4ff193124fc60e4a68c7061cf9299688c6c521cae29103bc3ef5",\n\nkata_overhead-mem: ~8G（不限） kata_overhead-cpu: -1（不限）\n\nkubepods_mem: 3313500160 (~3.08G) (limit+overhead) kubepods_cpu cfs_period_us: 100000 cpu.cfs_quota_us 425000 (4.25核) （limit+overhead）\n\n[root@localhost ~]# systemd-cgtop | grep kata /kata_overhead - - 4.9M - - /system.slice/kata-monitor.service 1 - 24.6M - - [root@localhost ~]# systemd-cgtop | grep pod3a449bdd-90d5-41fd-a57a-9cfd102f9e44 /kubepods/burstable/pod3a449bdd-90d5-41fd-a57a-9cfd102f9e44 - - 151.7M - -\n\nkubectl describe node | grep test-kata： 750m (9%) 4250m (54%)(limit+overhead) 660Mi (10%) 3160Mi (48%)(limit+overhead) 4m54s kubectl top pod： 1002m 1Mi kubectl top node： 1330m 17% 5507Mi 84%\n\n\n# 查看命令：\n\n[root@localhost ~]# systemd-cgtop | grep kata\n/kata_overhead                                                                                                                -      -     4.9M        -        -\n/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/kata_842463ada9994438f6c663b082bbf5735c64309f77a0b57838b8a16f347433a6       7      -   132.9M        -        -\n/system.slice/kata-monitor.service                                                                                            1      -    23.2M        -        -\n\n[root@localhost ~]# cat /sys/fs/cgroup/memory/kata_overhead/memory.limit_in_bytes\n9223372036854771712\n[root@localhost ~]#  cat /sys/fs/cgroup/cpu/kata_overhead/cpu.cfs_period_us\n100000\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/kata_overhead/cpu.cfs_quota_us\n-1\n\n[root@localhost ~]# cat /sys/fs/cgroup/memory/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/memory.limit_in_bytes\n1241513984\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/cpu.cfs_period_us\n100000\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/cpu.cfs_quota_us\n125000\n\n[root@localhost ~]#  cat /sys/fs/cgroup/memory/system.slice/kata-monitor.service/memory.limit_in_bytes\n9223372036854771712\n\n[root@localhost ~]# kubectl top pod test-kata\nNAME        CPU(cores)   MEMORY(bytes)\ntest-kata   0m           2Mi\n[root@localhost ~]# kubectl top node\nNAME                    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%\nlocalhost.localdomain   355m         4%     5469Mi          83%\n\n[root@localhost ~]# kubectl describe node | grep kata\n  default                     test-kata                                                1250m (16%)   1250m (16%)  1184Mi (18%)     1184Mi (18%)   16d\n  kube-system                 kata-deploy-q2cnv                                        0 (0%)        0 (0%)       0 (0%)           0 (0%)         21d\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\n\n\n# 验证2：如果不设置request limit，kubepod cgroup的限制是怎样的\n\n"cgroupsPath": "/kubepods/besteffort/pod09a392bc-1080-4044-8015-39f392e3862f/367368f8f5c44bc69b277febfa5d533063f096c65cd9b6729bbc7847a582f51f",\n\nkata_overhead-mem: ~8G（不限） kata_overhead-cpu: -1（不限）\n\nkubepods_mem: 9223372036854771712 ~8G（不限） kubepods_cpu cfs_period_us cfs_quota_us: 100000 -1 不限 kubectl top pod： 1000m 0Mi kubectl top node： 1316m 16% 5517Mi 84%\n\n[root@localhost hff]# systemd-cgtop | grep kata /kata_overhead - - 4.9M - - /system.slice/kata-monitor.service 1 - 25.1M - -\n\n[root@localhost hff]# systemd-cgtop | grep pod09a392bc-1080-4044-8015-39f392e3862f /kubepods/besteffort/pod09a392bc-1080-4044-8015-39f392e3862f - - 95.8M - -\n\nkubectl describe node | grep test-kata： 250m (3%)（overhead） 0 (0%) 160Mi (2%)（overhead） 0 (0%) 6m30s\n\nkubepod不限制，但是pod确实只能用到limit的值\n\n\n# 验证3： 验证overhead是否影响业务负载\n\n设置overhead 2C 2G后，limit 3C3G, 打满cpu=6,mem=3Gi\n\n[root@localhost hff]# kubectl get pod\nNAME                              READY   STATUS        RESTARTS   AGE\ntest-kata-5687cdcb66-28lgn        0/1     OutOfmemory   0          17s\ntest-kata-5687cdcb66-2lmd5        0/1     OutOfmemory   0          11s\ntest-kata-5687cdcb66-2pbhm        0/1     OutOfmemory   0          23s\ntest-kata-5687cdcb66-575sb        0/1     OutOfmemory   0          19s\ntest-kata-5687cdcb66-5gvt2        0/1     OutOfmemory   0          5s\ntest-kata-5687cdcb66-62fbd        0/1     OutOfmemory   0          33s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 验证4：验证如果不设置request limit，cpu mem的使用上线\n\n设置overhead 2C 2G后，limit不设置， 打满cpu=6,mem=1Gi\n\n[root@localhost hff]# kubectl get pod  -w\nNAME                              READY   STATUS        RESTARTS   AGE\ntest-kata-55867ffb58-26ndp        0/1     OutOfmemory   0          4s\ntest-kata-55867ffb58-2blnx        0/1     OutOfmemory   0          2s\ntest-kata-55867ffb58-2d858        0/1     OutOfmemory   0          1s\ntest-kata-55867ffb58-2qwzf        0/1     Pending       0          0s\ntest-kata-55867ffb58-4j4hl        0/1     OutOfmemory   0          1s\ntest-kata-55867ffb58-8zzbc        0/1     OutOfmemory   0          2s\ntest-kata-55867ffb58-crflb        0/1     OutOfmemory   0          4s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 验证5： 验证cpu mem小于1C 256Mi的情况（no overhead）\n\n    resources:\n      requests:\n        memory: "1Mi"\n        cpu: "0.1"\n      limits:\n        memory: "100Mi"\n        cpu: "550m"\n    args:\n    - -cpus\n    - "2"\n    - -mem-total\n    - 100Mi\n    - -mem-alloc-size\n    - 10Mi\n    - -mem-alloc-sleep\n    - 1s\n\n\n没有OOM，但是pod不断重启，所有并没有被重置成2G\n\n[root@localhost hff]# kubectl get pod -w\nNAME                              READY   STATUS    RESTARTS   AGE\nkubefilebrowser-896974bcc-z6scd   1/1     Running   3          31d\ntest-kata-6878f4fd9f-76c5k        1/1     Running   2          61s\ntest-runc-79d8bdc4cb-v6j28        1/1     Running   0          75m\ntest-kata-6878f4fd9f-76c5k        0/1     Error     2          72s\ntest-kata-6878f4fd9f-76c5k        0/1     CrashLoopBackOff   2          75s\n\n[root@localhost hff]# kubectl logs test-kata-6878f4fd9f-76c5k\nI0527 07:16:06.932758       1 main.go:26] Allocating "200Mi" memory, in "10Mi" chunks, with a 1s sleep between allocations\nI0527 07:16:06.933058       1 main.go:39] Spawning a thread to consume CPU\nI0527 07:16:06.933082       1 main.go:39] Spawning a thread to consume CPU\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 验证6： 极小资源占用测试\n\nlimit550m/200Mi，压2C100Mi，pod会不断重启，但是不是OOMKilled\n\n        resources:\n          requests:\n            memory: "1Mi"\n            cpu: "0.1"\n          limits:\n            memory: "200Mi"\n            cpu: "550m"\n        args:\n        - -cpus\n        - "2"\n        - -mem-total\n        - 100Mi\n        - -mem-alloc-size\n        - 10Mi\n        - -mem-alloc-sleep\n        - 1s\nEvents:\n  Type     Reason          Age                   From                            Message\n  ----     ------          ----                  ----                            -------\n  Normal   Scheduled       <unknown>             default-scheduler               Successfully assigned default/test-kata-68b77bc9f8-zlj5p to localhost.localdomain\n  Normal   Created         36m (x4 over 38m)     kubelet, localhost.localdomain  Created container cpu-stress-kata\n  Normal   Started         36m (x4 over 38m)     kubelet, localhost.localdomain  Started container cpu-stress-kata\n  Normal   SandboxChanged  35m (x4 over 37m)     kubelet, localhost.localdomain  Pod sandbox changed, it will be killed and re-created.\n  Normal   Pulled          7m53s (x11 over 38m)  kubelet, localhost.localdomain  Container image "vish/stress" already present on machine\n  Warning  BackOff         3m5s (x159 over 37m)  kubelet, localhost.localdomain  Back-off restarting failed container\n[root@localhost hff]#\n[root@localhost hff]# kubectl logs test-kata-68b77bc9f8-zlj5p\nI0527 08:13:52.926368       1 main.go:26] Allocating "100Mi" memory, in "10Mi" chunks, with a 1s sleep between allocations\nI0527 08:13:52.926544       1 main.go:39] Spawning a thread to consume CPU\nI0527 08:13:52.926570       1 main.go:39] Spawning a thread to consume CPU\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# 验证7： 查看kata vm中的cgroup\n\n不设置limit，overhead\n\nbash-5.1# more /sys/fs/cgroup/memory/\ncgroup.clone_children               memory.max_usage_in_bytes\ncgroup.event_control                memory.memsw.failcnt\ncgroup.procs                        memory.memsw.limit_in_bytes\ncgroup.sane_behavior                memory.memsw.max_usage_in_bytes\nkubepods/                           memory.memsw.usage_in_bytes\nmemory.failcnt                      memory.move_charge_at_immigrate\nmemory.force_empty                  memory.oom_control\nmemory.kmem.failcnt                 memory.pressure_level\nmemory.kmem.limit_in_bytes          memory.soft_limit_in_bytes\nmemory.kmem.max_usage_in_bytes      memory.stat\nmemory.kmem.slabinfo                memory.swappiness\nmemory.kmem.tcp.failcnt             memory.usage_in_bytes\nmemory.kmem.tcp.limit_in_bytes      memory.use_hierarchy\nmemory.kmem.tcp.max_usage_in_bytes  notify_on_release\nmemory.kmem.tcp.usage_in_bytes      release_agent\nmemory.kmem.usage_in_bytes          system.slice/\nmemory.limit_in_bytes               tasks\nbash-5.1# more /sys/fs/cgroup/memory/kubepods/\nbesteffort/                         memory.max_usage_in_bytes\ncgroup.clone_children               memory.memsw.failcnt\ncgroup.event_control                memory.memsw.limit_in_bytes\ncgroup.procs                        memory.memsw.max_usage_in_bytes\nmemory.failcnt                      memory.memsw.usage_in_bytes\nmemory.force_empty                  memory.move_charge_at_immigrate\nmemory.kmem.failcnt                 memory.oom_control\nmemory.kmem.limit_in_bytes          memory.pressure_level\nmemory.kmem.max_usage_in_bytes      memory.soft_limit_in_bytes\nmemory.kmem.slabinfo                memory.stat\nmemory.kmem.tcp.failcnt             memory.swappiness\nmemory.kmem.tcp.limit_in_bytes      memory.usage_in_bytes\nmemory.kmem.tcp.max_usage_in_bytes  memory.use_hierarchy\nmemory.kmem.tcp.usage_in_bytes      notify_on_release\nmemory.kmem.usage_in_bytes          tasks\nmemory.limit_in_bytes\nbash-5.1# more /sys/fs/cgroup/cpu/cpu.cfs_quota_us\n-1\nbash-5.1# more /sys/fs/cgroup/cpu/kubepods/besteffort/cpu.cfs_quota_us\n-1\nbash-5.1# more /sys/fs/cgroup/cpu/kubepods/besteffort/pode0eb5953-c643-4429-8812-b8e36d75e3d9/f3cffcf893000b0c5f6105f1adb94e3be7fa62ebecd801a29b9a77a472d62c86/cfs_quota_us\n-1\nbash-5.1# more /sys/fs/cgroup/memory/memory.limit_in_bytes\n9223372036854771712\nbash-5.1#  more /sys/fs/cgroup/memory/kubepods/memory.limit_in_bytes\n9223372036854771712\nbash-5.1#  more /sys/fs/cgroup/memory/kubepods/besteffort/memory.limit_in_bytes\n9223372036854771712\nbash-5.1#  more /sys/fs/cgroup/memory/kubepods/besteffort/pode0eb5953-c643-4429-8812-b8e36d75e3d9/.limit_in_bytes\n9223372036854771712\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n未找到default_vcpu/memory是在哪里做的限制\n\n\n# kata cgroup说明\n\nKata Containers 在两层 cgroup 上运行。\n\n * workload guest\n * VMM host （Kata Containers 在两层 cgroup 上运行。第一层在虚拟机中放置工作负载，而第二层在主机上运行 VMM和 关联线程。）\n\n从 Kubernetes 角度来讲，Cgroup 指的是 Pod Cgroup，由 Kubelet 创建，限制的是 Pod 的资源; 从 Container 角度来讲，Cgroup 指的是 Container Cgroup，由对应的 runtime 创建，限制的是 container 的资源。但是为了可以获取到更准确的容器资源，Kubelet 会根据 Container Cgroup 去调整 Pod Cgroup。 在传统的 runtime 中，两者没有太大的区别。\n\n而 Kata Containers 引入 VM 的概念，所以针对这种情况有两种处理方式：\n\n * 启用 SandboxCgroupOnly（默认），Kubelet 在调整 Pod Cgroup 的大小时，会将 sandbox 的开销统计进去 （就是说，用户申请的资源limit+overhead是业务负载和kata虚拟机开销的最大使用限制，如果不设置limit，默认是default_vcpus/mem??）\n * 禁用 SandboxCgroupOnly，sandbox 的开销和 Pod Cgroup 分开计算，独立存在 （就是说，用户申请的资源limit+overhead是业务负载自己的最大使用限制，kata虚拟机开销单独一个cgroup而且没有限制，如果不设置limit，业务使用默认是default_vcpus/mem）\n\n\n# 两种cgrouppath:\n\n * /kubepods/burstable/pod287707dd-0fda-4fab-874d-e1b00e87390a/c2bfeccb7580707e7559c00f7ee9d46e98745cc2a0d267fbb41c68da41df784f ()\n * /kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/kata_842463ada9994438f6c663b082bbf5735c64309f77a0b57838b8a16f347433a6 ()\n\n\n# pod overhead\n\n\n# sandbox_cgroup_only\n\n * 如果启用，运行时将在一个专用cgroup中添加所有kata进程。每个沙盒只创建一个cgroup，主机中的container cgroup将不会创建\n * kata runtime调用者可以自由地限制或收集整个Kata沙盒的cgroup统计信息。\n * sandbox cgroup路径是具有PodSandbox annotation(???)的容器的父cgroup。\n * 如果没有container type annotation(??)，则sandbox cgroup将受到限制\n * 意味着 pod cgroup 的大小适当，并考虑了 pod 开销（设置podoverhead考虑调度）\n * Kata shim 将在sandbox_cgroup_onlypod 的专用 cgroup 下为每个 pod 创建一个子 cgroup\n * kata shim、qemu 线程将与沙箱在同一个 cgroup 中。在这种情况下，它们将与 vcpu 线程共享同一组 cpu 内核\n\n=true好处：\n\n * 便于Pod资源统计\n * 更好的主机资源隔离\n\n=fasle优点及缺点：\n\n * 不限制会消耗大量主机资源\n * 在专用开销cgroup下运行所有非vcpu线程可以提供有关实际的开销准确值，可以设置开销cgroup大小（手动修改，无接口）\n\n\n# default_vcpus/memory\n\n\n# kata资源开销\n\n * 半虚拟化 I/O 后端\n * VMM 实例\n * Kata shim 进程\n * kata monitor开销（如果开启）\n\n\n# kata组件进程：\n\n * sandbox qemu-system-x86_64进程cgroup\n * containerd-shim-kata-v2进程\n * 两个virtiofsd进程\n\nkata pod起来后，其中，kata shim进程和qemu进程占用了大量的内存开销，其中，沙箱里的内核和 agent 是直接分享了应用内存但并不是应用的一部分，也就是说，这一部分是用户可见的开销。而 VMM 本身在宿主机上的开销以及 shim-v2 占用的内存，虽然用户应用不可见，但同样是 Kata 带来的开销，影响基础设施的资源效率。\n\n这些内存开销里，还包括了可共享开销和不可共享开销。所有宿主这边的代码段内存（只读内存），可以共享 page cache，所以是共享的，而在沙箱里的代码（只读）内存，在使用 DAX 或模版的情况下，也可以共享同一份。所以，可以共享的内存开销在节点全局范围内是唯一一份，所以在有多个Pod的情况下，这部分的常数开销相对而言是不太重要的，相反的，不可共享开销，尤其是堆内存开销，会随着 Pod 的增长而增长，的换句话说，堆内存（匿名页）是最需要被重视的开销。\n\n综上，第一位需要被遏制的开销是沙箱内的用户可见的不可共享开销，尤其是 Agent 的开销，而 VMM 和 shim 的匿名页开销次之。\n\n\n# 不支持Cgroups V2\n\n\n# 一些需要知道的配置\n\n# Default number of vCPUs per SB/VM:\n# unspecified or 0                --\x3e will be set to 1（不设置或0则默认是1）\n# < 0                             --\x3e will be set to the actual number of physical cores(小于0则设为实际物理核)\n# > 0 <= number of physical cores --\x3e will be set to the specified number\n# > number of physical cores      --\x3e will be set to the actual number of physical cores（大于物理核默认为物理核）\ndefault_vcpus = 1\n\n# Default memory size in MiB for SB/VM.\n# If unspecified then it will be set 2048 MiB.（不设置默认是2Gi）\ndefault_memory = 2048\n\n# Default maximum number of vCPUs per SB/VM:\n# unspecified or == 0             --\x3e will be set to the actual number of physical cores or to the maximum number（不设置或0默认为最大物理核数）\n#                                     of vCPUs supported by KVM if that number is exceeded\n# > 0 <= number of physical cores --\x3e will be set to the specified number\n# > number of physical cores      --\x3e will be set to the actual number of physical cores or to the maximum number\n#                                     of vCPUs supported by KVM if that number is exceeded\n# WARNING: Depending of the architecture, the maximum number of vCPUs supported by KVM is used when\n# the actual number of physical cores is greater than it.\n# WARNING: Be aware that this value impacts the virtual machine\'s memory footprint and CPU\n# the hotplug functionality. For example, `default_maxvcpus = 240` specifies that until 240 vCPUs\n# can be added to a SB/VM, but the memory footprint will be big. Another example, with\n# `default_maxvcpus = 8` the memory footprint will be small, but 8 will be the maximum number of\n# vCPUs supported by the SB/VM. In general, we recommend that you do not edit this variable,\n# unless you know what are you doing.\n# NOTICE: on arm platform with gicv2 interrupt controller, set it to 8.\ndefault_maxvcpus = 0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 通过注释修改配置：\n\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n runtime_type = "io.containerd.kata.v2"\n privileged_without_host_devices = false\n shim_debug = true\n pod_annotations = ["io.katacontainers.*"] #  <-- look here\n\n\n1\n2\n3\n4\n5\n\n\n> io.katacontainers.config.hypervisor.default_vcpus = 5\n\n\n# 打开--feature-gates PodOverhead\n\n> /etc/kubernetes/manifests/kube-apiserver.yaml\n\n1.17默认关闭，1.18默认打开\n\n> Environment="KUBELET_FEATURE=--feature-gates=RotateKubeletServerCertificate=true,VolumeSnapshotDataSource=true,ExpandCSIVolumes=true,VolumePVCDataSource=true,ServiceTopology=true,EndpointSlice=true,PodOverhead=true"\n\n\n# 启用RuntimeClass准入控制\n\n> --feature-gates=VolumeSnapshotDataSource=true,ExpandCSIVolumes=true,VolumePVCDataSource=true,TTLAfterFinished=true,ServiceTopology=true,EndpointSlice=true,PodOverhead=true\n\n\n# 设置podOverHead\n\nkind: RuntimeClass\napiVersion: node.k8s.io/v1beta1\nmetadata:\n  name: kata-containers\nhandler: kata\noverhead:\n  podFixed:\n  memory: "100Mi"\n  cpu: "100m"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# virtio-mem内存热插拔（仅支持QEMU）\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-use-virtio-mem-with-kata.md\n\n$ sudo sed -i -e \'s/^#enable_virtio_mem.*$/enable_virtio_mem = true/g\' /etc/kata-containers/configuration.toml\n\n\n1\n\n\n\n# 附件\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: test-kata\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: test-kata\n  template:\n    metadata:\n      labels:\n        app: test-kata\n    spec:\n      runtimeClassName: kata-containers\n      containers:\n      - image: vish/stress\n        imagePullPolicy: IfNotPresent\n        name: cpu-stress-kata\n        resources:\n          requests:\n            memory: "1Mi"\n            cpu: "0.1"\n          limits:\n            memory: "161Mi"\n            cpu: "350m"\n        args:\n        - -cpus\n        - "2"\n        - -mem-total\n        - 100Mi\n        - -mem-alloc-size\n        - 10Mi\n        - -mem-alloc-sleep\n        - 1s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n',normalizedContent:'# 参考：\n\n * host-cgroups.md\n * vcpu-handling.md\n\n\n# 结论\n\n * cgroupspath的路径根据qos类别不同\n * kata_overhead的cpu和mem没有限制，能用到宿主机所有资源，如果不开启sandbox_cgroup_only会导致主机资源被抢占\n * kubepod cgroup限制=limit+overhead，容器业务负载就是在这个限制之内使用，然后区分sandbox_cgroup_only是否开启决定kata vm(sandbox)开销是否统计到kubepod中，如果是则业务申请cpu mem资源就必须考虑kata sandbox开销\n * 虚拟机大小=kata vm中或者说pod中看到的cpu mem（lscpu lsmem）=default+limit（见验证1）\n * kubectl describe node | grep test-kata看到的资源申请=limit+overhead（同runc）（见验证1）\n * kubectl top pod看到的是业务真正的负载开销？？\n * pod overhead会影响调度，overhead只作用于sandbox开销，不能作用于业务负载（见验证3）\n * 为了限制资源抢占问题，建议开启sandbox_cgroup_only=true,overhead建议不设置（待定），以下说明均在sandbox_cgroup_only=true前提下进行说明\n * 业务负载+sandbox开销最大能使用的资源限制=limit+overhead（overhead部分只能是额外开销用）（见验证3）\n * default_vcpus/memory，影响虚拟机的大小/启动时间，这个值官方不建议修改\n * 如果container未设置limit，则kubepod cgroup无限制（但是业务负载只能使用default设置的1g2g???暂未找到在哪做的限制）（见验证7）；如果设置了limit，则这个default则只影响虚拟机大小，但不影响kubepod cgroup限制（见验证1）\n * ~一个pod的最小规格是1c 256m，当低于 256m 时，会重置为 2g。，支持的最大内存规格是256gb。如果用户分配的内存规格超过256gb，可能会出现未定义的错误，安全容器暂不支持超过256gb的大内存场景。~（未找到官方出处，应该只是openeuler内部做的限制）（见验证5）\n * 如果不设置request，则request的值和limit默认相等\n\n\n# 一些验证\n\n\n# 验证1： 查看cgroup大小\n\ncpu.cfs_period_us是cfs算法的一个调度周期，一般它的值是100000us，即100ms。 cpu.cfs_quota_us表示在cfs算法中，在一个调度周期里该控制组被允许的运行时间，比如这个值为50000时，就是50ms。用这个值去除以调度周期cpu.cfs_period_us，即50ms/100ms=0.5，得到的值表示该控制组被允许使用的cpu最大配额是0.5个cpu。在我的系统里，这个值是-1，为默认值，表示不限制。\n\ndefault_vcpu=1 default_memory=2gi overhead: "podfixed":{"cpu":"250m","memory":"160mi"} pod qos: resources: requests: memory: "500mi" cpu: "0.5" limits: memory: "3000mi" cpu: "4"\n\n\n# sandbox_cgroup_only=true\n\n"cgroupspath": "/kubepods/burstable/pod287707dd-0fda-4fab-874d-e1b00e87390a/c2bfeccb7580707e7559c00f7ee9d46e98745cc2a0d267fbb41c68da41df784f",\n\nkata_overhead-mem: ~8g（不限） kata_overhead-cpu: -1（不限） kubepods_mem: 3313500160 (~3.08g) (limit+overhead) kubepods_cpu cfs_period_us: 100000 cpu.cfs_quota_us 425000 (4.25核) （limit+overhead）\n\nlscpu: 5 (default+limit) lsmem： memory block size: 128m memory block size: 128m total online memory: 5g (default+limit)\n\nkubectl describe node | grep test-kata： 750m (9%) 4250m (54%)(limit+overhead) 660mi (10%) 3160mi (48%)(limit+overhead) 4m54s kubectl top pod： 1002m 1mi kubectl top node： 1306m 16% 5513mi 84%\n\n[root@localhost ~]# systemd-cgtop | grep kata /kata_overhead - - 4.9m - - /system.slice/kata-monitor.service 1 - 27.4m - - [root@localhost ~]# systemd-cgtop | grep pod287707dd-0fda-4fab-874d-e1b00e87390a /kubepods/burstable/pod287707dd-0fda-4fab-874d-e1b00e87390a - - 193.4m - -\n\n\n# sandbox_cgroup_only=false（结果同=true）\n\n"cgroupspath": "/kubepods/burstable/pod3a449bdd-90d5-41fd-a57a-9cfd102f9e44/87b5990ce61e4ff193124fc60e4a68c7061cf9299688c6c521cae29103bc3ef5",\n\nkata_overhead-mem: ~8g（不限） kata_overhead-cpu: -1（不限）\n\nkubepods_mem: 3313500160 (~3.08g) (limit+overhead) kubepods_cpu cfs_period_us: 100000 cpu.cfs_quota_us 425000 (4.25核) （limit+overhead）\n\n[root@localhost ~]# systemd-cgtop | grep kata /kata_overhead - - 4.9m - - /system.slice/kata-monitor.service 1 - 24.6m - - [root@localhost ~]# systemd-cgtop | grep pod3a449bdd-90d5-41fd-a57a-9cfd102f9e44 /kubepods/burstable/pod3a449bdd-90d5-41fd-a57a-9cfd102f9e44 - - 151.7m - -\n\nkubectl describe node | grep test-kata： 750m (9%) 4250m (54%)(limit+overhead) 660mi (10%) 3160mi (48%)(limit+overhead) 4m54s kubectl top pod： 1002m 1mi kubectl top node： 1330m 17% 5507mi 84%\n\n\n# 查看命令：\n\n[root@localhost ~]# systemd-cgtop | grep kata\n/kata_overhead                                                                                                                -      -     4.9m        -        -\n/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/kata_842463ada9994438f6c663b082bbf5735c64309f77a0b57838b8a16f347433a6       7      -   132.9m        -        -\n/system.slice/kata-monitor.service                                                                                            1      -    23.2m        -        -\n\n[root@localhost ~]# cat /sys/fs/cgroup/memory/kata_overhead/memory.limit_in_bytes\n9223372036854771712\n[root@localhost ~]#  cat /sys/fs/cgroup/cpu/kata_overhead/cpu.cfs_period_us\n100000\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/kata_overhead/cpu.cfs_quota_us\n-1\n\n[root@localhost ~]# cat /sys/fs/cgroup/memory/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/memory.limit_in_bytes\n1241513984\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/cpu.cfs_period_us\n100000\n[root@localhost ~]# cat /sys/fs/cgroup/cpu/kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/cpu.cfs_quota_us\n125000\n\n[root@localhost ~]#  cat /sys/fs/cgroup/memory/system.slice/kata-monitor.service/memory.limit_in_bytes\n9223372036854771712\n\n[root@localhost ~]# kubectl top pod test-kata\nname        cpu(cores)   memory(bytes)\ntest-kata   0m           2mi\n[root@localhost ~]# kubectl top node\nname                    cpu(cores)   cpu%   memory(bytes)   memory%\nlocalhost.localdomain   355m         4%     5469mi          83%\n\n[root@localhost ~]# kubectl describe node | grep kata\n  default                     test-kata                                                1250m (16%)   1250m (16%)  1184mi (18%)     1184mi (18%)   16d\n  kube-system                 kata-deploy-q2cnv                                        0 (0%)        0 (0%)       0 (0%)           0 (0%)         21d\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n\n\n\n# 验证2：如果不设置request limit，kubepod cgroup的限制是怎样的\n\n"cgroupspath": "/kubepods/besteffort/pod09a392bc-1080-4044-8015-39f392e3862f/367368f8f5c44bc69b277febfa5d533063f096c65cd9b6729bbc7847a582f51f",\n\nkata_overhead-mem: ~8g（不限） kata_overhead-cpu: -1（不限）\n\nkubepods_mem: 9223372036854771712 ~8g（不限） kubepods_cpu cfs_period_us cfs_quota_us: 100000 -1 不限 kubectl top pod： 1000m 0mi kubectl top node： 1316m 16% 5517mi 84%\n\n[root@localhost hff]# systemd-cgtop | grep kata /kata_overhead - - 4.9m - - /system.slice/kata-monitor.service 1 - 25.1m - -\n\n[root@localhost hff]# systemd-cgtop | grep pod09a392bc-1080-4044-8015-39f392e3862f /kubepods/besteffort/pod09a392bc-1080-4044-8015-39f392e3862f - - 95.8m - -\n\nkubectl describe node | grep test-kata： 250m (3%)（overhead） 0 (0%) 160mi (2%)（overhead） 0 (0%) 6m30s\n\nkubepod不限制，但是pod确实只能用到limit的值\n\n\n# 验证3： 验证overhead是否影响业务负载\n\n设置overhead 2c 2g后，limit 3c3g, 打满cpu=6,mem=3gi\n\n[root@localhost hff]# kubectl get pod\nname                              ready   status        restarts   age\ntest-kata-5687cdcb66-28lgn        0/1     outofmemory   0          17s\ntest-kata-5687cdcb66-2lmd5        0/1     outofmemory   0          11s\ntest-kata-5687cdcb66-2pbhm        0/1     outofmemory   0          23s\ntest-kata-5687cdcb66-575sb        0/1     outofmemory   0          19s\ntest-kata-5687cdcb66-5gvt2        0/1     outofmemory   0          5s\ntest-kata-5687cdcb66-62fbd        0/1     outofmemory   0          33s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 验证4：验证如果不设置request limit，cpu mem的使用上线\n\n设置overhead 2c 2g后，limit不设置， 打满cpu=6,mem=1gi\n\n[root@localhost hff]# kubectl get pod  -w\nname                              ready   status        restarts   age\ntest-kata-55867ffb58-26ndp        0/1     outofmemory   0          4s\ntest-kata-55867ffb58-2blnx        0/1     outofmemory   0          2s\ntest-kata-55867ffb58-2d858        0/1     outofmemory   0          1s\ntest-kata-55867ffb58-2qwzf        0/1     pending       0          0s\ntest-kata-55867ffb58-4j4hl        0/1     outofmemory   0          1s\ntest-kata-55867ffb58-8zzbc        0/1     outofmemory   0          2s\ntest-kata-55867ffb58-crflb        0/1     outofmemory   0          4s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 验证5： 验证cpu mem小于1c 256mi的情况（no overhead）\n\n    resources:\n      requests:\n        memory: "1mi"\n        cpu: "0.1"\n      limits:\n        memory: "100mi"\n        cpu: "550m"\n    args:\n    - -cpus\n    - "2"\n    - -mem-total\n    - 100mi\n    - -mem-alloc-size\n    - 10mi\n    - -mem-alloc-sleep\n    - 1s\n\n\n没有oom，但是pod不断重启，所有并没有被重置成2g\n\n[root@localhost hff]# kubectl get pod -w\nname                              ready   status    restarts   age\nkubefilebrowser-896974bcc-z6scd   1/1     running   3          31d\ntest-kata-6878f4fd9f-76c5k        1/1     running   2          61s\ntest-runc-79d8bdc4cb-v6j28        1/1     running   0          75m\ntest-kata-6878f4fd9f-76c5k        0/1     error     2          72s\ntest-kata-6878f4fd9f-76c5k        0/1     crashloopbackoff   2          75s\n\n[root@localhost hff]# kubectl logs test-kata-6878f4fd9f-76c5k\ni0527 07:16:06.932758       1 main.go:26] allocating "200mi" memory, in "10mi" chunks, with a 1s sleep between allocations\ni0527 07:16:06.933058       1 main.go:39] spawning a thread to consume cpu\ni0527 07:16:06.933082       1 main.go:39] spawning a thread to consume cpu\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 验证6： 极小资源占用测试\n\nlimit550m/200mi，压2c100mi，pod会不断重启，但是不是oomkilled\n\n        resources:\n          requests:\n            memory: "1mi"\n            cpu: "0.1"\n          limits:\n            memory: "200mi"\n            cpu: "550m"\n        args:\n        - -cpus\n        - "2"\n        - -mem-total\n        - 100mi\n        - -mem-alloc-size\n        - 10mi\n        - -mem-alloc-sleep\n        - 1s\nevents:\n  type     reason          age                   from                            message\n  ----     ------          ----                  ----                            -------\n  normal   scheduled       <unknown>             default-scheduler               successfully assigned default/test-kata-68b77bc9f8-zlj5p to localhost.localdomain\n  normal   created         36m (x4 over 38m)     kubelet, localhost.localdomain  created container cpu-stress-kata\n  normal   started         36m (x4 over 38m)     kubelet, localhost.localdomain  started container cpu-stress-kata\n  normal   sandboxchanged  35m (x4 over 37m)     kubelet, localhost.localdomain  pod sandbox changed, it will be killed and re-created.\n  normal   pulled          7m53s (x11 over 38m)  kubelet, localhost.localdomain  container image "vish/stress" already present on machine\n  warning  backoff         3m5s (x159 over 37m)  kubelet, localhost.localdomain  back-off restarting failed container\n[root@localhost hff]#\n[root@localhost hff]# kubectl logs test-kata-68b77bc9f8-zlj5p\ni0527 08:13:52.926368       1 main.go:26] allocating "100mi" memory, in "10mi" chunks, with a 1s sleep between allocations\ni0527 08:13:52.926544       1 main.go:39] spawning a thread to consume cpu\ni0527 08:13:52.926570       1 main.go:39] spawning a thread to consume cpu\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n\n\n\n# 验证7： 查看kata vm中的cgroup\n\n不设置limit，overhead\n\nbash-5.1# more /sys/fs/cgroup/memory/\ncgroup.clone_children               memory.max_usage_in_bytes\ncgroup.event_control                memory.memsw.failcnt\ncgroup.procs                        memory.memsw.limit_in_bytes\ncgroup.sane_behavior                memory.memsw.max_usage_in_bytes\nkubepods/                           memory.memsw.usage_in_bytes\nmemory.failcnt                      memory.move_charge_at_immigrate\nmemory.force_empty                  memory.oom_control\nmemory.kmem.failcnt                 memory.pressure_level\nmemory.kmem.limit_in_bytes          memory.soft_limit_in_bytes\nmemory.kmem.max_usage_in_bytes      memory.stat\nmemory.kmem.slabinfo                memory.swappiness\nmemory.kmem.tcp.failcnt             memory.usage_in_bytes\nmemory.kmem.tcp.limit_in_bytes      memory.use_hierarchy\nmemory.kmem.tcp.max_usage_in_bytes  notify_on_release\nmemory.kmem.tcp.usage_in_bytes      release_agent\nmemory.kmem.usage_in_bytes          system.slice/\nmemory.limit_in_bytes               tasks\nbash-5.1# more /sys/fs/cgroup/memory/kubepods/\nbesteffort/                         memory.max_usage_in_bytes\ncgroup.clone_children               memory.memsw.failcnt\ncgroup.event_control                memory.memsw.limit_in_bytes\ncgroup.procs                        memory.memsw.max_usage_in_bytes\nmemory.failcnt                      memory.memsw.usage_in_bytes\nmemory.force_empty                  memory.move_charge_at_immigrate\nmemory.kmem.failcnt                 memory.oom_control\nmemory.kmem.limit_in_bytes          memory.pressure_level\nmemory.kmem.max_usage_in_bytes      memory.soft_limit_in_bytes\nmemory.kmem.slabinfo                memory.stat\nmemory.kmem.tcp.failcnt             memory.swappiness\nmemory.kmem.tcp.limit_in_bytes      memory.usage_in_bytes\nmemory.kmem.tcp.max_usage_in_bytes  memory.use_hierarchy\nmemory.kmem.tcp.usage_in_bytes      notify_on_release\nmemory.kmem.usage_in_bytes          tasks\nmemory.limit_in_bytes\nbash-5.1# more /sys/fs/cgroup/cpu/cpu.cfs_quota_us\n-1\nbash-5.1# more /sys/fs/cgroup/cpu/kubepods/besteffort/cpu.cfs_quota_us\n-1\nbash-5.1# more /sys/fs/cgroup/cpu/kubepods/besteffort/pode0eb5953-c643-4429-8812-b8e36d75e3d9/f3cffcf893000b0c5f6105f1adb94e3be7fa62ebecd801a29b9a77a472d62c86/cfs_quota_us\n-1\nbash-5.1# more /sys/fs/cgroup/memory/memory.limit_in_bytes\n9223372036854771712\nbash-5.1#  more /sys/fs/cgroup/memory/kubepods/memory.limit_in_bytes\n9223372036854771712\nbash-5.1#  more /sys/fs/cgroup/memory/kubepods/besteffort/memory.limit_in_bytes\n9223372036854771712\nbash-5.1#  more /sys/fs/cgroup/memory/kubepods/besteffort/pode0eb5953-c643-4429-8812-b8e36d75e3d9/.limit_in_bytes\n9223372036854771712\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n未找到default_vcpu/memory是在哪里做的限制\n\n\n# kata cgroup说明\n\nkata containers 在两层 cgroup 上运行。\n\n * workload guest\n * vmm host （kata containers 在两层 cgroup 上运行。第一层在虚拟机中放置工作负载，而第二层在主机上运行 vmm和 关联线程。）\n\n从 kubernetes 角度来讲，cgroup 指的是 pod cgroup，由 kubelet 创建，限制的是 pod 的资源; 从 container 角度来讲，cgroup 指的是 container cgroup，由对应的 runtime 创建，限制的是 container 的资源。但是为了可以获取到更准确的容器资源，kubelet 会根据 container cgroup 去调整 pod cgroup。 在传统的 runtime 中，两者没有太大的区别。\n\n而 kata containers 引入 vm 的概念，所以针对这种情况有两种处理方式：\n\n * 启用 sandboxcgrouponly（默认），kubelet 在调整 pod cgroup 的大小时，会将 sandbox 的开销统计进去 （就是说，用户申请的资源limit+overhead是业务负载和kata虚拟机开销的最大使用限制，如果不设置limit，默认是default_vcpus/mem??）\n * 禁用 sandboxcgrouponly，sandbox 的开销和 pod cgroup 分开计算，独立存在 （就是说，用户申请的资源limit+overhead是业务负载自己的最大使用限制，kata虚拟机开销单独一个cgroup而且没有限制，如果不设置limit，业务使用默认是default_vcpus/mem）\n\n\n# 两种cgrouppath:\n\n * /kubepods/burstable/pod287707dd-0fda-4fab-874d-e1b00e87390a/c2bfeccb7580707e7559c00f7ee9d46e98745cc2a0d267fbb41c68da41df784f ()\n * /kubepods/pod24356d87-3993-4e9a-8d3f-55207af763f9/kata_842463ada9994438f6c663b082bbf5735c64309f77a0b57838b8a16f347433a6 ()\n\n\n# pod overhead\n\n\n# sandbox_cgroup_only\n\n * 如果启用，运行时将在一个专用cgroup中添加所有kata进程。每个沙盒只创建一个cgroup，主机中的container cgroup将不会创建\n * kata runtime调用者可以自由地限制或收集整个kata沙盒的cgroup统计信息。\n * sandbox cgroup路径是具有podsandbox annotation(???)的容器的父cgroup。\n * 如果没有container type annotation(??)，则sandbox cgroup将受到限制\n * 意味着 pod cgroup 的大小适当，并考虑了 pod 开销（设置podoverhead考虑调度）\n * kata shim 将在sandbox_cgroup_onlypod 的专用 cgroup 下为每个 pod 创建一个子 cgroup\n * kata shim、qemu 线程将与沙箱在同一个 cgroup 中。在这种情况下，它们将与 vcpu 线程共享同一组 cpu 内核\n\n=true好处：\n\n * 便于pod资源统计\n * 更好的主机资源隔离\n\n=fasle优点及缺点：\n\n * 不限制会消耗大量主机资源\n * 在专用开销cgroup下运行所有非vcpu线程可以提供有关实际的开销准确值，可以设置开销cgroup大小（手动修改，无接口）\n\n\n# default_vcpus/memory\n\n\n# kata资源开销\n\n * 半虚拟化 i/o 后端\n * vmm 实例\n * kata shim 进程\n * kata monitor开销（如果开启）\n\n\n# kata组件进程：\n\n * sandbox qemu-system-x86_64进程cgroup\n * containerd-shim-kata-v2进程\n * 两个virtiofsd进程\n\nkata pod起来后，其中，kata shim进程和qemu进程占用了大量的内存开销，其中，沙箱里的内核和 agent 是直接分享了应用内存但并不是应用的一部分，也就是说，这一部分是用户可见的开销。而 vmm 本身在宿主机上的开销以及 shim-v2 占用的内存，虽然用户应用不可见，但同样是 kata 带来的开销，影响基础设施的资源效率。\n\n这些内存开销里，还包括了可共享开销和不可共享开销。所有宿主这边的代码段内存（只读内存），可以共享 page cache，所以是共享的，而在沙箱里的代码（只读）内存，在使用 dax 或模版的情况下，也可以共享同一份。所以，可以共享的内存开销在节点全局范围内是唯一一份，所以在有多个pod的情况下，这部分的常数开销相对而言是不太重要的，相反的，不可共享开销，尤其是堆内存开销，会随着 pod 的增长而增长，的换句话说，堆内存（匿名页）是最需要被重视的开销。\n\n综上，第一位需要被遏制的开销是沙箱内的用户可见的不可共享开销，尤其是 agent 的开销，而 vmm 和 shim 的匿名页开销次之。\n\n\n# 不支持cgroups v2\n\n\n# 一些需要知道的配置\n\n# default number of vcpus per sb/vm:\n# unspecified or 0                --\x3e will be set to 1（不设置或0则默认是1）\n# < 0                             --\x3e will be set to the actual number of physical cores(小于0则设为实际物理核)\n# > 0 <= number of physical cores --\x3e will be set to the specified number\n# > number of physical cores      --\x3e will be set to the actual number of physical cores（大于物理核默认为物理核）\ndefault_vcpus = 1\n\n# default memory size in mib for sb/vm.\n# if unspecified then it will be set 2048 mib.（不设置默认是2gi）\ndefault_memory = 2048\n\n# default maximum number of vcpus per sb/vm:\n# unspecified or == 0             --\x3e will be set to the actual number of physical cores or to the maximum number（不设置或0默认为最大物理核数）\n#                                     of vcpus supported by kvm if that number is exceeded\n# > 0 <= number of physical cores --\x3e will be set to the specified number\n# > number of physical cores      --\x3e will be set to the actual number of physical cores or to the maximum number\n#                                     of vcpus supported by kvm if that number is exceeded\n# warning: depending of the architecture, the maximum number of vcpus supported by kvm is used when\n# the actual number of physical cores is greater than it.\n# warning: be aware that this value impacts the virtual machine\'s memory footprint and cpu\n# the hotplug functionality. for example, `default_maxvcpus = 240` specifies that until 240 vcpus\n# can be added to a sb/vm, but the memory footprint will be big. another example, with\n# `default_maxvcpus = 8` the memory footprint will be small, but 8 will be the maximum number of\n# vcpus supported by the sb/vm. in general, we recommend that you do not edit this variable,\n# unless you know what are you doing.\n# notice: on arm platform with gicv2 interrupt controller, set it to 8.\ndefault_maxvcpus = 0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n\n\n\n# 通过注释修改配置：\n\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n runtime_type = "io.containerd.kata.v2"\n privileged_without_host_devices = false\n shim_debug = true\n pod_annotations = ["io.katacontainers.*"] #  <-- look here\n\n\n1\n2\n3\n4\n5\n\n\n> io.katacontainers.config.hypervisor.default_vcpus = 5\n\n\n# 打开--feature-gates podoverhead\n\n> /etc/kubernetes/manifests/kube-apiserver.yaml\n\n1.17默认关闭，1.18默认打开\n\n> environment="kubelet_feature=--feature-gates=rotatekubeletservercertificate=true,volumesnapshotdatasource=true,expandcsivolumes=true,volumepvcdatasource=true,servicetopology=true,endpointslice=true,podoverhead=true"\n\n\n# 启用runtimeclass准入控制\n\n> --feature-gates=volumesnapshotdatasource=true,expandcsivolumes=true,volumepvcdatasource=true,ttlafterfinished=true,servicetopology=true,endpointslice=true,podoverhead=true\n\n\n# 设置podoverhead\n\nkind: runtimeclass\napiversion: node.k8s.io/v1beta1\nmetadata:\n  name: kata-containers\nhandler: kata\noverhead:\n  podfixed:\n  memory: "100mi"\n  cpu: "100m"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# virtio-mem内存热插拔（仅支持qemu）\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-use-virtio-mem-with-kata.md\n\n$ sudo sed -i -e \'s/^#enable_virtio_mem.*$/enable_virtio_mem = true/g\' /etc/kata-containers/configuration.toml\n\n\n1\n\n\n\n# 附件\n\n---\napiversion: apps/v1\nkind: deployment\nmetadata:\n  name: test-kata\nspec:\n  replicas: 1\n  selector:\n    matchlabels:\n      app: test-kata\n  template:\n    metadata:\n      labels:\n        app: test-kata\n    spec:\n      runtimeclassname: kata-containers\n      containers:\n      - image: vish/stress\n        imagepullpolicy: ifnotpresent\n        name: cpu-stress-kata\n        resources:\n          requests:\n            memory: "1mi"\n            cpu: "0.1"\n          limits:\n            memory: "161mi"\n            cpu: "350m"\n        args:\n        - -cpus\n        - "2"\n        - -mem-total\n        - 100mi\n        - -mem-alloc-size\n        - 10mi\n        - -mem-alloc-sleep\n        - 1s\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"guest kernel和guestos",frontmatter:{title:"guest kernel和guestos",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata4/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:"系统管理程序 hypervisor将启动一个虚拟机，该虚拟机包括最小的 虚拟机内核和虚拟机镜像。",meta:[{name:"twitter:title",content:"guest kernel和guestos"},{name:"twitter:description",content:"系统管理程序 hypervisor将启动一个虚拟机，该虚拟机包括最小的 虚拟机内核和虚拟机镜像。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/04.guest%20kernel%E5%92%8Cguestos.html"},{property:"og:type",content:"article"},{property:"og:title",content:"guest kernel和guestos"},{property:"og:description",content:"系统管理程序 hypervisor将启动一个虚拟机，该虚拟机包括最小的 虚拟机内核和虚拟机镜像。"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/04.guest%20kernel%E5%92%8Cguestos.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"guest kernel和guestos"},{itemprop:"description",content:"系统管理程序 hypervisor将启动一个虚拟机，该虚拟机包括最小的 虚拟机内核和虚拟机镜像。"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/04.guest%20kernel%E5%92%8Cguestos.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/04.guest kernel和guestos.md",key:"v-e15ee02a",path:"/pages/kata4/",headers:[{level:2,title:"image type(rootfs)",slug:"image-type-rootfs",normalizedTitle:"image type(rootfs)",charIndex:821},{level:2,title:"initrd type",slug:"initrd-type",normalizedTitle:"initrd type",charIndex:943},{level:2,title:"使用 Kata 配置文件configuration.toml（全局）",slug:"使用-kata-配置文件configuration-toml-全局",normalizedTitle:"使用 kata 配置文件configuration.toml（全局）",charIndex:2209},{level:2,title:"使用注释",slug:"使用注释",normalizedTitle:"使用注释",charIndex:2338}],headersStr:"image type(rootfs) initrd type 使用 Kata 配置文件configuration.toml（全局） 使用注释",content:'系统管理程序 hypervisor将启动一个虚拟机，该虚拟机包括最小的 虚拟机内核和虚拟机镜像。\n\n\n# 配置\n\n[hypervisor.qemu]\npath = "/opt/kata/bin/qemu-system-x86_64"\nkernel = "/opt/kata/share/kata-containers/vmlinux.container"\nimage = "/opt/kata/share/kata-containers/kata-containers.img"\nmachine_type = "q35"\n[Kernel]\n Path = "/opt/kata/share/kata-containers/vmlinux-5.15.23-89"\n Parameters = "systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026"\n [Image]\n Path = "/opt/kata/share/kata-containers/kata-clearlinux-latest.image"\n [Initrd]\n Path = ""\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# Guest kernel\n\n用于启动VM。Kata-container高度优化了内核启动时间和极小的内存占用，只用于一个容器的运行。\n\n\n# Guest image\n\n支持基于initrd和rootfs(image)的最小镜像，默认包中提供一个镜像和一个initrd，他们都是通过osbuilder生成的。\n\n\n# image type(rootfs)\n\n默认的 root filesystem image (有时称为mini O/S)是一个基于 Clear Linux 的高度优化的容器引导系统。它提供了一个极小的环境，并有一个高度优化的引导路径。\n\n\n# initrd type\n\n压缩的 cpio(1) 文件，从 rootfs （被载入内存并作为 linux 启动过程的一部分被使用）创建。\n\nKata 运行时配置文件中的initrd和image选项之一必须设置，但不能同时设置。选项之间的主要区别在于initrd(10MB+) 的大小明显小于 rootfs image(100MB+)。\n\n通过initrd=和image=配置决定使用哪一个类型\n\n\n# 最小镜像极度简化\n\nhttps://github.com/kata-containers/kata-containers/issues/2010\n\n\n# 内核构建build-kernel.sh\n\nhttps://github.com/kata-containers/kata-containers/tree/main/tools/packaging/kernel\n\n例子：\n\n$ ./build-kernel.sh -v 5.10.25 -g nvidia -f -d setup\n· -v 5.10.25：指定来宾内核版本。\n· -g nvidia: 构建一个支持 Nvidia GPU 的来宾内核。\n· -f:.config即使内核目录已经存在也强制生成文件。\n· -d: 启用 bash 调试模式。\n\n\n1\n2\n3\n4\n5\n\n\n添加补丁：${GOPATH}/src/github.com/kata-containers/kata-containers/tools/packaging/kernel/patches/\n\n内核配置：${GOPATH}/src/github.com/kata-containers/kata-containers/tools/packaging/kernel/configs/\n\n\n# osbuilder\n\nhttps://github.com/kata-containers/kata-containers/tree/main/tools/osbuilder\n\n\n# 修改内核参数\n\n[Kernel]\n Path = "/opt/kata/share/kata-containers/vmlinux-5.15.23-89"\n Parameters = "systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026"\n\n\n1\n2\n3\n\n\n\n# 加载内核模块\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-load-kernel-modules-with-kata.md\n\n\n# 使用 Kata 配置文件configuration.toml（全局）\n\n> \n\nkernel_modules =[ “ e1000e InterruptThrottleRate=3000,3000,3000 EEE=1 ” , “ i915 ” ]\n\n\n# 使用注释\n\nannotations:\n  io.katacontainers.config.agent.kernel_modules: "e1000e EEE=1; i915"spec:\n\n\n1\n2\n\n\n\n# 使用 Kata 设置sysctl\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-use-sysctls-with-kata.md\n\nsysctl 使用 pod 的 securityContext 在 pod 上设置。securityContext 适用于同一 pod 中的所有容器。\n\napiVersion: v1kind: Podmetadata:\nname: sysctl-examplespec:\nsecurityContext:\n  sysctls:\n   - name: kernel.shm_rmid_forced\n     value: "0"\n   - name: net.ipv4.route.min_pmtu\n     value: "552"\n   - name: kernel.msgmax\n     value: "65536"\n ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n所有安全sysctls默认被开启\n\n使用不安全的 sysctls，集群管理员需要允许这些：\n\n$ kubelet --allowed-unsafe-sysctls \'kernel.msg*,net.ipv4.route.min_pmtu\' ...\n\n\n1\n',normalizedContent:'系统管理程序 hypervisor将启动一个虚拟机，该虚拟机包括最小的 虚拟机内核和虚拟机镜像。\n\n\n# 配置\n\n[hypervisor.qemu]\npath = "/opt/kata/bin/qemu-system-x86_64"\nkernel = "/opt/kata/share/kata-containers/vmlinux.container"\nimage = "/opt/kata/share/kata-containers/kata-containers.img"\nmachine_type = "q35"\n[kernel]\n path = "/opt/kata/share/kata-containers/vmlinux-5.15.23-89"\n parameters = "systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026"\n [image]\n path = "/opt/kata/share/kata-containers/kata-clearlinux-latest.image"\n [initrd]\n path = ""\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# guest kernel\n\n用于启动vm。kata-container高度优化了内核启动时间和极小的内存占用，只用于一个容器的运行。\n\n\n# guest image\n\n支持基于initrd和rootfs(image)的最小镜像，默认包中提供一个镜像和一个initrd，他们都是通过osbuilder生成的。\n\n\n# image type(rootfs)\n\n默认的 root filesystem image (有时称为mini o/s)是一个基于 clear linux 的高度优化的容器引导系统。它提供了一个极小的环境，并有一个高度优化的引导路径。\n\n\n# initrd type\n\n压缩的 cpio(1) 文件，从 rootfs （被载入内存并作为 linux 启动过程的一部分被使用）创建。\n\nkata 运行时配置文件中的initrd和image选项之一必须设置，但不能同时设置。选项之间的主要区别在于initrd(10mb+) 的大小明显小于 rootfs image(100mb+)。\n\n通过initrd=和image=配置决定使用哪一个类型\n\n\n# 最小镜像极度简化\n\nhttps://github.com/kata-containers/kata-containers/issues/2010\n\n\n# 内核构建build-kernel.sh\n\nhttps://github.com/kata-containers/kata-containers/tree/main/tools/packaging/kernel\n\n例子：\n\n$ ./build-kernel.sh -v 5.10.25 -g nvidia -f -d setup\n· -v 5.10.25：指定来宾内核版本。\n· -g nvidia: 构建一个支持 nvidia gpu 的来宾内核。\n· -f:.config即使内核目录已经存在也强制生成文件。\n· -d: 启用 bash 调试模式。\n\n\n1\n2\n3\n4\n5\n\n\n添加补丁：${gopath}/src/github.com/kata-containers/kata-containers/tools/packaging/kernel/patches/\n\n内核配置：${gopath}/src/github.com/kata-containers/kata-containers/tools/packaging/kernel/configs/\n\n\n# osbuilder\n\nhttps://github.com/kata-containers/kata-containers/tree/main/tools/osbuilder\n\n\n# 修改内核参数\n\n[kernel]\n path = "/opt/kata/share/kata-containers/vmlinux-5.15.23-89"\n parameters = "systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026"\n\n\n1\n2\n3\n\n\n\n# 加载内核模块\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-load-kernel-modules-with-kata.md\n\n\n# 使用 kata 配置文件configuration.toml（全局）\n\n> \n\nkernel_modules =[ “ e1000e interruptthrottlerate=3000,3000,3000 eee=1 ” , “ i915 ” ]\n\n\n# 使用注释\n\nannotations:\n  io.katacontainers.config.agent.kernel_modules: "e1000e eee=1; i915"spec:\n\n\n1\n2\n\n\n\n# 使用 kata 设置sysctl\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-use-sysctls-with-kata.md\n\nsysctl 使用 pod 的 securitycontext 在 pod 上设置。securitycontext 适用于同一 pod 中的所有容器。\n\napiversion: v1kind: podmetadata:\nname: sysctl-examplespec:\nsecuritycontext:\n  sysctls:\n   - name: kernel.shm_rmid_forced\n     value: "0"\n   - name: net.ipv4.route.min_pmtu\n     value: "552"\n   - name: kernel.msgmax\n     value: "65536"\n ...\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n所有安全sysctls默认被开启\n\n使用不安全的 sysctls，集群管理员需要允许这些：\n\n$ kubelet --allowed-unsafe-sysctls \'kernel.msg*,net.ipv4.route.min_pmtu\' ...\n\n\n1\n',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata使用限制",frontmatter:{title:"kata使用限制",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata6/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"kata使用限制"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/06.kata%E4%BD%BF%E7%94%A8%E9%99%90%E5%88%B6.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata使用限制"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/06.kata%E4%BD%BF%E7%94%A8%E9%99%90%E5%88%B6.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata使用限制"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/06.kata%E4%BD%BF%E7%94%A8%E9%99%90%E5%88%B6.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/06.kata使用限制.md",key:"v-3a4f35cc",path:"/pages/kata6/",headers:[{level:2,title:"CLI命令：不支持docker和Podman",slug:"cli命令-不支持docker和podman",normalizedTitle:"cli命令：不支持docker和podman",charIndex:358},{level:2,title:"runtime命令：不支持checkpoint、restore、events 、update",slug:"runtime命令-不支持checkpoint、restore、events-、update",normalizedTitle:"runtime命令：不支持checkpoint、restore、events 、update",charIndex:415},{level:2,title:"网络？未列出",slug:"网络-未列出",normalizedTitle:"网络？未列出",charIndex:466},{level:2,title:"资源管理",slug:"资源管理",normalizedTitle:"资源管理",charIndex:477},{level:3,title:"docker 的--cpu",slug:"docker-的-cpu",normalizedTitle:"docker 的--cpu",charIndex:539},{level:3,title:"vcpus",slug:"vcpus",normalizedTitle:"vcpus",charIndex:557},{level:2,title:"架构限制",slug:"架构限制",normalizedTitle:"架构限制",charIndex:567},{level:3,title:"存储限制subPaths",slug:"存储限制subpaths",normalizedTitle:"存储限制subpaths",charIndex:576},{level:3,title:"主机资源共享:securityContext privileged",slug:"主机资源共享-securitycontext-privileged",normalizedTitle:"主机资源共享:securitycontext privileged",charIndex:593},{level:2,title:"通过guest kernel参数设置限制kata vm，如sysctl参数等",slug:"通过guest-kernel参数设置限制kata-vm-如sysctl参数等",normalizedTitle:"通过guest kernel参数设置限制kata vm，如sysctl参数等",charIndex:734},{level:2,title:"限制kata container",slug:"限制kata-container",normalizedTitle:"限制kata container",charIndex:777},{level:2,title:"通过主机级约束限制hypervisor；设置hypervisor参数",slug:"通过主机级约束限制hypervisor-设置hypervisor参数",normalizedTitle:"通过主机级约束限制hypervisor；设置hypervisor参数",charIndex:798}],headersStr:"CLI命令：不支持docker和Podman runtime命令：不支持checkpoint、restore、events 、update 网络？未列出 资源管理 docker 的--cpu vcpus 架构限制 存储限制subPaths 主机资源共享:securityContext privileged 通过guest kernel参数设置限制kata vm，如sysctl参数等 限制kata container 通过主机级约束限制hypervisor；设置hypervisor参数",content:"https://github.com/kata-containers/kata-containers/blob/main/docs/Limitations.md\n\nkata在硬件隔离的虚拟机中运行容器，每个vm都有独立的内核，由于这种高程度的隔离，某些容器功能无法启用，或者通过vm隐式启用。\n\nOCI 规范定义了运行时必须支持的最低规范，以便与 Docker 等容器管理器进行互操作。如果运行时不支持 OCI 规范的某些方面，则根据定义它是一个限制。\n\n但是，runc并不完全符合 OCI 规范本身。\n\n以下是社区列出的限制 https://github.com/pulls?q=label%3Alimitation+org%3Akata-containers+is%3Aopen\n\n\n# 一些列出的限制\n\n\n# CLI命令：不支持docker和Podman\n\n不支持docker --runtime指定kata运行时\n\n\n# runtime命令：不支持checkpoint、restore、events 、update\n\n\n# 网络？未列出\n\n\n# 资源管理\n\n对于基于 VM 的系统，将 cgroup、CPU、内存和存储等资源约束应用于工作负载并不总是那么简单。\n\n\n# docker 的--cpu\n\n\n# vcpus\n\n\n# 架构限制\n\n\n# 存储限制subPaths\n\n\n# 主机资源共享:securityContext privileged\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/privileged.md\n\n\n# kata容器限制级别\n\n\n# 通过guest kernel参数设置限制kata vm，如sysctl参数等\n\n\n# 限制kata container\n\n\n# 通过主机级约束限制hypervisor；设置hypervisor参数",normalizedContent:"https://github.com/kata-containers/kata-containers/blob/main/docs/limitations.md\n\nkata在硬件隔离的虚拟机中运行容器，每个vm都有独立的内核，由于这种高程度的隔离，某些容器功能无法启用，或者通过vm隐式启用。\n\noci 规范定义了运行时必须支持的最低规范，以便与 docker 等容器管理器进行互操作。如果运行时不支持 oci 规范的某些方面，则根据定义它是一个限制。\n\n但是，runc并不完全符合 oci 规范本身。\n\n以下是社区列出的限制 https://github.com/pulls?q=label%3alimitation+org%3akata-containers+is%3aopen\n\n\n# 一些列出的限制\n\n\n# cli命令：不支持docker和podman\n\n不支持docker --runtime指定kata运行时\n\n\n# runtime命令：不支持checkpoint、restore、events 、update\n\n\n# 网络？未列出\n\n\n# 资源管理\n\n对于基于 vm 的系统，将 cgroup、cpu、内存和存储等资源约束应用于工作负载并不总是那么简单。\n\n\n# docker 的--cpu\n\n\n# vcpus\n\n\n# 架构限制\n\n\n# 存储限制subpaths\n\n\n# 主机资源共享:securitycontext privileged\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/privileged.md\n\n\n# kata容器限制级别\n\n\n# 通过guest kernel参数设置限制kata vm，如sysctl参数等\n\n\n# 限制kata container\n\n\n# 通过主机级约束限制hypervisor；设置hypervisor参数",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata-monitor监控",frontmatter:{title:"kata-monitor监控",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata5/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:"https://github.com/kata-containers/kata-containers/blob/main/docs/design/kata-2-0-metrics.md",meta:[{name:"twitter:title",content:"kata-monitor监控"},{name:"twitter:description",content:"https://github.com/kata-containers/kata-containers/blob/main/docs/design/kata-2-0-metrics.md"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/05.kata-monitor%E7%9B%91%E6%8E%A7.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata-monitor监控"},{property:"og:description",content:"https://github.com/kata-containers/kata-containers/blob/main/docs/design/kata-2-0-metrics.md"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/05.kata-monitor%E7%9B%91%E6%8E%A7.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata-monitor监控"},{itemprop:"description",content:"https://github.com/kata-containers/kata-containers/blob/main/docs/design/kata-2-0-metrics.md"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/05.kata-monitor%E7%9B%91%E6%8E%A7.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/05.kata-monitor监控.md",key:"v-50a8e3a0",path:"/pages/kata5/",headers:[{level:2,title:"kata-monitor启动方式",slug:"kata-monitor启动方式",normalizedTitle:"kata-monitor启动方式",charIndex:282},{level:2,title:"promethues增加scrape_configs",slug:"promethues增加scrape-configs",normalizedTitle:"promethues增加scrape_configs",charIndex:1078},{level:2,title:"导入 Grafana dashborad",slug:"导入-grafana-dashborad",normalizedTitle:"导入 grafana dashborad",charIndex:1193},{level:2,title:"Kata Containers 目前采集了下面几种类型的 metrics：",slug:"kata-containers-目前采集了下面几种类型的-metrics",normalizedTitle:"kata containers 目前采集了下面几种类型的 metrics：",charIndex:1927},{level:2,title:"promethues监控负载指标",slug:"promethues监控负载指标",normalizedTitle:"promethues监控负载指标",charIndex:2725},{level:2,title:"指标的性能与开销",slug:"指标的性能与开销",normalizedTitle:"指标的性能与开销",charIndex:2966}],headersStr:"kata-monitor启动方式 promethues增加scrape_configs 导入 Grafana dashborad Kata Containers 目前采集了下面几种类型的 metrics： promethues监控负载指标 指标的性能与开销",content:'https://github.com/kata-containers/kata-containers/blob/main/docs/design/kata-2-0-metrics.md\n\nkata-monitor 进程运行在宿主机上，负责从各 Kata Containers 容器/VM中获取 metrics，并返回给 Prometheus。\n\n默认情况下 kata-monitor 不需要指定参数，它会监听在本地的 8090 端口，这也是在 Prometheus 配置文件中 target 指定的端口号。如果要修改这个端口号，则需要注意两处要保持一致。\n\n\n# kata-monitor启动方式\n\n 1. kata节点运行kata-monitor守护进程\n\n[root@localhost ~]# cat /etc/systemd/system/kata-monitor.service\n[Unit]\nDescription=kata monitor\n\n[Service]\nExecStart=/opt/kata/bin/kata-monitor -listen-address 0.0.0.0:8090\nRestart=always\nStartLimitInterval=0\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 2. daemonset(？？没有镜像，手动编译不过)（TODO）\n\n$ kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/how-to/data/kata-monitor-daemonset.yml\n\n\n1\n\n\nOnce the daemonset is running, Prometheus should discover kata-monitor as a target. You can open http://:30909/service-discovery and find kubernetes-pods under the Service Discovery list\n\n * 关于没有kata-monitor 镜像问题 https://github.com/kata-containers/kata-containers/issues/2421\n\n\n# promethues增加scrape_configs\n\n- job_name: \'kata\'\n    static_configs:\n    - targets: [\'<kata节点IP>:8090\']\n\n\n1\n2\n3\n\n\n\n# 导入 Grafana dashborad\n\n[root@localhost ~]# curl -XPOST -i <grafana节点IP>:3000/api/dashboards/import \\\n>     -u admin:admin \\\n>     -H "Content-Type: application/json" \\\n> -d "{\\"dashboard\\":$(curl -sL https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/how-to/data/dashboard.json )}"\n\nHTTP/1.1 100 Continue\n\nHTTP/1.1 200 OK\nContent-Type: application/json\nDate: Mon, 16 May 2022 05:16:33 GMT\nContent-Length: 253\n\n{"pluginId":"","title":"Kata containers","imported":true,"importedUri":"db/kata-containers","importedUrl":"/d/75pdqURGk/kata-containers","slug":"","dashboardId":0,"folderId":0,"importedRevision":1,"revision":1,"description":"","path":"","removed":false}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 监控指标\n\n\n# Kata Containers 目前采集了下面几种类型的 metrics：\n\nKata agent metrics：agent 进程的 metrics Kata guest OS metrics：VM 中的 guest metrics Hypervisor metrics：hypervisor 进程的 metrics（如果 hypervisor 本身提供了 metrics 接口，比如 firecracker，也会采集到 Kata Containers 的 metrics） Kata monitor metrics：kata-monitor 进程的 metrics Kata containerd shim v2 metrics：shimv2 进程的 metrics\n\n在kata vm中/proc//io stat status等的数据 kata_agent_io_stat代理进程 IO 统计 kata_agent_process_cpu_seconds_total 以秒为单位花费的总用户和系统 CPU 时间。 kata_agent_total_vm\n\n在kata vm中/proc/stat diskstats meminfo等的数据 kata_guest_cpu_time kata_guest_diskstat kata_guest_load kata_guest_meminfo kata_guest_vm_stat\n\nkata_hypervisor_io_stat 处理IO统计 kata_hypervisor_proc_stat 进程统计\n\nkata_shim_pod_overhead_cpu CPU 资源的 Kata Pod 开销（百分比） kata_shim_pod_overhead_memory_in_bytes Kata Pod 的内存资源开销（字节）\n\n\n# promethues监控负载指标\n\n * container_fs_writes_bytes_total\n\n * container_cpu_usage_seconds_total没有container字段\n\n * \n\nsum(irate(container_cpu_usage_seconds_total{namespace=~"${allNamespace}",pod=~"^${loadNames}",container!=""}[3m]))by(pod)\n\n\n1\n\n\n\n# 指标的性能与开销\n\n * 端到端（从 Prometheus 服务器到kata-monitor并kata-monitor写回响应）：20 毫秒（平均）\n\n * 代理（从 shim 到agent的所有 RPC）：3 毫秒（平均）\n\n * Prometheus 默认scrape_interval为 1 分钟，但通常设置为 15 秒。较小scrape_interval会导致更多开销，因此用户应根据自己的监控需求进行设置。\n   \n   Prometheus 发出的一个指标获取请求的大小。当没有 gzip 压缩时，计算预期大小的公式是：\n   9 + (144 - 9) *number of kata sandboxes Prometheus支持gzip压缩. 启用后，每个请求的响应大小会更小：\n   2 + (10 - 2) *number of kata sandboxes\n\n\n# endpoint\n\nkata-monitor公开了以下endpoint·：\n\n * /metrics : 获取 Kata 沙箱指标。\n * /sandboxes : 列出主机上运行的所有 Kata 沙箱。\n * /agent-url : 获取 Kata 沙箱的代理 URL。\n * /debug/vars : Kata 运行时 shim 的内部数据。\n * /debug/pprof/ : Kata 运行时 shim 的 Golang 分析数据：索引页。\n * /debug/pprof/cmdline : Kata 运行时 shim 的 Golang 分析数据：cmdlineendpoint。\n * /debug/pprof/profile : Kata 运行时 shim 的 Golang 分析数据：profileendpoint（CPU 分析）。\n * /debug/pprof/symbol : Kata 运行时 shim 的 Golang 分析数据：symbolendpoint。\n * /debug/pprof/trace : Kata 运行时 shim 的 Golang 分析数据：traceendpoint。\n\n/agent-url和所有/debug/ * 都需要在查询字符串中指定sandbox_id\n\ncurl 127.0.0.1:8090/sandboxes curl 127.0.0.1:8090/agent-url?sandboxes=df96b24bd49ec437c872c1a758edc084121d607ce1242ff5d2263a0e1b693343',normalizedContent:'https://github.com/kata-containers/kata-containers/blob/main/docs/design/kata-2-0-metrics.md\n\nkata-monitor 进程运行在宿主机上，负责从各 kata containers 容器/vm中获取 metrics，并返回给 prometheus。\n\n默认情况下 kata-monitor 不需要指定参数，它会监听在本地的 8090 端口，这也是在 prometheus 配置文件中 target 指定的端口号。如果要修改这个端口号，则需要注意两处要保持一致。\n\n\n# kata-monitor启动方式\n\n 1. kata节点运行kata-monitor守护进程\n\n[root@localhost ~]# cat /etc/systemd/system/kata-monitor.service\n[unit]\ndescription=kata monitor\n\n[service]\nexecstart=/opt/kata/bin/kata-monitor -listen-address 0.0.0.0:8090\nrestart=always\nstartlimitinterval=0\nrestartsec=10\n\n[install]\nwantedby=multi-user.target\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n 2. daemonset(？？没有镜像，手动编译不过)（todo）\n\n$ kubectl apply -f https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/how-to/data/kata-monitor-daemonset.yml\n\n\n1\n\n\nonce the daemonset is running, prometheus should discover kata-monitor as a target. you can open http://:30909/service-discovery and find kubernetes-pods under the service discovery list\n\n * 关于没有kata-monitor 镜像问题 https://github.com/kata-containers/kata-containers/issues/2421\n\n\n# promethues增加scrape_configs\n\n- job_name: \'kata\'\n    static_configs:\n    - targets: [\'<kata节点ip>:8090\']\n\n\n1\n2\n3\n\n\n\n# 导入 grafana dashborad\n\n[root@localhost ~]# curl -xpost -i <grafana节点ip>:3000/api/dashboards/import \\\n>     -u admin:admin \\\n>     -h "content-type: application/json" \\\n> -d "{\\"dashboard\\":$(curl -sl https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/how-to/data/dashboard.json )}"\n\nhttp/1.1 100 continue\n\nhttp/1.1 200 ok\ncontent-type: application/json\ndate: mon, 16 may 2022 05:16:33 gmt\ncontent-length: 253\n\n{"pluginid":"","title":"kata containers","imported":true,"importeduri":"db/kata-containers","importedurl":"/d/75pdqurgk/kata-containers","slug":"","dashboardid":0,"folderid":0,"importedrevision":1,"revision":1,"description":"","path":"","removed":false}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n\n\n\n# 监控指标\n\n\n# kata containers 目前采集了下面几种类型的 metrics：\n\nkata agent metrics：agent 进程的 metrics kata guest os metrics：vm 中的 guest metrics hypervisor metrics：hypervisor 进程的 metrics（如果 hypervisor 本身提供了 metrics 接口，比如 firecracker，也会采集到 kata containers 的 metrics） kata monitor metrics：kata-monitor 进程的 metrics kata containerd shim v2 metrics：shimv2 进程的 metrics\n\n在kata vm中/proc//io stat status等的数据 kata_agent_io_stat代理进程 io 统计 kata_agent_process_cpu_seconds_total 以秒为单位花费的总用户和系统 cpu 时间。 kata_agent_total_vm\n\n在kata vm中/proc/stat diskstats meminfo等的数据 kata_guest_cpu_time kata_guest_diskstat kata_guest_load kata_guest_meminfo kata_guest_vm_stat\n\nkata_hypervisor_io_stat 处理io统计 kata_hypervisor_proc_stat 进程统计\n\nkata_shim_pod_overhead_cpu cpu 资源的 kata pod 开销（百分比） kata_shim_pod_overhead_memory_in_bytes kata pod 的内存资源开销（字节）\n\n\n# promethues监控负载指标\n\n * container_fs_writes_bytes_total\n\n * container_cpu_usage_seconds_total没有container字段\n\n * \n\nsum(irate(container_cpu_usage_seconds_total{namespace=~"${allnamespace}",pod=~"^${loadnames}",container!=""}[3m]))by(pod)\n\n\n1\n\n\n\n# 指标的性能与开销\n\n * 端到端（从 prometheus 服务器到kata-monitor并kata-monitor写回响应）：20 毫秒（平均）\n\n * 代理（从 shim 到agent的所有 rpc）：3 毫秒（平均）\n\n * prometheus 默认scrape_interval为 1 分钟，但通常设置为 15 秒。较小scrape_interval会导致更多开销，因此用户应根据自己的监控需求进行设置。\n   \n   prometheus 发出的一个指标获取请求的大小。当没有 gzip 压缩时，计算预期大小的公式是：\n   9 + (144 - 9) *number of kata sandboxes prometheus支持gzip压缩. 启用后，每个请求的响应大小会更小：\n   2 + (10 - 2) *number of kata sandboxes\n\n\n# endpoint\n\nkata-monitor公开了以下endpoint·：\n\n * /metrics : 获取 kata 沙箱指标。\n * /sandboxes : 列出主机上运行的所有 kata 沙箱。\n * /agent-url : 获取 kata 沙箱的代理 url。\n * /debug/vars : kata 运行时 shim 的内部数据。\n * /debug/pprof/ : kata 运行时 shim 的 golang 分析数据：索引页。\n * /debug/pprof/cmdline : kata 运行时 shim 的 golang 分析数据：cmdlineendpoint。\n * /debug/pprof/profile : kata 运行时 shim 的 golang 分析数据：profileendpoint（cpu 分析）。\n * /debug/pprof/symbol : kata 运行时 shim 的 golang 分析数据：symbolendpoint。\n * /debug/pprof/trace : kata 运行时 shim 的 golang 分析数据：traceendpoint。\n\n/agent-url和所有/debug/ * 都需要在查询字符串中指定sandbox_id\n\ncurl 127.0.0.1:8090/sandboxes curl 127.0.0.1:8090/agent-url?sandboxes=df96b24bd49ec437c872c1a758edc084121d607ce1242ff5d2263a0e1b693343',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"其他特性",frontmatter:{title:"其他特性",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata7/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"其他特性"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/07.%E5%85%B6%E4%BB%96%E7%89%B9%E6%80%A7.html"},{property:"og:type",content:"article"},{property:"og:title",content:"其他特性"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/07.%E5%85%B6%E4%BB%96%E7%89%B9%E6%80%A7.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"其他特性"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/07.%E5%85%B6%E4%BB%96%E7%89%B9%E6%80%A7.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/07.其他特性.md",key:"v-77a29116",path:"/pages/kata7/",headersStr:null,content:"# vm cache\n\nVMCache 服务器将创建一些 VM 并通过工厂缓存对其进行缓存。它将 VM 转换为 gRPC 格式，并在收到客户端请求时进行传输。\n\nvm_cache_number指定VMCache的缓存数量：\n- 未指定或 == 0\n  VMCache 已禁用\n- \\> 0\n  将被设置为指定的数字\nvm_cache_endpoint指定 Unix 套接字的地址。\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过调用创建一个 VM 模板供以后使用：\n\n$ sudo kata-runtime factory init\n\n\n1\n\n\n\n# 虚拟机模板\n\n\n# 特权容器\n\n具有通常不授予的附加功能和访问权限 如果配置不正确，它可能会降低 Kata Containers 的安全性。\n\n默认情况下，当为容器启用特权时，/dev/*主机中的所有块设备都会挂载到guest中。这将允许 Kata guest内部的特权容器获得从主机挂载任何块设备的访问权限，这是降低 Kata 安全性的潜在不良副作用。\n\n通过privileged_without_host_devices， 允许在 containerd 配置中为每个运行时配置特权主机设备行为，将此设置为true将禁用主机设备热插入来宾，即使启用了特权也是如此。\n\n\n# Serverless",normalizedContent:"# vm cache\n\nvmcache 服务器将创建一些 vm 并通过工厂缓存对其进行缓存。它将 vm 转换为 grpc 格式，并在收到客户端请求时进行传输。\n\nvm_cache_number指定vmcache的缓存数量：\n- 未指定或 == 0\n  vmcache 已禁用\n- \\> 0\n  将被设置为指定的数字\nvm_cache_endpoint指定 unix 套接字的地址。\n\n\n1\n2\n3\n4\n5\n6\n\n\n通过调用创建一个 vm 模板供以后使用：\n\n$ sudo kata-runtime factory init\n\n\n1\n\n\n\n# 虚拟机模板\n\n\n# 特权容器\n\n具有通常不授予的附加功能和访问权限 如果配置不正确，它可能会降低 kata containers 的安全性。\n\n默认情况下，当为容器启用特权时，/dev/*主机中的所有块设备都会挂载到guest中。这将允许 kata guest内部的特权容器获得从主机挂载任何块设备的访问权限，这是降低 kata 安全性的潜在不良副作用。\n\n通过privileged_without_host_devices， 允许在 containerd 配置中为每个运行时配置特权主机设备行为，将此设置为true将禁用主机设备热插入来宾，即使启用了特权也是如此。\n\n\n# serverless",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"一个kata容器的创建示例",frontmatter:{title:"一个kata容器的创建示例",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata8/",categories:["技术杂谈","kata-containers","kata初识"],tags:[null],titleTag:"原创",readingShow:"top",description:"k8s: 1.17.2\ncontainerd: 1.4.6\nkata: 2.4.0",meta:[{name:"twitter:title",content:"一个kata容器的创建示例"},{name:"twitter:description",content:"k8s: 1.17.2\ncontainerd: 1.4.6\nkata: 2.4.0"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/08.%E4%B8%80%E4%B8%AAkata%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E7%A4%BA%E4%BE%8B.html"},{property:"og:type",content:"article"},{property:"og:title",content:"一个kata容器的创建示例"},{property:"og:description",content:"k8s: 1.17.2\ncontainerd: 1.4.6\nkata: 2.4.0"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/08.%E4%B8%80%E4%B8%AAkata%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E7%A4%BA%E4%BE%8B.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"一个kata容器的创建示例"},{itemprop:"description",content:"k8s: 1.17.2\ncontainerd: 1.4.6\nkata: 2.4.0"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/01.kata%E5%88%9D%E8%AF%86/08.%E4%B8%80%E4%B8%AAkata%E5%AE%B9%E5%99%A8%E7%9A%84%E5%88%9B%E5%BB%BA%E7%A4%BA%E4%BE%8B.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/01.kata初识/08.一个kata容器的创建示例.md",key:"v-58d0a1ce",path:"/pages/kata8/",headers:[{level:2,title:"crictl pods",slug:"crictl-pods",normalizedTitle:"crictl pods",charIndex:902},{level:2,title:"crictl ps",slug:"crictl-ps",normalizedTitle:"crictl ps",charIndex:1296},{level:2,title:"crictl stats",slug:"crictl-stats",normalizedTitle:"crictl stats",charIndex:1652},{level:2,title:"获取sandboxID",slug:"获取sandboxid",normalizedTitle:"获取sandboxid",charIndex:1899},{level:2,title:"宿主机进程",slug:"宿主机进程",normalizedTitle:"宿主机进程",charIndex:2074},{level:2,title:"ip netns",slug:"ip-netns",normalizedTitle:"ip netns",charIndex:5851},{level:2,title:"宿主机目录",slug:"宿主机目录",normalizedTitle:"宿主机目录",charIndex:8032},{level:2,title:"vm_pid",slug:"vm-pid",normalizedTitle:"vm_pid",charIndex:8218},{level:2,title:"df -h",slug:"df-h",normalizedTitle:"df -h",charIndex:9781},{level:2,title:"lsblk",slug:"lsblk",normalizedTitle:"lsblk",charIndex:10298},{level:2,title:"ip addr",slug:"ip-addr",normalizedTitle:"ip addr",charIndex:10493},{level:2,title:"mount",slug:"mount",normalizedTitle:"mount",charIndex:2853},{level:2,title:"lsblk",slug:"lsblk-2",normalizedTitle:"lsblk",charIndex:10298},{level:2,title:"看看挂载了什么分区",slug:"看看挂载了什么分区",normalizedTitle:"看看挂载了什么分区",charIndex:14012},{level:2,title:"ls都没有，只能echo * 代替。",slug:"ls都没有-只能echo-代替。",normalizedTitle:"ls都没有，只能echo * 代替。",charIndex:17558},{level:2,title:"uname -a",slug:"uname-a",normalizedTitle:"uname -a",charIndex:17705},{level:2,title:"看看激活了什么内核模块",slug:"看看激活了什么内核模块",normalizedTitle:"看看激活了什么内核模块",charIndex:17718},{level:2,title:"看看都有什么进程",slug:"看看都有什么进程",normalizedTitle:"看看都有什么进程",charIndex:17918},{level:2,title:"看看有多少内存",slug:"看看有多少内存",normalizedTitle:"看看有多少内存",charIndex:17952},{level:2,title:"看看内核启动参数",slug:"看看内核启动参数",normalizedTitle:"看看内核启动参数",charIndex:17983},{level:2,title:"看看systemctl的服务",slug:"看看systemctl的服务",normalizedTitle:"看看systemctl的服务",charIndex:18019},{level:2,title:"cpuinfo/meminfo  (2C)",slug:"cpuinfo-meminfo-2c",normalizedTitle:"cpuinfo/meminfo  (2c)",charIndex:null}],headersStr:"crictl pods crictl ps crictl stats 获取sandboxID 宿主机进程 ip netns 宿主机目录 vm_pid df -h lsblk ip addr mount lsblk 看看挂载了什么分区 ls都没有，只能echo * 代替。 uname -a 看看激活了什么内核模块 看看都有什么进程 看看有多少内存 看看内核启动参数 看看systemctl的服务 cpuinfo/meminfo  (2C)",content:'# 环境\n\n> k8s: 1.17.2 containerd: 1.4.6 kata: 2.4.0\n\n\n# 创建一个kata容器\n\n    resources:\n      limits:\n        cpu: "1"\n        memory: 1Gi\n      requests:\n        cpu: "1"\n        memory: 1Gi\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n[root@localhost ~]# kubectl get pod -o wide\nNAME                              READY   STATUS    RESTARTS   AGE   IP               NODE                    NOMINATED NODE   READINESS GATES\ntest-runc                         1/1     Running   0          19h   10.241.102.169   localhost.localdomain   <none>           <none>\n[root@localhost ~]# kubectl top pod\nNAME                              CPU(cores)   MEMORY(bytes)\ntest-kata                         0m           2Mi\n[root@localhost ~]# kubectl describe node | grep kata\n  default                     test-kata                                                1250m (16%)   1250m (16%)  1184Mi (18%)     1184Mi (18%)   64m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# crictl pods\n\n[root@localhost ~]# crictl pods\nPOD ID              CREATED             STATE               NAME                                                    NAMESPACE              ATTEMPT             RUNTIME\n3871d0c8108c6       About an hour ago   Ready               test-kata                                               default                0                   kata-qemu\n\n\n1\n2\n3\n\n\n\n# crictl ps\n\n[root@localhost ~]# crictl ps\nCONTAINER           IMAGE               CREATED             STATE               NAME                                   ATTEMPT             POD ID\na83ce7bc82f78       e39e5c33c2d50       About an hour ago   Running             pod1                                   0                   3871d0c8108c6\n\n\n\n1\n2\n3\n4\n\n\n\n# crictl stats\n\n[root@localhost ~]# crictl stats a83ce7bc82f78\nCONTAINER           CPU %               MEM                 DISK                INODES\na83ce7bc82f78       0.00                3.056MB             16.38kB             14\n\n\n\n1\n2\n3\n4\n\n\n\n# 获取sandboxID\n\n[root@localhost ~]# crictl inspect a83ce7bc82f78 | grep sandboxID\n    "sandboxID": "3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985",\n\n\n1\n2\n\n\n\n# 宿主机进程\n\n[root@localhost ~]# ps -ef | grep 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\nroot      2251   429  0 11:32 pts/2    00:00:00 grep --color=auto 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\nroot     23520     1  0 10:24 ?        00:00:01 /opt/kata/bin/containerd-shim-kata-v2 -namespace k8s.io -address /run/containerd/containerd.sock -publish-binary /usr/bin/containerd -id 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\nroot     23528 23520  0 10:24 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\nroot     23535     1  0 10:24 ?        00:00:09 /opt/kata/bin/qemu-system-x86_64 -name sandbox-3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985 -uuid 2cfc6a6d-63ab-41aa-ac4b-18cb10377791 -machine q35,accel=kvm,kernel_irqchip=on,nvdimm=on -cpu host,pmu=off -qmp unix:/run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/qmp.sock,server=on,wait=off -m 2048M,slots=10,maxmem=8773M -device pci-bridge,bus=pcie.0,id=pci-bridge-0,chassis_nr=1,shpc=off,addr=2,io-reserve=4k,mem-reserve=1m,pref64-reserve=1m -device virtio-serial-pci,disable-modern=false,id=serial0 -device virtconsole,chardev=charconsole0,id=console0 -chardev socket,id=charconsole0,path=/run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/console.sock,server=on,wait=off -device nvdimm,id=nv0,memdev=mem0,unarmed=on -object memory-backend-file,id=mem0,mem-path=/opt/kata/share/kata-containers/kata-clearlinux-latest.image,size=134217728,readonly=on -device virtio-scsi-pci,id=scsi0,disable-modern=false -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -device vhost-vsock-pci,disable-modern=false,vhostfd=3,id=vsock-4001198526,guest-cid=4001198526 -chardev socket,id=char-93f9924bc919f096,path=/run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/vhost-fs.sock -device vhost-user-fs-pci,chardev=char-93f9924bc919f096,tag=kataShared -netdev tap,id=network-0,vhost=on,vhostfds=4,fds=5 -device driver=virtio-net-pci,netdev=network-0,mac=ea:e4:96:23:5e:9f,disable-modern=false,mq=on,vectors=4 -rtc base=utc,driftfix=slew,clock=host -global kvm-pit.lost_tick_policy=discard -vga none -no-user-config -nodefaults -nographic --no-reboot -daemonize -object memory-backend-file,id=dimm1,size=2048M,mem-path=/dev/shm,share=on -numa node,memdev=dimm1 -kernel /opt/kata/share/kata-containers/vmlinux-5.15.26-90 -append tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k console=hvc0 console=hvc1 cryptomgr.notests net.ifnames=0 pci=lastbus=0 root=/dev/pmem0p1 rootflags=dax,data=ordered,errors=remount-ro ro rootfstype=ext4 quiet systemd.show_status=false panic=1 nr_cpus=8 systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026 -pidfile /run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/pid -smp 1,cores=1,threads=1,sockets=8,maxcpus=8\nroot     23543 23528  0 10:24 ?        00:00:01 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\nroot     27463 17898  0 10:26 pts/0    00:00:00 kata-runtime exec 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# ip netns\n\n[root@localhost ~]# ip netns exec cni-75b072ca-fd5a-ceda-617d-9ce0b606ac5e  ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: tunl0@NONE: <NOARP> mtu 1480 qdisc noop state DOWN group default qlen 1000\n    link/ipip 0.0.0.0 brd 0.0.0.0\n4: eth0@if17552: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc noqueue state UP group default qlen 1000\n    link/ether ea:e4:96:23:5e:9f brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 10.241.103.177/32 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::e8e4:96ff:fe23:5e9f/64 scope link\n       valid_lft forever preferred_lft forever\n5: tap0_kata: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc mq state UNKNOWN group default qlen 1000\n    link/ether a2:a5:96:5b:90:23 brd ff:ff:ff:ff:ff:ff\n    inet6 fe80::a0a5:96ff:fe5b:9023/64 scope link\n       valid_lft forever preferred_lft forever\n[root@localhost ~]# ip netns exec cni-75b072ca-fd5a-ceda-617d-9ce0b606ac5e  tc -s qdisc\nqdisc noqueue 0: dev lo root refcnt 2\n Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc noqueue 0: dev eth0 root refcnt 2\n Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev eth0 parent ffff:fff1 ----------------\n Sent 468 bytes 7 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc mq 0: dev tap0_kata root\n Sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc pfifo_fast 0: dev tap0_kata parent :1 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1\n Sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev tap0_kata parent ffff:fff1 ----------------\n Sent 992 bytes 16 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 宿主机目录\n\n> /run/kata-containers/shared/sandboxes/ /run/vc/vm/ /run/vc/sbs/ /sys/fs/cgroup/(memory、devices、cpu,cpuacct...) /sys/fs/cgroup/systemd/kata_overhead/ /app/docker/containerd/\n\n\n# vm_pid\n\n[root@localhost ~]# cat /proc/23535/status\nName:   qemu-system-x86\nUmask:  0027\nState:  S (sleeping)\nTgid:   23535\nNgid:   0\nPid:    23535\nPPid:   1\nTracerPid:      0\nUid:    0       0       0       0\nGid:    0       0       0       0\nFDSize: 128\nGroups:\nVmPeak:  3659100 kB\nVmSize:  3659100 kB\nVmLck:         0 kB\nVmPin:         0 kB\nVmHWM:    152104 kB\nVmRSS:    152104 kB\nRssAnon:           14288 kB\nRssFile:           35956 kB\nRssShmem:         101860 kB\nVmData:   326316 kB\nVmStk:       132 kB\nVmExe:      8496 kB\nVmLib:         0 kB\nVmPTE:       652 kB\nVmSwap:        0 kB\nThreads:        5\nSigQ:   0/30632\nSigPnd: 0000000000000000\nShdPnd: 0000000000000000\nSigBlk: 0000000010002240\nSigIgn: 0000000000381000\nSigCgt: 0000000180004243\nCapInh: 0000000000000000\nCapPrm: 0000001fffffffff\nCapEff: 0000001fffffffff\nCapBnd: 0000001fffffffff\nCapAmb: 0000000000000000\nNoNewPrivs:     0\nSeccomp:        0\nSpeculation_Store_Bypass:       thread vulnerable\nCpus_allowed:   ff\nCpus_allowed_list:      0-7\nMems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001\nMems_allowed_list:      0\nvoluntary_ctxt_switches:        1769\nnonvoluntary_ctxt_switches:     4\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n\n# 进入kata容器\n\n\n# df -h\n\n\nroot@hostpath-kata-7949f86f8c-8gfqj:/# df -h\n\nFilesystem      Size  Used Avail Use% Mounted on\n\nnone            494G   28G  466G   6% /\n\ntmpfs            64M     0   64M   0% /dev\n\ntmpfs           992M     0  992M   0% /sys/fs/cgroup\n\nnone            494G   28G  466G   6% /hff\n\nkataShared      494G   28G  466G   6% /etc/hosts\n\nshm             992M     0  992M   0% /dev/shm\n\ntmpfs           992M   12K  992M   1% /run/secrets/kubernetes.io/serviceaccount\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# lsblk\n\n\nroot@hostpath-kata-7949f86f8c-8gfqj:/# lsblk\n\nNAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\n\npmem0     259:0    0  126M  1 disk\n\n`-pmem0p1 259:1    0  124M  1 part\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# ip addr\n\n/ # ip addr\nroot@test-kata:/# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1440 qdisc fq state UP group default qlen 1000\n    link/ether ea:e4:96:23:5e:9f brd ff:ff:ff:ff:ff:ff\n    inet 10.241.103.177/32 brd 10.241.103.177 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::e8e4:96ff:fe23:5e9f/64 scope link\n       valid_lft forever preferred_lft forever\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# mount\n\nroot@test-kata:/# mount\nnone on / type virtiofs (rw,relatime)\nproc on /proc type proc (rw,nosuid,nodev,noexec,relatime)\ntmpfs on /dev type tmpfs (rw,nosuid,size=65536k,nr_inodes=255223,mode=755)\ndevpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666)\nmqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)\nsysfs on /sys type sysfs (ro,nosuid,nodev,noexec,relatime)\ntmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,relatime,size=1020892k,nr_inodes=255223)\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd)\ncgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory)\ncgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset)\ncgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct)\ncgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer)\nnone on /test type virtiofs (rw,relatime)\nkataShared on /etc/hosts type virtiofs (rw,relatime)\nkataShared on /dev/termination-log type virtiofs (rw,relatime)\nkataShared on /etc/hostname type virtiofs (rw,relatime)\nkataShared on /etc/resolv.conf type virtiofs (rw,relatime)\nshm on /dev/shm type tmpfs (rw,relatime,size=1020892k,nr_inodes=255223)\ntmpfs on /run/secrets/kubernetes.io/serviceaccount type tmpfs (ro,relatime,size=1020892k,nr_inodes=255223)\ntmpfs on /proc/timer_list type tmpfs (rw,nosuid,size=65536k,nr_inodes=255223,mode=755)\nproc on /proc/bus type proc (ro,relatime)\nproc on /proc/fs type proc (ro,relatime)\nproc on /proc/irq type proc (ro,relatime)\nproc on /proc/sys type proc (ro,relatime)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n\n# 进入kata vm\n\nhttps://github.com/kata-containers/kata-containers/issues/2010\n\n[root@rqy-k8s-1 kbuser]# kata-runtime exec 1b482bb4613ba606894d30370fe7637610a495d9b3a504bc36e9aa292db9a0f0\nbash: grep: command not found\nbash: grep: command not found\nbash: tty: command not found\nbash: expr: command not found\nbash: [: : integer expression expected\nbash-5.1#\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# lsblk\n\nbash-5.1# lsblk\nNAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS\npmem0     259:0    0  126M  1 disk\n`-pmem0p1 259:1    0  124M  1 part /\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n\n\n\n# 看看挂载了什么分区\n\nbash-5.1# mount\n/dev/pmem0p1 on / type ext4 (ro,relatime,errors=remount-ro,data=ordered,dax=always)\ndevtmpfs on /dev type devtmpfs (rw,relatime,size=1019140k,nr_inodes=254785,mode=755)\nproc on /proc type proc (rw,nosuid,nodev,noexec,relatime)\nsysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)\ntmpfs on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,size=1020892k,nr_inodes=255223)\ndevpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)\ntmpfs on /run type tmpfs (rw,nosuid,nodev,size=408360k,nr_inodes=819200,mode=755)\ntmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,size=4096k,nr_inodes=1024,mode=755)\ncgroup2 on /sys/fs/cgroup/unified type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate)\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd)\nbpf on /sys/fs/bpf type bpf (rw,nosuid,nodev,noexec,relatime,mode=700)\nhugetlbfs on /dev/hugepages type hugetlbfs (rw,nosuid,nodev,noexec,relatime,pagesize=2M)\nmqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)\nfusectl on /sys/fs/fuse/connections type fusectl (rw,nosuid,nodev,noexec,relatime)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)\ncgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)\ntmpfs on /etc/machine-id type tmpfs (ro,size=408360k,nr_inodes=819200,mode=755)\nsystemd-1 on /proc/sys/fs/binfmt_misc type autofs (rw,relatime,fd=29,pgrp=1,timeout=0,minproto=5,maxproto=5,direct)\ntmpfs on /tmp type tmpfs (rw,nosuid,nodev,size=1020896k,nr_inodes=1048576)\nnsfs on /run/sandbox-ns/ipc type nsfs (rw)\nnsfs on /run/sandbox-ns/uts type nsfs (rw)\nkataShared on /run/kata-containers/shared/containers type virtiofs (rw,relatime)\nshm on /run/kata-containers/sandbox/shm type tmpfs (rw,relatime,size=1020892k,nr_inodes=255223)\ntmpfs on /etc/resolv.conf type tmpfs (rw,nosuid,nodev,size=408360k,nr_inodes=819200,mode=755)\nnone on /run/kata-containers/shared/containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs type virtiofs (rw,relatime)\nnone on /run/kata-containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs type virtiofs (rw,relatime)\ntmpfs on /run/kata-containers/shared/containers/watchable type tmpfs (rw,relatime,size=1020892k,nr_inodes=255223)\nnone on /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-172195b99cf7a9fd-serviceaccount type virtiofs (rw,relatime)\nnone on /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs type virtiofs (rw,relatime)\nnone on /run/kata-containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs type virtiofs (rw,relatime)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# ls都没有，只能echo * 代替。\n\nbash-5.1# echo *\nautofs bin boot dev etc home lib lib64 lost+found media mnt proc root run sbin srv sys tmp usr var\n\n\n1\n2\n\n\n\n# uname -a\n\n\n# 看看激活了什么内核模块\n\nbash-5.1# lsmod\nlibkmod: kmod_module_new_from_loaded: could not open /proc/modules: No such file or directory\nError: could not get list of modules: No such file or directory\n\n\n1\n2\n3\n\n\n\n# 看看都有什么进程\n\nbash-5.1# ps efx ww\n\n\n# 看看有多少内存\n\nbash-5.1# free -h\n\n\n# 看看内核启动参数\n\nbash-5.1# cat cmdline\n\n\n# 看看systemctl的服务\n\nbash-5.1# systemctl list-units\n  UNIT                                                                                                                                                  LOAD   ACTIVE     SUB       DESCRIPTION          \n  proc-sys-fs-binfmt_misc.automount                                                                                                                     loaded active     waiting   Arbitrary Executable File Formats File System Automount Point\n  dev-pmem0p1.device                                                                                                                                    loaded activating tentative /dev/pmem0p1         \n  -.mount                                                                                                                                               loaded active     mounted   Root Mount\n  etc-machine\\x2did.mount                                                                                                                               loaded active     mounted   /etc/machine-id\n  etc-resolv.conf.mount                                                                                                                                 loaded active     mounted   /etc/resolv.conf\n  run-kata\\x2dcontainers-3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985-rootfs.mount                                                  loaded active     mounted   /run/kata-containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs\n  run-kata\\x2dcontainers-a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-rootfs.mount                                                  loaded active     mounted   /run/kata-containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs\n  run-kata\\x2dcontainers-sandbox-shm.mount                                                                                                              loaded active     mounted   /run/kata-containers/sandbox/shm\n  run-kata\\x2dcontainers-shared-containers-3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985-rootfs.mount                                loaded active     mounted   /run/kata-containers/shared/containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs\n  run-kata\\x2dcontainers-shared-containers-a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-rootfs.mount                                loaded active     mounted   /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs\n  run-kata\\x2dcontainers-shared-containers-a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a\\x2d172195b99cf7a9fd\\x2dserviceaccount.mount loaded active     mounted   /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-172195b99cf7a9fd-serviceaccount\n  run-kata\\x2dcontainers-shared-containers-watchable.mount                                                                                              loaded active     mounted   /run/kata-containers/shared/containers/watchable\n  run-kata\\x2dcontainers-shared-containers.mount                                                                                                        loaded active     mounted   /run/kata-containers/shared/containers\n  run-sandbox\\x2dns-ipc.mount                                                                                                                           loaded active     mounted   /run/sandbox-ns/ipc\n  run-sandbox\\x2dns-uts.mount                                                                                                                           loaded active     mounted   /run/sandbox-ns/uts\n  tmp.mount                                                                                                                                             loaded active     mounted   Temporary Directory /tmp\n  systemd-ask-password-console.path                                                                                                                     loaded active     waiting   Dispatch Password Requests to Console Directory Watch\n  init.scope                                                                                                                                            loaded active     running   System and Service Manager\n● chronyd.service                                                                                                                                       loaded failed     failed    NTP client/server\n  kata-agent.service                                                                                                                                    loaded active     running   Kata Containers Agent\n  systemd-remount-fs.service                                                                                                                            loaded active     exited    Remount Root and Kernel File Systems\n  systemd-sysctl.service                                                                                                                                loaded active     exited    Apply Kernel Variables\n  -.slice                                                                                                                                               loaded active     active    Root Slice\n  system.slice                                                                                                                                          loaded active     active    System Slice         \n  systemd-coredump.socket                                                                                                                               loaded active     listening Process Core Dump Socket\n  basic.target                                                                                                                                          loaded active     active    Basic System\n  cryptsetup.target                                                                                                                                     loaded active     active    Local Encrypted Volumes\n  kata-containers.target                                                                                                                                loaded active     active    Kata Containers Agent Target\n  local-fs-pre.target                                                                                                                                   loaded active     active    Preparation for Local File Systems\n  local-fs.target                                                                                                                                       loaded active     active    Local File Systems\n  paths.target                                                                                                                                          loaded active     active    Path Units\n  slices.target                                                                                                                                         loaded active     active    Slice Units\n  sockets.target                                                                                                                                        loaded active     active    Socket Units\n  swap.target                                                                                                                                           loaded active     active    Swaps\n  sysinit.target                                                                                                                                        loaded active     active    System Initialization\n  timers.target                                                                                                                                         loaded active     active    Timer Units          \n  systemd-tmpfiles-clean.timer                                                                                                                          loaded active     waiting   Daily Cleanup of Temporary Directories\n\nLOAD   = Reflects whether the unit definition was properly loaded.\nACTIVE = The high-level unit activation state, i.e. generalization of SUB.\nSUB    = The low-level unit activation state, values depend on unit type.\n37 loaded units listed. Pass --all to see loaded but inactive units, too.\nTo show all installed unit files use \'systemctl list-unit-files\'.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\nbash-5.1#   systemctl cat kata-containers.target\n# /usr/lib/systemd/system/kata-containers.target\n#\n# Copyright (c) 2018-2019 Intel Corporation\n#\n# SPDX-License-Identifier: Apache-2.0\n#\n\n[Unit]\nDescription=Kata Containers Agent Target\nRequires=basic.target\nRequires=tmp.mount\nWants=chronyd.service\nRequires=kata-agent.service\nConflicts=rescue.service rescue.target\nAfter=basic.target rescue.service rescue.target\nAllowIsolate=yes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# cpuinfo/meminfo (2C)\n\nbash-5.1# more /proc/cpuinfo\nprocessor       : 0\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 158\nmodel name      : Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz\nstepping        : 9\nmicrocode       : 0xea\ncpu MHz         : 3599.982\ncache size      : 16384 KB\nphysical id     : 0\nsiblings        : 1\ncore id         : 0\ncpu cores       : 1\napicid          : 0\ninitial apicid  : 0\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nflags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid tsc_known_ arat md_clearinvpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1--More--e_timer aes xsave avx f16c rdra--More--\niority tsc_offset vtpr mtf vapic ept vpid unrestricted_guest pmld ept_1gb flexpr--More--\nswapgs taa itlb_multihit srbds spectre_v1 spectre_v2 spec_store_bypass l1tf mds --More--\nbogomips        : 7199.96\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 39 bits physical, 48 bits virtual\npower management:\n\nprocessor       : 1\nvendor_id       : GenuineIntel\ncpu family      : 6\nmodel           : 158\nmodel name      : Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz\nstepping        : 9\nmicrocode       : 0xea\ncpu MHz         : 3599.982\ncache size      : 16384 KB\nphysical id     : 7\nsiblings        : 1\ncore id         : 0\ncpu cores       : 1\napicid          : 7\ninitial apicid  : 7\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nlushopt xsaveopt xsavec xgetbv1 arat md_clearinvpcid rtm mpx rdseed adx smap clf--More--\nswapgs taa itlb_multihit srbds spectre_v1 spectre_v2 spec_store_bypass l1tf mds --More--\nbogomips        : 7199.96\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 39 bits physical, 48 bits virtual\npower management:\n\n[root@localhost ~]# more /proc/meminfo   (??)\nMemTotal:        7935356 kB\nMemFree:          478024 kB\nMemAvailable:    1827752 kB\nBuffers:            1064 kB\nCached:          1903388 kB\nSwapCached:            0 kB\nActive:          5728076 kB\nInactive:         891144 kB\nActive(anon):    5029108 kB\nInactive(anon):   207680 kB\nActive(file):     698968 kB\nInactive(file):   683464 kB\nUnevictable:           4 kB\nMlocked:               4 kB\nSwapTotal:             0 kB\nSwapFree:              0 kB\nDirty:              9584 kB\nWriteback:             0 kB\nAnonPages:       4715640 kB\nMapped:           564200 kB\nShmem:            522020 kB\nSlab:             469116 kB\nSReclaimable:     280468 kB\nSUnreclaim:       188648 kB\nKernelStack:       43248 kB\nPageTables:        39740 kB\nNFS_Unstable:          0 kB\nBounce:                0 kB\nWritebackTmp:          0 kB\nCommitLimit:     3967676 kB\nCommitted_AS:   23822760 kB\nVmallocTotal:   34359738367 kB\nVmallocUsed:      461976 kB\nVmallocChunk:   34358937596 kB\nPercpu:            11552 kB\nHardwareCorrupted:     0 kB\nAnonHugePages:     20480 kB\nCmaTotal:              0 kB\nCmaFree:               0 kB\nHugePages_Total:       0\nHugePages_Free:        0\nHugePages_Rsvd:        0\nHugePages_Surp:        0\nHugepagesize:       2048 kB\nDirectMap4k:      211152 kB\nDirectMap2M:     8038400 kB\nDirectMap1G:           0 kB\n[root@localhost ~]#\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n\n\n\n# 总结\n\nlimit 1C1G default:1C2G\n\nvm: cpuinfo： 2CPU meminfo: MemTotal: 7935356 kB (7.5G)\n\npod: cpuinfo：2CPU meminfo: MemTotal: 3090364 kB (2.9G) free -h: 2.9G',normalizedContent:'# 环境\n\n> k8s: 1.17.2 containerd: 1.4.6 kata: 2.4.0\n\n\n# 创建一个kata容器\n\n    resources:\n      limits:\n        cpu: "1"\n        memory: 1gi\n      requests:\n        cpu: "1"\n        memory: 1gi\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n[root@localhost ~]# kubectl get pod -o wide\nname                              ready   status    restarts   age   ip               node                    nominated node   readiness gates\ntest-runc                         1/1     running   0          19h   10.241.102.169   localhost.localdomain   <none>           <none>\n[root@localhost ~]# kubectl top pod\nname                              cpu(cores)   memory(bytes)\ntest-kata                         0m           2mi\n[root@localhost ~]# kubectl describe node | grep kata\n  default                     test-kata                                                1250m (16%)   1250m (16%)  1184mi (18%)     1184mi (18%)   64m\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# crictl pods\n\n[root@localhost ~]# crictl pods\npod id              created             state               name                                                    namespace              attempt             runtime\n3871d0c8108c6       about an hour ago   ready               test-kata                                               default                0                   kata-qemu\n\n\n1\n2\n3\n\n\n\n# crictl ps\n\n[root@localhost ~]# crictl ps\ncontainer           image               created             state               name                                   attempt             pod id\na83ce7bc82f78       e39e5c33c2d50       about an hour ago   running             pod1                                   0                   3871d0c8108c6\n\n\n\n1\n2\n3\n4\n\n\n\n# crictl stats\n\n[root@localhost ~]# crictl stats a83ce7bc82f78\ncontainer           cpu %               mem                 disk                inodes\na83ce7bc82f78       0.00                3.056mb             16.38kb             14\n\n\n\n1\n2\n3\n4\n\n\n\n# 获取sandboxid\n\n[root@localhost ~]# crictl inspect a83ce7bc82f78 | grep sandboxid\n    "sandboxid": "3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985",\n\n\n1\n2\n\n\n\n# 宿主机进程\n\n[root@localhost ~]# ps -ef | grep 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\nroot      2251   429  0 11:32 pts/2    00:00:00 grep --color=auto 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\nroot     23520     1  0 10:24 ?        00:00:01 /opt/kata/bin/containerd-shim-kata-v2 -namespace k8s.io -address /run/containerd/containerd.sock -publish-binary /usr/bin/containerd -id 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\nroot     23528 23520  0 10:24 ?        00:00:00 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\nroot     23535     1  0 10:24 ?        00:00:09 /opt/kata/bin/qemu-system-x86_64 -name sandbox-3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985 -uuid 2cfc6a6d-63ab-41aa-ac4b-18cb10377791 -machine q35,accel=kvm,kernel_irqchip=on,nvdimm=on -cpu host,pmu=off -qmp unix:/run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/qmp.sock,server=on,wait=off -m 2048m,slots=10,maxmem=8773m -device pci-bridge,bus=pcie.0,id=pci-bridge-0,chassis_nr=1,shpc=off,addr=2,io-reserve=4k,mem-reserve=1m,pref64-reserve=1m -device virtio-serial-pci,disable-modern=false,id=serial0 -device virtconsole,chardev=charconsole0,id=console0 -chardev socket,id=charconsole0,path=/run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/console.sock,server=on,wait=off -device nvdimm,id=nv0,memdev=mem0,unarmed=on -object memory-backend-file,id=mem0,mem-path=/opt/kata/share/kata-containers/kata-clearlinux-latest.image,size=134217728,readonly=on -device virtio-scsi-pci,id=scsi0,disable-modern=false -object rng-random,id=rng0,filename=/dev/urandom -device virtio-rng-pci,rng=rng0 -device vhost-vsock-pci,disable-modern=false,vhostfd=3,id=vsock-4001198526,guest-cid=4001198526 -chardev socket,id=char-93f9924bc919f096,path=/run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/vhost-fs.sock -device vhost-user-fs-pci,chardev=char-93f9924bc919f096,tag=katashared -netdev tap,id=network-0,vhost=on,vhostfds=4,fds=5 -device driver=virtio-net-pci,netdev=network-0,mac=ea:e4:96:23:5e:9f,disable-modern=false,mq=on,vectors=4 -rtc base=utc,driftfix=slew,clock=host -global kvm-pit.lost_tick_policy=discard -vga none -no-user-config -nodefaults -nographic --no-reboot -daemonize -object memory-backend-file,id=dimm1,size=2048m,mem-path=/dev/shm,share=on -numa node,memdev=dimm1 -kernel /opt/kata/share/kata-containers/vmlinux-5.15.26-90 -append tsc=reliable no_timer_check rcupdate.rcu_expedited=1 i8042.direct=1 i8042.dumbkbd=1 i8042.nopnp=1 i8042.noaux=1 noreplace-smp reboot=k console=hvc0 console=hvc1 cryptomgr.notests net.ifnames=0 pci=lastbus=0 root=/dev/pmem0p1 rootflags=dax,data=ordered,errors=remount-ro ro rootfstype=ext4 quiet systemd.show_status=false panic=1 nr_cpus=8 systemd.unit=kata-containers.target systemd.mask=systemd-networkd.service systemd.mask=systemd-networkd.socket scsi_mod.scan=none agent.debug_console agent.debug_console_vport=1026 -pidfile /run/vc/vm/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/pid -smp 1,cores=1,threads=1,sockets=8,maxcpus=8\nroot     23543 23528  0 10:24 ?        00:00:01 /opt/kata/libexec/kata-qemu/virtiofsd --syslog -o cache=auto -o no_posix_lock -o source=/run/kata-containers/shared/sandboxes/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/shared --fd=3 -f --thread-pool-size=1 -o announce_submounts\nroot     27463 17898  0 10:26 pts/0    00:00:00 kata-runtime exec 3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# ip netns\n\n[root@localhost ~]# ip netns exec cni-75b072ca-fd5a-ceda-617d-9ce0b606ac5e  ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: tunl0@none: <noarp> mtu 1480 qdisc noop state down group default qlen 1000\n    link/ipip 0.0.0.0 brd 0.0.0.0\n4: eth0@if17552: <broadcast,multicast,up,lower_up> mtu 1440 qdisc noqueue state up group default qlen 1000\n    link/ether ea:e4:96:23:5e:9f brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 10.241.103.177/32 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::e8e4:96ff:fe23:5e9f/64 scope link\n       valid_lft forever preferred_lft forever\n5: tap0_kata: <broadcast,multicast,up,lower_up> mtu 1440 qdisc mq state unknown group default qlen 1000\n    link/ether a2:a5:96:5b:90:23 brd ff:ff:ff:ff:ff:ff\n    inet6 fe80::a0a5:96ff:fe5b:9023/64 scope link\n       valid_lft forever preferred_lft forever\n[root@localhost ~]# ip netns exec cni-75b072ca-fd5a-ceda-617d-9ce0b606ac5e  tc -s qdisc\nqdisc noqueue 0: dev lo root refcnt 2\n sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc noqueue 0: dev eth0 root refcnt 2\n sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev eth0 parent ffff:fff1 ----------------\n sent 468 bytes 7 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc mq 0: dev tap0_kata root\n sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc pfifo_fast 0: dev tap0_kata parent :1 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1\n sent 1222 bytes 15 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\nqdisc ingress ffff: dev tap0_kata parent ffff:fff1 ----------------\n sent 992 bytes 16 pkt (dropped 0, overlimits 0 requeues 0)\n backlog 0b 0p requeues 0\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# 宿主机目录\n\n> /run/kata-containers/shared/sandboxes/ /run/vc/vm/ /run/vc/sbs/ /sys/fs/cgroup/(memory、devices、cpu,cpuacct...) /sys/fs/cgroup/systemd/kata_overhead/ /app/docker/containerd/\n\n\n# vm_pid\n\n[root@localhost ~]# cat /proc/23535/status\nname:   qemu-system-x86\numask:  0027\nstate:  s (sleeping)\ntgid:   23535\nngid:   0\npid:    23535\nppid:   1\ntracerpid:      0\nuid:    0       0       0       0\ngid:    0       0       0       0\nfdsize: 128\ngroups:\nvmpeak:  3659100 kb\nvmsize:  3659100 kb\nvmlck:         0 kb\nvmpin:         0 kb\nvmhwm:    152104 kb\nvmrss:    152104 kb\nrssanon:           14288 kb\nrssfile:           35956 kb\nrssshmem:         101860 kb\nvmdata:   326316 kb\nvmstk:       132 kb\nvmexe:      8496 kb\nvmlib:         0 kb\nvmpte:       652 kb\nvmswap:        0 kb\nthreads:        5\nsigq:   0/30632\nsigpnd: 0000000000000000\nshdpnd: 0000000000000000\nsigblk: 0000000010002240\nsigign: 0000000000381000\nsigcgt: 0000000180004243\ncapinh: 0000000000000000\ncapprm: 0000001fffffffff\ncapeff: 0000001fffffffff\ncapbnd: 0000001fffffffff\ncapamb: 0000000000000000\nnonewprivs:     0\nseccomp:        0\nspeculation_store_bypass:       thread vulnerable\ncpus_allowed:   ff\ncpus_allowed_list:      0-7\nmems_allowed:   00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000000,00000001\nmems_allowed_list:      0\nvoluntary_ctxt_switches:        1769\nnonvoluntary_ctxt_switches:     4\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n\n\n\n# 进入kata容器\n\n\n# df -h\n\n\nroot@hostpath-kata-7949f86f8c-8gfqj:/# df -h\n\nfilesystem      size  used avail use% mounted on\n\nnone            494g   28g  466g   6% /\n\ntmpfs            64m     0   64m   0% /dev\n\ntmpfs           992m     0  992m   0% /sys/fs/cgroup\n\nnone            494g   28g  466g   6% /hff\n\nkatashared      494g   28g  466g   6% /etc/hosts\n\nshm             992m     0  992m   0% /dev/shm\n\ntmpfs           992m   12k  992m   1% /run/secrets/kubernetes.io/serviceaccount\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# lsblk\n\n\nroot@hostpath-kata-7949f86f8c-8gfqj:/# lsblk\n\nname      maj:min rm  size ro type mountpoint\n\npmem0     259:0    0  126m  1 disk\n\n`-pmem0p1 259:1    0  124m  1 part\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# ip addr\n\n/ # ip addr\nroot@test-kata:/# ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: eth0: <broadcast,multicast,up,lower_up> mtu 1440 qdisc fq state up group default qlen 1000\n    link/ether ea:e4:96:23:5e:9f brd ff:ff:ff:ff:ff:ff\n    inet 10.241.103.177/32 brd 10.241.103.177 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::e8e4:96ff:fe23:5e9f/64 scope link\n       valid_lft forever preferred_lft forever\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# mount\n\nroot@test-kata:/# mount\nnone on / type virtiofs (rw,relatime)\nproc on /proc type proc (rw,nosuid,nodev,noexec,relatime)\ntmpfs on /dev type tmpfs (rw,nosuid,size=65536k,nr_inodes=255223,mode=755)\ndevpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666)\nmqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)\nsysfs on /sys type sysfs (ro,nosuid,nodev,noexec,relatime)\ntmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,relatime,size=1020892k,nr_inodes=255223)\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd)\ncgroup on /sys/fs/cgroup/memory type cgroup (ro,nosuid,nodev,noexec,relatime,memory)\ncgroup on /sys/fs/cgroup/devices type cgroup (ro,nosuid,nodev,noexec,relatime,devices)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (ro,nosuid,nodev,noexec,relatime,cpuset)\ncgroup on /sys/fs/cgroup/pids type cgroup (ro,nosuid,nodev,noexec,relatime,pids)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (ro,nosuid,nodev,noexec,relatime,net_cls,net_prio)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (ro,nosuid,nodev,noexec,relatime,perf_event)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (ro,nosuid,nodev,noexec,relatime,cpu,cpuacct)\ncgroup on /sys/fs/cgroup/blkio type cgroup (ro,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/freezer type cgroup (ro,nosuid,nodev,noexec,relatime,freezer)\nnone on /test type virtiofs (rw,relatime)\nkatashared on /etc/hosts type virtiofs (rw,relatime)\nkatashared on /dev/termination-log type virtiofs (rw,relatime)\nkatashared on /etc/hostname type virtiofs (rw,relatime)\nkatashared on /etc/resolv.conf type virtiofs (rw,relatime)\nshm on /dev/shm type tmpfs (rw,relatime,size=1020892k,nr_inodes=255223)\ntmpfs on /run/secrets/kubernetes.io/serviceaccount type tmpfs (ro,relatime,size=1020892k,nr_inodes=255223)\ntmpfs on /proc/timer_list type tmpfs (rw,nosuid,size=65536k,nr_inodes=255223,mode=755)\nproc on /proc/bus type proc (ro,relatime)\nproc on /proc/fs type proc (ro,relatime)\nproc on /proc/irq type proc (ro,relatime)\nproc on /proc/sys type proc (ro,relatime)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n\n\n\n# 进入kata vm\n\nhttps://github.com/kata-containers/kata-containers/issues/2010\n\n[root@rqy-k8s-1 kbuser]# kata-runtime exec 1b482bb4613ba606894d30370fe7637610a495d9b3a504bc36e9aa292db9a0f0\nbash: grep: command not found\nbash: grep: command not found\nbash: tty: command not found\nbash: expr: command not found\nbash: [: : integer expression expected\nbash-5.1#\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# lsblk\n\nbash-5.1# lsblk\nname      maj:min rm  size ro type mountpoints\npmem0     259:0    0  126m  1 disk\n`-pmem0p1 259:1    0  124m  1 part /\nbash-5.1#\n\n\n1\n2\n3\n4\n5\n\n\n\n# 看看挂载了什么分区\n\nbash-5.1# mount\n/dev/pmem0p1 on / type ext4 (ro,relatime,errors=remount-ro,data=ordered,dax=always)\ndevtmpfs on /dev type devtmpfs (rw,relatime,size=1019140k,nr_inodes=254785,mode=755)\nproc on /proc type proc (rw,nosuid,nodev,noexec,relatime)\nsysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)\ntmpfs on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,size=1020892k,nr_inodes=255223)\ndevpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)\ntmpfs on /run type tmpfs (rw,nosuid,nodev,size=408360k,nr_inodes=819200,mode=755)\ntmpfs on /sys/fs/cgroup type tmpfs (ro,nosuid,nodev,noexec,size=4096k,nr_inodes=1024,mode=755)\ncgroup2 on /sys/fs/cgroup/unified type cgroup2 (rw,nosuid,nodev,noexec,relatime,nsdelegate)\ncgroup on /sys/fs/cgroup/systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,name=systemd)\nbpf on /sys/fs/bpf type bpf (rw,nosuid,nodev,noexec,relatime,mode=700)\nhugetlbfs on /dev/hugepages type hugetlbfs (rw,nosuid,nodev,noexec,relatime,pagesize=2m)\nmqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)\nfusectl on /sys/fs/fuse/connections type fusectl (rw,nosuid,nodev,noexec,relatime)\ncgroup on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)\ncgroup on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)\ncgroup on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)\ncgroup on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)\ncgroup on /sys/fs/cgroup/cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpu,cpuacct)\ncgroup on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)\ncgroup on /sys/fs/cgroup/net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls,net_prio)\ncgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)\ncgroup on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)\ntmpfs on /etc/machine-id type tmpfs (ro,size=408360k,nr_inodes=819200,mode=755)\nsystemd-1 on /proc/sys/fs/binfmt_misc type autofs (rw,relatime,fd=29,pgrp=1,timeout=0,minproto=5,maxproto=5,direct)\ntmpfs on /tmp type tmpfs (rw,nosuid,nodev,size=1020896k,nr_inodes=1048576)\nnsfs on /run/sandbox-ns/ipc type nsfs (rw)\nnsfs on /run/sandbox-ns/uts type nsfs (rw)\nkatashared on /run/kata-containers/shared/containers type virtiofs (rw,relatime)\nshm on /run/kata-containers/sandbox/shm type tmpfs (rw,relatime,size=1020892k,nr_inodes=255223)\ntmpfs on /etc/resolv.conf type tmpfs (rw,nosuid,nodev,size=408360k,nr_inodes=819200,mode=755)\nnone on /run/kata-containers/shared/containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs type virtiofs (rw,relatime)\nnone on /run/kata-containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs type virtiofs (rw,relatime)\ntmpfs on /run/kata-containers/shared/containers/watchable type tmpfs (rw,relatime,size=1020892k,nr_inodes=255223)\nnone on /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-172195b99cf7a9fd-serviceaccount type virtiofs (rw,relatime)\nnone on /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs type virtiofs (rw,relatime)\nnone on /run/kata-containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs type virtiofs (rw,relatime)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n\n\n\n# ls都没有，只能echo * 代替。\n\nbash-5.1# echo *\nautofs bin boot dev etc home lib lib64 lost+found media mnt proc root run sbin srv sys tmp usr var\n\n\n1\n2\n\n\n\n# uname -a\n\n\n# 看看激活了什么内核模块\n\nbash-5.1# lsmod\nlibkmod: kmod_module_new_from_loaded: could not open /proc/modules: no such file or directory\nerror: could not get list of modules: no such file or directory\n\n\n1\n2\n3\n\n\n\n# 看看都有什么进程\n\nbash-5.1# ps efx ww\n\n\n# 看看有多少内存\n\nbash-5.1# free -h\n\n\n# 看看内核启动参数\n\nbash-5.1# cat cmdline\n\n\n# 看看systemctl的服务\n\nbash-5.1# systemctl list-units\n  unit                                                                                                                                                  load   active     sub       description          \n  proc-sys-fs-binfmt_misc.automount                                                                                                                     loaded active     waiting   arbitrary executable file formats file system automount point\n  dev-pmem0p1.device                                                                                                                                    loaded activating tentative /dev/pmem0p1         \n  -.mount                                                                                                                                               loaded active     mounted   root mount\n  etc-machine\\x2did.mount                                                                                                                               loaded active     mounted   /etc/machine-id\n  etc-resolv.conf.mount                                                                                                                                 loaded active     mounted   /etc/resolv.conf\n  run-kata\\x2dcontainers-3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985-rootfs.mount                                                  loaded active     mounted   /run/kata-containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs\n  run-kata\\x2dcontainers-a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-rootfs.mount                                                  loaded active     mounted   /run/kata-containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs\n  run-kata\\x2dcontainers-sandbox-shm.mount                                                                                                              loaded active     mounted   /run/kata-containers/sandbox/shm\n  run-kata\\x2dcontainers-shared-containers-3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985-rootfs.mount                                loaded active     mounted   /run/kata-containers/shared/containers/3871d0c8108c66d3388f883f0d4de0cdf3e724607a06bce653fc13a988cd1985/rootfs\n  run-kata\\x2dcontainers-shared-containers-a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-rootfs.mount                                loaded active     mounted   /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a/rootfs\n  run-kata\\x2dcontainers-shared-containers-a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a\\x2d172195b99cf7a9fd\\x2dserviceaccount.mount loaded active     mounted   /run/kata-containers/shared/containers/a83ce7bc82f78808ff1aa8165e705ecded65634ba54a57a1eda68c19d751f98a-172195b99cf7a9fd-serviceaccount\n  run-kata\\x2dcontainers-shared-containers-watchable.mount                                                                                              loaded active     mounted   /run/kata-containers/shared/containers/watchable\n  run-kata\\x2dcontainers-shared-containers.mount                                                                                                        loaded active     mounted   /run/kata-containers/shared/containers\n  run-sandbox\\x2dns-ipc.mount                                                                                                                           loaded active     mounted   /run/sandbox-ns/ipc\n  run-sandbox\\x2dns-uts.mount                                                                                                                           loaded active     mounted   /run/sandbox-ns/uts\n  tmp.mount                                                                                                                                             loaded active     mounted   temporary directory /tmp\n  systemd-ask-password-console.path                                                                                                                     loaded active     waiting   dispatch password requests to console directory watch\n  init.scope                                                                                                                                            loaded active     running   system and service manager\n● chronyd.service                                                                                                                                       loaded failed     failed    ntp client/server\n  kata-agent.service                                                                                                                                    loaded active     running   kata containers agent\n  systemd-remount-fs.service                                                                                                                            loaded active     exited    remount root and kernel file systems\n  systemd-sysctl.service                                                                                                                                loaded active     exited    apply kernel variables\n  -.slice                                                                                                                                               loaded active     active    root slice\n  system.slice                                                                                                                                          loaded active     active    system slice         \n  systemd-coredump.socket                                                                                                                               loaded active     listening process core dump socket\n  basic.target                                                                                                                                          loaded active     active    basic system\n  cryptsetup.target                                                                                                                                     loaded active     active    local encrypted volumes\n  kata-containers.target                                                                                                                                loaded active     active    kata containers agent target\n  local-fs-pre.target                                                                                                                                   loaded active     active    preparation for local file systems\n  local-fs.target                                                                                                                                       loaded active     active    local file systems\n  paths.target                                                                                                                                          loaded active     active    path units\n  slices.target                                                                                                                                         loaded active     active    slice units\n  sockets.target                                                                                                                                        loaded active     active    socket units\n  swap.target                                                                                                                                           loaded active     active    swaps\n  sysinit.target                                                                                                                                        loaded active     active    system initialization\n  timers.target                                                                                                                                         loaded active     active    timer units          \n  systemd-tmpfiles-clean.timer                                                                                                                          loaded active     waiting   daily cleanup of temporary directories\n\nload   = reflects whether the unit definition was properly loaded.\nactive = the high-level unit activation state, i.e. generalization of sub.\nsub    = the low-level unit activation state, values depend on unit type.\n37 loaded units listed. pass --all to see loaded but inactive units, too.\nto show all installed unit files use \'systemctl list-unit-files\'.\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n\n\nbash-5.1#   systemctl cat kata-containers.target\n# /usr/lib/systemd/system/kata-containers.target\n#\n# copyright (c) 2018-2019 intel corporation\n#\n# spdx-license-identifier: apache-2.0\n#\n\n[unit]\ndescription=kata containers agent target\nrequires=basic.target\nrequires=tmp.mount\nwants=chronyd.service\nrequires=kata-agent.service\nconflicts=rescue.service rescue.target\nafter=basic.target rescue.service rescue.target\nallowisolate=yes\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# cpuinfo/meminfo (2c)\n\nbash-5.1# more /proc/cpuinfo\nprocessor       : 0\nvendor_id       : genuineintel\ncpu family      : 6\nmodel           : 158\nmodel name      : intel(r) core(tm) i7-7700 cpu @ 3.60ghz\nstepping        : 9\nmicrocode       : 0xea\ncpu mhz         : 3599.982\ncache size      : 16384 kb\nphysical id     : 0\nsiblings        : 1\ncore id         : 0\ncpu cores       : 1\napicid          : 0\ninitial apicid  : 0\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nflags           : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid tsc_known_ arat md_clearinvpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1--more--e_timer aes xsave avx f16c rdra--more--\niority tsc_offset vtpr mtf vapic ept vpid unrestricted_guest pmld ept_1gb flexpr--more--\nswapgs taa itlb_multihit srbds spectre_v1 spectre_v2 spec_store_bypass l1tf mds --more--\nbogomips        : 7199.96\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 39 bits physical, 48 bits virtual\npower management:\n\nprocessor       : 1\nvendor_id       : genuineintel\ncpu family      : 6\nmodel           : 158\nmodel name      : intel(r) core(tm) i7-7700 cpu @ 3.60ghz\nstepping        : 9\nmicrocode       : 0xea\ncpu mhz         : 3599.982\ncache size      : 16384 kb\nphysical id     : 7\nsiblings        : 1\ncore id         : 0\ncpu cores       : 1\napicid          : 7\ninitial apicid  : 7\nfpu             : yes\nfpu_exception   : yes\ncpuid level     : 13\nwp              : yes\nlushopt xsaveopt xsavec xgetbv1 arat md_clearinvpcid rtm mpx rdseed adx smap clf--more--\nswapgs taa itlb_multihit srbds spectre_v1 spectre_v2 spec_store_bypass l1tf mds --more--\nbogomips        : 7199.96\nclflush size    : 64\ncache_alignment : 64\naddress sizes   : 39 bits physical, 48 bits virtual\npower management:\n\n[root@localhost ~]# more /proc/meminfo   (??)\nmemtotal:        7935356 kb\nmemfree:          478024 kb\nmemavailable:    1827752 kb\nbuffers:            1064 kb\ncached:          1903388 kb\nswapcached:            0 kb\nactive:          5728076 kb\ninactive:         891144 kb\nactive(anon):    5029108 kb\ninactive(anon):   207680 kb\nactive(file):     698968 kb\ninactive(file):   683464 kb\nunevictable:           4 kb\nmlocked:               4 kb\nswaptotal:             0 kb\nswapfree:              0 kb\ndirty:              9584 kb\nwriteback:             0 kb\nanonpages:       4715640 kb\nmapped:           564200 kb\nshmem:            522020 kb\nslab:             469116 kb\nsreclaimable:     280468 kb\nsunreclaim:       188648 kb\nkernelstack:       43248 kb\npagetables:        39740 kb\nnfs_unstable:          0 kb\nbounce:                0 kb\nwritebacktmp:          0 kb\ncommitlimit:     3967676 kb\ncommitted_as:   23822760 kb\nvmalloctotal:   34359738367 kb\nvmallocused:      461976 kb\nvmallocchunk:   34358937596 kb\npercpu:            11552 kb\nhardwarecorrupted:     0 kb\nanonhugepages:     20480 kb\ncmatotal:              0 kb\ncmafree:               0 kb\nhugepages_total:       0\nhugepages_free:        0\nhugepages_rsvd:        0\nhugepages_surp:        0\nhugepagesize:       2048 kb\ndirectmap4k:      211152 kb\ndirectmap2m:     8038400 kb\ndirectmap1g:           0 kb\n[root@localhost ~]#\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n54\n55\n56\n57\n58\n59\n60\n61\n62\n63\n64\n65\n66\n67\n68\n69\n70\n71\n72\n73\n74\n75\n76\n77\n78\n79\n80\n81\n82\n83\n84\n85\n86\n87\n88\n89\n90\n91\n92\n93\n94\n95\n96\n97\n98\n99\n100\n101\n102\n103\n104\n105\n106\n\n\n\n# 总结\n\nlimit 1c1g default:1c2g\n\nvm: cpuinfo： 2cpu meminfo: memtotal: 7935356 kb (7.5g)\n\npod: cpuinfo：2cpu meminfo: memtotal: 3090364 kb (2.9g) free -h: 2.9g',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata-deploy部署、卸载与升级",frontmatter:{title:"kata-deploy部署、卸载与升级",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata0201/",categories:["技术杂谈","kata-containers","kata部署"],tags:[null],titleTag:"原创",readingShow:"top",description:"$ kubectl apply -f kata-rbac.yaml\n$ kubectl apply -f kata-deploy.yaml",meta:[{name:"twitter:title",content:"kata-deploy部署、卸载与升级"},{name:"twitter:description",content:"$ kubectl apply -f kata-rbac.yaml\n$ kubectl apply -f kata-deploy.yaml"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/02.kata%E9%83%A8%E7%BD%B2/01.kata-deploy%E9%83%A8%E7%BD%B2%E3%80%81%E5%8D%B8%E8%BD%BD%E4%B8%8E%E5%8D%87%E7%BA%A7.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata-deploy部署、卸载与升级"},{property:"og:description",content:"$ kubectl apply -f kata-rbac.yaml\n$ kubectl apply -f kata-deploy.yaml"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/02.kata%E9%83%A8%E7%BD%B2/01.kata-deploy%E9%83%A8%E7%BD%B2%E3%80%81%E5%8D%B8%E8%BD%BD%E4%B8%8E%E5%8D%87%E7%BA%A7.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata-deploy部署、卸载与升级"},{itemprop:"description",content:"$ kubectl apply -f kata-rbac.yaml\n$ kubectl apply -f kata-deploy.yaml"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/02.kata%E9%83%A8%E7%BD%B2/01.kata-deploy%E9%83%A8%E7%BD%B2%E3%80%81%E5%8D%B8%E8%BD%BD%E4%B8%8E%E5%8D%87%E7%BA%A7.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/02.kata部署/01.kata-deploy部署、卸载与升级.md",key:"v-d7e2a582",path:"/pages/kata0201/",headers:[{level:2,title:"部署kata-monitor",slug:"部署kata-monitor",normalizedTitle:"部署kata-monitor",charIndex:916},{level:3,title:"kata节点运行kata-monitor守护进程",slug:"kata节点运行kata-monitor守护进程",normalizedTitle:"kata节点运行kata-monitor守护进程",charIndex:958},{level:3,title:"promethues增加scrape_configs",slug:"promethues增加scrape-configs",normalizedTitle:"promethues增加scrape_configs",charIndex:1280},{level:3,title:"导入 Grafana dashborad",slug:"导入-grafana-dashborad",normalizedTitle:"导入 grafana dashborad",charIndex:1395},{level:2,title:"检查：",slug:"检查",normalizedTitle:"检查：",charIndex:1693}],headersStr:"部署kata-monitor kata节点运行kata-monitor守护进程 promethues增加scrape_configs 导入 Grafana dashborad 检查：",content:'# 前提\n\n * 物理机已开启硬件虚拟化\n * k8s容器运行时使用containerd（推荐）\n\n\n# 部署\n\n * 给kata节点打上label: kata-worker=true（如果不需要区分kata节点，可以把kata-deploy中的节点亲和性去掉）\n * 生成configuration.toml分发到各个kata节点（所有节点）/etc/kata-containers/configuration.toml\n * 创建kata资源：kata-rbac.yaml、kata-deploy.yaml，创建runtimeClass： runtimeClass.yaml\n\n$ kubectl apply -f kata-rbac.yaml\n$ kubectl apply -f kata-deploy.yaml\n\n$ kubectl -n kube-system wait --timeout=10m --for=condition=Ready -l name=kata-deploy pod\n\n$ kubectl apply -f kata-runtimeClasses.yaml\n\n\n1\n2\n3\n4\n5\n6\n\n * 各个kata节点（所有节点）创建软链接：\n\nln -s /opt/kata/bin/kata-runtime /usr/bin/kata-runtime\nln -s /opt/kata/bin/kata-monitor /usr/bin/kata-monitor\n\n\n1\n2\n\n\n注：\n\n * 需要注意的是kata-deploy重启可能会导致默认的configuration.toml文件恢复默认配置，因此使用的是优先级更高的/etc/kata-containers/configuration.toml\n * 使用ctr run创建的容器默认使用的是-qemu配置（/opt/kata/share/defaults/kata-containers/configuration-qemu.toml），如果需要使用ctr run测试，请同步配置到-qemu配置，或重定向shim链接到新的文件下\n\n\n# 部署kata-monitor\n\n详情见[[kata-monitor监控]]\n\n\n# kata节点运行kata-monitor守护进程\n\n[root@localhost ~]# cat /etc/systemd/system/kata-monitor.service\n[Unit]\nDescription=kata monitor\n\n[Service]\nExecStart=/opt/kata/bin/kata-monitor -listen-address 0.0.0.0:8090\nRestart=always\nStartLimitInterval=0\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# promethues增加scrape_configs\n\n- job_name: \'kata\'\n    static_configs:\n    - targets: [\'<kata节点IP>:8090\']\n\n\n1\n2\n3\n\n\n\n# 导入 Grafana dashborad\n\n$ curl -XPOST -i <grafana节点IP>:3000/api/dashboards/import \\\n    -u admin:admin \\\n    -H "Content-Type: application/json" \\\n\t-d "{\\"dashboard\\":$(curl -sL https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/how-to/data/dashboard.json )}"\n\n\n1\n2\n3\n4\n\n\n\n# 检查：\n\n[root@rqy-k8s-1 ~]# kata-runtime check\n  WARN[0000] Not running network checks as super user      arch=amd64 name=kata-runtime pid=48176 source=runtime\n  System is capable of running Kata Containers\n  System can currently create Kata Containers\n\n\n1\n2\n3\n4\n\n\n\n# 卸载\n\n * 删除所有kata容器\n * 删除kata节点软连接\n * 删除kata资源：kata-rbac.yaml、kata-deploy.yaml、runtimeClass.yaml\n * 删除kata节点configuration.toml文件\n\n$ kubectl delete -f kata-deploy.yaml\n\n$ kubectl -n kube-system wait --timeout=10m --for=delete -l name=kata-deploy pod\n\n$ kubectl apply -f kata-cleanup.yaml\n# The cleanup daemon-set will run a single time, cleaning up the node-label, which makes it difficult to check in an automated fashion. This process should take, at most, 5 minutes.\n# kubectl get pod -n kube-system | grep kubelet-kata-cleanup\n\n$ kubectl delete -f kata-cleanup.yaml\n$ kubectl delete -f kata-rbac.yaml\n$ kubectl delete -f kata-runtimeClasses.yaml\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 升级(TODO)',normalizedContent:'# 前提\n\n * 物理机已开启硬件虚拟化\n * k8s容器运行时使用containerd（推荐）\n\n\n# 部署\n\n * 给kata节点打上label: kata-worker=true（如果不需要区分kata节点，可以把kata-deploy中的节点亲和性去掉）\n * 生成configuration.toml分发到各个kata节点（所有节点）/etc/kata-containers/configuration.toml\n * 创建kata资源：kata-rbac.yaml、kata-deploy.yaml，创建runtimeclass： runtimeclass.yaml\n\n$ kubectl apply -f kata-rbac.yaml\n$ kubectl apply -f kata-deploy.yaml\n\n$ kubectl -n kube-system wait --timeout=10m --for=condition=ready -l name=kata-deploy pod\n\n$ kubectl apply -f kata-runtimeclasses.yaml\n\n\n1\n2\n3\n4\n5\n6\n\n * 各个kata节点（所有节点）创建软链接：\n\nln -s /opt/kata/bin/kata-runtime /usr/bin/kata-runtime\nln -s /opt/kata/bin/kata-monitor /usr/bin/kata-monitor\n\n\n1\n2\n\n\n注：\n\n * 需要注意的是kata-deploy重启可能会导致默认的configuration.toml文件恢复默认配置，因此使用的是优先级更高的/etc/kata-containers/configuration.toml\n * 使用ctr run创建的容器默认使用的是-qemu配置（/opt/kata/share/defaults/kata-containers/configuration-qemu.toml），如果需要使用ctr run测试，请同步配置到-qemu配置，或重定向shim链接到新的文件下\n\n\n# 部署kata-monitor\n\n详情见[[kata-monitor监控]]\n\n\n# kata节点运行kata-monitor守护进程\n\n[root@localhost ~]# cat /etc/systemd/system/kata-monitor.service\n[unit]\ndescription=kata monitor\n\n[service]\nexecstart=/opt/kata/bin/kata-monitor -listen-address 0.0.0.0:8090\nrestart=always\nstartlimitinterval=0\nrestartsec=10\n\n[install]\nwantedby=multi-user.target\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# promethues增加scrape_configs\n\n- job_name: \'kata\'\n    static_configs:\n    - targets: [\'<kata节点ip>:8090\']\n\n\n1\n2\n3\n\n\n\n# 导入 grafana dashborad\n\n$ curl -xpost -i <grafana节点ip>:3000/api/dashboards/import \\\n    -u admin:admin \\\n    -h "content-type: application/json" \\\n\t-d "{\\"dashboard\\":$(curl -sl https://raw.githubusercontent.com/kata-containers/kata-containers/main/docs/how-to/data/dashboard.json )}"\n\n\n1\n2\n3\n4\n\n\n\n# 检查：\n\n[root@rqy-k8s-1 ~]# kata-runtime check\n  warn[0000] not running network checks as super user      arch=amd64 name=kata-runtime pid=48176 source=runtime\n  system is capable of running kata containers\n  system can currently create kata containers\n\n\n1\n2\n3\n4\n\n\n\n# 卸载\n\n * 删除所有kata容器\n * 删除kata节点软连接\n * 删除kata资源：kata-rbac.yaml、kata-deploy.yaml、runtimeclass.yaml\n * 删除kata节点configuration.toml文件\n\n$ kubectl delete -f kata-deploy.yaml\n\n$ kubectl -n kube-system wait --timeout=10m --for=delete -l name=kata-deploy pod\n\n$ kubectl apply -f kata-cleanup.yaml\n# the cleanup daemon-set will run a single time, cleaning up the node-label, which makes it difficult to check in an automated fashion. this process should take, at most, 5 minutes.\n# kubectl get pod -n kube-system | grep kubelet-kata-cleanup\n\n$ kubectl delete -f kata-cleanup.yaml\n$ kubectl delete -f kata-rbac.yaml\n$ kubectl delete -f kata-runtimeclasses.yaml\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 升级(todo)',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata-deploy分析",frontmatter:{title:"kata-deploy分析",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata0202/",categories:["技术杂谈","kata-containers","kata部署"],tags:[null],titleTag:"原创",readingShow:"top",description:"在节点上安装必要的 Kata 二进制文件、配置文件和虚拟机组件。安装后，DaemonSet 添加一个节点标签katacontainers.io/kata-runtime=true并重新配置 CRI-O 或 containerd 以注册三个runtimeClasses：kata-clh、kata-qemu和kata-fc。作为最后一步，DaemonSet 重新启动 CRI-O 或 containerd。删除后，DaemonSet 会删除 Kata 二进制文件和 VM 工件，并将节点标签更新为katacontainers.io/kata-runtime=cleanup.",meta:[{name:"twitter:title",content:"kata-deploy分析"},{name:"twitter:description",content:"在节点上安装必要的 Kata 二进制文件、配置文件和虚拟机组件。安装后，DaemonSet 添加一个节点标签katacontainers.io/kata-runtime=true并重新配置 CRI-O 或 containerd 以注册三个runtimeClasses：kata-clh、kata-qemu和kata-fc。作为最后一步，DaemonSet 重新启动 CRI-O 或 containerd。删除后，DaemonSet 会删除 Kata 二进制文件和 VM 工件，并将节点标签更新为katacontainers.io/kata-runtime=cleanup."},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/02.kata%E9%83%A8%E7%BD%B2/02.kata-deploy%E5%88%86%E6%9E%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata-deploy分析"},{property:"og:description",content:"在节点上安装必要的 Kata 二进制文件、配置文件和虚拟机组件。安装后，DaemonSet 添加一个节点标签katacontainers.io/kata-runtime=true并重新配置 CRI-O 或 containerd 以注册三个runtimeClasses：kata-clh、kata-qemu和kata-fc。作为最后一步，DaemonSet 重新启动 CRI-O 或 containerd。删除后，DaemonSet 会删除 Kata 二进制文件和 VM 工件，并将节点标签更新为katacontainers.io/kata-runtime=cleanup."},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/02.kata%E9%83%A8%E7%BD%B2/02.kata-deploy%E5%88%86%E6%9E%90.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata-deploy分析"},{itemprop:"description",content:"在节点上安装必要的 Kata 二进制文件、配置文件和虚拟机组件。安装后，DaemonSet 添加一个节点标签katacontainers.io/kata-runtime=true并重新配置 CRI-O 或 containerd 以注册三个runtimeClasses：kata-clh、kata-qemu和kata-fc。作为最后一步，DaemonSet 重新启动 CRI-O 或 containerd。删除后，DaemonSet 会删除 Kata 二进制文件和 VM 工件，并将节点标签更新为katacontainers.io/kata-runtime=cleanup."}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/02.kata%E9%83%A8%E7%BD%B2/02.kata-deploy%E5%88%86%E6%9E%90.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/02.kata部署/02.kata-deploy分析.md",key:"v-7ebc8c8b",path:"/pages/kata0202/",headers:[{level:2,title:"Host artifacts:",slug:"host-artifacts",normalizedTitle:"host artifacts:",charIndex:291},{level:2,title:"Virtual Machine artifacts:",slug:"virtual-machine-artifacts",normalizedTitle:"virtual machine artifacts:",charIndex:431},{level:2,title:"kata-deploy内部",slug:"kata-deploy内部",normalizedTitle:"kata-deploy内部",charIndex:1405}],headersStr:"Host artifacts: Virtual Machine artifacts: kata-deploy内部",content:'在节点上安装必要的 Kata 二进制文件、配置文件和虚拟机组件。安装后，DaemonSet 添加一个节点标签katacontainers.io/kata-runtime=true并重新配置 CRI-O 或 containerd 以注册三个runtimeClasses：kata-clh、kata-qemu和kata-fc。作为最后一步，DaemonSet 重新启动 CRI-O 或 containerd。删除后，DaemonSet 会删除 Kata 二进制文件和 VM 工件，并将节点标签更新为katacontainers.io/kata-runtime=cleanup.\n\n\n# Host artifacts:\n\ncloud-hypervisor, firecracker, qemu, and supporting binaries containerd-shim-kata-v2 kata-collect-data.sh kata-runtime\n\n\n# Virtual Machine artifacts:\n\nkata-containers.img and kata-containers-initrd.img vmlinuz.container and vmlinuz-virtiofs.container\n\n\n# 部署kata-deploy之后\n\n[root@localhost ~]# ps -ef | grep kata\nroot     16533 16031  0 14:26 pts/1    00:00:00 grep --color=auto kata\nroot     24526 20728  0 11:09 ?        00:00:00 bash /opt/kata-artifacts/scripts/kata-deploy.sh install\n[root@localhost ~]# ps -ef | grep qemu\nroot     18834 16031  0 14:27 pts/1    00:00:00 grep --color=auto qemu\n[root@localhost ~]#\n[root@localhost ~]#\n[root@localhost ~]# ps -ef | grep kvm\nroot       756     2  0 Mar25 ?        00:00:00 [kvm-irqfd-clean]\nroot     18975 16031  0 14:27 pts/1    00:00:00 grep --color=auto kvm\n[root@localhost ~]# ls /opt/kata/\nbin  libexec  share\n[root@localhost ~]# ls /opt/kata/bin/\ncloud-hypervisor         firecracker  kata-collect-data.sh  kata-runtime\ncontainerd-shim-kata-v2  jailer       kata-monitor          qemu-system-x86_64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# kata-deploy内部\n\n[root@kata-deploy-6r86s /]# ps -ef \nUID        PID  PPID  C STIME TTY          TIME CMD\nroot         1     0  0 03:09 ?        00:00:00 bash /opt/kata-artifacts/scripts/kata-deploy.sh install\nroot        80     1  0 03:09 ?        00:00:00 sleep infinity\nroot        81     0  0 06:41 pts/0    00:00:00 bash\nroot        96    81  0 06:42 pts/0    00:00:00 ps -ef\n挂载/run/system后可以控制宿主机服务\n[root@kata-deploy-6r86s /]# systemctl status containerd\n● containerd.service - containerd container runtime\n   Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)\n   Active: active (running) since Thu 2022-04-07 06:47:47 UTC; 6min ago\n     Docs: https://containerd.io\n  Process: 3033 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCCESS)\n Main PID: 3035\n    Tasks: 585\n   Memory: 535.9M\n   CGroup: /system.slice/containerd.service\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 部署后containerd配置追加\n\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n  runtime_type = "io.containerd.kata.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc]\n  runtime_type = "io.containerd.kata-fc.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration-fc.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu]\n  runtime_type = "io.containerd.kata-qemu.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration-qemu.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh]\n  runtime_type = "io.containerd.kata-clh.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration-clh.toml"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 部署日志：\n\ncopying kata artifacts onto host\nwarning: containerd-shim-kata-fc-v2 already exists\n#!/usr/bin/env bash\nKATA_CONF_FILE=/opt/kata/share/defaults/kata-containers/configuration-fc.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\nwarning: containerd-shim-kata-qemu-v2 already exists\n#!/usr/bin/env bash\nKATA_CONF_FILE=/opt/kata/share/defaults/kata-containers/configuration-qemu.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\nCreating the default shim-v2 binary\nwarning: containerd-shim-kata-clh-v2 already exists\n#!/usr/bin/env bash\nKATA_CONF_FILE=/opt/kata/share/defaults/kata-containers/configuration-clh.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\nAdd Kata Containers as a supported runtime for containerd\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n  runtime_type = "io.containerd.kata.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc]\n  runtime_type = "io.containerd.kata-fc.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration-fc.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu]\n  runtime_type = "io.containerd.kata-qemu.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration-qemu.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh]\n  runtime_type = "io.containerd.kata-clh.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh.options]\n    ConfigPath = "/opt/kata/share/defaults/kata-containers/configuration-clh.toml"\nnode/localhost.localdomain unlabeled\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n',normalizedContent:'在节点上安装必要的 kata 二进制文件、配置文件和虚拟机组件。安装后，daemonset 添加一个节点标签katacontainers.io/kata-runtime=true并重新配置 cri-o 或 containerd 以注册三个runtimeclasses：kata-clh、kata-qemu和kata-fc。作为最后一步，daemonset 重新启动 cri-o 或 containerd。删除后，daemonset 会删除 kata 二进制文件和 vm 工件，并将节点标签更新为katacontainers.io/kata-runtime=cleanup.\n\n\n# host artifacts:\n\ncloud-hypervisor, firecracker, qemu, and supporting binaries containerd-shim-kata-v2 kata-collect-data.sh kata-runtime\n\n\n# virtual machine artifacts:\n\nkata-containers.img and kata-containers-initrd.img vmlinuz.container and vmlinuz-virtiofs.container\n\n\n# 部署kata-deploy之后\n\n[root@localhost ~]# ps -ef | grep kata\nroot     16533 16031  0 14:26 pts/1    00:00:00 grep --color=auto kata\nroot     24526 20728  0 11:09 ?        00:00:00 bash /opt/kata-artifacts/scripts/kata-deploy.sh install\n[root@localhost ~]# ps -ef | grep qemu\nroot     18834 16031  0 14:27 pts/1    00:00:00 grep --color=auto qemu\n[root@localhost ~]#\n[root@localhost ~]#\n[root@localhost ~]# ps -ef | grep kvm\nroot       756     2  0 mar25 ?        00:00:00 [kvm-irqfd-clean]\nroot     18975 16031  0 14:27 pts/1    00:00:00 grep --color=auto kvm\n[root@localhost ~]# ls /opt/kata/\nbin  libexec  share\n[root@localhost ~]# ls /opt/kata/bin/\ncloud-hypervisor         firecracker  kata-collect-data.sh  kata-runtime\ncontainerd-shim-kata-v2  jailer       kata-monitor          qemu-system-x86_64\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n\n# kata-deploy内部\n\n[root@kata-deploy-6r86s /]# ps -ef \nuid        pid  ppid  c stime tty          time cmd\nroot         1     0  0 03:09 ?        00:00:00 bash /opt/kata-artifacts/scripts/kata-deploy.sh install\nroot        80     1  0 03:09 ?        00:00:00 sleep infinity\nroot        81     0  0 06:41 pts/0    00:00:00 bash\nroot        96    81  0 06:42 pts/0    00:00:00 ps -ef\n挂载/run/system后可以控制宿主机服务\n[root@kata-deploy-6r86s /]# systemctl status containerd\n● containerd.service - containerd container runtime\n   loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; vendor preset: disabled)\n   active: active (running) since thu 2022-04-07 06:47:47 utc; 6min ago\n     docs: https://containerd.io\n  process: 3033 execstartpre=/sbin/modprobe overlay (code=exited, status=0/success)\n main pid: 3035\n    tasks: 585\n   memory: 535.9m\n   cgroup: /system.slice/containerd.service\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\n\n# 部署后containerd配置追加\n\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n  runtime_type = "io.containerd.kata.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc]\n  runtime_type = "io.containerd.kata-fc.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration-fc.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu]\n  runtime_type = "io.containerd.kata-qemu.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration-qemu.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh]\n  runtime_type = "io.containerd.kata-clh.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration-clh.toml"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n\n\n\n# 部署日志：\n\ncopying kata artifacts onto host\nwarning: containerd-shim-kata-fc-v2 already exists\n#!/usr/bin/env bash\nkata_conf_file=/opt/kata/share/defaults/kata-containers/configuration-fc.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\nwarning: containerd-shim-kata-qemu-v2 already exists\n#!/usr/bin/env bash\nkata_conf_file=/opt/kata/share/defaults/kata-containers/configuration-qemu.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\ncreating the default shim-v2 binary\nwarning: containerd-shim-kata-clh-v2 already exists\n#!/usr/bin/env bash\nkata_conf_file=/opt/kata/share/defaults/kata-containers/configuration-clh.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\nadd kata containers as a supported runtime for containerd\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n  runtime_type = "io.containerd.kata.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc]\n  runtime_type = "io.containerd.kata-fc.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-fc.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration-fc.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu]\n  runtime_type = "io.containerd.kata-qemu.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-qemu.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration-qemu.toml"\n[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh]\n  runtime_type = "io.containerd.kata-clh.v2"\n  privileged_without_host_devices = true\n  pod_annotations = ["io.katacontainers.*"]\n  [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata-clh.options]\n    configpath = "/opt/kata/share/defaults/kata-containers/configuration-clh.toml"\nnode/localhost.localdomain unlabeled\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"常用命令",frontmatter:{title:"常用命令",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata0401/",categories:["技术杂谈","kata-containers","kata应用"],tags:[null],titleTag:"原创",readingShow:"top",description:"WARN[0000] Not running network checks as super user      arch=amd64 name=kata-runtime pid=25571 source=runtime\n>\n> System is capable of running Kata Containers\n>\n> System can currently create Kata Containers",meta:[{name:"twitter:title",content:"常用命令"},{name:"twitter:description",content:"WARN[0000] Not running network checks as super user      arch=amd64 name=kata-runtime pid=25571 source=runtime\n>\n> System is capable of running Kata Containers\n>\n> System can currently create Kata Containers"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/01.%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html"},{property:"og:type",content:"article"},{property:"og:title",content:"常用命令"},{property:"og:description",content:"WARN[0000] Not running network checks as super user      arch=amd64 name=kata-runtime pid=25571 source=runtime\n>\n> System is capable of running Kata Containers\n>\n> System can currently create Kata Containers"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/01.%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"常用命令"},{itemprop:"description",content:"WARN[0000] Not running network checks as super user      arch=amd64 name=kata-runtime pid=25571 source=runtime\n>\n> System is capable of running Kata Containers\n>\n> System can currently create Kata Containers"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/01.%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/01.常用命令.md",key:"v-33dd887e",path:"/pages/kata0401/",headers:[{level:2,title:"进入kata虚拟机  kata-runtime  exec",slug:"进入kata虚拟机-kata-runtime-exec",normalizedTitle:"进入kata虚拟机  kata-runtime  exec",charIndex:null}],headersStr:"进入kata虚拟机  kata-runtime  exec",content:'# kata-rumtime\n\n * kata-runtime check\n\n> WARN[0000] Not running network checks as super user      arch=amd64 name=kata-runtime pid=25571 source=runtime\n> \n> System is capable of running Kata Containers\n> \n> System can currently create Kata Containers\n\n * kata-runtime env\n\n * kata-runtime metrics fd77dc25ad3e958ded82cc5449c521a00b8300b71981370ba43a757e14ce7b19\n\n\n# 进入kata虚拟机 kata-runtime exec\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/Developer-Guide.md#connect-to-debug-console\n\nkata v2环境中考虑到安全性问题不能直接使用kata-runtime exec进入sandbox虚拟机，并且kata release版本的镜像没有包含登录组件，如果要登录需要重新制作sandbox文件系统，登录sandbox需要通过kata-monitor并且sandbox需要在kata-monitor启动之后再启动才能进行调试工作\n\n * 修改配置 debug_console_enabled\n\n> [agent.kata] debug_console_enabled = true\n\n * 启动kata-monitor\n\n[root@rqy-k8s-1 kbuser]# /opt/kata/bin/kata-monitor\nINFO[0000] announce                    app=kata-monitor arch=amd64 git-commit=8d545f7438fc8b1189c1dcc8c414dcc50f7e5587 go-version=go1.17.3 listen-address="127.0.0.1:8090" log-level=info os=linux runtime-endpoint=/run/containerd/containerd.sock version=0.3.0\n\n\n\n# 虚拟机里面，是个超级简化的系统，命令奇缺\n[root@rqy-k8s-1 kbuser]# kata-runtime exec 1b482bb4613ba606894d30370fe7637610a495d9b3a504bc36e9aa292db9a0f0\nbash: grep: command not found\nbash: grep: command not found\nbash: tty: command not found\nbash: expr: command not found\nbash: [: : integer expression expected\nbash-5.1#\nbash-5.1#\nbash-5.1# df -h\nbash: df: command not found\nbash-5.1# lsblk\nNAME    MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS\npmem0   259:0   0  126M  1 disk\n`-pmem0p1 259:1   0  124M  1 part /\nbash-5.1# ip addr\nbash: ip: command not found\nbash-5.1# ifconfig\nbash: ifconfig: command not found\n# 详情见[一个kata容器的创建示例]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# crictl\n\nctr是containerd的一个客户端工具\n\ncrictl 是 CRI 兼容的容器运行时命令行接口，可以使用它来检查和调试 Kubernetes 节点上的容器运行时和应用程序\n\ncrictl 使用命名空间 k8s.io，即crictl image list = ctr -n=k8s.io image list\n\ncrictl config runtime-endpoint unix:///run/containerd/containerd.sock crictl ps #同docker ps crictl inspect crictl exec crictl pods # 可以查看哪些是kata容器 crictl images # 同docker images crictl logs\n\ncrictl ps | grep stress\n86a94ad5059a4  14701355bb465   12 minutes ago   Running    stress   0    7247eaccec1b6\ncrictl inspect  86a94ad5059a4\ncrictl exec -it  86a94ad5059a4 bash\nrictl stats 86a94ad5059a4\nCONTAINER    CPU %     MEM        DISK         INODES\n86a94ad5059a4  99.88     1.628GB       0B          13\ncrictl pods | grep stress\nbcfeedf0c17bf   3 minutes ago    Ready   stress-b4fdd868-s8d7n     default     0      kata\ncrictl images | grep vish/stress\ndocker.io/vish/stress      latest          14701355bb465    1.56MB\n[root@localhost kata]# POD_ID="$(sudo crictl pods --name test -q)"\n[root@localhost kata]# echo $POD_ID\n2766411ac797b74cdb16fc7a042715e434cfa127c522e45ffe347bd5f7f88cbb\n[root@localhost kata]# crictl inspectp -o=json $POD_ID | grep cgroupsPath\n "cgroupsPath": "/kubepods/pod31c20d7a-3733-4b8c-8651-160b23868773/2766411ac797b74cdb16fc7a042715e434cfa127c522e45ffe347bd5f7f88cbb",\n [root@localhost kata]# cat /sys/fs/cgroup/memory/kubepods/pod31c20d7a-3733-4b8c-8651-160b23868773/memory.limit_in_bytes\n524288000\n[root@rqy-k8s-1 kbuser]# ls /run/vc/vm/\n685a6f8538efaee72b1d38efd824aff76241b6ff307e75d3764b3d0606d33894  6d46a824dae01c4675da741ca2aff98b1e7eb005103d10cf0c3af6f758c97afe [root@rqy-k8s-1 kbuser]# kata-runtime exec 685a6f8538efaee72b1d38efd824aff76241b6ff307e75d3764b3d0606d33894 rpc error: code = DeadlineExceeded desc = timed out connecting to vsock 621008089:1026\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# ctr\n\nctr -n k8s.io image list\n\nctr -n k8s.io i export img.tar imgname\n\nctr -n k8s.io i import img.tar\n\nctr run -d imgname hfftest\n\n// 测试增加--rm参数退出后删除，否则退出后进程不会删除 ctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/xridge/fio:latest hfftest sh\n\nctr -n k8s.io t kill -s SIGKILL hfftest ctr -n k8s.io t rm hfftest\n\nctr -n k8s.io snapshot rm hfftest ctr -n k8s.io container rm hfftest\n\nctr -n k8s.io tasks list\n\nctr -n k8s.io task ps hfftest ctr -n k8s.io t exec --exec-id $RANDOM -t hfftest sh\n\n\n# 镜像管理命令\n\ndockers images ctr -n k8s.io images list crictl images\n\ndocker inspect pause:3.1 crictl inspecti docker.io/vish/stress:latest ctr无inspec命令\n\ndocker pull vish/stress ctr -n k8s.io pull vish/stress\n\n\n# 附件',normalizedContent:'# kata-rumtime\n\n * kata-runtime check\n\n> warn[0000] not running network checks as super user      arch=amd64 name=kata-runtime pid=25571 source=runtime\n> \n> system is capable of running kata containers\n> \n> system can currently create kata containers\n\n * kata-runtime env\n\n * kata-runtime metrics fd77dc25ad3e958ded82cc5449c521a00b8300b71981370ba43a757e14ce7b19\n\n\n# 进入kata虚拟机 kata-runtime exec\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/developer-guide.md#connect-to-debug-console\n\nkata v2环境中考虑到安全性问题不能直接使用kata-runtime exec进入sandbox虚拟机，并且kata release版本的镜像没有包含登录组件，如果要登录需要重新制作sandbox文件系统，登录sandbox需要通过kata-monitor并且sandbox需要在kata-monitor启动之后再启动才能进行调试工作\n\n * 修改配置 debug_console_enabled\n\n> [agent.kata] debug_console_enabled = true\n\n * 启动kata-monitor\n\n[root@rqy-k8s-1 kbuser]# /opt/kata/bin/kata-monitor\ninfo[0000] announce                    app=kata-monitor arch=amd64 git-commit=8d545f7438fc8b1189c1dcc8c414dcc50f7e5587 go-version=go1.17.3 listen-address="127.0.0.1:8090" log-level=info os=linux runtime-endpoint=/run/containerd/containerd.sock version=0.3.0\n\n\n\n# 虚拟机里面，是个超级简化的系统，命令奇缺\n[root@rqy-k8s-1 kbuser]# kata-runtime exec 1b482bb4613ba606894d30370fe7637610a495d9b3a504bc36e9aa292db9a0f0\nbash: grep: command not found\nbash: grep: command not found\nbash: tty: command not found\nbash: expr: command not found\nbash: [: : integer expression expected\nbash-5.1#\nbash-5.1#\nbash-5.1# df -h\nbash: df: command not found\nbash-5.1# lsblk\nname    maj:min rm  size ro type mountpoints\npmem0   259:0   0  126m  1 disk\n`-pmem0p1 259:1   0  124m  1 part /\nbash-5.1# ip addr\nbash: ip: command not found\nbash-5.1# ifconfig\nbash: ifconfig: command not found\n# 详情见[一个kata容器的创建示例]\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n\n\n\n# crictl\n\nctr是containerd的一个客户端工具\n\ncrictl 是 cri 兼容的容器运行时命令行接口，可以使用它来检查和调试 kubernetes 节点上的容器运行时和应用程序\n\ncrictl 使用命名空间 k8s.io，即crictl image list = ctr -n=k8s.io image list\n\ncrictl config runtime-endpoint unix:///run/containerd/containerd.sock crictl ps #同docker ps crictl inspect crictl exec crictl pods # 可以查看哪些是kata容器 crictl images # 同docker images crictl logs\n\ncrictl ps | grep stress\n86a94ad5059a4  14701355bb465   12 minutes ago   running    stress   0    7247eaccec1b6\ncrictl inspect  86a94ad5059a4\ncrictl exec -it  86a94ad5059a4 bash\nrictl stats 86a94ad5059a4\ncontainer    cpu %     mem        disk         inodes\n86a94ad5059a4  99.88     1.628gb       0b          13\ncrictl pods | grep stress\nbcfeedf0c17bf   3 minutes ago    ready   stress-b4fdd868-s8d7n     default     0      kata\ncrictl images | grep vish/stress\ndocker.io/vish/stress      latest          14701355bb465    1.56mb\n[root@localhost kata]# pod_id="$(sudo crictl pods --name test -q)"\n[root@localhost kata]# echo $pod_id\n2766411ac797b74cdb16fc7a042715e434cfa127c522e45ffe347bd5f7f88cbb\n[root@localhost kata]# crictl inspectp -o=json $pod_id | grep cgroupspath\n "cgroupspath": "/kubepods/pod31c20d7a-3733-4b8c-8651-160b23868773/2766411ac797b74cdb16fc7a042715e434cfa127c522e45ffe347bd5f7f88cbb",\n [root@localhost kata]# cat /sys/fs/cgroup/memory/kubepods/pod31c20d7a-3733-4b8c-8651-160b23868773/memory.limit_in_bytes\n524288000\n[root@rqy-k8s-1 kbuser]# ls /run/vc/vm/\n685a6f8538efaee72b1d38efd824aff76241b6ff307e75d3764b3d0606d33894  6d46a824dae01c4675da741ca2aff98b1e7eb005103d10cf0c3af6f758c97afe [root@rqy-k8s-1 kbuser]# kata-runtime exec 685a6f8538efaee72b1d38efd824aff76241b6ff307e75d3764b3d0606d33894 rpc error: code = deadlineexceeded desc = timed out connecting to vsock 621008089:1026\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# ctr\n\nctr -n k8s.io image list\n\nctr -n k8s.io i export img.tar imgname\n\nctr -n k8s.io i import img.tar\n\nctr run -d imgname hfftest\n\n// 测试增加--rm参数退出后删除，否则退出后进程不会删除 ctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/xridge/fio:latest hfftest sh\n\nctr -n k8s.io t kill -s sigkill hfftest ctr -n k8s.io t rm hfftest\n\nctr -n k8s.io snapshot rm hfftest ctr -n k8s.io container rm hfftest\n\nctr -n k8s.io tasks list\n\nctr -n k8s.io task ps hfftest ctr -n k8s.io t exec --exec-id $random -t hfftest sh\n\n\n# 镜像管理命令\n\ndockers images ctr -n k8s.io images list crictl images\n\ndocker inspect pause:3.1 crictl inspecti docker.io/vish/stress:latest ctr无inspec命令\n\ndocker pull vish/stress ctr -n k8s.io pull vish/stress\n\n\n# 附件',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata使用问题汇总",frontmatter:{title:"kata使用问题汇总",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata0402/",categories:["技术杂谈","kata-containers","kata应用"],tags:[null],titleTag:"原创",readingShow:"top",description:"​\t\t一些使用主机网络的k8s组件和业务无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。",meta:[{name:"twitter:title",content:"kata使用问题汇总"},{name:"twitter:description",content:"​\t\t一些使用主机网络的k8s组件和业务无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/02.kata%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata使用问题汇总"},{property:"og:description",content:"​\t\t一些使用主机网络的k8s组件和业务无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/02.kata%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata使用问题汇总"},{itemprop:"description",content:"​\t\t一些使用主机网络的k8s组件和业务无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/02.kata%E4%BD%BF%E7%94%A8%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/02.kata使用问题汇总.md",key:"v-03d01b37",path:"/pages/kata0402/",headers:[{level:2,title:"不支持subPaths(emptyDir )使用",slug:"不支持subpaths-emptydir-使用",normalizedTitle:"不支持subpaths(emptydir )使用",charIndex:75},{level:2,title:"kata不支持host网络",slug:"kata不支持host网络",normalizedTitle:"kata不支持host网络",charIndex:104},{level:2,title:"不支持网络命名空间共享",slug:"不支持网络命名空间共享",normalizedTitle:"不支持网络命名空间共享",charIndex:212},{level:2,title:"不支持cpuset-cpus",slug:"不支持cpuset-cpus",normalizedTitle:"不支持cpuset-cpus",charIndex:433},{level:2,title:"容器内fio测试(压内存)会导致host上对应qemu进程oom，或节点卡死，节点异常问题",slug:"容器内fio测试-压内存-会导致host上对应qemu进程oom-或节点卡死-节点异常问题",normalizedTitle:"容器内fio测试(压内存)会导致host上对应qemu进程oom，或节点卡死，节点异常问题",charIndex:1995},{level:2,title:"Overhead的CPU和内存占用应该纳入已分配配额？？？",slug:"overhead的cpu和内存占用应该纳入已分配配额",normalizedTitle:"overhead的cpu和内存占用应该纳入已分配配额？？？",charIndex:2267},{level:2,title:"容器使用内存不会自动release？？",slug:"容器使用内存不会自动release",normalizedTitle:"容器使用内存不会自动release？？",charIndex:2301},{level:2,title:"未enable DAX, fio测试结果较差？？",slug:"未enable-dax-fio测试结果较差",normalizedTitle:"未enable dax, fio测试结果较差？？",charIndex:2336},{level:2,title:"qemu 不能直接使用 veth-pair, 导致vm+container的网络拓扑比较复杂且容易有性能问题, kubevirt同样的问题",slug:"qemu-不能直接使用-veth-pair-导致vm-container的网络拓扑比较复杂且容易有性能问题-kubevirt同样的问题",normalizedTitle:"qemu 不能直接使用 veth-pair, 导致vm+container的网络拓扑比较复杂且容易有性能问题, kubevirt同样的问题",charIndex:2374}],headersStr:"不支持subPaths(emptyDir )使用 kata不支持host网络 不支持网络命名空间共享 不支持cpuset-cpus 容器内fio测试(压内存)会导致host上对应qemu进程oom，或节点卡死，节点异常问题 Overhead的CPU和内存占用应该纳入已分配配额？？？ 容器使用内存不会自动release？？ 未enable DAX, fio测试结果较差？？ qemu 不能直接使用 veth-pair, 导致vm+container的网络拓扑比较复杂且容易有性能问题, kubevirt同样的问题",content:'# docker 兼容问题\n\n * kata已去掉docker cli支持，请使用crictl命令\n\n * DinD问题\n\n\n# 使用限制：\n\n\n# 不支持subPaths(emptyDir )使用\n\n\n# kata不支持host网络\n\n一些使用主机网络的k8s组件和业务无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。\n\n\n# 不支持网络命名空间共享\n\nDocker 支持容器使用docker run --net=containers语法加入另一个容器命名空间的能力。这允许多个容器共享一个公共网络命名空间和放置在网络命名空间中的网络接口。Kata Containers 不支持网络命名空间共享。如果将 Kata 容器设置为共享runc容器的网络命名空间，则运行时会有效地接管分配给命名空间的所有网络接口并将它们绑定到 VM。因此，runc容器失去其网络连接。\n\n\n# 不支持cpuset-cpus\n\nhttps://github.com/kata-containers/runtime/issues/1079 docker run -d --cpuset-cpus= “ 0-1 ” ubuntu sleep 30000\n\n\n# ctr依赖/configuration-qemu.toml路径问题\n\n/etc/kata-containers/configuration.toml已存在，为测试删除了默认配置文件，但是containerd配置保留\n\n[root@localhost ~]# cat  /etc/containerd/config.toml \n      [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n        runtime_type = "io.containerd.kata.v2"\n        privileged_without_host_devices = true\n        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata.options]\n           ConfigPath = "/etc/kata-containers/configuration.toml"\n\n[root@localhost ~]# kubectl get runtimeclasses.node.k8s.io kata-containers -o yaml | grep handler\nhandler: kata\n\n[root@localhost ~]# ctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/library/busybox:latest hfftest dmesg \nctr: Cannot find usable config file (file /opt/kata/share/defaults/kata-containers/configuration-qemu.toml does not exist): not found\n\n\n[root@rqy-k8s-1 kbuser]# ll /usr/local/bin/containerd-shim-kata-v2\nlrwxrwxrwx. 1 root root 43 Mar 18 11:31 /usr/local/bin/containerd-shim-kata-v2 -> /usr/local/bin/containerd-shim-kata-qemu-v2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# kata deploy重启/节点重启会导致配置还原问题（必现）\n\ncat /opt/kata/share/defaults/kata-containers/configuration-qemu.toml  | grep sandbox_cgroup_only\nsandbox_cgroup_only=true\n\n## 重启后\n[root@localhost ~]# cat /opt/kata/share/defaults/kata-containers/configuration-qemu.toml  | grep sandbox_cgroup_only\nsandbox_cgroup_only=false\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 资源开销问题\n\n\n# 容器内fio测试(压内存)会导致host上对应qemu进程oom，或节点卡死，节点异常问题\n\n问题1： pod sanbox change，exec退出，pod重启次数加1 问题2： 节点卡死，节点notrady，相同配置runc测试无该问题\n\n怀疑： 未开启SandboxCgroupOnly，导致sanbox overhead无限制占用主机资源，导致节点异常，这样的话就说明kata的资源开销还是很大的。\n\n开启SandboxCgroupOnly后测试卡死，但是pod/节点未异常,进程结束。。。 所以，问题是，为什么没有错误信息\n\n\n# Overhead的CPU和内存占用应该纳入已分配配额？？？\n\n\n# 容器使用内存不会自动release？？\n\n\n# 存储性能问题\n\n\n# 未enable DAX, fio测试结果较差？？\n\n\n# 网络问题\n\n\n# qemu 不能直接使用 veth-pair, 导致vm+container的网络拓扑比较复杂且容易有性能问题, kubevirt同样的问题\n\n\n# 参考资料\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/Limitations.md https://github.com/pulls?q=label%3Alimitation+org%3Akata-containers+is%3Aclosed https://github.com/chestack/k8s-blog/blob/master/kata-container/kata-container.md',normalizedContent:'# docker 兼容问题\n\n * kata已去掉docker cli支持，请使用crictl命令\n\n * dind问题\n\n\n# 使用限制：\n\n\n# 不支持subpaths(emptydir )使用\n\n\n# kata不支持host网络\n\n一些使用主机网络的k8s组件和业务无法使用kata容器，所以runc（containerd）必须保留作为默认运行时，而kata-container作为可选运行时给特定负载使用。\n\n\n# 不支持网络命名空间共享\n\ndocker 支持容器使用docker run --net=containers语法加入另一个容器命名空间的能力。这允许多个容器共享一个公共网络命名空间和放置在网络命名空间中的网络接口。kata containers 不支持网络命名空间共享。如果将 kata 容器设置为共享runc容器的网络命名空间，则运行时会有效地接管分配给命名空间的所有网络接口并将它们绑定到 vm。因此，runc容器失去其网络连接。\n\n\n# 不支持cpuset-cpus\n\nhttps://github.com/kata-containers/runtime/issues/1079 docker run -d --cpuset-cpus= “ 0-1 ” ubuntu sleep 30000\n\n\n# ctr依赖/configuration-qemu.toml路径问题\n\n/etc/kata-containers/configuration.toml已存在，为测试删除了默认配置文件，但是containerd配置保留\n\n[root@localhost ~]# cat  /etc/containerd/config.toml \n      [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n        runtime_type = "io.containerd.kata.v2"\n        privileged_without_host_devices = true\n        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata.options]\n           configpath = "/etc/kata-containers/configuration.toml"\n\n[root@localhost ~]# kubectl get runtimeclasses.node.k8s.io kata-containers -o yaml | grep handler\nhandler: kata\n\n[root@localhost ~]# ctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/library/busybox:latest hfftest dmesg \nctr: cannot find usable config file (file /opt/kata/share/defaults/kata-containers/configuration-qemu.toml does not exist): not found\n\n\n[root@rqy-k8s-1 kbuser]# ll /usr/local/bin/containerd-shim-kata-v2\nlrwxrwxrwx. 1 root root 43 mar 18 11:31 /usr/local/bin/containerd-shim-kata-v2 -> /usr/local/bin/containerd-shim-kata-qemu-v2\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# kata deploy重启/节点重启会导致配置还原问题（必现）\n\ncat /opt/kata/share/defaults/kata-containers/configuration-qemu.toml  | grep sandbox_cgroup_only\nsandbox_cgroup_only=true\n\n## 重启后\n[root@localhost ~]# cat /opt/kata/share/defaults/kata-containers/configuration-qemu.toml  | grep sandbox_cgroup_only\nsandbox_cgroup_only=false\n\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 资源开销问题\n\n\n# 容器内fio测试(压内存)会导致host上对应qemu进程oom，或节点卡死，节点异常问题\n\n问题1： pod sanbox change，exec退出，pod重启次数加1 问题2： 节点卡死，节点notrady，相同配置runc测试无该问题\n\n怀疑： 未开启sandboxcgrouponly，导致sanbox overhead无限制占用主机资源，导致节点异常，这样的话就说明kata的资源开销还是很大的。\n\n开启sandboxcgrouponly后测试卡死，但是pod/节点未异常,进程结束。。。 所以，问题是，为什么没有错误信息\n\n\n# overhead的cpu和内存占用应该纳入已分配配额？？？\n\n\n# 容器使用内存不会自动release？？\n\n\n# 存储性能问题\n\n\n# 未enable dax, fio测试结果较差？？\n\n\n# 网络问题\n\n\n# qemu 不能直接使用 veth-pair, 导致vm+container的网络拓扑比较复杂且容易有性能问题, kubevirt同样的问题\n\n\n# 参考资料\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/limitations.md https://github.com/pulls?q=label%3alimitation+org%3akata-containers+is%3aclosed https://github.com/chestack/k8s-blog/blob/master/kata-container/kata-container.md',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata debug与日志",frontmatter:{title:"kata debug与日志",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata0404/",categories:["技术杂谈","kata-containers","kata应用"],tags:[null],titleTag:"原创",readingShow:"top",description:"Kata containerd shimv2 运行时日志通过containerd，其日志将被发送到containerd日志指向的任何地方。",meta:[{name:"twitter:title",content:"kata debug与日志"},{name:"twitter:description",content:"Kata containerd shimv2 运行时日志通过containerd，其日志将被发送到containerd日志指向的任何地方。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/04.kata%20debug%E4%B8%8E%E6%97%A5%E5%BF%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata debug与日志"},{property:"og:description",content:"Kata containerd shimv2 运行时日志通过containerd，其日志将被发送到containerd日志指向的任何地方。"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/04.kata%20debug%E4%B8%8E%E6%97%A5%E5%BF%97.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata debug与日志"},{itemprop:"description",content:"Kata containerd shimv2 运行时日志通过containerd，其日志将被发送到containerd日志指向的任何地方。"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/04.kata%20debug%E4%B8%8E%E6%97%A5%E5%BF%97.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/04.kata debug与日志.md",key:"v-6e85c154",path:"/pages/kata0404/",headers:[{level:2,title:"journalctl -t kata",slug:"journalctl-t-kata",normalizedTitle:"journalctl -t kata",charIndex:2},{level:2,title:"journalctl -t containerd",slug:"journalctl-t-containerd",normalizedTitle:"journalctl -t containerd",charIndex:141}],headersStr:"journalctl -t kata journalctl -t containerd",content:'# journalctl -t kata\n\nKata containerd shimv2 运行时日志通过containerd，其日志将被发送到containerd日志指向的任何地方。\n\n查看shimv2运行时日志：\n\n> $ sudo journalctl -t kata\n\n\n# journalctl -t containerd\n\n\n# 开启 debug log\n\n开启 debug log 可以帮助我们获得更详细的 log，除了 runtime 的 log，而且还能看到 agent 的 log，以及 guest OS 中 kernel 的 log（dmesg命令的输出）。\n\n开启 debug log，需要修改两个配置文件：\n\n * containerd 配置文件按如下修改即可： [debug] level = "debug"\n\n * Kata Containers需要开启 runtime 和 agent 的 debug log\n\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep enable_debug\n#enable_debug = true\n#enable_debug = true\n#enable_debug = true\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep kernel_params\nkernel_params = ""\n\n\n$ sudo sed -i -e \'s/^# *\\(enable_debug\\).*=.*$/\\1 = true/g\' /etc/kata-containers/configuration.toml\n$ sudo sed -i -e \'s/^kernel_params = "\\(.*\\)"/kernel_params = "\\1 agent.log=debug"/g\' /etc/kata-containers/configuration.toml\n\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep enable_debug\nenable_debug = true\nenable_debug = true\nenable_debug = true\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep kernel_params\nkernel_params = " agent.log=debug"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/Developer-Guide.md#troubleshoot-kata-containers\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/Developer-Guide.md#connect-to-debug-console （进入虚拟机需要打开debug_console_enabled）\n\n\n# tracing\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/tracing.md\n\n\n# kata-log-parser\n\nhttps://github.com/kata-containers/tests/tree/main/cmd/log-parser\n\n\n# kata-collect-data.sh\n\n向社区提issue需要添加采集信息\n\n\n# 开启debug的开销\n\n开启前，已开启了debug_console_enabled，好像并不会因为pod增加而增加？\n\n[root@localhost hff]# systemd-cgtop | grep kata\n/kata_overhead                                                                                                                -      -     2.4M        -        -\n/kubepods/podfa152857-05d1-44fc-9cdc-d448b2c98941/kata_f40286f09e1ef5de468d894f1519c7ca6d30962653e7dce8daf90681802a0dde       7      -   167.8M        -        -\n/system.slice/kata-monitor.service                                                                                            1      -    22.2M        -        -\n\n\n1\n2\n3\n4\n\n\n按上述开启 debug log设置后\n\n[root@localhost hff]# systemd-cgtop | grep kata\n/kata_overhead                                                                                                                -      -     2.4M        -        -\n/kubepods/podfa152857-05d1-44fc-9cdc-d448b2c98941/kata_f40286f09e1ef5de468d894f1519c7ca6d30962653e7dce8daf90681802a0dde       7      -   166.6M        -        -\n/system.slice/kata-monitor.service                                                                                            1      -    21.8M        -        -\n\n\n1\n2\n3\n4\n\n\ndmesg日志\n\n[root@localhost hff]# dmesg | grep kata\n[2056734.849647] containerd-shim cpuset=kata_5051ee8a1c623152246de3245c514de818127663500f71c01ae4f2952dbdc73a mems_allowed=0\n[2056734.849679] Task in /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a/kata_5051ee8a1c623152246de3245c514de818127663500f71c01ae4f2952dbdc73a killed as a result of limit of /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a\n[2056734.849690] Memory cgroup stats for /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a/kata_5051ee8a1c623152246de3245c514de818127663500f71c01ae4f2952dbdc73a: cache:188900KB rss:15900KB rss_huge:0KB mapped_file:188876KB swap:0KB inactive_anon:188372KB active_anon:16428KB inactive_file:0KB active_file:0KB unevictable:0KB\n[2056751.353176] pool cpuset=kata_d888b88f19234d8148f43414242b99ec4de2d25e881d0453a920622da946c2e1 mems_allowed=0\n[2056751.353223] Task in /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a/kata_d888b88f19234d8148f43414242b99ec4de2d25e881d0453a920622da946c2e1 killed as a result of limit of /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a\n\n\n\n1\n2\n3\n4\n5\n6\n7\n',normalizedContent:'# journalctl -t kata\n\nkata containerd shimv2 运行时日志通过containerd，其日志将被发送到containerd日志指向的任何地方。\n\n查看shimv2运行时日志：\n\n> $ sudo journalctl -t kata\n\n\n# journalctl -t containerd\n\n\n# 开启 debug log\n\n开启 debug log 可以帮助我们获得更详细的 log，除了 runtime 的 log，而且还能看到 agent 的 log，以及 guest os 中 kernel 的 log（dmesg命令的输出）。\n\n开启 debug log，需要修改两个配置文件：\n\n * containerd 配置文件按如下修改即可： [debug] level = "debug"\n\n * kata containers需要开启 runtime 和 agent 的 debug log\n\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep enable_debug\n#enable_debug = true\n#enable_debug = true\n#enable_debug = true\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep kernel_params\nkernel_params = ""\n\n\n$ sudo sed -i -e \'s/^# *\\(enable_debug\\).*=.*$/\\1 = true/g\' /etc/kata-containers/configuration.toml\n$ sudo sed -i -e \'s/^kernel_params = "\\(.*\\)"/kernel_params = "\\1 agent.log=debug"/g\' /etc/kata-containers/configuration.toml\n\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep enable_debug\nenable_debug = true\nenable_debug = true\nenable_debug = true\n[root@localhost hff]# cat /etc/kata-containers/configuration.toml | grep kernel_params\nkernel_params = " agent.log=debug"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/developer-guide.md#troubleshoot-kata-containers\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/developer-guide.md#connect-to-debug-console （进入虚拟机需要打开debug_console_enabled）\n\n\n# tracing\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/tracing.md\n\n\n# kata-log-parser\n\nhttps://github.com/kata-containers/tests/tree/main/cmd/log-parser\n\n\n# kata-collect-data.sh\n\n向社区提issue需要添加采集信息\n\n\n# 开启debug的开销\n\n开启前，已开启了debug_console_enabled，好像并不会因为pod增加而增加？\n\n[root@localhost hff]# systemd-cgtop | grep kata\n/kata_overhead                                                                                                                -      -     2.4m        -        -\n/kubepods/podfa152857-05d1-44fc-9cdc-d448b2c98941/kata_f40286f09e1ef5de468d894f1519c7ca6d30962653e7dce8daf90681802a0dde       7      -   167.8m        -        -\n/system.slice/kata-monitor.service                                                                                            1      -    22.2m        -        -\n\n\n1\n2\n3\n4\n\n\n按上述开启 debug log设置后\n\n[root@localhost hff]# systemd-cgtop | grep kata\n/kata_overhead                                                                                                                -      -     2.4m        -        -\n/kubepods/podfa152857-05d1-44fc-9cdc-d448b2c98941/kata_f40286f09e1ef5de468d894f1519c7ca6d30962653e7dce8daf90681802a0dde       7      -   166.6m        -        -\n/system.slice/kata-monitor.service                                                                                            1      -    21.8m        -        -\n\n\n1\n2\n3\n4\n\n\ndmesg日志\n\n[root@localhost hff]# dmesg | grep kata\n[2056734.849647] containerd-shim cpuset=kata_5051ee8a1c623152246de3245c514de818127663500f71c01ae4f2952dbdc73a mems_allowed=0\n[2056734.849679] task in /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a/kata_5051ee8a1c623152246de3245c514de818127663500f71c01ae4f2952dbdc73a killed as a result of limit of /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a\n[2056734.849690] memory cgroup stats for /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a/kata_5051ee8a1c623152246de3245c514de818127663500f71c01ae4f2952dbdc73a: cache:188900kb rss:15900kb rss_huge:0kb mapped_file:188876kb swap:0kb inactive_anon:188372kb active_anon:16428kb inactive_file:0kb active_file:0kb unevictable:0kb\n[2056751.353176] pool cpuset=kata_d888b88f19234d8148f43414242b99ec4de2d25e881d0453a920622da946c2e1 mems_allowed=0\n[2056751.353223] task in /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a/kata_d888b88f19234d8148f43414242b99ec4de2d25e881d0453a920622da946c2e1 killed as a result of limit of /kubepods/burstable/podf4bff02f-469b-4fbb-8152-5daafbe2cb3a\n\n\n\n1\n2\n3\n4\n5\n6\n7\n',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata相关配置及路径",frontmatter:{title:"kata相关配置及路径",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata0403/",categories:["技术杂谈","kata-containers","kata应用"],tags:[null],titleTag:"原创",readingShow:"top",description:"/etc/containerd/config.toml\n> /etc/systemd/system/kubelet.service.d/0-containerd.conf",meta:[{name:"twitter:title",content:"kata相关配置及路径"},{name:"twitter:description",content:"/etc/containerd/config.toml\n> /etc/systemd/system/kubelet.service.d/0-containerd.conf"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/03.kata%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E5%8F%8A%E8%B7%AF%E5%BE%84.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata相关配置及路径"},{property:"og:description",content:"/etc/containerd/config.toml\n> /etc/systemd/system/kubelet.service.d/0-containerd.conf"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/03.kata%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E5%8F%8A%E8%B7%AF%E5%BE%84.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata相关配置及路径"},{itemprop:"description",content:"/etc/containerd/config.toml\n> /etc/systemd/system/kubelet.service.d/0-containerd.conf"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/04.kata%E5%BA%94%E7%94%A8/03.kata%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E5%8F%8A%E8%B7%AF%E5%BE%84.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/04.kata应用/03.kata相关配置及路径.md",key:"v-68efef1e",path:"/pages/kata0403/",headers:[{level:2,title:"containerd数据路径",slug:"containerd数据路径",normalizedTitle:"containerd数据路径",charIndex:106},{level:2,title:"containerd插件数据",slug:"containerd插件数据",normalizedTitle:"containerd插件数据",charIndex:197},{level:2,title:"注意配置文件问题",slug:"注意配置文件问题",normalizedTitle:"注意配置文件问题",charIndex:900},{level:2,title:"1. [hypervisor.qemu]",slug:"_1-hypervisor-qemu",normalizedTitle:"1. [hypervisor.qemu]",charIndex:1006},{level:2,title:"containerd配置：",slug:"containerd配置-2",normalizedTitle:"containerd配置：",charIndex:3626},{level:2,title:"受限注释：",slug:"受限注释",normalizedTitle:"受限注释：",charIndex:3859}],headersStr:"containerd数据路径 containerd插件数据 注意配置文件问题 1. [hypervisor.qemu] containerd配置： 受限注释：",content:'# containerd配置\n\n> /etc/containerd/config.toml /etc/systemd/system/kubelet.service.d/0-containerd.conf\n\n\n# containerd数据路径\n\n> root = "/app/docker/containerd" state = "/app/docker/run/containerd"\n\n\n# containerd插件数据\n\n> ctr plugin ls\n\n\n# kata配置configuration.toml\n\n默认的配置文件位于/opt/kata/share/defaults/kata-containers/configuration.toml，如果/etc/kata-containers/configuration.toml的配置文件存在，则会替代默认的配置文件。\n\n[root@rqy-k8s-1 hff]# kata-runtime --kata-show-default-config-paths\n/etc/kata-containers/configuration.toml\n/opt/kata/share/defaults/kata-containers/configuration.toml\n\n\n1\n2\n3\n\n\n[hypervisor.qemu]\nuse_vsock ：使用vsocks与agent直接通信（前提支持vsocks），默认false \n[runtime]\nenable_cpu_memory_hotplug ：使能cpu和内存热插拔，默认false\n[agent.kata]\ndebug_console_enabled = true\n[hypervisor.qemu]\nsed -i -e \'s/^kernel_params = "\\(.*\\)"/kernel_params = "\\1 agent.debug_console"/g\' "${kata_configuration_file}"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n修改后新容器生效\n\n\n# 注意配置文件问题\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/containerd-kata.md\n\n\n# 1. [hypervisor.qemu]\n\npath = "/usr/bin/qemu-system-x86_64" 指定 qemu 的路径\nkernel = "/usr/share/kata-containers/vmlinuz.container" 指定启动内核路径\ninitrd = "/usr/share/kata-containers/kata-containers-initrd.img" 指定 initrd\nimage = "/usr/share/kata-containers/kata-containers-centos.img" 指定系统盘，initrd 和 image 不可以同时配置，否则会出错\nkernel_params = "" 配置-append 参数，定制虚拟机内核启动参数\nfirmware = "" 指定固件，影响 qemu 的-bios 参数\nmachine_accelerators="" virtcontainers/qemu.go 的 getQemuMachine() 进行处理，加到 machine.Options 中，最终是加到-machine 参数中\ndefault_vcpus = 1 默认 vcpu 个数\ndefault_maxvcpus = 0  默认最大 vcpu 个数，设置为 0 时实际上时 240\ndefault_bridges = 1 默认 PCI 桥个数\ndefault_memory = 2048  VM 默认内存大小\nmemory_slots = 10 内存插槽个数\ndisable_block_device_use = false 是否禁用块设备\nblock_device_driver = "virtio-scsi" 块设备驱动，可以是 virtio-scsi、virtio-blk 或 nvdimm\n#block_device_cache_set = true\n#block_device_cache_direct = true\n#block_device_cache_noflush = true  块设备是否设置 cache\nenable_iothreads = false  //enable_iothreas 当前仅针对 virtio-scsi 块设备生效\n#enable_mem_prealloc = true\n#enable_hugepages = true\n#file_mem_backend = ""  //这几个配置统一用于 kata-runtime qemu 插件启动虚拟机时的内存配置\n#enable_swap=true  //是否允许虚拟机内存 swap，以支持更大的虚拟机密度\n#enable_debug=false  //影响 guest kernel 内核启动，在 enable_debug 后，guest kernel 启动项会加上 systemd.show_status true systemd.log_level debug\n#disable_nesting_checks = true 虚拟机标志是否 nestedRun，即虚拟化嵌套\nmsize=8192 9p fs msize 选项\n#use_vsock = true 是否使用 vsock\n#hotplug_vfio_on_root_bus = true 对于 vfio 设备，会挂在到 root bus 上，否则挂载到 PCI bridge 上, 默认是 false\n#disable_vhost_net = true 禁用 vhost_net\n#entropy_source= "/dev/urandom" 指定随机数发生器，默认为/dev/urandom,kata 启动虚拟机时会给虚拟机附加一个随机数发生器\n#guest_hook_path = "/usr/share/oci/hooks" guest 钩子函数执行路径,用于 OCI\n#enable_template = true 默认为 false，enable 后新的虚拟机从模板通过虚拟机克隆方式启动，所有 VM 共享相同的初始化 kernel、initramfs 和 agent 内存\n#enable_debug = true 默认为 false，enable 后，shim 将消息发往 system log\n#enable_tracing = true 默认为 false，用于跟踪\n#diable_new_netns=true 默认为 false，enable 后，runtime 不会再为 shim 和 hypervisor 进程创建一个网络 namespace，在 enable_netmon、网络模式采用 bridged 或者 macvtap 后不能 enable 该选项\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n\n# crictl\n\ncrictl 默认连接到 unix:///var/run/dockershim.sock\n\n[root@rqy-k8s-3 fio-iperf]# cat /etc/crictl.yaml\nruntime-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 0\ndebug: false\n\n\n1\n2\n3\n4\n\n\n\n# 镜像配置：\n\n> [plugins."io.containerd.grpc.v1.cri".registry]\n\n镜像存储路径：\n\n> /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/ 原docker: /app/docker/overlay2\n\n\n# 修改sanbox(虚拟机)配置\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-set-sandbox-config-kata.md\n\n\n# containerd配置：\n\n​ [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n​  runtime_type = "io.containerd.kata.v2"\n​  pod_annotations = ["io.katacontainers.*"]\n​  container_annotations = ["io.katacontainers.*"]\n\n\n1\n2\n3\n4\n\n\n\n# 受限注释：\n\n一些注释是受限的，这意味着配置文件指定了可接受的值。目前，出于安全原因，仅管理程序注释受到限制，目的是控制 Kata Containers 运行时将代表您启动哪些二进制文件。\n\n> configuration.toml： enable_annotations = []\n\n\n# 关于runtime 名字怎么写？\n\nhttp://liubin.org/kata-dev-book/src/runtime-arch.html\n\n在 K8s 和 containerd 中，我们会看到很多用于设置 runtime 的地方，比如 RuntimeClass 、Pod 的 runtimeClassName 定义，以及 ctr run --runtime io.containerd.run.kata.v2 和 crictl runp -r kata ，里面都有参数指定运行时的名字。\n\nPod 的 runtimeClassName 属性会查找同名的 RuntimeClass 资源 根据 该资源的 handler ，在 containerd 的配置文件查找相应的运行时（ [plugins.cri.containerd.runtimes.${HANDLER_NAME}] ）。 一般情况下 containerd 配置会像这样：\n\n> [plugins.cri.containerd.runtimes.kata] runtime_type = "io.containerd.kata.v2"\n\n * ctr 命令使用的是 containerd 配置文件中的 runtime_type 属性（ containerd 用）。\n * crictl 和 K8s（实际也是 CRI 接口） 使用的是 containerd 配置中的 HANDLER_NAME（ CRI 用）。\n\n默认情况下，containerd 会根据 runtime_type 按规则对应到具体的运行时的可执行文件名。比如 Kata Containers(io.containerd.kata.v2) 运行时最终会转换为 containerd-shim-kata-v2 命令，该命令默认安装在 /usr/local/bin/containerd-shim-kata-v2。\n\n[root@localhost ~]# cat /usr/local/bin/containerd-shim-kata-v2\n#!/usr/bin/env bash\nKATA_CONF_FILE=/opt/kata/share/defaults/kata-containers/configuration-qemu.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\n\n\n1\n2\n3\n',normalizedContent:'# containerd配置\n\n> /etc/containerd/config.toml /etc/systemd/system/kubelet.service.d/0-containerd.conf\n\n\n# containerd数据路径\n\n> root = "/app/docker/containerd" state = "/app/docker/run/containerd"\n\n\n# containerd插件数据\n\n> ctr plugin ls\n\n\n# kata配置configuration.toml\n\n默认的配置文件位于/opt/kata/share/defaults/kata-containers/configuration.toml，如果/etc/kata-containers/configuration.toml的配置文件存在，则会替代默认的配置文件。\n\n[root@rqy-k8s-1 hff]# kata-runtime --kata-show-default-config-paths\n/etc/kata-containers/configuration.toml\n/opt/kata/share/defaults/kata-containers/configuration.toml\n\n\n1\n2\n3\n\n\n[hypervisor.qemu]\nuse_vsock ：使用vsocks与agent直接通信（前提支持vsocks），默认false \n[runtime]\nenable_cpu_memory_hotplug ：使能cpu和内存热插拔，默认false\n[agent.kata]\ndebug_console_enabled = true\n[hypervisor.qemu]\nsed -i -e \'s/^kernel_params = "\\(.*\\)"/kernel_params = "\\1 agent.debug_console"/g\' "${kata_configuration_file}"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n修改后新容器生效\n\n\n# 注意配置文件问题\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/containerd-kata.md\n\n\n# 1. [hypervisor.qemu]\n\npath = "/usr/bin/qemu-system-x86_64" 指定 qemu 的路径\nkernel = "/usr/share/kata-containers/vmlinuz.container" 指定启动内核路径\ninitrd = "/usr/share/kata-containers/kata-containers-initrd.img" 指定 initrd\nimage = "/usr/share/kata-containers/kata-containers-centos.img" 指定系统盘，initrd 和 image 不可以同时配置，否则会出错\nkernel_params = "" 配置-append 参数，定制虚拟机内核启动参数\nfirmware = "" 指定固件，影响 qemu 的-bios 参数\nmachine_accelerators="" virtcontainers/qemu.go 的 getqemumachine() 进行处理，加到 machine.options 中，最终是加到-machine 参数中\ndefault_vcpus = 1 默认 vcpu 个数\ndefault_maxvcpus = 0  默认最大 vcpu 个数，设置为 0 时实际上时 240\ndefault_bridges = 1 默认 pci 桥个数\ndefault_memory = 2048  vm 默认内存大小\nmemory_slots = 10 内存插槽个数\ndisable_block_device_use = false 是否禁用块设备\nblock_device_driver = "virtio-scsi" 块设备驱动，可以是 virtio-scsi、virtio-blk 或 nvdimm\n#block_device_cache_set = true\n#block_device_cache_direct = true\n#block_device_cache_noflush = true  块设备是否设置 cache\nenable_iothreads = false  //enable_iothreas 当前仅针对 virtio-scsi 块设备生效\n#enable_mem_prealloc = true\n#enable_hugepages = true\n#file_mem_backend = ""  //这几个配置统一用于 kata-runtime qemu 插件启动虚拟机时的内存配置\n#enable_swap=true  //是否允许虚拟机内存 swap，以支持更大的虚拟机密度\n#enable_debug=false  //影响 guest kernel 内核启动，在 enable_debug 后，guest kernel 启动项会加上 systemd.show_status true systemd.log_level debug\n#disable_nesting_checks = true 虚拟机标志是否 nestedrun，即虚拟化嵌套\nmsize=8192 9p fs msize 选项\n#use_vsock = true 是否使用 vsock\n#hotplug_vfio_on_root_bus = true 对于 vfio 设备，会挂在到 root bus 上，否则挂载到 pci bridge 上, 默认是 false\n#disable_vhost_net = true 禁用 vhost_net\n#entropy_source= "/dev/urandom" 指定随机数发生器，默认为/dev/urandom,kata 启动虚拟机时会给虚拟机附加一个随机数发生器\n#guest_hook_path = "/usr/share/oci/hooks" guest 钩子函数执行路径,用于 oci\n#enable_template = true 默认为 false，enable 后新的虚拟机从模板通过虚拟机克隆方式启动，所有 vm 共享相同的初始化 kernel、initramfs 和 agent 内存\n#enable_debug = true 默认为 false，enable 后，shim 将消息发往 system log\n#enable_tracing = true 默认为 false，用于跟踪\n#diable_new_netns=true 默认为 false，enable 后，runtime 不会再为 shim 和 hypervisor 进程创建一个网络 namespace，在 enable_netmon、网络模式采用 bridged 或者 macvtap 后不能 enable 该选项\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n\n\n\n# crictl\n\ncrictl 默认连接到 unix:///var/run/dockershim.sock\n\n[root@rqy-k8s-3 fio-iperf]# cat /etc/crictl.yaml\nruntime-endpoint: unix:///run/containerd/containerd.sock\ntimeout: 0\ndebug: false\n\n\n1\n2\n3\n4\n\n\n\n# 镜像配置：\n\n> [plugins."io.containerd.grpc.v1.cri".registry]\n\n镜像存储路径：\n\n> /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs/snapshots/ 原docker: /app/docker/overlay2\n\n\n# 修改sanbox(虚拟机)配置\n\nhttps://github.com/kata-containers/kata-containers/blob/main/docs/how-to/how-to-set-sandbox-config-kata.md\n\n\n# containerd配置：\n\n​ [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.kata]\n​  runtime_type = "io.containerd.kata.v2"\n​  pod_annotations = ["io.katacontainers.*"]\n​  container_annotations = ["io.katacontainers.*"]\n\n\n1\n2\n3\n4\n\n\n\n# 受限注释：\n\n一些注释是受限的，这意味着配置文件指定了可接受的值。目前，出于安全原因，仅管理程序注释受到限制，目的是控制 kata containers 运行时将代表您启动哪些二进制文件。\n\n> configuration.toml： enable_annotations = []\n\n\n# 关于runtime 名字怎么写？\n\nhttp://liubin.org/kata-dev-book/src/runtime-arch.html\n\n在 k8s 和 containerd 中，我们会看到很多用于设置 runtime 的地方，比如 runtimeclass 、pod 的 runtimeclassname 定义，以及 ctr run --runtime io.containerd.run.kata.v2 和 crictl runp -r kata ，里面都有参数指定运行时的名字。\n\npod 的 runtimeclassname 属性会查找同名的 runtimeclass 资源 根据 该资源的 handler ，在 containerd 的配置文件查找相应的运行时（ [plugins.cri.containerd.runtimes.${handler_name}] ）。 一般情况下 containerd 配置会像这样：\n\n> [plugins.cri.containerd.runtimes.kata] runtime_type = "io.containerd.kata.v2"\n\n * ctr 命令使用的是 containerd 配置文件中的 runtime_type 属性（ containerd 用）。\n * crictl 和 k8s（实际也是 cri 接口） 使用的是 containerd 配置中的 handler_name（ cri 用）。\n\n默认情况下，containerd 会根据 runtime_type 按规则对应到具体的运行时的可执行文件名。比如 kata containers(io.containerd.kata.v2) 运行时最终会转换为 containerd-shim-kata-v2 命令，该命令默认安装在 /usr/local/bin/containerd-shim-kata-v2。\n\n[root@localhost ~]# cat /usr/local/bin/containerd-shim-kata-v2\n#!/usr/bin/env bash\nkata_conf_file=/opt/kata/share/defaults/kata-containers/configuration-qemu.toml /opt/kata/bin/containerd-shim-kata-v2 "$@"\n\n\n1\n2\n3\n',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"kata3.0",frontmatter:{title:"kata3.0",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/kata0501/",categories:["技术杂谈","kata-containers","kata应用"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"kata3.0"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/05.kataV3.0/01.kata%20v3.0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"kata3.0"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/05.kataV3.0/01.kata%20v3.0.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"kata3.0"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/303.kata-containers/05.kataV3.0/01.kata%20v3.0.html",relativePath:"01.技术杂谈/03.kubernetes/303.kata-containers/05.kataV3.0/01.kata v3.0.md",key:"v-5b19c60a",path:"/pages/kata0501/",headers:[{level:2,title:"Kata的发展回顾",slug:"kata的发展回顾",normalizedTitle:"kata的发展回顾",charIndex:2},{level:2,title:"Kata3.0新增设计",slug:"kata3-0新增设计",normalizedTitle:"kata3.0新增设计",charIndex:327},{level:3,title:"Dragonball沙箱",slug:"dragonball沙箱",normalizedTitle:"dragonball沙箱",charIndex:343},{level:3,title:"Async Rust Runtime",slug:"async-rust-runtime",normalizedTitle:"async rust runtime",charIndex:360},{level:2,title:"Kata 3.0开发路线",slug:"kata-3-0开发路线",normalizedTitle:"kata 3.0开发路线",charIndex:383}],headersStr:"Kata的发展回顾 Kata3.0新增设计 Dragonball沙箱 Async Rust Runtime Kata 3.0开发路线",content:"# Kata的发展回顾\n\n * 2018年5月：Kata 1.x阶段， Kata和containerd社区共同制定了shimv2接口规范，并率先在Kata Containers支持了该规范\n * 18年11月：通过containerd-shim-v2和vsock技术，Kata精简了大量的组件，配合轻量级hypervisor和精简内核，kata可以大幅降低内存开销和容器启动时间。更关键的是，降低系统部署复杂度还大幅提高了稳定性，特别是在系统重载情况下的稳定性。\n * 2019 年的时候，Kata 从 1.x 升级到了 2.x , 有了非常重要的技术进步。Kata-agent 使用 Rust 进行了重构，极大程度减少了内存开销以及整体攻击面\n\n\n# Kata3.0新增设计\n\n\n# Dragonball沙箱\n\n\n# Async Rust Runtime\n\n\n# Kata 3.0开发路线\n\n * 2022-07-25 在main分支有可用的alpha版本\n * 2022.10.10 3.0.0-release",normalizedContent:"# kata的发展回顾\n\n * 2018年5月：kata 1.x阶段， kata和containerd社区共同制定了shimv2接口规范，并率先在kata containers支持了该规范\n * 18年11月：通过containerd-shim-v2和vsock技术，kata精简了大量的组件，配合轻量级hypervisor和精简内核，kata可以大幅降低内存开销和容器启动时间。更关键的是，降低系统部署复杂度还大幅提高了稳定性，特别是在系统重载情况下的稳定性。\n * 2019 年的时候，kata 从 1.x 升级到了 2.x , 有了非常重要的技术进步。kata-agent 使用 rust 进行了重构，极大程度减少了内存开销以及整体攻击面\n\n\n# kata3.0新增设计\n\n\n# dragonball沙箱\n\n\n# async rust runtime\n\n\n# kata 3.0开发路线\n\n * 2022-07-25 在main分支有可用的alpha版本\n * 2022.10.10 3.0.0-release",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"docker镜像",frontmatter:{title:"docker镜像",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/docker03/",categories:["技术杂谈","kubernetes","docker"],tags:[null],titleTag:"原创",readingShow:"top",description:"ctr -n k8s.io run  -t --rm docker.io/ljishen/sysbench:latest sysbench cpu run",meta:[{name:"twitter:title",content:"docker镜像"},{name:"twitter:description",content:"ctr -n k8s.io run  -t --rm docker.io/ljishen/sysbench:latest sysbench cpu run"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/03.docker%E9%95%9C%E5%83%8F.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker镜像"},{property:"og:description",content:"ctr -n k8s.io run  -t --rm docker.io/ljishen/sysbench:latest sysbench cpu run"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/03.docker%E9%95%9C%E5%83%8F.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"docker镜像"},{itemprop:"description",content:"ctr -n k8s.io run  -t --rm docker.io/ljishen/sysbench:latest sysbench cpu run"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/03.docker%E9%95%9C%E5%83%8F.html",relativePath:"01.技术杂谈/03.kubernetes/304.docker/03.docker镜像.md",key:"v-e1ca0762",path:"/pages/docker03/",headers:[{level:2,title:"sysbench",slug:"sysbench",normalizedTitle:"sysbench",charIndex:2},{level:2,title:"fio",slug:"fio",normalizedTitle:"fio",charIndex:195},{level:2,title:"iperf3",slug:"iperf3",normalizedTitle:"iperf3",charIndex:301}],headersStr:"sysbench fio iperf3",content:"# sysbench\n\nctr -n k8s.io run -t --rm docker.io/ljishen/sysbench:latest sysbench cpu run\n\nctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/dotnetdr/sysbench:0.5 hfftest sh\n\n\n# fio\n\nctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/xridge/fio:latest hfftest sh\n\n\n# iperf3\n\nctr -n k8s.io run -t --rm sirot/netperf-latest netperf sh",normalizedContent:"# sysbench\n\nctr -n k8s.io run -t --rm docker.io/ljishen/sysbench:latest sysbench cpu run\n\nctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/dotnetdr/sysbench:0.5 hfftest sh\n\n\n# fio\n\nctr -n k8s.io run --runtime io.containerd.kata.v2 -t --rm docker.io/xridge/fio:latest hfftest sh\n\n\n# iperf3\n\nctr -n k8s.io run -t --rm sirot/netperf-latest netperf sh",charsets:{},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"dockerfile改源",frontmatter:{title:"dockerfile改源",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/docker02/",categories:["技术杂谈","kubernetes","docker"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"dockerfile改源"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/02.dockerfile%E6%94%B9%E6%BA%90.html"},{property:"og:type",content:"article"},{property:"og:title",content:"dockerfile改源"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/02.dockerfile%E6%94%B9%E6%BA%90.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"dockerfile改源"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/02.dockerfile%E6%94%B9%E6%BA%90.html",relativePath:"01.技术杂谈/03.kubernetes/304.docker/02.dockerfile改源.md",key:"v-32d723b6",path:"/pages/docker02/",headers:[{level:2,title:"apk源",slug:"apk源",normalizedTitle:"apk源",charIndex:2},{level:2,title:"apt源",slug:"apt源",normalizedTitle:"apt源",charIndex:369}],headersStr:"apk源 apt源",content:'# apk源\n\nFROM alpine:3.14\n\nRUN sed -i \'s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\' /etc/apk/repositories\n\nRUN apk update\n\n\n1\n2\n3\n4\n5\n\n\nFROM golang:${GO_VER}-alpine${ALPINE_VER} as golang\nRUN sed -i \'s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\' /etc/apk/repositories    #新加的\nRUN apk add --no-cache \\\n\tbash \\\n\tgcc \\\n\tgit \\\n\tmake \\\n\tmusl-dev\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# apt源\n\nFROM debian\n\nRUN mv /etc/apt/sources.list /etc/apt/sources.list.bak && \\\n    echo "deb http://mirrors.cloud.aliyuncs.com/debian stable main contrib non-free" >/etc/apt/sources.list && \\\n    echo "deb http://mirrors.cloud.aliyuncs.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb http://mirrors.cloud.aliyuncs.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb-src http://mirrors.cloud.aliyuncs.com/debian stable main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb-src http://mirrors.cloud.aliyuncs.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb-src http://mirrors.cloud.aliyuncs.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb http://mirrors.aliyun.com/debian stable main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb http://mirrors.aliyun.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb http://mirrors.aliyun.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb-src http://mirrors.aliyun.com/debian stable main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb-src http://mirrors.aliyun.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb-src http://mirrors.aliyun.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    apt-get update && \\\n    apt-get install procps -y --allow-unauthenticated && \\\n    apt-get install telnetd -y --allow-unauthenticated && \\\n    apt-get install telnet -y --allow-unauthenticated && \\\n    apt-get install wget -y --allow-unauthenticated\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nsed -i "s@http://deb.debian.org@http://mirrors.163.com@g" /etc/apt/sources.list\n\nsed -i "s@http://security.debian.org@http://mirrors.163.com@g" /etc/apt/sources.list',normalizedContent:'# apk源\n\nfrom alpine:3.14\n\nrun sed -i \'s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\' /etc/apk/repositories\n\nrun apk update\n\n\n1\n2\n3\n4\n5\n\n\nfrom golang:${go_ver}-alpine${alpine_ver} as golang\nrun sed -i \'s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g\' /etc/apk/repositories    #新加的\nrun apk add --no-cache \\\n\tbash \\\n\tgcc \\\n\tgit \\\n\tmake \\\n\tmusl-dev\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# apt源\n\nfrom debian\n\nrun mv /etc/apt/sources.list /etc/apt/sources.list.bak && \\\n    echo "deb http://mirrors.cloud.aliyuncs.com/debian stable main contrib non-free" >/etc/apt/sources.list && \\\n    echo "deb http://mirrors.cloud.aliyuncs.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb http://mirrors.cloud.aliyuncs.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb-src http://mirrors.cloud.aliyuncs.com/debian stable main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb-src http://mirrors.cloud.aliyuncs.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb-src http://mirrors.cloud.aliyuncs.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb http://mirrors.aliyun.com/debian stable main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb http://mirrors.aliyun.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb http://mirrors.aliyun.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list  && \\\n    echo "deb-src http://mirrors.aliyun.com/debian stable main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb-src http://mirrors.aliyun.com/debian stable-proposed-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    echo "deb-src http://mirrors.aliyun.com/debian stable-updates main contrib non-free" >>/etc/apt/sources.list && \\\n    apt-get update && \\\n    apt-get install procps -y --allow-unauthenticated && \\\n    apt-get install telnetd -y --allow-unauthenticated && \\\n    apt-get install telnet -y --allow-unauthenticated && \\\n    apt-get install wget -y --allow-unauthenticated\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\nsed -i "s@http://deb.debian.org@http://mirrors.163.com@g" /etc/apt/sources.list\n\nsed -i "s@http://security.debian.org@http://mirrors.163.com@g" /etc/apt/sources.list',charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"docker镜像优化",frontmatter:{title:"docker镜像优化",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/docker04/",categories:["技术杂谈","kubernetes","docker"],tags:[null],titleTag:"原创",readingShow:"top",description:"1、  apk –no-cache\n2、  rm –rf /var/lib/apk/*\n3、  pip install –no-cache-dir\n4、  run rm –rf find / -name ‘*.pyc’\n5、  禁止使用docker commit，使用dockerfile\n6、  镜像layer不得超过6层\n7、  &&\\ 可以把run、copy等合成一个\n8、  基础镜像可以处理成scratch,使用2个阶段构建镜像",meta:[{name:"twitter:title",content:"docker镜像优化"},{name:"twitter:description",content:"1、  apk –no-cache\n2、  rm –rf /var/lib/apk/*\n3、  pip install –no-cache-dir\n4、  run rm –rf find / -name ‘*.pyc’\n5、  禁止使用docker commit，使用dockerfile\n6、  镜像layer不得超过6层\n7、  &&\\ 可以把run、copy等合成一个\n8、  基础镜像可以处理成scratch,使用2个阶段构建镜像"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/04.docker%E9%95%9C%E5%83%8F%E4%BC%98%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker镜像优化"},{property:"og:description",content:"1、  apk –no-cache\n2、  rm –rf /var/lib/apk/*\n3、  pip install –no-cache-dir\n4、  run rm –rf find / -name ‘*.pyc’\n5、  禁止使用docker commit，使用dockerfile\n6、  镜像layer不得超过6层\n7、  &&\\ 可以把run、copy等合成一个\n8、  基础镜像可以处理成scratch,使用2个阶段构建镜像"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/04.docker%E9%95%9C%E5%83%8F%E4%BC%98%E5%8C%96.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"docker镜像优化"},{itemprop:"description",content:"1、  apk –no-cache\n2、  rm –rf /var/lib/apk/*\n3、  pip install –no-cache-dir\n4、  run rm –rf find / -name ‘*.pyc’\n5、  禁止使用docker commit，使用dockerfile\n6、  镜像layer不得超过6层\n7、  &&\\ 可以把run、copy等合成一个\n8、  基础镜像可以处理成scratch,使用2个阶段构建镜像"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/04.docker%E9%95%9C%E5%83%8F%E4%BC%98%E5%8C%96.html",relativePath:"01.技术杂谈/03.kubernetes/304.docker/04.docker镜像优化.md",key:"v-5d2403be",path:"/pages/docker04/",headersStr:null,content:"1、 apk –no-cache 2、 rm –rf /var/lib/apk/* 3、 pip install –no-cache-dir 4、 run rm –rf find / -name ‘*.pyc’ 5、 禁止使用docker commit，使用dockerfile 6、 镜像layer不得超过6层 7、 &&\\ 可以把run、copy等合成一个 8、 基础镜像可以处理成scratch,使用2个阶段构建镜像",normalizedContent:"1、 apk –no-cache 2、 rm –rf /var/lib/apk/* 3、 pip install –no-cache-dir 4、 run rm –rf find / -name ‘*.pyc’ 5、 禁止使用docker commit，使用dockerfile 6、 镜像layer不得超过6层 7、 &&\\ 可以把run、copy等合成一个 8、 基础镜像可以处理成scratch,使用2个阶段构建镜像",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"buildx多平台构建",frontmatter:{title:"buildx多平台构建",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/docker01/",categories:["技术杂谈","kubernetes","docker"],tags:[null],titleTag:"原创",readingShow:"top",description:"Docker的多架构支持是基于不同cpu的架构而不是不同操作系统的架构",meta:[{name:"twitter:title",content:"buildx多平台构建"},{name:"twitter:description",content:"Docker的多架构支持是基于不同cpu的架构而不是不同操作系统的架构"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/01.buildx%E5%A4%9A%E5%B9%B3%E5%8F%B0%E6%9E%84%E5%BB%BA.html"},{property:"og:type",content:"article"},{property:"og:title",content:"buildx多平台构建"},{property:"og:description",content:"Docker的多架构支持是基于不同cpu的架构而不是不同操作系统的架构"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/01.buildx%E5%A4%9A%E5%B9%B3%E5%8F%B0%E6%9E%84%E5%BB%BA.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"buildx多平台构建"},{itemprop:"description",content:"Docker的多架构支持是基于不同cpu的架构而不是不同操作系统的架构"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/01.buildx%E5%A4%9A%E5%B9%B3%E5%8F%B0%E6%9E%84%E5%BB%BA.html",relativePath:"01.技术杂谈/03.kubernetes/304.docker/01.buildx多平台构建.md",key:"v-43971d6a",path:"/pages/docker01/",headers:[{level:2,title:"跨 CPU 架构编译程序的方法",slug:"跨-cpu-架构编译程序的方法",normalizedTitle:"跨 cpu 架构编译程序的方法",charIndex:40},{level:2,title:"buildx",slug:"buildx",normalizedTitle:"buildx",charIndex:134},{level:3,title:"环境要求",slug:"环境要求",normalizedTitle:"环境要求",charIndex:286},{level:3,title:"构建镜像",slug:"构建镜像",normalizedTitle:"构建镜像",charIndex:827}],headersStr:"跨 CPU 架构编译程序的方法 buildx 环境要求 构建镜像",content:"Docker的多架构支持是基于不同cpu的架构而不是不同操作系统的架构\n\n\n# 跨 CPU 架构编译程序的方法\n\n 1. 直接在目标硬件上编译（常用）\n 2. 模拟目标硬件\n 3. 通过 binfmt_misc 模拟目标硬件的用户空间\n 4. 使用交叉编译器\n\n\n# buildx\n\nDocker 19.03 引入的插件 buildx buildx 会通过 QEMU 和 binfmt_misc 分别为不同的 CPU 架构（arm，arm64 和 amd64等）构建不同的镜像。构建完成后，就会创建一个 manifest list，其中包含了指向这些镜像的指针。\n\n\n# 环境要求\n\n * 要确保 Docker 版本不低于 19.03，同时还要通过设置环境变量 DOCKER_CLI_EXPERIMENTAL 来启用\n\n * 如果你使用的是 Linux，需要手动启用 binfmt_misc 大多数 Linux 发行版都很容易启用，不过还有一个更容易的办法，直接运行一个特权容器，容器里面写好了设置脚本： 🐳 → docker run --rm --privileged docker/binfmt:66f9012c56a8316f9244ffd7622d7c21c1f6f28d 建议将 Linux 内核版本升级到 4.x 以上，特别是 CentOS 用户，你可能会遇到错误。 cat /proc/sys/fs/binfmt_misc/qemu-aarch64\n\n * Docker 默认会使用不支持多 CPU 架构的构建器，我们需要手动切换。 先创建一个新的构建器：docker buildx create --use --name mybuilder 启动构建器： docker buildx inspect mybuilder --bootstrap 查看当前使用的构建器及构建器支持的 CPU 架构：docker buildx ls\n\n\n# 构建镜像\n\ndocker buildx build -t yangchuansheng/hello-arch --platform=linux/arm,linux/arm64,linux/amd64 . --push\n\n如果想将构建好的镜像保存在本地，可以将 type 指定为 docker，但必须分别为不同的 CPU 架构构建不同的镜像，不能合并成一个镜像 🐳 → docker buildx build -t yangchuansheng/hello-arch --platform=linux/arm -o type=docker . 🐳 → docker buildx build -t yangchuansheng/hello-arch --platform=linux/arm64 -o type=docker . 🐳 → docker buildx build -t yangchuansheng/hello-arch --platform=linux/amd64 -o type=docker .",normalizedContent:"docker的多架构支持是基于不同cpu的架构而不是不同操作系统的架构\n\n\n# 跨 cpu 架构编译程序的方法\n\n 1. 直接在目标硬件上编译（常用）\n 2. 模拟目标硬件\n 3. 通过 binfmt_misc 模拟目标硬件的用户空间\n 4. 使用交叉编译器\n\n\n# buildx\n\ndocker 19.03 引入的插件 buildx buildx 会通过 qemu 和 binfmt_misc 分别为不同的 cpu 架构（arm，arm64 和 amd64等）构建不同的镜像。构建完成后，就会创建一个 manifest list，其中包含了指向这些镜像的指针。\n\n\n# 环境要求\n\n * 要确保 docker 版本不低于 19.03，同时还要通过设置环境变量 docker_cli_experimental 来启用\n\n * 如果你使用的是 linux，需要手动启用 binfmt_misc 大多数 linux 发行版都很容易启用，不过还有一个更容易的办法，直接运行一个特权容器，容器里面写好了设置脚本： 🐳 → docker run --rm --privileged docker/binfmt:66f9012c56a8316f9244ffd7622d7c21c1f6f28d 建议将 linux 内核版本升级到 4.x 以上，特别是 centos 用户，你可能会遇到错误。 cat /proc/sys/fs/binfmt_misc/qemu-aarch64\n\n * docker 默认会使用不支持多 cpu 架构的构建器，我们需要手动切换。 先创建一个新的构建器：docker buildx create --use --name mybuilder 启动构建器： docker buildx inspect mybuilder --bootstrap 查看当前使用的构建器及构建器支持的 cpu 架构：docker buildx ls\n\n\n# 构建镜像\n\ndocker buildx build -t yangchuansheng/hello-arch --platform=linux/arm,linux/arm64,linux/amd64 . --push\n\n如果想将构建好的镜像保存在本地，可以将 type 指定为 docker，但必须分别为不同的 cpu 架构构建不同的镜像，不能合并成一个镜像 🐳 → docker buildx build -t yangchuansheng/hello-arch --platform=linux/arm -o type=docker . 🐳 → docker buildx build -t yangchuansheng/hello-arch --platform=linux/arm64 -o type=docker . 🐳 → docker buildx build -t yangchuansheng/hello-arch --platform=linux/amd64 -o type=docker .",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"在Docker中设置时区",frontmatter:{title:"在Docker中设置时区",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/docker05/",categories:["技术杂谈","kubernetes","docker"],tags:[null],titleTag:"原创",readingShow:"top",description:"由于 Debian 镜像中已经包含了tzdata，因此设置时区的方法比较简单，只需添加环境变量TZ即可。\nFROM debian:stretch",meta:[{name:"twitter:title",content:"在Docker中设置时区"},{name:"twitter:description",content:"由于 Debian 镜像中已经包含了tzdata，因此设置时区的方法比较简单，只需添加环境变量TZ即可。\nFROM debian:stretch"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/05.%E5%9C%A8Docker%E4%B8%AD%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA.html"},{property:"og:type",content:"article"},{property:"og:title",content:"在Docker中设置时区"},{property:"og:description",content:"由于 Debian 镜像中已经包含了tzdata，因此设置时区的方法比较简单，只需添加环境变量TZ即可。\nFROM debian:stretch"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/05.%E5%9C%A8Docker%E4%B8%AD%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"在Docker中设置时区"},{itemprop:"description",content:"由于 Debian 镜像中已经包含了tzdata，因此设置时区的方法比较简单，只需添加环境变量TZ即可。\nFROM debian:stretch"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/05.%E5%9C%A8Docker%E4%B8%AD%E8%AE%BE%E7%BD%AE%E6%97%B6%E5%8C%BA.html",relativePath:"01.技术杂谈/03.kubernetes/304.docker/05.在Docker中设置时区.md",key:"v-11c4c310",path:"/pages/docker05/",headers:[{level:2,title:"基于 Debian 镜像",slug:"基于-debian-镜像",normalizedTitle:"基于 debian 镜像",charIndex:2},{level:2,title:"基于 Alpine 镜像",slug:"基于-alpine-镜像",normalizedTitle:"基于 alpine 镜像",charIndex:125},{level:2,title:"基于 Ubuntu 镜像",slug:"基于-ubuntu-镜像",normalizedTitle:"基于 ubuntu 镜像",charIndex:366}],headersStr:"基于 Debian 镜像 基于 Alpine 镜像 基于 Ubuntu 镜像",content:'# 基于 Debian 镜像\n\n由于 Debian 镜像中已经包含了tzdata，因此设置时区的方法比较简单，只需添加环境变量TZ即可。\n\nFROM debian:stretch\n\nENV TZ=Asia/Shanghai\n\n\n1\n2\n3\n\n\n\n# 基于 Alpine 镜像\n\nFROM alpine:3.9\n\nENV TZ=Asia/Shanghai\n\nRUN apk update \\\n    && apk add tzdata \\\n    && echo "${TZ}" > /etc/timezone \\\n    && ln -sf /usr/share/zoneinfo/${TZ} /etc/localtime \\\n    && rm /var/cache/apk/*\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 基于 Ubuntu 镜像\n\nFROM ubuntu:bionic\n\nENV TZ=Asia/Shanghai\n\nRUN echo "${TZ}" > /etc/timezone \\\n    && ln -sf /usr/share/zoneinfo/${TZ} /etc/localtime \\\n    && apt update \\\n    && apt install -y tzdata \\\n    && rm -rf /var/lib/apt/lists/*\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n',normalizedContent:'# 基于 debian 镜像\n\n由于 debian 镜像中已经包含了tzdata，因此设置时区的方法比较简单，只需添加环境变量tz即可。\n\nfrom debian:stretch\n\nenv tz=asia/shanghai\n\n\n1\n2\n3\n\n\n\n# 基于 alpine 镜像\n\nfrom alpine:3.9\n\nenv tz=asia/shanghai\n\nrun apk update \\\n    && apk add tzdata \\\n    && echo "${tz}" > /etc/timezone \\\n    && ln -sf /usr/share/zoneinfo/${tz} /etc/localtime \\\n    && rm /var/cache/apk/*\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 基于 ubuntu 镜像\n\nfrom ubuntu:bionic\n\nenv tz=asia/shanghai\n\nrun echo "${tz}" > /etc/timezone \\\n    && ln -sf /usr/share/zoneinfo/${tz} /etc/localtime \\\n    && apt update \\\n    && apt install -y tzdata \\\n    && rm -rf /var/lib/apt/lists/*\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n',charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"docker基础",frontmatter:{title:"docker基础",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/docker06/",categories:["技术杂谈","kubernetes","docker"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"docker基础"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/06.docker%E5%9F%BA%E7%A1%80.html"},{property:"og:type",content:"article"},{property:"og:title",content:"docker基础"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/06.docker%E5%9F%BA%E7%A1%80.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"docker基础"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/304.docker/06.docker%E5%9F%BA%E7%A1%80.html",relativePath:"01.技术杂谈/03.kubernetes/304.docker/06.docker基础.md",key:"v-3b906eab",path:"/pages/docker06/",headers:[{level:2,title:"虚悬镜像",slug:"虚悬镜像",normalizedTitle:"虚悬镜像",charIndex:2},{level:2,title:"中间层镜像",slug:"中间层镜像",normalizedTitle:"中间层镜像",charIndex:638},{level:2,title:"一些命令技巧",slug:"一些命令技巧",normalizedTitle:"一些命令技巧",charIndex:740},{level:2,title:"重启docker不影响pod",slug:"重启docker不影响pod",normalizedTitle:"重启docker不影响pod",charIndex:1071}],headersStr:"虚悬镜像 中间层镜像 一些命令技巧 重启docker不影响pod",content:'# 虚悬镜像\n\n镜像列表中，可能会看到一个特殊的镜像，这个镜像既没有仓库名，也没有标签，均为\n\n<none>               <none>              00285df0df87        5 days ago          342 MB\n\n\n1\n\n\n原因有可能是官方镜像维护，发布了新版本后，原镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像：\n\ndocker image ls -f dangling=true\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\n<none>              <none>              00285df0df87        5 days ago          342 MB\n\n\n1\n2\n3\n\n\n一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。\n\ndocker image prune\n\n\n1\n\n\n??实测无法全部删完\n\n\n# 中间层镜像\n\n默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。\n\ndocker image ls -a\n\n\n1\n\n\n\n# 一些命令技巧\n\n * 只输出镜像ID和仓库名：\n\n$ docker image ls --format "{{.ID}}:{{.Repository}}"\n5f515359c7f8: redis\n05a60462f8ba: nginx\nfe9198c04d62: mongo\n00285df0df87: <none>\n329ed837d508: ubuntu\n329ed837d508: ubuntu\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 只输出id列\n\ndocker image ls -q\n\n\n1\n\n * 删除所有仓库名为 redis 的镜像\n\n$ docker image rm $(docker image ls -q redis)\n\n\n1\n\n\n\n# 重启docker不影响pod\n\n/etc/docker/daemon.json配置文件中设置 { "live-restore": true }',normalizedContent:'# 虚悬镜像\n\n镜像列表中，可能会看到一个特殊的镜像，这个镜像既没有仓库名，也没有标签，均为\n\n<none>               <none>              00285df0df87        5 days ago          342 mb\n\n\n1\n\n\n原因有可能是官方镜像维护，发布了新版本后，原镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像：\n\ndocker image ls -f dangling=true\nrepository          tag                 image id            created             size\n<none>              <none>              00285df0df87        5 days ago          342 mb\n\n\n1\n2\n3\n\n\n一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。\n\ndocker image prune\n\n\n1\n\n\n??实测无法全部删完\n\n\n# 中间层镜像\n\n默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。\n\ndocker image ls -a\n\n\n1\n\n\n\n# 一些命令技巧\n\n * 只输出镜像id和仓库名：\n\n$ docker image ls --format "{{.id}}:{{.repository}}"\n5f515359c7f8: redis\n05a60462f8ba: nginx\nfe9198c04d62: mongo\n00285df0df87: <none>\n329ed837d508: ubuntu\n329ed837d508: ubuntu\n\n\n1\n2\n3\n4\n5\n6\n7\n\n * 只输出id列\n\ndocker image ls -q\n\n\n1\n\n * 删除所有仓库名为 redis 的镜像\n\n$ docker image rm $(docker image ls -q redis)\n\n\n1\n\n\n\n# 重启docker不影响pod\n\n/etc/docker/daemon.json配置文件中设置 { "live-restore": true }',charsets:{cjk:!0}},{title:"日志采集方案",frontmatter:{title:"日志采集方案",date:"2022-10-09T17:56:54.000Z",permalink:"/pages/rzcjfa/",categories:["技术杂谈","kubernetes","日志采集"],tags:["fluentd","loki"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"日志采集方案"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/01.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E6%96%B9%E6%A1%88.html"},{property:"og:type",content:"article"},{property:"og:title",content:"日志采集方案"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/01.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E6%96%B9%E6%A1%88.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T17:56:54.000Z"},{property:"article:tag",content:"fluentd"},{property:"article:tag",content:"loki"},{itemprop:"name",content:"日志采集方案"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/01.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E6%96%B9%E6%A1%88.html",relativePath:"01.技术杂谈/03.kubernetes/305.日志采集/01.日志采集方案.md",key:"v-0523fe6a",path:"/pages/rzcjfa/",headers:[{level:2,title:"EFK",slug:"efk",normalizedTitle:"efk",charIndex:2},{level:2,title:"loki",slug:"loki",normalizedTitle:"loki",charIndex:188}],headersStr:"EFK loki",content:"# EFK\n\nEFK(Elasticsearch + Fluentd + Kibana)是kubernetes官方推荐的日志收集方案，且fluentd已从CNCF 毕业 优缺点：\n\n * 技术比较成熟，用户较多\n * 更复杂的查询和数据分析建议使用EFK\n * fluentd性能不好，业界有部分已淘汰fluentd\n * ES查询功能较复杂，对我们来说有点大材小用\n\n\n# loki\n\nPromtail + Loki + Grafana（需要 Grafana v6.0+）\n\n * Loki 是主服务器，负责存储日志和处理查询。 Loki 有几个客户端选项：Promtail（它还支持 systemd 日志摄取和基于 TCP 的 syslog 摄取）、Fluentd、Fluent Bit、Docker 插件等等！\n * promtail 是代理，负责收集日志并将其发送给 loki 。\n * Grafana 用于 UI 展示。 优缺点：\n * 使用了和Prometheus一样的标签来作为索引，也就是说，你通过这些标签既可以查询日志的内容也可以查询到监控的数据，不但减少了两种查询之间的切换成本，也极大地降低了日志索引的存储。\n * 特别适合储存 Kubernetes Pod日志; 诸如Pod标签之类的元数据会被自动删除和编入索引;\n * 受Grafana原生支持,避免kibana和grafana来回切换;",normalizedContent:"# efk\n\nefk(elasticsearch + fluentd + kibana)是kubernetes官方推荐的日志收集方案，且fluentd已从cncf 毕业 优缺点：\n\n * 技术比较成熟，用户较多\n * 更复杂的查询和数据分析建议使用efk\n * fluentd性能不好，业界有部分已淘汰fluentd\n * es查询功能较复杂，对我们来说有点大材小用\n\n\n# loki\n\npromtail + loki + grafana（需要 grafana v6.0+）\n\n * loki 是主服务器，负责存储日志和处理查询。 loki 有几个客户端选项：promtail（它还支持 systemd 日志摄取和基于 tcp 的 syslog 摄取）、fluentd、fluent bit、docker 插件等等！\n * promtail 是代理，负责收集日志并将其发送给 loki 。\n * grafana 用于 ui 展示。 优缺点：\n * 使用了和prometheus一样的标签来作为索引，也就是说，你通过这些标签既可以查询日志的内容也可以查询到监控的数据，不但减少了两种查询之间的切换成本，也极大地降低了日志索引的存储。\n * 特别适合储存 kubernetes pod日志; 诸如pod标签之类的元数据会被自动删除和编入索引;\n * 受grafana原生支持,避免kibana和grafana来回切换;",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"loki",frontmatter:{title:"loki",date:"2022-10-09T17:56:54.000Z",permalink:"/pages/loki/",categories:["技术杂谈","kubernetes","日志采集"],tags:["loki"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"loki"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/05.loki.html"},{property:"og:type",content:"article"},{property:"og:title",content:"loki"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/05.loki.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T17:56:54.000Z"},{property:"article:tag",content:"loki"},{itemprop:"name",content:"loki"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/05.loki.html",relativePath:"01.技术杂谈/03.kubernetes/305.日志采集/05.loki.md",key:"v-31339544",path:"/pages/loki/",headers:[{level:2,title:"部署与配置：",slug:"部署与配置",normalizedTitle:"部署与配置：",charIndex:2},{level:2,title:"fluetnd+loki",slug:"fluetnd-loki",normalizedTitle:"fluetnd+loki",charIndex:1567}],headersStr:"部署与配置： fluetnd+loki",content:"# 部署与配置：\n\n官方最佳示例： https://grafana.com/docs/loki/latest/best-practices/\n\n * 已部署grafana\n\n * 部署部署Loki和Promtail helm chart部署\n\n * 配置Loki和Promtai：\n   \n   > 存储位置：pvc(本地或ceph) 配置grafana添加Loki数据源：journal、event-exporter\n\n * 避免使用动态标签去匹配具有较大范围的可能值，比如ip值。这样会导致Loki建立一个巨大的索引，性能非常差。 promtail 需要运行在所有运行应用容器的节点, 所以会是 DaemonSet, loki 作为核心服务, 带有持久化存储而且支持横向扩展, 所以应该是 StatefulSet, Grafana 是比较基本的独立应用, 可以复用已部署的. https://grafana.com/docs/loki/latest/installation/microservices-helm/????????? https://grafana.github.io/loki/charts/\n\n$ helm repo add loki https://grafana.github.io/loki/charts\n$ helm repo update\n$ helm fetch loki/loki-stack --untar --untardir .\n$ cd loki-stack\n# 修改配置...\n$ helm install -n loki --namespace loki -f values.yaml ../loki-stack\n$ kubectl get svc -n loki \n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n注：\n\n * 可以修改values.yaml文件，指定是否开启Grafana、Prometheus等服务，默认不开启的：\n\n * promtail服务在构建时会自动挂载：cat charts/promtail/values.yaml 宿主机docker主目录下的containers目录，一般默认都为/var/lib/docker/containers（改为/app/docker/containers） pod的日志目录，一般默认为/var/log/pods（未改） 如果是修改过docker默认的存储路径的，需要将mount的路径进行修改，promtail找不到对应的容器日志 具体docker 存储路径，可以使用docker info 命令查询\n\n * 如果是安装Loki时开启了Grafana，那系统会自动配置好Data sources。但是，如果是手动搭建的Grafana，需要手动添加Data Sources时，一定注意：数据源名称中的Loki，L一定要是大写！！！\n\n * grafana升级 wget https://dl.grafana.com/oss/release/grafana-9.1.2-1.x86_64.rpm yum localinstall grafana-9.1.2-1.x86_64.rpm service grafana-server restart\n\n * loki svc 要暴露nodeport，否则grafana连接不到\n\n * 添加宿主机journal日志：/run/log/journal 参考：https://grafana.com/docs/loki/latest/installation/microservices-helm/ Run Promtail with systemd-journal support\n\n\n# fluetnd+loki\n\n * Loki为fluetnd提供了一个输出插件fluent-plugin-grafana-loki，它可以将采集到的日志传送到Loki实例当中。\n\ngem install fluent-plugin-grafana-loki",normalizedContent:"# 部署与配置：\n\n官方最佳示例： https://grafana.com/docs/loki/latest/best-practices/\n\n * 已部署grafana\n\n * 部署部署loki和promtail helm chart部署\n\n * 配置loki和promtai：\n   \n   > 存储位置：pvc(本地或ceph) 配置grafana添加loki数据源：journal、event-exporter\n\n * 避免使用动态标签去匹配具有较大范围的可能值，比如ip值。这样会导致loki建立一个巨大的索引，性能非常差。 promtail 需要运行在所有运行应用容器的节点, 所以会是 daemonset, loki 作为核心服务, 带有持久化存储而且支持横向扩展, 所以应该是 statefulset, grafana 是比较基本的独立应用, 可以复用已部署的. https://grafana.com/docs/loki/latest/installation/microservices-helm/????????? https://grafana.github.io/loki/charts/\n\n$ helm repo add loki https://grafana.github.io/loki/charts\n$ helm repo update\n$ helm fetch loki/loki-stack --untar --untardir .\n$ cd loki-stack\n# 修改配置...\n$ helm install -n loki --namespace loki -f values.yaml ../loki-stack\n$ kubectl get svc -n loki \n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n注：\n\n * 可以修改values.yaml文件，指定是否开启grafana、prometheus等服务，默认不开启的：\n\n * promtail服务在构建时会自动挂载：cat charts/promtail/values.yaml 宿主机docker主目录下的containers目录，一般默认都为/var/lib/docker/containers（改为/app/docker/containers） pod的日志目录，一般默认为/var/log/pods（未改） 如果是修改过docker默认的存储路径的，需要将mount的路径进行修改，promtail找不到对应的容器日志 具体docker 存储路径，可以使用docker info 命令查询\n\n * 如果是安装loki时开启了grafana，那系统会自动配置好data sources。但是，如果是手动搭建的grafana，需要手动添加data sources时，一定注意：数据源名称中的loki，l一定要是大写！！！\n\n * grafana升级 wget https://dl.grafana.com/oss/release/grafana-9.1.2-1.x86_64.rpm yum localinstall grafana-9.1.2-1.x86_64.rpm service grafana-server restart\n\n * loki svc 要暴露nodeport，否则grafana连接不到\n\n * 添加宿主机journal日志：/run/log/journal 参考：https://grafana.com/docs/loki/latest/installation/microservices-helm/ run promtail with systemd-journal support\n\n\n# fluetnd+loki\n\n * loki为fluetnd提供了一个输出插件fluent-plugin-grafana-loki，它可以将采集到的日志传送到loki实例当中。\n\ngem install fluent-plugin-grafana-loki",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"nvidia-device-plugin",frontmatter:{title:"nvidia-device-plugin",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/gpu01/",categories:["技术杂谈","kubernetes"],tags:["gpu"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"nvidia-device-plugin"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/01.nvidia-device-plugins.html"},{property:"og:type",content:"article"},{property:"og:title",content:"nvidia-device-plugin"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/01.nvidia-device-plugins.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:"gpu"},{itemprop:"name",content:"nvidia-device-plugin"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/01.nvidia-device-plugins.html",relativePath:"01.技术杂谈/03.kubernetes/306.GPU/01.nvidia-device-plugins.md",key:"v-7e4b3a46",path:"/pages/gpu01/",headers:[{level:2,title:"k8s英伟达GPU插件（nvidia-device-plugin）",slug:"k8s英伟达gpu插件-nvidia-device-plugin",normalizedTitle:"k8s英伟达gpu插件（nvidia-device-plugin）",charIndex:2},{level:3,title:"安装方法",slug:"安装方法",normalizedTitle:"安装方法",charIndex:40},{level:3,title:"使用方法",slug:"使用方法",normalizedTitle:"使用方法",charIndex:3405},{level:4,title:"docker",slug:"docker",normalizedTitle:"docker",charIndex:1844},{level:4,title:"k8s",slug:"k8s",normalizedTitle:"k8s",charIndex:2},{level:2,title:"参考",slug:"参考",normalizedTitle:"参考",charIndex:5569}],headersStr:"k8s英伟达GPU插件（nvidia-device-plugin） 安装方法 使用方法 docker k8s 参考",content:'# k8s英伟达GPU插件（nvidia-device-plugin）\n\n\n# 安装方法\n\nhttps://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\n\n 1. 本地节点添加 NVIDIA 驱动程序 要求：NVIDIA drivers ~= 384.81 先确保你的主机上的 NVIDIA 驱动程序正常工作，你应该能够成功运行 nvidia-smi 并查看你的 GPU 名称、驱动程序版本和 CUDA 版本\n\n$ nvidia-smi\nThu Jul 14 11:49:33 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 515.57       Driver Version: 515.57       CUDA Version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n|  0%   48C    P8    11W / 200W |      0MiB /  8192MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n需要注意的是，第一次安装显卡驱动的话，是不用重启服务器的\n\n 2. 本地节点安装nvidia-docker或nvidia-container-toolkit\n\nnvidia-docker >= 2.0 || nvidia-container-toolkit >= 1.7.0\n\n运行NVIDIA Container Toolkit的条件：\n\n * 内核版本 > 3.10 的 GNU/Linux x86_64\n * Docker >= 19.03（推荐，但某些发行版可能包含旧版本的 Docker。支持的最低版本为 1.12）\n * 架构 >= Kepler（或计算能力 3.0）的 NVIDIA GPU\n * NVIDIA Linux 驱动程序>= 418.81.07（请注意，不支持较旧的驱动程序版本或分支。）\n\n如：centos, nvidia-container-toolkit\n\n$ curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo\n$ yum install -y nvidia-container-toolkit\n$ rpm -qa | grep nvidia\nlibnvidia-container-tools-1.10.0-1.x86_64\nlibnvidia-container1-1.10.0-1.x86_64\nnvidia-container-toolkit-1.10.0-1.x86_64\n\n\n1\n2\n3\n4\n5\n6\n\n 3. 每个节点Docker的默认运行时设置为 nvidia-container-runtime\n\n$ cat /etc/docker/daemon.json\n{\n    "default-runtime":"nvidia",\n    "runtimes": {\n        "nvidia": {\n            "path":"/usr/bin/nvidia-container-runtime",\n            "runtimeArgs": []\n        }\n    }\n}\n\n$ systemctl daemon-reload\n$ systemctl restart docker\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 4. 部署 NVIDIA 设备插件: kubectl create -f nvidia-device-plugin.yml\n\n#1.0.0-beta4\n$ docker pull nvidia/k8s-device-plugin:1.0.0-beta4\n$ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/1.0.0-beta4/nvidia-device-plugin.yml\n# 或1.12\n$ docker pull nvidia/k8s-device-plugin:1.11\n$ kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v1.12/nvidia-device-plugin.yml\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 检查： Kubernetes将暴露 amd.com/gpu或nvidia.com/gpu为可调度的资源\n\n$ kubectl describe node | grep nvidia.com/gpu\n\n\n1\n\n\n\n# 使用方法\n\n# docker\n\n$ docker run --name hfftest --rm -it --gpus all nvidia/cuda:10.0-base nvidia-smi\nThu Jul 14 04:54:04 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 515.57       Driver Version: 515.57       CUDA Version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:02:00.0 Off |                  N/A |\n| 21%   49C    P8    16W / 200W |      0MiB /  8192MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n# k8s\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-gpu\nspec:\n  restartPolicy: OnFailure\n  containers:\n    - name: test-gpu\n      image: "k8s.gcr.io/cuda-vector-add:v0.1"\n      resources:\n        limits:\n          nvidia.com/gpu: 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n一些限制的：\n\n * GPUs 只能设置在 limits 部分，这意味着：\n\n> 你可以指定 GPU 的 limits 而不指定其 requests，Kubernetes 将使用限制 值作为默认的请求值； 你可以同时指定 limits 和 requests，不过这两个值必须相等。 你不可以仅指定 requests 而不指定 limits。\n\n * 容器（以及 Pod）之间是不共享 GPU 的。GPU 也不可以过量分配（Overcommitting）。\n * 每个容器可以请求一个或者多个 GPU，但是用小数值来请求部分 GPU 是不允许的。\n\n\n# 参考\n\n * https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\n * https://kubernetes.io/zh-cn/docs/tasks/manage-gpus/scheduling-gpus/#deploying-nvidia-gpu-device-plugin\n * https://github.com/NVIDIA/k8s-device-plugin',normalizedContent:'# k8s英伟达gpu插件（nvidia-device-plugin）\n\n\n# 安装方法\n\nhttps://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\n\n 1. 本地节点添加 nvidia 驱动程序 要求：nvidia drivers ~= 384.81 先确保你的主机上的 nvidia 驱动程序正常工作，你应该能够成功运行 nvidia-smi 并查看你的 gpu 名称、驱动程序版本和 cuda 版本\n\n$ nvidia-smi\nthu jul 14 11:49:33 2022\n+-----------------------------------------------------------------------------+\n| nvidia-smi 515.57       driver version: 515.57       cuda version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| gpu  name        persistence-m| bus-id        disp.a | volatile uncorr. ecc |\n| fan  temp  perf  pwr:usage/cap|         memory-usage | gpu-util  compute m. |\n|                               |                      |               mig m. |\n|===============================+======================+======================|\n|   0  nvidia geforce ...  off  | 00000000:02:00.0 off |                  n/a |\n|  0%   48c    p8    11w / 200w |      0mib /  8192mib |      0%      default |\n|                               |                      |                  n/a |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| processes:                                                                  |\n|  gpu   gi   ci        pid   type   process name                  gpu memory |\n|        id   id                                                   usage      |\n|=============================================================================|\n|  no running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n需要注意的是，第一次安装显卡驱动的话，是不用重启服务器的\n\n 2. 本地节点安装nvidia-docker或nvidia-container-toolkit\n\nnvidia-docker >= 2.0 || nvidia-container-toolkit >= 1.7.0\n\n运行nvidia container toolkit的条件：\n\n * 内核版本 > 3.10 的 gnu/linux x86_64\n * docker >= 19.03（推荐，但某些发行版可能包含旧版本的 docker。支持的最低版本为 1.12）\n * 架构 >= kepler（或计算能力 3.0）的 nvidia gpu\n * nvidia linux 驱动程序>= 418.81.07（请注意，不支持较旧的驱动程序版本或分支。）\n\n如：centos, nvidia-container-toolkit\n\n$ curl -s -l https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | sudo tee /etc/yum.repos.d/nvidia-docker.repo\n$ yum install -y nvidia-container-toolkit\n$ rpm -qa | grep nvidia\nlibnvidia-container-tools-1.10.0-1.x86_64\nlibnvidia-container1-1.10.0-1.x86_64\nnvidia-container-toolkit-1.10.0-1.x86_64\n\n\n1\n2\n3\n4\n5\n6\n\n 3. 每个节点docker的默认运行时设置为 nvidia-container-runtime\n\n$ cat /etc/docker/daemon.json\n{\n    "default-runtime":"nvidia",\n    "runtimes": {\n        "nvidia": {\n            "path":"/usr/bin/nvidia-container-runtime",\n            "runtimeargs": []\n        }\n    }\n}\n\n$ systemctl daemon-reload\n$ systemctl restart docker\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n\n 4. 部署 nvidia 设备插件: kubectl create -f nvidia-device-plugin.yml\n\n#1.0.0-beta4\n$ docker pull nvidia/k8s-device-plugin:1.0.0-beta4\n$ kubectl create -f https://raw.githubusercontent.com/nvidia/k8s-device-plugin/1.0.0-beta4/nvidia-device-plugin.yml\n# 或1.12\n$ docker pull nvidia/k8s-device-plugin:1.11\n$ kubectl create -f https://raw.githubusercontent.com/nvidia/k8s-device-plugin/v1.12/nvidia-device-plugin.yml\n\n\n1\n2\n3\n4\n5\n6\n\n 5. 检查： kubernetes将暴露 amd.com/gpu或nvidia.com/gpu为可调度的资源\n\n$ kubectl describe node | grep nvidia.com/gpu\n\n\n1\n\n\n\n# 使用方法\n\n# docker\n\n$ docker run --name hfftest --rm -it --gpus all nvidia/cuda:10.0-base nvidia-smi\nthu jul 14 04:54:04 2022\n+-----------------------------------------------------------------------------+\n| nvidia-smi 515.57       driver version: 515.57       cuda version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| gpu  name        persistence-m| bus-id        disp.a | volatile uncorr. ecc |\n| fan  temp  perf  pwr:usage/cap|         memory-usage | gpu-util  compute m. |\n|                               |                      |               mig m. |\n|===============================+======================+======================|\n|   0  nvidia geforce ...  off  | 00000000:02:00.0 off |                  n/a |\n| 21%   49c    p8    16w / 200w |      0mib /  8192mib |      0%      default |\n|                               |                      |                  n/a |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| processes:                                                                  |\n|  gpu   gi   ci        pid   type   process name                  gpu memory |\n|        id   id                                                   usage      |\n|=============================================================================|\n|  no running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n# k8s\n\napiversion: v1\nkind: pod\nmetadata:\n  name: test-gpu\nspec:\n  restartpolicy: onfailure\n  containers:\n    - name: test-gpu\n      image: "k8s.gcr.io/cuda-vector-add:v0.1"\n      resources:\n        limits:\n          nvidia.com/gpu: 1\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n一些限制的：\n\n * gpus 只能设置在 limits 部分，这意味着：\n\n> 你可以指定 gpu 的 limits 而不指定其 requests，kubernetes 将使用限制 值作为默认的请求值； 你可以同时指定 limits 和 requests，不过这两个值必须相等。 你不可以仅指定 requests 而不指定 limits。\n\n * 容器（以及 pod）之间是不共享 gpu 的。gpu 也不可以过量分配（overcommitting）。\n * 每个容器可以请求一个或者多个 gpu，但是用小数值来请求部分 gpu 是不允许的。\n\n\n# 参考\n\n * https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\n * https://kubernetes.io/zh-cn/docs/tasks/manage-gpus/scheduling-gpus/#deploying-nvidia-gpu-device-plugin\n * https://github.com/nvidia/k8s-device-plugin',charsets:{cjk:!0}},{title:"第四范式vgpu",frontmatter:{title:"第四范式vgpu",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/4paradigm/",categories:["技术杂谈","kubernetes"],tags:["gpu"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"第四范式vgpu"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/02.%E7%AC%AC%E5%9B%9B%E8%8C%83%E5%BC%8FvGPU.html"},{property:"og:type",content:"article"},{property:"og:title",content:"第四范式vgpu"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/02.%E7%AC%AC%E5%9B%9B%E8%8C%83%E5%BC%8FvGPU.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:"gpu"},{itemprop:"name",content:"第四范式vgpu"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/02.%E7%AC%AC%E5%9B%9B%E8%8C%83%E5%BC%8FvGPU.html",relativePath:"01.技术杂谈/03.kubernetes/306.GPU/02.第四范式vGPU.md",key:"v-be31a184",path:"/pages/4paradigm/",headers:[{level:2,title:"部署",slug:"部署",normalizedTitle:"部署",charIndex:497},{level:2,title:"参数",slug:"参数",normalizedTitle:"参数",charIndex:619},{level:2,title:"验证",slug:"验证",normalizedTitle:"验证",charIndex:566}],headersStr:"部署 参数 验证",content:"github地址：https://github.com/4paradigm/k8s-device-plugin/blob/master/README_cn.md\n\nvGPU device plugin 基于NVIDIA官方插件(NVIDIA/k8s-device-plugin)，在保留官方功能的基础上，实现了对物理GPU进行切分，并对显存和计算单元进行限制，从而模拟出多张小的vGPU卡。\n\n第四范式的GPU共享方案还叫vGPU，也是CUDA劫持方案。由于没有开源资源隔离部分的代码，从文档中推测，其实现和GaiaGPU的vcuda较为类似：显存隔离使用的是经典CUDA劫持方法，通过预估获得context大小；使用监控隔离的方案隔离算力。同样地，方案的优缺点也和vCUDA类似。较为特别的一点是，和阿里Antman相同地，第四范式vGPU通过Nvidia UVM实现了虚拟显存。不过UVM实质上是使用内存来虚拟显存，因此会消耗较大的内存，且性能会有较大下降。若要使用虚拟显存功能，还需思考程序本身占用的内存和虚拟显存的trade off。\n\n同时，采用这种方案不需重新设计调度器。\n\n\n# 部署\n\ndocker pull 4pdosc/k8s-device-plugin:latest (注意v1.8镜像使用有问题，拉最新的镜像验证没问题) kubectl apply -f nvidia-device-plugin.yml\n\n\n# 参数\n\n--device-split-count=3 整数类型，预设值是2。NVIDIA装置的分割数。对于一个总共包含N张NVIDIA GPU的Kubernetes集群，如果我们将device-split-count参数配置为K，这个Kubernetes集群将有K * N个可分配的vGPU资源 --device-memory-scaling=3 浮点数类型，预设值是1。NVIDIA装置显存使用比例，可以大于1（启用虚拟显存，实验功能）。对于有M 显存大小的NVIDIA GPU，如果我们配置device-memory-scaling参数为S，在部署了我们装置插件的Kubenetes集群中，这张GPU分出的vGPU将总共包含 S * M显存。张vGPU的显存大小也受device-split-count参数影响。在先前的例子中，如果device-split-count参数配置为K，那每一张vGPU最后会取得 S * M / K 大小的显存。\n\n\n# 验证\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-gpu-4paradigm\nspec:\n  restartPolicy: OnFailure\n  containers:\n    - name: cuda\n      image: nvidia/cuda:10.0-base\n      imagePullPolicy: IfNotPresent\n      tty: true\n      resources:\n        limits:\n          nvidia.com/gpu: 1\n  nodeName: node01\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n[root@master02 4paradigm]# kubectl describe node node01 | grep gpu\n  nvidia.com/gpu:     3\n  nvidia.com/gpu:     3\n  nvidia.com/gpu     0            0\n\n\n1\n2\n3\n4\n",normalizedContent:"github地址：https://github.com/4paradigm/k8s-device-plugin/blob/master/readme_cn.md\n\nvgpu device plugin 基于nvidia官方插件(nvidia/k8s-device-plugin)，在保留官方功能的基础上，实现了对物理gpu进行切分，并对显存和计算单元进行限制，从而模拟出多张小的vgpu卡。\n\n第四范式的gpu共享方案还叫vgpu，也是cuda劫持方案。由于没有开源资源隔离部分的代码，从文档中推测，其实现和gaiagpu的vcuda较为类似：显存隔离使用的是经典cuda劫持方法，通过预估获得context大小；使用监控隔离的方案隔离算力。同样地，方案的优缺点也和vcuda类似。较为特别的一点是，和阿里antman相同地，第四范式vgpu通过nvidia uvm实现了虚拟显存。不过uvm实质上是使用内存来虚拟显存，因此会消耗较大的内存，且性能会有较大下降。若要使用虚拟显存功能，还需思考程序本身占用的内存和虚拟显存的trade off。\n\n同时，采用这种方案不需重新设计调度器。\n\n\n# 部署\n\ndocker pull 4pdosc/k8s-device-plugin:latest (注意v1.8镜像使用有问题，拉最新的镜像验证没问题) kubectl apply -f nvidia-device-plugin.yml\n\n\n# 参数\n\n--device-split-count=3 整数类型，预设值是2。nvidia装置的分割数。对于一个总共包含n张nvidia gpu的kubernetes集群，如果我们将device-split-count参数配置为k，这个kubernetes集群将有k * n个可分配的vgpu资源 --device-memory-scaling=3 浮点数类型，预设值是1。nvidia装置显存使用比例，可以大于1（启用虚拟显存，实验功能）。对于有m 显存大小的nvidia gpu，如果我们配置device-memory-scaling参数为s，在部署了我们装置插件的kubenetes集群中，这张gpu分出的vgpu将总共包含 s * m显存。张vgpu的显存大小也受device-split-count参数影响。在先前的例子中，如果device-split-count参数配置为k，那每一张vgpu最后会取得 s * m / k 大小的显存。\n\n\n# 验证\n\napiversion: v1\nkind: pod\nmetadata:\n  name: test-gpu-4paradigm\nspec:\n  restartpolicy: onfailure\n  containers:\n    - name: cuda\n      image: nvidia/cuda:10.0-base\n      imagepullpolicy: ifnotpresent\n      tty: true\n      resources:\n        limits:\n          nvidia.com/gpu: 1\n  nodename: node01\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n\n\n[root@master02 4paradigm]# kubectl describe node node01 | grep gpu\n  nvidia.com/gpu:     3\n  nvidia.com/gpu:     3\n  nvidia.com/gpu     0            0\n\n\n1\n2\n3\n4\n",charsets:{cjk:!0}},{title:"日志采集方案",frontmatter:{title:"日志采集方案",date:"2022-10-09T17:56:54.000Z",permalink:"/pages/fluentd-log/",categories:["技术杂谈","kubernetes","日志采集"],tags:["fluentd"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"日志采集方案"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/02.fluentd%E9%85%8D%E7%BD%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"日志采集方案"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/02.fluentd%E9%85%8D%E7%BD%AE.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T17:56:54.000Z"},{property:"article:tag",content:"fluentd"},{itemprop:"name",content:"日志采集方案"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/02.fluentd%E9%85%8D%E7%BD%AE.html",relativePath:"01.技术杂谈/03.kubernetes/305.日志采集/02.fluentd配置.md",key:"v-338caad2",path:"/pages/fluentd-log/",headers:[{level:2,title:"采集k8s容器标准输出日志",slug:"采集k8s容器标准输出日志",normalizedTitle:"采集k8s容器标准输出日志",charIndex:2},{level:2,title:"本地日志文件-主机审计日志",slug:"本地日志文件-主机审计日志",normalizedTitle:"本地日志文件-主机审计日志",charIndex:2058},{level:2,title:"journal日志",slug:"journal日志",normalizedTitle:"journal日志",charIndex:3050},{level:2,title:"输出",slug:"输出",normalizedTitle:"输出",charIndex:11}],headersStr:"采集k8s容器标准输出日志 本地日志文件-主机审计日志 journal日志 输出",content:'# 采集k8s容器标准输出日志\n\n <source>\n      @type tail\n      path /var/log/containers/kube-*.log,/var/log/containers/myapp-*.log  # 逗号分隔\n      exclude_path ["/var/log/containers/kubectl-*.log"]    # 排除的日志\n      pos_file /var/log/pos/containers.log.pos              # 保存已读日志文件的位置\n      tag raw.*\n      read_from_head true\n      <parse>\n        @type multi_format\n        # 匹配docker容器日志格式json\n        <pattern>\n          format json\n          time_key time\n          time_format %Y-%m-%dT%H:%M:%S.%NZ\n        </pattern>\n        #这部分用来正则匹配CRI容器日志格式text\n        <pattern>\n          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/\n          time_format %Y-%m-%dT%H:%M:%S.%N%:z\n        </pattern>\n      </parse>\n    </source>\n\n\n    <filter raw.**>\n        @type kubernetes_metadata\n        @id kubernetes_metadata_container_out\n        skip_container_metadata true\n        skip_master_url true\n        cache_size 3000\n        cache_ttl 1800   \n    </filter>\n\n    <match raw.**>\n      @type record_modifier\n      @id label.container.out\n      tag k8s-containers-${record.dig("k8s_container_name")}\n      # tag ${record.dig(\'log-collect\') ? k8s-containers-${record.dig("k8s_container_name")} : \'dropped.raw\'}\n      <record>\n        k8s_container_id ${record.dig("docker", "container_id")}\n        k8s_cloud_cluster "#{ENV[\'CLOUD_CLUSTER\'] || \'default\'}"\n        k8s_node ${record.dig(\'kubernetes\', \'host\')}\n        k8s_container_name ${record.dig(\'kubernetes\', \'container_name\')}\n        k8s_pod_name ${record.dig(\'kubernetes\', \'pod_name\')}\n        k8s_namespace_name ${record.dig(\'kubernetes\', \'namespace_name\')}\n        # log-collect ${record.dig("kubernetes", "labels", "log-collect") or false}\n        formated_time "${Time.at(time).to_datetime.iso8601(9)}"\n        fluentd_worker "#{worker_id}"\n      </record>\n      remove_keys docker,kubernetes                            # 删除原生metadata字段\n    </match>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n\n# 本地日志文件-主机审计日志\n\n    <source>\n        @type tail\n        read_from_head false\n        path /var/log/operation/*.log                       # 宿主机操作日志\n        follow_inodes true                                  # 如果没有这个参数，文件轮转会导致日志重复\n        path_key file_name                                  # 指定事件中path的key名称\n        pos_file /var/log/pos/operation.log.pos             # 保存已读日志文件的位置\n        tag host-operation\n        limit_recently_modified 7d                          # 只监控指定修改时间范围内的文件\n        multiline_flush_interval 1s                         # 多行处理模式下的缓存输出间隔\n        <parse>\n          @type json\n          time_key time                                     # 从事件的什么字段中获取时间，如果该字段不存在，则取当前时间\n          time_type string                                  # 可选值:float:UNIX时间.纳秒、unixtime: UNIX时间(秒)、string:根据后面几个参数决定具体格式\n          time_format %Y-%m-%d %H:%M:%S                     # 时间格式\n          timezone +08:00\n        </parse>\n    </source>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# journal日志\n\n    <source>                  \n      @type systemd\n      path /run/log/journal\n      matches [{ "_SYSTEMD_UNIT": ["kubelet.service", "etcd.service"] }]      # 指定journald日志,屏蔽此行则采集所有journal日志\n      <storage>\n        @type local\n        persistent true\n        path /var/log/pos/journal.pos\n      </storage>\n      read_from_head true\n      tag journald\n    </source>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 输出\n\n    # <match dropped.**>\n    #   @type null                                             # 需要忽略的日志\n    # </match>\n    <filter k8s-*>\n      @type record_transformer\n      <record>\n        nodename "#{ENV[\'K8S_NODE_NAME\']}"                     # 为每条记录附加节点字段\n        dc "#{ENV[\'CLUSTER_NAME\']}"                            # 为每条记录附加集群名\n      </record>\n    </filter>\n\n    <match k8s-*>                                             # 存储到es地址\n    @type forward\n    <server>\n        host "#{ENV[\'FLUENT_ELASTICSEARCH_HOST\']}"     \n        port "#{ENV[\'FLUENT_ELASTICSEARCH_PORT\']}"\n    </server>\n    <buffer tag,time>\n        @type file\n        path /var/log/td-agent/buffer/docker-k8s\n        timekey 3600\n        timekey_wait 0s\n        timekey_use_utc false\n        flush_mode interval\n        flush_interval 10s\n        chunk_limit_size 20M\n    </buffer>\n    </match>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n',normalizedContent:'# 采集k8s容器标准输出日志\n\n <source>\n      @type tail\n      path /var/log/containers/kube-*.log,/var/log/containers/myapp-*.log  # 逗号分隔\n      exclude_path ["/var/log/containers/kubectl-*.log"]    # 排除的日志\n      pos_file /var/log/pos/containers.log.pos              # 保存已读日志文件的位置\n      tag raw.*\n      read_from_head true\n      <parse>\n        @type multi_format\n        # 匹配docker容器日志格式json\n        <pattern>\n          format json\n          time_key time\n          time_format %y-%m-%dt%h:%m:%s.%nz\n        </pattern>\n        #这部分用来正则匹配cri容器日志格式text\n        <pattern>\n          format /^(?<time>.+) (?<stream>stdout|stderr) [^ ]* (?<log>.*)$/\n          time_format %y-%m-%dt%h:%m:%s.%n%:z\n        </pattern>\n      </parse>\n    </source>\n\n\n    <filter raw.**>\n        @type kubernetes_metadata\n        @id kubernetes_metadata_container_out\n        skip_container_metadata true\n        skip_master_url true\n        cache_size 3000\n        cache_ttl 1800   \n    </filter>\n\n    <match raw.**>\n      @type record_modifier\n      @id label.container.out\n      tag k8s-containers-${record.dig("k8s_container_name")}\n      # tag ${record.dig(\'log-collect\') ? k8s-containers-${record.dig("k8s_container_name")} : \'dropped.raw\'}\n      <record>\n        k8s_container_id ${record.dig("docker", "container_id")}\n        k8s_cloud_cluster "#{env[\'cloud_cluster\'] || \'default\'}"\n        k8s_node ${record.dig(\'kubernetes\', \'host\')}\n        k8s_container_name ${record.dig(\'kubernetes\', \'container_name\')}\n        k8s_pod_name ${record.dig(\'kubernetes\', \'pod_name\')}\n        k8s_namespace_name ${record.dig(\'kubernetes\', \'namespace_name\')}\n        # log-collect ${record.dig("kubernetes", "labels", "log-collect") or false}\n        formated_time "${time.at(time).to_datetime.iso8601(9)}"\n        fluentd_worker "#{worker_id}"\n      </record>\n      remove_keys docker,kubernetes                            # 删除原生metadata字段\n    </match>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n\n\n\n# 本地日志文件-主机审计日志\n\n    <source>\n        @type tail\n        read_from_head false\n        path /var/log/operation/*.log                       # 宿主机操作日志\n        follow_inodes true                                  # 如果没有这个参数，文件轮转会导致日志重复\n        path_key file_name                                  # 指定事件中path的key名称\n        pos_file /var/log/pos/operation.log.pos             # 保存已读日志文件的位置\n        tag host-operation\n        limit_recently_modified 7d                          # 只监控指定修改时间范围内的文件\n        multiline_flush_interval 1s                         # 多行处理模式下的缓存输出间隔\n        <parse>\n          @type json\n          time_key time                                     # 从事件的什么字段中获取时间，如果该字段不存在，则取当前时间\n          time_type string                                  # 可选值:float:unix时间.纳秒、unixtime: unix时间(秒)、string:根据后面几个参数决定具体格式\n          time_format %y-%m-%d %h:%m:%s                     # 时间格式\n          timezone +08:00\n        </parse>\n    </source>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n\n\n\n# journal日志\n\n    <source>                  \n      @type systemd\n      path /run/log/journal\n      matches [{ "_systemd_unit": ["kubelet.service", "etcd.service"] }]      # 指定journald日志,屏蔽此行则采集所有journal日志\n      <storage>\n        @type local\n        persistent true\n        path /var/log/pos/journal.pos\n      </storage>\n      read_from_head true\n      tag journald\n    </source>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 输出\n\n    # <match dropped.**>\n    #   @type null                                             # 需要忽略的日志\n    # </match>\n    <filter k8s-*>\n      @type record_transformer\n      <record>\n        nodename "#{env[\'k8s_node_name\']}"                     # 为每条记录附加节点字段\n        dc "#{env[\'cluster_name\']}"                            # 为每条记录附加集群名\n      </record>\n    </filter>\n\n    <match k8s-*>                                             # 存储到es地址\n    @type forward\n    <server>\n        host "#{env[\'fluent_elasticsearch_host\']}"     \n        port "#{env[\'fluent_elasticsearch_port\']}"\n    </server>\n    <buffer tag,time>\n        @type file\n        path /var/log/td-agent/buffer/docker-k8s\n        timekey 3600\n        timekey_wait 0s\n        timekey_use_utc false\n        flush_mode interval\n        flush_interval 10s\n        chunk_limit_size 20m\n    </buffer>\n    </match>\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n',charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"腾讯gpu-manager",frontmatter:{title:"腾讯gpu-manager",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/tencnt-cpu-manager/",categories:["技术杂谈","kubernetes"],tags:["gpu"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"腾讯gpu-manager"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/03.%E8%85%BE%E8%AE%AFgpu-manager.html"},{property:"og:type",content:"article"},{property:"og:title",content:"腾讯gpu-manager"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/03.%E8%85%BE%E8%AE%AFgpu-manager.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:"gpu"},{itemprop:"name",content:"腾讯gpu-manager"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/03.%E8%85%BE%E8%AE%AFgpu-manager.html",relativePath:"01.技术杂谈/03.kubernetes/306.GPU/03.腾讯gpu-manager.md",key:"v-572ce303",path:"/pages/tencnt-cpu-manager/",headers:[{level:2,title:"关于叫法",slug:"关于叫法",normalizedTitle:"关于叫法",charIndex:2},{level:2,title:"基本原理",slug:"基本原理",normalizedTitle:"基本原理",charIndex:44},{level:2,title:"缺陷",slug:"缺陷",normalizedTitle:"缺陷",charIndex:417},{level:2,title:"优点",slug:"优点",normalizedTitle:"优点",charIndex:495},{level:2,title:"参数",slug:"参数",normalizedTitle:"参数",charIndex:563},{level:2,title:"部署",slug:"部署",normalizedTitle:"部署",charIndex:841},{level:2,title:"验证",slug:"验证",normalizedTitle:"验证",charIndex:1243},{level:3,title:"问题： Unable to set Type=notify in systemd service file(TODO) ; Function Not Found  (TODO);",slug:"问题-unable-to-set-type-notify-in-systemd-service-file-todo-function-not-found-todo",normalizedTitle:"问题： unable to set type=notify in systemd service file(todo) ; function not found  (todo);",charIndex:null}],headersStr:"关于叫法 基本原理 缺陷 优点 参数 部署 验证 问题： Unable to set Type=notify in systemd service file(TODO) ; Function Not Found  (TODO);",content:'# 关于叫法\n\ngpu-manager？？ vCUDA？？ GaiaGPU？？\n\n\n# 基本原理\n\nvCUDA通过劫持CUDA的显存申请和释放请求，为每个容器管理它的显存使用量，进而实现了显存隔离。唯一需要注意的是申请context并不通过malloc函数，因此无法知道进程在context使用了多少显存。因此vcuda每次都去向GPU查询当前的显存使用量。在算力隔离方面，使用者可以指定容器的GPU利用率。vCUDA将会监控利用率，并在超出限制利用率时做一些处理。此处可以支持硬隔离和软隔离。两者的不同点是，如果有资源空闲，软隔离允许任务超过设置，而硬隔离不允许。\n\n由于使用的是监控调节的方案，因此无法在短时间内限制算力，只能保证长时间的效率公平。所以不适合推理等任务时间极短的场景。\n\n显存隔离是属于硬隔离，容器实际使用量不能超出限制值；算力隔离属于软隔离，其实际使用量会在限制值上下波动，但是平均值基本满足限制条件。\n\n\n# 缺陷\n\n不适合推理等任务时间极短的场景 由于该方案是依赖cuda库函数，对少部分cuda版本支持不足\n\n似乎不怎么维护了，issue较多没什么回应\n\n\n# 优点\n\n不需要修改默认runc运行时 同时支持碎片和整卡调度，提高GPU资源利用率 支持同一张卡上容器间GPU和显存的使用隔离\n\n\n# 参数\n\n * tencent.com/vcuda-core 和tencent.com/vcuda-memory 是新增的针对单卡共享的一个资源标记，core对应的是使用率，单张卡有100个core，memory是显存，每个单位是256MB的显存。\n * 如果申请的资源为50%利用率，7680MB显存。tencent.com/vcuda-core 填写50，tencent.com/vcuda-memory 填写成30。\n * 当然我们也同样支持原来的独占卡的方式，只需要在core的地方填写100的整数倍，memory值填写大于0的任意值即可。\n\n\n# 部署\n\nkubectl label node master01 nvidia-device-enable=enable\n\nkubectl apply -f gpu-manager-svc.yaml gpu-manager.yaml\n\n# kubectl describe node master01 | grep tencent\n  tencent.com/vcuda-core:    100\n  tencent.com/vcuda-memory:  32\n  tencent.com/vcuda-core:    100\n  tencent.com/vcuda-memory:  32\n  tencent.com/vcuda-core    0            0\n  tencent.com/vcuda-memory  0            0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 验证\n\napiVersion: v1\nkind: Pod\nmetadata:\n  name: test-gpu\n  annotations:\n    tencent.com/vcuda-core-limit: "50"\nspec:\n  restartPolicy: OnFailure\n  containers:\n    - name: cuda\n      image: nvidia/cuda:10.0-base\n      imagePullPolicy: IfNotPresent\n      tty: true\n      resources:\n        requests:\n          tencent.com/vcuda-core: 30\n          tencent.com/vcuda-memory: 10\n        limits:\n          tencent.com/vcuda-core: 30\n          tencent.com/vcuda-memory: 10\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# 问题： Unable to set Type=notify in systemd service file(TODO) ; Function Not Found (TODO);\n\nrebuild ldcache\n65\nlaunch gpu manager\n66\nE0729 10:17:58.085641   14167 server.go:131] Unable to set Type=notify in systemd service file?\n67\nE0729 10:17:59.109882   14167 tree.go:333] No topology level found at 0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nhttps://github.com/tkestack/gpu-manager/issues/7\n\nroot@test-gpu:/# nvidia-smi \nFri Jul 29 04:40:47 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 515.57       Driver Version: 515.57       CUDA Version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n|  0%   38C    P8    13W / 200W | Function Not Found   |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n怀疑跟cuda版本有关',normalizedContent:'# 关于叫法\n\ngpu-manager？？ vcuda？？ gaiagpu？？\n\n\n# 基本原理\n\nvcuda通过劫持cuda的显存申请和释放请求，为每个容器管理它的显存使用量，进而实现了显存隔离。唯一需要注意的是申请context并不通过malloc函数，因此无法知道进程在context使用了多少显存。因此vcuda每次都去向gpu查询当前的显存使用量。在算力隔离方面，使用者可以指定容器的gpu利用率。vcuda将会监控利用率，并在超出限制利用率时做一些处理。此处可以支持硬隔离和软隔离。两者的不同点是，如果有资源空闲，软隔离允许任务超过设置，而硬隔离不允许。\n\n由于使用的是监控调节的方案，因此无法在短时间内限制算力，只能保证长时间的效率公平。所以不适合推理等任务时间极短的场景。\n\n显存隔离是属于硬隔离，容器实际使用量不能超出限制值；算力隔离属于软隔离，其实际使用量会在限制值上下波动，但是平均值基本满足限制条件。\n\n\n# 缺陷\n\n不适合推理等任务时间极短的场景 由于该方案是依赖cuda库函数，对少部分cuda版本支持不足\n\n似乎不怎么维护了，issue较多没什么回应\n\n\n# 优点\n\n不需要修改默认runc运行时 同时支持碎片和整卡调度，提高gpu资源利用率 支持同一张卡上容器间gpu和显存的使用隔离\n\n\n# 参数\n\n * tencent.com/vcuda-core 和tencent.com/vcuda-memory 是新增的针对单卡共享的一个资源标记，core对应的是使用率，单张卡有100个core，memory是显存，每个单位是256mb的显存。\n * 如果申请的资源为50%利用率，7680mb显存。tencent.com/vcuda-core 填写50，tencent.com/vcuda-memory 填写成30。\n * 当然我们也同样支持原来的独占卡的方式，只需要在core的地方填写100的整数倍，memory值填写大于0的任意值即可。\n\n\n# 部署\n\nkubectl label node master01 nvidia-device-enable=enable\n\nkubectl apply -f gpu-manager-svc.yaml gpu-manager.yaml\n\n# kubectl describe node master01 | grep tencent\n  tencent.com/vcuda-core:    100\n  tencent.com/vcuda-memory:  32\n  tencent.com/vcuda-core:    100\n  tencent.com/vcuda-memory:  32\n  tencent.com/vcuda-core    0            0\n  tencent.com/vcuda-memory  0            0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 验证\n\napiversion: v1\nkind: pod\nmetadata:\n  name: test-gpu\n  annotations:\n    tencent.com/vcuda-core-limit: "50"\nspec:\n  restartpolicy: onfailure\n  containers:\n    - name: cuda\n      image: nvidia/cuda:10.0-base\n      imagepullpolicy: ifnotpresent\n      tty: true\n      resources:\n        requests:\n          tencent.com/vcuda-core: 30\n          tencent.com/vcuda-memory: 10\n        limits:\n          tencent.com/vcuda-core: 30\n          tencent.com/vcuda-memory: 10\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n\n\n# 问题： unable to set type=notify in systemd service file(todo) ; function not found (todo);\n\nrebuild ldcache\n65\nlaunch gpu manager\n66\ne0729 10:17:58.085641   14167 server.go:131] unable to set type=notify in systemd service file?\n67\ne0729 10:17:59.109882   14167 tree.go:333] no topology level found at 0\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\nhttps://github.com/tkestack/gpu-manager/issues/7\n\nroot@test-gpu:/# nvidia-smi \nfri jul 29 04:40:47 2022       \n+-----------------------------------------------------------------------------+\n| nvidia-smi 515.57       driver version: 515.57       cuda version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| gpu  name        persistence-m| bus-id        disp.a | volatile uncorr. ecc |\n| fan  temp  perf  pwr:usage/cap|         memory-usage | gpu-util  compute m. |\n|                               |                      |               mig m. |\n|===============================+======================+======================|\n|   0  nvidia geforce ...  off  | 00000000:01:00.0 off |                  n/a |\n|  0%   38c    p8    13w / 200w | function not found   |      0%      default |\n|                               |                      |                  n/a |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| processes:                                                                  |\n|  gpu   gi   ci        pid   type   process name                  gpu memory |\n|        id   id                                                   usage      |\n|=============================================================================|\n|  no running processes found                                                 |\n+-----------------------------------------------------------------------------+\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n\n\n怀疑跟cuda版本有关',charsets:{cjk:!0}},{title:"阿里gpu-share",frontmatter:{title:"阿里gpu-share",date:"2022-07-27T14:56:55.000Z",permalink:"/pages/ali-gpushare/",categories:["技术杂谈","kubernetes"],tags:["gpu"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"阿里gpu-share"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/04.%E9%98%BF%E9%87%8Cgpu-share.html"},{property:"og:type",content:"article"},{property:"og:title",content:"阿里gpu-share"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/04.%E9%98%BF%E9%87%8Cgpu-share.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:55.000Z"},{property:"article:tag",content:"gpu"},{itemprop:"name",content:"阿里gpu-share"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/04.%E9%98%BF%E9%87%8Cgpu-share.html",relativePath:"01.技术杂谈/03.kubernetes/306.GPU/04.阿里gpu-share.md",key:"v-131bc9a5",path:"/pages/ali-gpushare/",headersStr:null,content:"gitHub地址：https://github.com/AliyunContainerService/gpushare-device-plugin\n\n\n# 缺陷：\n\n * 没有暴露每个容器GPU资源利用率的指标；\n * 只是在调度上实现了GPU显存粒度的虚拟化，没有实现资源隔离。\n * 按显存(GPU Memory)和按卡(GPU count)调度的方式可以在集群内并存，但是同一个节点内是互斥的。\n * 不支持共享GPU显存资源的隔离，需要应用在代码中配置该任务可使用的GPU显存大小。",normalizedContent:"github地址：https://github.com/aliyuncontainerservice/gpushare-device-plugin\n\n\n# 缺陷：\n\n * 没有暴露每个容器gpu资源利用率的指标；\n * 只是在调度上实现了gpu显存粒度的虚拟化，没有实现资源隔离。\n * 按显存(gpu memory)和按卡(gpu count)调度的方式可以在集群内并存，但是同一个节点内是互斥的。\n * 不支持共享gpu显存资源的隔离，需要应用在代码中配置该任务可使用的gpu显存大小。",charsets:{cjk:!0}},{title:"events持久化",frontmatter:{title:"events持久化",date:"2022-10-09T18:31:35.000Z",permalink:"/pages/fadb16/",categories:["技术杂谈","kubernetes","日志采集"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"events持久化"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/03.events%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"events持久化"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/03.events%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T18:31:35.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"events持久化"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/03.events%E6%8C%81%E4%B9%85%E5%8C%96.html",relativePath:"01.技术杂谈/03.kubernetes/305.日志采集/03.events持久化.md",key:"v-582a5ac3",path:"/pages/fadb16/",headers:[{level:2,title:"titleTag: 原创",slug:"titletag-原创",normalizedTitle:"titletag: 原创",charIndex:171},{level:2,title:"开源方案",slug:"开源方案",normalizedTitle:"开源方案",charIndex:700},{level:3,title:"kubernetes-event-exporter",slug:"kubernetes-event-exporter",normalizedTitle:"kubernetes-event-exporter",charIndex:781},{level:4,title:"kubernetes-event-exporter + Loki",slug:"kubernetes-event-exporter-loki",normalizedTitle:"kubernetes-event-exporter + loki",charIndex:1241},{level:4,title:"kubernetes-event-exporter + fluentd:",slug:"kubernetes-event-exporter-fluentd",normalizedTitle:"kubernetes-event-exporter + fluentd:",charIndex:1609}],headersStr:"titleTag: 原创 开源方案 kubernetes-event-exporter kubernetes-event-exporter + Loki kubernetes-event-exporter + fluentd:",content:'----------------------------------------\n\ntitle: events持久化 date: 2022-10-9 17:56:54 permalink: /pages/events-log/ categories:\n\n * 技术杂谈\n * kubernetes\n * 日志采集 tags:\n * \n\n\n# titleTag: 原创\n\nKubernetes的事件（Event）是一种资源对象（Resource Object），用于展示集群内发生的情况，Kubernetes系统中的各个组件会将运行时发生的各种事件上报给Kubernetes API Server。例如，调度器做了什么决定，某些Pod为什么被从节点中驱逐。可以通过kubectl get event或kubectl describe pod 命令显示事件，查看Kubernetes集群中发生了哪些事件。\n\n执行这些命令后，默认情况下只会显示最近（1小时内）发生的事件。\n\n由于Kubernetes的事件是一种资源对象，因此它们存储在Kubernetes API Server的Etcd集群中。为避免磁盘空间被填满，故强制执行保留策略：在最后一次的事件发生后，删除1小时之前发生的事件。\n\n默认情况下 kubectl get events 并没有按照 events 发生的顺序进行排列，所以我们往往需要为其增加 --sort-by=\'{.metadata.creationTimestamp}\' 参数来让其输出可以按时间进行排列。\n\nKubernetes 会自动将重复的 events 进行合并\n\n\n# 开源方案\n\n * eventrouter https://github.com/heptiolabs/eventrouter\n\n * KubeWatch\n\n * kubernetes-event-exporter（推荐） https://github.com/opsgenie/kubernetes-event-exporter https://qiankunli.github.io/2020/04/27/kubernetes_event.html\n\n\n# kubernetes-event-exporter\n\n使用kubernetes-event-exporter将k8s的事件导出到elasticsearch日志系统中\n\n00-roles.yaml 01-config.yaml配置接收者，默认是输出到本地路径 02-deployment.yaml\n\nkubectl apply -f 00-roles.yaml\nkubectl apply -f 01-config.yaml\nkubectl apply -f 02-deployment.yaml\n\n\n1\n2\n3\n\n\n问题：\n\n * 1.0版本前会出现超时问题\n\n * 采集到ES配置未验证通过，目前通过标准输出采集\n\n# kubernetes-event-exporter + Loki\n\nPromtail 配置：\n\nscrapeConfigs:\n- job_name: kubernetes-events\n  pipeline_stages:\n    - cri: {}\n    - match:\n        selector: \'{app="event-exporter"}\'\n        stages:\n        - json:\n            expressions:\n              namespace: involvedObject.namespace\n        - labels:\n            namespace: ""  \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n# kubernetes-event-exporter + fluentd:\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: event-exporter-cfg\n  namespace: monitoring\ndata:\n  config.yaml: |\n    logLevel: error\n    logFormat: json\n    route:\n      routes:\n        - match:\n            - receiver: "dump"\t\t# 与下面的name对应\n    receivers:\n      - name: "dump"\n        # stdout: {}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',normalizedContent:'----------------------------------------\n\ntitle: events持久化 date: 2022-10-9 17:56:54 permalink: /pages/events-log/ categories:\n\n * 技术杂谈\n * kubernetes\n * 日志采集 tags:\n * \n\n\n# titletag: 原创\n\nkubernetes的事件（event）是一种资源对象（resource object），用于展示集群内发生的情况，kubernetes系统中的各个组件会将运行时发生的各种事件上报给kubernetes api server。例如，调度器做了什么决定，某些pod为什么被从节点中驱逐。可以通过kubectl get event或kubectl describe pod 命令显示事件，查看kubernetes集群中发生了哪些事件。\n\n执行这些命令后，默认情况下只会显示最近（1小时内）发生的事件。\n\n由于kubernetes的事件是一种资源对象，因此它们存储在kubernetes api server的etcd集群中。为避免磁盘空间被填满，故强制执行保留策略：在最后一次的事件发生后，删除1小时之前发生的事件。\n\n默认情况下 kubectl get events 并没有按照 events 发生的顺序进行排列，所以我们往往需要为其增加 --sort-by=\'{.metadata.creationtimestamp}\' 参数来让其输出可以按时间进行排列。\n\nkubernetes 会自动将重复的 events 进行合并\n\n\n# 开源方案\n\n * eventrouter https://github.com/heptiolabs/eventrouter\n\n * kubewatch\n\n * kubernetes-event-exporter（推荐） https://github.com/opsgenie/kubernetes-event-exporter https://qiankunli.github.io/2020/04/27/kubernetes_event.html\n\n\n# kubernetes-event-exporter\n\n使用kubernetes-event-exporter将k8s的事件导出到elasticsearch日志系统中\n\n00-roles.yaml 01-config.yaml配置接收者，默认是输出到本地路径 02-deployment.yaml\n\nkubectl apply -f 00-roles.yaml\nkubectl apply -f 01-config.yaml\nkubectl apply -f 02-deployment.yaml\n\n\n1\n2\n3\n\n\n问题：\n\n * 1.0版本前会出现超时问题\n\n * 采集到es配置未验证通过，目前通过标准输出采集\n\n# kubernetes-event-exporter + loki\n\npromtail 配置：\n\nscrapeconfigs:\n- job_name: kubernetes-events\n  pipeline_stages:\n    - cri: {}\n    - match:\n        selector: \'{app="event-exporter"}\'\n        stages:\n        - json:\n            expressions:\n              namespace: involvedobject.namespace\n        - labels:\n            namespace: ""  \n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n# kubernetes-event-exporter + fluentd:\n\napiversion: v1\nkind: configmap\nmetadata:\n  name: event-exporter-cfg\n  namespace: monitoring\ndata:\n  config.yaml: |\n    loglevel: error\n    logformat: json\n    route:\n      routes:\n        - match:\n            - receiver: "dump"\t\t# 与下面的name对应\n    receivers:\n      - name: "dump"\n        # stdout: {}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n',charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"英伟达驱动安装",frontmatter:{title:"英伟达驱动安装",date:"2022-08-24T18:56:55.000Z",permalink:"/pages/nvidiadevice/",categories:["技术杂谈","kubernetes"],tags:["gpu"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"英伟达驱动安装"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/05.%E8%8B%B1%E4%BC%9F%E8%BE%BE%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85.html"},{property:"og:type",content:"article"},{property:"og:title",content:"英伟达驱动安装"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/05.%E8%8B%B1%E4%BC%9F%E8%BE%BE%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-24T18:56:55.000Z"},{property:"article:tag",content:"gpu"},{itemprop:"name",content:"英伟达驱动安装"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/05.%E8%8B%B1%E4%BC%9F%E8%BE%BE%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85.html",relativePath:"01.技术杂谈/03.kubernetes/306.GPU/05.英伟达驱动安装.md",key:"v-6a155cef",path:"/pages/nvidiadevice/",headers:[{level:2,title:"centos安装nvidia GPU驱动",slug:"centos安装nvidia-gpu驱动",normalizedTitle:"centos安装nvidia gpu驱动",charIndex:2}],headersStr:"centos安装nvidia GPU驱动",content:"# centos安装nvidia GPU驱动\n\n下载好显卡驱动包：在官网上http://www.geforce.cn/drivers搜索到对应型号的显卡驱动并下载，下载到的驱动文件是一个后缀名为.run的文件\n链接：https://www.nvidia.cn/Download/index.aspx?lang=cn\n\n1、执行以下4个命令操作安装环境工具包\nyum install kernel.x86* -y yum install kernel-devel-* -y yum install kernel-headers* -y yum install kernel-tools-libs* -y yum install kernel-tools-3* -y\n\n2、执行命令 yum list | grep kernel //查看4个环境工具包版本要一致（如：3.10.0-1062.1.1.el7）\n\n3、执行命令 yum install -y gcc* glibc* glibc-* / /最后再安装编译环境\n\n4、禁用系统默认安装的 nouveau 驱动：\n\nlsmod | grep nouveau      //# 查看nouveau是否启动，如果结果为空即为禁用成功\n\n\n1\n\n\n注意： 禁用后需要重启才能生效，如果已经禁用，则不需要重启\n\n5、 使用WinSCP工具或者其他工具将显卡驱动包上传至本地服务器（如上传至/11目录）\n\n6、执行命令cd /11/切换到显卡驱动包路径\n\n7、执行命令 chmod u+x NVIDIA-Linux-x86_64-415.13.run // 修改.run文件有可执行权限：\n\n8、执行命令 sh NVIDIA-Linux-x86_64-390.116-201902.run //安装显卡驱动包，然后根据提示默认安装即可\n\n9、执行命令 nvidia-smi 查看安装成功与否，至此完成安装。",normalizedContent:"# centos安装nvidia gpu驱动\n\n下载好显卡驱动包：在官网上http://www.geforce.cn/drivers搜索到对应型号的显卡驱动并下载，下载到的驱动文件是一个后缀名为.run的文件\n链接：https://www.nvidia.cn/download/index.aspx?lang=cn\n\n1、执行以下4个命令操作安装环境工具包\nyum install kernel.x86* -y yum install kernel-devel-* -y yum install kernel-headers* -y yum install kernel-tools-libs* -y yum install kernel-tools-3* -y\n\n2、执行命令 yum list | grep kernel //查看4个环境工具包版本要一致（如：3.10.0-1062.1.1.el7）\n\n3、执行命令 yum install -y gcc* glibc* glibc-* / /最后再安装编译环境\n\n4、禁用系统默认安装的 nouveau 驱动：\n\nlsmod | grep nouveau      //# 查看nouveau是否启动，如果结果为空即为禁用成功\n\n\n1\n\n\n注意： 禁用后需要重启才能生效，如果已经禁用，则不需要重启\n\n5、 使用winscp工具或者其他工具将显卡驱动包上传至本地服务器（如上传至/11目录）\n\n6、执行命令cd /11/切换到显卡驱动包路径\n\n7、执行命令 chmod u+x nvidia-linux-x86_64-415.13.run // 修改.run文件有可执行权限：\n\n8、执行命令 sh nvidia-linux-x86_64-390.116-201902.run //安装显卡驱动包，然后根据提示默认安装即可\n\n9、执行命令 nvidia-smi 查看安装成功与否，至此完成安装。",charsets:{cjk:!0}},{title:"常用计算",frontmatter:{title:"常用计算",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang01/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"常用计算"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/01.%E5%B8%B8%E7%94%A8%E8%AE%A1%E7%AE%97.html"},{property:"og:type",content:"article"},{property:"og:title",content:"常用计算"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/01.%E5%B8%B8%E7%94%A8%E8%AE%A1%E7%AE%97.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"常用计算"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/01.%E5%B8%B8%E7%94%A8%E8%AE%A1%E7%AE%97.html",relativePath:"01.技术杂谈/04.golang/01.常用计算.md",key:"v-fa04c054",path:"/pages/golang01/",headers:[{level:2,title:"数组去重",slug:"数组去重",normalizedTitle:"数组去重",charIndex:2}],headersStr:"数组去重",content:"# 数组去重\n\nfunc RemoveRepeatedElement(arr []string) (newArr []string) {\n\tnewArr = make([]string, 0)\n\tfor i := 0; i < len(arr); i++ {\n\t\trepeat := false\n\t\tfor j := i + 1; j < len(arr); j++ {\n\t\t\tif arr[i] == arr[j] {\n\t\t\t\trepeat = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !repeat {\n\t\t\tnewArr = append(newArr, arr[i])\n\t\t}\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",normalizedContent:"# 数组去重\n\nfunc removerepeatedelement(arr []string) (newarr []string) {\n\tnewarr = make([]string, 0)\n\tfor i := 0; i < len(arr); i++ {\n\t\trepeat := false\n\t\tfor j := i + 1; j < len(arr); j++ {\n\t\t\tif arr[i] == arr[j] {\n\t\t\t\trepeat = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !repeat {\n\t\t\tnewarr = append(newarr, arr[i])\n\t\t}\n\t}\n\treturn\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"腾讯云qGPU",frontmatter:{title:"腾讯云qGPU",date:"2022-08-24T18:56:55.000Z",permalink:"/pages/qgpu/",categories:["技术杂谈","kubernetes"],tags:["gpu"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"腾讯云qGPU"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/06.%E8%85%BE%E8%AE%AF%E4%BA%91qGPU.html"},{property:"og:type",content:"article"},{property:"og:title",content:"腾讯云qGPU"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/06.%E8%85%BE%E8%AE%AF%E4%BA%91qGPU.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-24T18:56:55.000Z"},{property:"article:tag",content:"gpu"},{itemprop:"name",content:"腾讯云qGPU"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/306.GPU/06.%E8%85%BE%E8%AE%AF%E4%BA%91qGPU.html",relativePath:"01.技术杂谈/03.kubernetes/306.GPU/06.腾讯云qGPU.md",key:"v-394a82c1",path:"/pages/qgpu/",headersStr:null,content:"https://mp.weixin.qq.com/s/W-Ntu2xdjypFgs5EPMVjkg",normalizedContent:"https://mp.weixin.qq.com/s/w-ntu2xdjypfgs5epmvjkg",charsets:{}},{title:"golang面试问题",frontmatter:{title:"golang面试问题",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang02/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"golang面试问题"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/02.golang%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98.html"},{property:"og:type",content:"article"},{property:"og:title",content:"golang面试问题"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/02.golang%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"golang面试问题"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/02.golang%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98.html",relativePath:"01.技术杂谈/04.golang/02.golang面试问题.md",key:"v-6c7b2800",path:"/pages/golang02/",headers:[{level:3,title:"Golang中有哪些方式安全读写共享变量？",slug:"golang中有哪些方式安全读写共享变量",normalizedTitle:"golang中有哪些方式安全读写共享变量？",charIndex:2},{level:3,title:"Golang 中的并发模型",slug:"golang-中的并发模型",normalizedTitle:"golang 中的并发模型",charIndex:103},{level:3,title:"Go线程实现模型MPG",slug:"go线程实现模型mpg",normalizedTitle:"go线程实现模型mpg",charIndex:623},{level:3,title:"什么是channel，它是线程安全的吗？",slug:"什么是channel-它是线程安全的吗",normalizedTitle:"什么是channel，它是线程安全的吗？",charIndex:927},{level:3,title:"goroutine中的调度原理",slug:"goroutine中的调度原理",normalizedTitle:"goroutine中的调度原理",charIndex:952},{level:3,title:"线程/协程/进程的区别",slug:"线程-协程-进程的区别",normalizedTitle:"线程/协程/进程的区别",charIndex:972},{level:3,title:"golang双链表的实现，怎么定义，初始化，添加，删除节点",slug:"golang双链表的实现-怎么定义-初始化-添加-删除节点",normalizedTitle:"golang双链表的实现，怎么定义，初始化，添加，删除节点",charIndex:1275},{level:3,title:"make和new差别",slug:"make和new差别",normalizedTitle:"make和new差别",charIndex:1309},{level:3,title:"nil切片和空切片的区别",slug:"nil切片和空切片的区别",normalizedTitle:"nil切片和空切片的区别",charIndex:1769},{level:3,title:"对已经关闭的的 chan 进行读写，会怎么样？为什么？",slug:"对已经关闭的的-chan-进行读写-会怎么样-为什么",normalizedTitle:"对已经关闭的的 chan 进行读写，会怎么样？为什么？",charIndex:1873},{level:3,title:"用过 fallthrough 关键字吗？这个关键字的作用是什么？",slug:"用过-fallthrough-关键字吗-这个关键字的作用是什么",normalizedTitle:"用过 fallthrough 关键字吗？这个关键字的作用是什么？",charIndex:2141},{level:3,title:"restful熟悉吗？都有哪些请求方法，分别代表什么意思？",slug:"restful熟悉吗-都有哪些请求方法-分别代表什么意思",normalizedTitle:"restful熟悉吗？都有哪些请求方法，分别代表什么意思？",charIndex:2388},{level:3,title:"Golang导入包时，使用’_’/’.'导入有什么区别",slug:"golang导入包时-使用-导入有什么区别",normalizedTitle:"golang导入包时，使用’_’/’.'导入有什么区别",charIndex:2422},{level:3,title:"Go支持类型继承吗，Go 是面向对象的语言吗",slug:"go支持类型继承吗-go-是面向对象的语言吗",normalizedTitle:"go支持类型继承吗，go 是面向对象的语言吗",charIndex:2454},{level:3,title:"如何判断链表有环",slug:"如何判断链表有环",normalizedTitle:"如何判断链表有环",charIndex:2760}],headersStr:"Golang中有哪些方式安全读写共享变量？ Golang 中的并发模型 Go线程实现模型MPG 什么是channel，它是线程安全的吗？ goroutine中的调度原理 线程/协程/进程的区别 golang双链表的实现，怎么定义，初始化，添加，删除节点 make和new差别 nil切片和空切片的区别 对已经关闭的的 chan 进行读写，会怎么样？为什么？ 用过 fallthrough 关键字吗？这个关键字的作用是什么？ restful熟悉吗？都有哪些请求方法，分别代表什么意思？ Golang导入包时，使用’_’/’.'导入有什么区别 Go支持类型继承吗，Go 是面向对象的语言吗 如何判断链表有环",content:'# Golang中有哪些方式安全读写共享变量？\n\nmutex锁 Golang中Goroutine 可以通过 Channel 进行安全读写共享变量\n\n有缓冲channel和无缓充channel的区别\n\n\n# Golang 中的并发模型\n\n请谈一谈 go 语言的并发机制以及它所使用的CSP并发模型\n\nGo实现了两种并发形式。第一种是大家普遍认知的：多线程共享内存。其实就是Java或者C++等语言中的多线程开发。另外一种是Go语言特有的，也是Go语言推荐的：CSP（communicating sequential processes）并发模型。\n\n通过channel通知实现并发控制 通过sync包中的WaitGroup实现并发控制 当主 goroutine 运行到 <-ch 接受 channel 的值的时候，如果该 channel 中没有数据，就会一直阻塞等待，直到有值。这样就可以简单实现并发控制\n\n在Go 1.7 以后引进的强大的Context上下文，实现并发控制\n\nGo的CSP并发模型，是通过goroutine和channel来实现的。 goroutine 是Go语言中并发的执行单位。有点抽象，其实就是和传统概念上的”线程“类似，可以理解为”线程“。 channel是Go语言中各个并发结构体(goroutine)之前的通信机制。 通俗的讲，就是各个goroutine之间通信的”管道“，有点类似于Linux中的管道。\n\n\n# Go线程实现模型MPG\n\nM指的是Machine，一个M直接关联了一个内核线程。由操作系统管理。 P指的是”processor”，代表了M所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接M和G的调度上下文，将等待执行的G与M对接。 G指的是Goroutine，其实本质上也是一种轻量级的线程。包括了调用栈，重要的调度信息，例如channel等。 P的数量由环境变量中的GOMAXPROCS决定，通常来说它是和核心数对应，例如在4Core的服务器上回启动4个线程。G会有很多个，每个P会将Goroutine从一个就绪的队列中做Pop操作，为了减小锁的竞争，通常情况下每个P会负责一个队列。\n\n\n# 什么是channel，它是线程安全的吗？\n\n\n# goroutine中的调度原理\n\n\n# 线程/协程/进程的区别\n\n线程拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程的切换一般也由操作系统调度。 和线程类似，共享堆，不共享栈，协程的切换一般由程序员在代码中显式控制。它避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂。\n\nGoroutine和其他语言的协程（coroutine）在使用方式上类似，但从字面意义上来看不同（一个是Goroutine，一个是coroutine），再就是协程是一种协作任务控制机制，在最简单的意义上，协程不是并发的，而Goroutine支持并发的。因此Goroutine可以理解为一种Go语言的协程。同时它可以运行在一个或多个线程上。\n\n\n# golang双链表的实现，怎么定义，初始化，添加，删除节点\n\n\n# make和new差别\n\nnew ()是内建函数，函数原型为: func new(Type) *Type 1 make 也是内建函数，它的函数原型 比 new 多了一个（长度）参数，返回值也不同: //第一个参数是一个类型，第二个参数是长度 //返回值是一个指向该类型的一个引用 func make(Type, size IntegerType) Type make和new都是golang用来分配内存的內建函数，且在堆上分配内存，并为该变量执行了初始化操作make 用于为引用类型分配内存空间，其在分配内存的同时，也初始化了一些相关属性(这里初始化这些相关属性时不再是简单的用默认零值来初始化了！！！)。new只是分配默认零值内存并返回指向该零值内存的一个指针也就是执行了一个默认初始化，全部用默认零值来进行初始化）。 make返回的是一个引用类型；而new返回的是一个指向零值内存空间的指针。 make只能用来分配及初始化引用类型：slice，map，channel的数据； new可以分配任意类型的数据。\n\n\n# nil切片和空切片的区别\n\nnil切片和空切片指向的地址不一样。nil空切片引用数组指针地址为0（无指向任何实际地址） 空切片的引用数组指针地址是有的，且固定为一个值 能否通过for循环遍历删除元素\n\n\n# 对已经关闭的的 chan 进行读写，会怎么样？为什么？\n\n读已经关闭的 chan 能一直读到东西，但是读到的内容根据通道内关闭前是否有元素而不同。 如果 chan 关闭前，buffer 内有元素还未读 , 会正确读到 chan 内的值，且返回的第二个 bool 值（是否读成功）为 true。 如果 chan 关闭前，buffer 内有元素已经被读完，chan 内无值，接下来所有接收的值都会非阻塞直接成功，返回 channel 元素的零值，但是第二个 bool 值一直为 false。 写已经关闭的 chan 会 panic\n\n\n# 用过 fallthrough 关键字吗？这个关键字的作用是什么？\n\n其他语言中，switch-case 结构中一般都需要在每个 case 分支结束处显式的调用 break 语句以防止 前一个 case 分支被贯穿后调用下一个 case 分支的逻辑，go 编译器从语法层面上消除了这种重复的工作，让开发者更轻松；但有时候我们的场景就是需要贯穿多个 case，但是编译器默认是不贯穿的，这个时候 fallthrough 就起作用了，让某个 case 分支再次贯穿到下一个 case 分支。\n\n\n# restful熟悉吗？都有哪些请求方法，分别代表什么意思？\n\n\n# Golang导入包时，使用’_’/’.\'导入有什么区别\n\n\n# Go支持类型继承吗，Go 是面向对象的语言吗\n\n没有传统的类，也没有继承。\n\n取而代之的是结构和组合的方式\n\nGo 有类型和方法，并且允许面向对象的编程风格，但没有类型层次。\n\nGo 中的 "接口 "概念提供了一种不同的方法，我们认为这种方法易于使用，而且在某些方面更加通用。还有一些方法可以将类型嵌入到其他类型中，以提供类似的东西，但不等同于子类。\n\nGo 中的方法比 C++ 或 Java 中的方法更通用：它们可以为任何类型的数据定义，甚至是内置类型，如普通的、"未装箱的 "整数。它们并不局限于结构（类）。\n\nGo 由于缺乏类型层次，Go 中的 "对象 "比 C++ 或 Java 等语言更轻巧。\n\n\n# 如何判断链表有环\n\n不允许修改链表结构。 时间复杂度O(n)，空间复杂度O(1)。\n\nhttps://blog.csdn.net/u010983881/article/details/78896293 快慢指针，一个跳1，一个跳2\n\n方法一、穷举遍历 方法一：首先从头节点开始，依次遍历单链表的每一个节点。每遍历到一个新节点，就从头节点重新遍历新节点之前的所有节点，用新节点ID和此节点之前所有节点ID依次作比较。如果发现新节点之前的所有节点当中存在相同节点ID，则说明该节点被遍历过两次，链表有环；如果之前的所有节点当中不存在相同的节点，就继续遍历下一个新节点，继续重复刚才的操作。 算法的时间复杂度是0+1+2+3+…+(D+S-1) = (D+S-1)(D+S)/2 ， 可以简单地理解成 O(NN)。而此算法没有创建额外存储空间，空间复杂度可以简单地理解成为O(1) 方法二、哈希表缓存 首先创建一个以节点ID为键的HashSet集合，用来存储曾经遍历过的节点。然后同样是从头节点开始，依次遍历单链表的每一个节点。每遍历到一个新节点，就用新节点和HashSet集合当中存储的节点作比较，如果发现HashSet当中存在相同节点ID，则说明链表有环，如果HashSet当中不存在相同的节点ID，就把这个新节点ID存入HashSet，之后进入下一节点，继续重复刚才的操作。\n\n方法三、快慢指针 首先创建两个指针1和2（在java里就是两个对象引用），同时指向这个链表的头节点。然后开始一个大循环，在循环体中，让指针1每次向下移动一个节点，让指针2每次向下移动两个节点，然后比较两个指针指向的节点是否相同。如果相同，则判断出链表有环，如果不同，则继续下一次循环。 方法四、Set集合大小变化 把节点放入set里，每次访问下个节点时，如果set长度不变，则跳出，说明有环。否则set长度+1，继续遍历。 该方法时间复杂度是O（N），空间复杂度上因为需要额外等数量的存储空间，所以空间复杂度是O（n）。 如何判断两个单链表是否相交，以及相交点 方法一、直接法 直接判断第一个链表的每个结点是否在第二个链表中，时间复杂度为O(len1*len2)，耗时很大',normalizedContent:'# golang中有哪些方式安全读写共享变量？\n\nmutex锁 golang中goroutine 可以通过 channel 进行安全读写共享变量\n\n有缓冲channel和无缓充channel的区别\n\n\n# golang 中的并发模型\n\n请谈一谈 go 语言的并发机制以及它所使用的csp并发模型\n\ngo实现了两种并发形式。第一种是大家普遍认知的：多线程共享内存。其实就是java或者c++等语言中的多线程开发。另外一种是go语言特有的，也是go语言推荐的：csp（communicating sequential processes）并发模型。\n\n通过channel通知实现并发控制 通过sync包中的waitgroup实现并发控制 当主 goroutine 运行到 <-ch 接受 channel 的值的时候，如果该 channel 中没有数据，就会一直阻塞等待，直到有值。这样就可以简单实现并发控制\n\n在go 1.7 以后引进的强大的context上下文，实现并发控制\n\ngo的csp并发模型，是通过goroutine和channel来实现的。 goroutine 是go语言中并发的执行单位。有点抽象，其实就是和传统概念上的”线程“类似，可以理解为”线程“。 channel是go语言中各个并发结构体(goroutine)之前的通信机制。 通俗的讲，就是各个goroutine之间通信的”管道“，有点类似于linux中的管道。\n\n\n# go线程实现模型mpg\n\nm指的是machine，一个m直接关联了一个内核线程。由操作系统管理。 p指的是”processor”，代表了m所需的上下文环境，也是处理用户级代码逻辑的处理器。它负责衔接m和g的调度上下文，将等待执行的g与m对接。 g指的是goroutine，其实本质上也是一种轻量级的线程。包括了调用栈，重要的调度信息，例如channel等。 p的数量由环境变量中的gomaxprocs决定，通常来说它是和核心数对应，例如在4core的服务器上回启动4个线程。g会有很多个，每个p会将goroutine从一个就绪的队列中做pop操作，为了减小锁的竞争，通常情况下每个p会负责一个队列。\n\n\n# 什么是channel，它是线程安全的吗？\n\n\n# goroutine中的调度原理\n\n\n# 线程/协程/进程的区别\n\n线程拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程的切换一般也由操作系统调度。 和线程类似，共享堆，不共享栈，协程的切换一般由程序员在代码中显式控制。它避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂。\n\ngoroutine和其他语言的协程（coroutine）在使用方式上类似，但从字面意义上来看不同（一个是goroutine，一个是coroutine），再就是协程是一种协作任务控制机制，在最简单的意义上，协程不是并发的，而goroutine支持并发的。因此goroutine可以理解为一种go语言的协程。同时它可以运行在一个或多个线程上。\n\n\n# golang双链表的实现，怎么定义，初始化，添加，删除节点\n\n\n# make和new差别\n\nnew ()是内建函数，函数原型为: func new(type) *type 1 make 也是内建函数，它的函数原型 比 new 多了一个（长度）参数，返回值也不同: //第一个参数是一个类型，第二个参数是长度 //返回值是一个指向该类型的一个引用 func make(type, size integertype) type make和new都是golang用来分配内存的內建函数，且在堆上分配内存，并为该变量执行了初始化操作make 用于为引用类型分配内存空间，其在分配内存的同时，也初始化了一些相关属性(这里初始化这些相关属性时不再是简单的用默认零值来初始化了！！！)。new只是分配默认零值内存并返回指向该零值内存的一个指针也就是执行了一个默认初始化，全部用默认零值来进行初始化）。 make返回的是一个引用类型；而new返回的是一个指向零值内存空间的指针。 make只能用来分配及初始化引用类型：slice，map，channel的数据； new可以分配任意类型的数据。\n\n\n# nil切片和空切片的区别\n\nnil切片和空切片指向的地址不一样。nil空切片引用数组指针地址为0（无指向任何实际地址） 空切片的引用数组指针地址是有的，且固定为一个值 能否通过for循环遍历删除元素\n\n\n# 对已经关闭的的 chan 进行读写，会怎么样？为什么？\n\n读已经关闭的 chan 能一直读到东西，但是读到的内容根据通道内关闭前是否有元素而不同。 如果 chan 关闭前，buffer 内有元素还未读 , 会正确读到 chan 内的值，且返回的第二个 bool 值（是否读成功）为 true。 如果 chan 关闭前，buffer 内有元素已经被读完，chan 内无值，接下来所有接收的值都会非阻塞直接成功，返回 channel 元素的零值，但是第二个 bool 值一直为 false。 写已经关闭的 chan 会 panic\n\n\n# 用过 fallthrough 关键字吗？这个关键字的作用是什么？\n\n其他语言中，switch-case 结构中一般都需要在每个 case 分支结束处显式的调用 break 语句以防止 前一个 case 分支被贯穿后调用下一个 case 分支的逻辑，go 编译器从语法层面上消除了这种重复的工作，让开发者更轻松；但有时候我们的场景就是需要贯穿多个 case，但是编译器默认是不贯穿的，这个时候 fallthrough 就起作用了，让某个 case 分支再次贯穿到下一个 case 分支。\n\n\n# restful熟悉吗？都有哪些请求方法，分别代表什么意思？\n\n\n# golang导入包时，使用’_’/’.\'导入有什么区别\n\n\n# go支持类型继承吗，go 是面向对象的语言吗\n\n没有传统的类，也没有继承。\n\n取而代之的是结构和组合的方式\n\ngo 有类型和方法，并且允许面向对象的编程风格，但没有类型层次。\n\ngo 中的 "接口 "概念提供了一种不同的方法，我们认为这种方法易于使用，而且在某些方面更加通用。还有一些方法可以将类型嵌入到其他类型中，以提供类似的东西，但不等同于子类。\n\ngo 中的方法比 c++ 或 java 中的方法更通用：它们可以为任何类型的数据定义，甚至是内置类型，如普通的、"未装箱的 "整数。它们并不局限于结构（类）。\n\ngo 由于缺乏类型层次，go 中的 "对象 "比 c++ 或 java 等语言更轻巧。\n\n\n# 如何判断链表有环\n\n不允许修改链表结构。 时间复杂度o(n)，空间复杂度o(1)。\n\nhttps://blog.csdn.net/u010983881/article/details/78896293 快慢指针，一个跳1，一个跳2\n\n方法一、穷举遍历 方法一：首先从头节点开始，依次遍历单链表的每一个节点。每遍历到一个新节点，就从头节点重新遍历新节点之前的所有节点，用新节点id和此节点之前所有节点id依次作比较。如果发现新节点之前的所有节点当中存在相同节点id，则说明该节点被遍历过两次，链表有环；如果之前的所有节点当中不存在相同的节点，就继续遍历下一个新节点，继续重复刚才的操作。 算法的时间复杂度是0+1+2+3+…+(d+s-1) = (d+s-1)(d+s)/2 ， 可以简单地理解成 o(nn)。而此算法没有创建额外存储空间，空间复杂度可以简单地理解成为o(1) 方法二、哈希表缓存 首先创建一个以节点id为键的hashset集合，用来存储曾经遍历过的节点。然后同样是从头节点开始，依次遍历单链表的每一个节点。每遍历到一个新节点，就用新节点和hashset集合当中存储的节点作比较，如果发现hashset当中存在相同节点id，则说明链表有环，如果hashset当中不存在相同的节点id，就把这个新节点id存入hashset，之后进入下一节点，继续重复刚才的操作。\n\n方法三、快慢指针 首先创建两个指针1和2（在java里就是两个对象引用），同时指向这个链表的头节点。然后开始一个大循环，在循环体中，让指针1每次向下移动一个节点，让指针2每次向下移动两个节点，然后比较两个指针指向的节点是否相同。如果相同，则判断出链表有环，如果不同，则继续下一次循环。 方法四、set集合大小变化 把节点放入set里，每次访问下个节点时，如果set长度不变，则跳出，说明有环。否则set长度+1，继续遍历。 该方法时间复杂度是o（n），空间复杂度上因为需要额外等数量的存储空间，所以空间复杂度是o（n）。 如何判断两个单链表是否相交，以及相交点 方法一、直接法 直接判断第一个链表的每个结点是否在第二个链表中，时间复杂度为o(len1*len2)，耗时很大',charsets:{cjk:!0},lastUpdated:"2022/07/27, 18:59:09",lastUpdatedTimestamp:1658919549e3},{title:"alertmanager持久化",frontmatter:{title:"alertmanager持久化",date:"2022-10-09T17:56:54.000Z",permalink:"/pages/alert-log/",categories:["技术杂谈","kubernetes","日志采集"],tags:["alertmanager"],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"alertmanager持久化"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/04.alertmanager%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"alertmanager持久化"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/04.alertmanager%E6%8C%81%E4%B9%85%E5%8C%96.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T17:56:54.000Z"},{property:"article:tag",content:"alertmanager"},{itemprop:"name",content:"alertmanager持久化"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/03.kubernetes/305.%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86/04.alertmanager%E6%8C%81%E4%B9%85%E5%8C%96.html",relativePath:"01.技术杂谈/03.kubernetes/305.日志采集/04.alertmanager持久化.md",key:"v-306f5d23",path:"/pages/alert-log/",headers:[{level:2,title:"前言",slug:"前言",normalizedTitle:"前言",charIndex:2},{level:2,title:"alertsnitch + mysql + grafana",slug:"alertsnitch-mysql-grafana",normalizedTitle:"alertsnitch + mysql + grafana",charIndex:280},{level:3,title:"alertsnitch",slug:"alertsnitch",normalizedTitle:"alertsnitch",charIndex:280},{level:3,title:"grafana dashboard",slug:"grafana-dashboard",normalizedTitle:"grafana dashboard",charIndex:807},{level:2,title:"alertmanager2es + ES + kibana",slug:"alertmanager2es-es-kibana",normalizedTitle:"alertmanager2es + es + kibana",charIndex:911},{level:2,title:"alertmanager-webhook-logger",slug:"alertmanager-webhook-logger",normalizedTitle:"alertmanager-webhook-logger",charIndex:1136},{level:3,title:"部署",slug:"部署",normalizedTitle:"部署",charIndex:528},{level:3,title:"alertmanager配置",slug:"alertmanager配置",normalizedTitle:"alertmanager配置",charIndex:2301}],headersStr:"前言 alertsnitch + mysql + grafana alertsnitch grafana dashboard alertmanager2es + ES + kibana alertmanager-webhook-logger 部署 alertmanager配置",content:"# 前言\n\nprometheus通过抓取监控数据，将触发规则的告警，推送到Alertmanger，Alertmanger对告警进行分组、聚合等处理后，可以通过邮件、Slack、webhook等方式对用户进行发送告警信息。alertmanager告警的记录不支持持久化记录，发送的告警信息不会存储在数据库中，prometheus将所有数据存储为时间序列，却不会将alertmanager发送的告警信息做为一条记录存储下来。\n\n解决的思路就是通过webhook发送告警信息到指定服务，并将记录输出到stdout，再通过fluentd采集容器日志推送到ES\n\n\n# alertsnitch + mysql + grafana\n\nalertsnitch支持将alertmanager的告警数据写入mysql和pg， 并结合grafna面板，将数据进行展示。\n\n\n# alertsnitch\n\nhttps://gitlab.com/yakshaving.art/alertsnitch\n\n * 配置变量： 环境变量数据库配置格式ALERTSNITCH_DSN=\"${MYSQL_USER}😒{MYSQL_PASSWORD}@/${MYSQL_DATABASE}\" 部署完成后配置ingress，映射域名对外提供服务，过程略，配置域名后调用方式为： https://alertsnitch.test.com/webhook\n\n * 配置alertmanager：\n\n# 配置接收者\n- name: default\n  webhook_configs:\n  - send_resolved: true\n    http_config:\n      follow_redirects: true\n    url: https://alertsnitch.test.cn/webhook\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# grafana dashboard\n\nID: 15833 https://grafana.com/grafana/dashboards/15833-prometheus-alert-history/\n\n\n# alertmanager2es + ES + kibana\n\nhttps://github.com/cloudflare/alertmanager2es\n\nhttps://github.com/webdevops/alertmanager2es\n\ndocker pull webdevops/alertmanager2es:20.11.0\n\ndocker pull webdevops/alertmanager2es:development\n\n\n# alertmanager-webhook-logger\n\nhttps://github.com/tomtom-international/alertmanager-webhook-logger docker pull ghcr.io/tomtom-international/alertmanager-webhook-logger:1.0\n\nhttps://github.com/grafana/alertmanager-webhook-logger docker pull grafana/alertmanager-webhook-logger:0.3\n\n通events持久化，通过fluentd+容器标准输出采集到ES\n\n\n# 部署\n\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: alertmanager-webhook-logger\n  namespace: monitoring\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: alertmanager-webhook-logger\n    spec:\n      containers:\n        - name: alertmanager-webhook-logger\n          image: ghcr.io/tomtom-international/alertmanager-webhook-logger:1.0\n          imagePullPolicy: IfNotPresent\n\n  selector:\n    matchLabels:\n      app: alertmanager-webhook-logger\n---\nkind: Service\napiVersion: v1\nmetadata:\n  name: alertmanager-webhook-logger\n  namespace: monitoring\nspec:\n  ports:\n    - name: '6725'\n      protocol: TCP\n      port: 6725\n      targetPort: 6725\n  selector:\n    app: alertmanager-webhook-logger\n  type: ClusterIP\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n\n# alertmanager配置\n\nglobal:\n  route:\n    receiver: default-receiver\n\nreceivers:\n- name: default-receiver\n  webhook_configs: \n  - url: http://alertmanager-webhook-logger.monitoring:6725\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n",normalizedContent:"# 前言\n\nprometheus通过抓取监控数据，将触发规则的告警，推送到alertmanger，alertmanger对告警进行分组、聚合等处理后，可以通过邮件、slack、webhook等方式对用户进行发送告警信息。alertmanager告警的记录不支持持久化记录，发送的告警信息不会存储在数据库中，prometheus将所有数据存储为时间序列，却不会将alertmanager发送的告警信息做为一条记录存储下来。\n\n解决的思路就是通过webhook发送告警信息到指定服务，并将记录输出到stdout，再通过fluentd采集容器日志推送到es\n\n\n# alertsnitch + mysql + grafana\n\nalertsnitch支持将alertmanager的告警数据写入mysql和pg， 并结合grafna面板，将数据进行展示。\n\n\n# alertsnitch\n\nhttps://gitlab.com/yakshaving.art/alertsnitch\n\n * 配置变量： 环境变量数据库配置格式alertsnitch_dsn=\"${mysql_user}😒{mysql_password}@/${mysql_database}\" 部署完成后配置ingress，映射域名对外提供服务，过程略，配置域名后调用方式为： https://alertsnitch.test.com/webhook\n\n * 配置alertmanager：\n\n# 配置接收者\n- name: default\n  webhook_configs:\n  - send_resolved: true\n    http_config:\n      follow_redirects: true\n    url: https://alertsnitch.test.cn/webhook\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# grafana dashboard\n\nid: 15833 https://grafana.com/grafana/dashboards/15833-prometheus-alert-history/\n\n\n# alertmanager2es + es + kibana\n\nhttps://github.com/cloudflare/alertmanager2es\n\nhttps://github.com/webdevops/alertmanager2es\n\ndocker pull webdevops/alertmanager2es:20.11.0\n\ndocker pull webdevops/alertmanager2es:development\n\n\n# alertmanager-webhook-logger\n\nhttps://github.com/tomtom-international/alertmanager-webhook-logger docker pull ghcr.io/tomtom-international/alertmanager-webhook-logger:1.0\n\nhttps://github.com/grafana/alertmanager-webhook-logger docker pull grafana/alertmanager-webhook-logger:0.3\n\n通events持久化，通过fluentd+容器标准输出采集到es\n\n\n# 部署\n\n---\napiversion: apps/v1\nkind: deployment\nmetadata:\n  name: alertmanager-webhook-logger\n  namespace: monitoring\nspec:\n  replicas: 1\n  template:\n    metadata:\n      labels:\n        app: alertmanager-webhook-logger\n    spec:\n      containers:\n        - name: alertmanager-webhook-logger\n          image: ghcr.io/tomtom-international/alertmanager-webhook-logger:1.0\n          imagepullpolicy: ifnotpresent\n\n  selector:\n    matchlabels:\n      app: alertmanager-webhook-logger\n---\nkind: service\napiversion: v1\nmetadata:\n  name: alertmanager-webhook-logger\n  namespace: monitoring\nspec:\n  ports:\n    - name: '6725'\n      protocol: tcp\n      port: 6725\n      targetport: 6725\n  selector:\n    app: alertmanager-webhook-logger\n  type: clusterip\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n\n\n\n# alertmanager配置\n\nglobal:\n  route:\n    receiver: default-receiver\n\nreceivers:\n- name: default-receiver\n  webhook_configs: \n  - url: http://alertmanager-webhook-logger.monitoring:6725\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"go-封装继承和多态",frontmatter:{title:"go-封装继承和多态",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang05/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"go 中没有面向对象的说法，也没有对应的封装、继承和多态",meta:[{name:"twitter:title",content:"go-封装继承和多态"},{name:"twitter:description",content:"go 中没有面向对象的说法，也没有对应的封装、继承和多态"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/05.go-%E5%B0%81%E8%A3%85%E7%BB%A7%E6%89%BF%E5%92%8C%E5%A4%9A%E6%80%81.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go-封装继承和多态"},{property:"og:description",content:"go 中没有面向对象的说法，也没有对应的封装、继承和多态"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/05.go-%E5%B0%81%E8%A3%85%E7%BB%A7%E6%89%BF%E5%92%8C%E5%A4%9A%E6%80%81.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"go-封装继承和多态"},{itemprop:"description",content:"go 中没有面向对象的说法，也没有对应的封装、继承和多态"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/05.go-%E5%B0%81%E8%A3%85%E7%BB%A7%E6%89%BF%E5%92%8C%E5%A4%9A%E6%80%81.html",relativePath:"01.技术杂谈/04.golang/05.go-封装继承和多态.md",key:"v-0169ea0d",path:"/pages/golang05/",headers:[{level:2,title:"继承",slug:"继承",normalizedTitle:"继承",charIndex:23},{level:2,title:"封装",slug:"封装",normalizedTitle:"封装",charIndex:20},{level:2,title:"多态",slug:"多态",normalizedTitle:"多态",charIndex:26}],headersStr:"继承 封装 多态",content:"go 中没有面向对象的说法，也没有对应的封装、继承和多态\n\n封装，通过结构体中的匿名字段来实现 继承可以使用接口和嵌套结构体 go 中，尽管没有多态，但是能实现多态相同的用法\n\n\n# 继承\n\ntype BaseNum struct {\n     num1 int\n     num2 int\n} // BaseNum 即为父类型名称\n\ntype Add struct {\n    BaseNum\n} //加法子类, 定义加法子类的主要目的, 是为了定义对应子类的方法\n\ntype Sub struct {\n    BaseNum\n} //减法子类\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n//Add 和Sub 就是BaseNum的子类\n\n\n# 封装\n\nfunc (a *Add)Opt()(value int) {\n    return a.num1 + a.num2\n}//加法的方法实现\n\nfunc (s *Sub)Opt()(value int) {\n    return s.num1 + s.num2\n}//减法的方法实现\ntype Opter interface { //接口定义\n    Opt()int      //封装, 归纳子类方法, 注意此处需要加上返回值, 不然没有办法输出返回值(因为方法中使用了返回值)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 多态\n\nfunc MultiState(o *Opter)(value int) { //多态定义, 可以简单理解为以接口作为形参的函数, 方便学习\n    value = o.Opt()\n    return\n}\n\n// 继承\ndata:= BaseNum{2,3}\nvar a Add = Add{data}\nvar b Sub= Sub{data}\n   \n//使用接口\nvar i Opter\ni = &a\nvalue := i.Opt()\ni = &b\nvalue := i.Opt()\n\n//使用多态\nvalue := MultiState(&a)\nvalue := MultiState(&b)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n",normalizedContent:"go 中没有面向对象的说法，也没有对应的封装、继承和多态\n\n封装，通过结构体中的匿名字段来实现 继承可以使用接口和嵌套结构体 go 中，尽管没有多态，但是能实现多态相同的用法\n\n\n# 继承\n\ntype basenum struct {\n     num1 int\n     num2 int\n} // basenum 即为父类型名称\n\ntype add struct {\n    basenum\n} //加法子类, 定义加法子类的主要目的, 是为了定义对应子类的方法\n\ntype sub struct {\n    basenum\n} //减法子类\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n//add 和sub 就是basenum的子类\n\n\n# 封装\n\nfunc (a *add)opt()(value int) {\n    return a.num1 + a.num2\n}//加法的方法实现\n\nfunc (s *sub)opt()(value int) {\n    return s.num1 + s.num2\n}//减法的方法实现\ntype opter interface { //接口定义\n    opt()int      //封装, 归纳子类方法, 注意此处需要加上返回值, 不然没有办法输出返回值(因为方法中使用了返回值)\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n# 多态\n\nfunc multistate(o *opter)(value int) { //多态定义, 可以简单理解为以接口作为形参的函数, 方便学习\n    value = o.opt()\n    return\n}\n\n// 继承\ndata:= basenum{2,3}\nvar a add = add{data}\nvar b sub= sub{data}\n   \n//使用接口\nvar i opter\ni = &a\nvalue := i.opt()\ni = &b\nvalue := i.opt()\n\n//使用多态\nvalue := multistate(&a)\nvalue := multistate(&b)\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"go embed",frontmatter:{title:"go embed",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang04/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"embed是在Go 1.16中新加包。它通过//go:embed指令，可以在编译阶段将静态资源文件打包进编译好的程序中，并提供访问这些文件的能力。",meta:[{name:"twitter:title",content:"go embed"},{name:"twitter:description",content:"embed是在Go 1.16中新加包。它通过//go:embed指令，可以在编译阶段将静态资源文件打包进编译好的程序中，并提供访问这些文件的能力。"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/04.go%20embed.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go embed"},{property:"og:description",content:"embed是在Go 1.16中新加包。它通过//go:embed指令，可以在编译阶段将静态资源文件打包进编译好的程序中，并提供访问这些文件的能力。"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/04.go%20embed.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"go embed"},{itemprop:"description",content:"embed是在Go 1.16中新加包。它通过//go:embed指令，可以在编译阶段将静态资源文件打包进编译好的程序中，并提供访问这些文件的能力。"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/04.go%20embed.html",relativePath:"01.技术杂谈/04.golang/04.go embed.md",key:"v-51cd8504",path:"/pages/golang04/",headers:[{level:2,title:"embed的基本语法",slug:"embed的基本语法",normalizedTitle:"embed的基本语法",charIndex:78}],headersStr:"embed的基本语法",content:"embed是在Go 1.16中新加包。它通过//go:embed指令，可以在编译阶段将静态资源文件打包进编译好的程序中，并提供访问这些文件的能力。\n\n\n# embed的基本语法\n\n基本语法非常简单，首先导入embed包，然后使用指令//go:embed 文件名 将对应的文件或目录结构导入到对应的变量上。",normalizedContent:"embed是在go 1.16中新加包。它通过//go:embed指令，可以在编译阶段将静态资源文件打包进编译好的程序中，并提供访问这些文件的能力。\n\n\n# embed的基本语法\n\n基本语法非常简单，首先导入embed包，然后使用指令//go:embed 文件名 将对应的文件或目录结构导入到对应的变量上。",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"go-指针",frontmatter:{title:"go-指针",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang03/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"Go 是一门静态语言,所有的变量都必须为标量类型.不同的类型不能够进行赋值,计算等跨类型的操作\n指针也对应着相对的类型,也在 Compile 的静态类型检查的范围内\n同时静态语言,也称为强类型.也就是一旦定义了,就不能再改变它",meta:[{name:"twitter:title",content:"go-指针"},{name:"twitter:description",content:"Go 是一门静态语言,所有的变量都必须为标量类型.不同的类型不能够进行赋值,计算等跨类型的操作\n指针也对应着相对的类型,也在 Compile 的静态类型检查的范围内\n同时静态语言,也称为强类型.也就是一旦定义了,就不能再改变它"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/03.go-%E6%8C%87%E9%92%88.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go-指针"},{property:"og:description",content:"Go 是一门静态语言,所有的变量都必须为标量类型.不同的类型不能够进行赋值,计算等跨类型的操作\n指针也对应着相对的类型,也在 Compile 的静态类型检查的范围内\n同时静态语言,也称为强类型.也就是一旦定义了,就不能再改变它"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/03.go-%E6%8C%87%E9%92%88.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"go-指针"},{itemprop:"description",content:"Go 是一门静态语言,所有的变量都必须为标量类型.不同的类型不能够进行赋值,计算等跨类型的操作\n指针也对应着相对的类型,也在 Compile 的静态类型检查的范围内\n同时静态语言,也称为强类型.也就是一旦定义了,就不能再改变它"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/03.go-%E6%8C%87%E9%92%88.html",relativePath:"01.技术杂谈/04.golang/03.go-指针.md",key:"v-783e73dc",path:"/pages/golang03/",headers:[{level:2,title:"Go 的指针是不支持指针运算和转换",slug:"go-的指针是不支持指针运算和转换",normalizedTitle:"go 的指针是不支持指针运算和转换",charIndex:2},{level:2,title:"unsafe.Pointer不安全指针",slug:"unsafe-pointer不安全指针",normalizedTitle:"unsafe.pointer不安全指针",charIndex:139}],headersStr:"Go 的指针是不支持指针运算和转换 unsafe.Pointer不安全指针",content:"# Go 的指针是不支持指针运算和转换\n\nGo 是一门静态语言,所有的变量都必须为标量类型.不同的类型不能够进行赋值,计算等跨类型的操作 指针也对应着相对的类型,也在 Compile 的静态类型检查的范围内 同时静态语言,也称为强类型.也就是一旦定义了,就不能再改变它\n\n\n# unsafe.Pointer不安全指针\n\n它表示任意类型且可寻址的指针值,可以在不同的指针类型之间进行转换（类似 C 语言的 void * 的用途） 其包含四种核心操作：\n\n * 任何类型的指针值都可以转换为 Pointer\n * Pointer 可以转换为任何类型的指针值\n * uintptr 可以转换为 Pointer\n * Pointer 可以转换为 uintptr\n\nunsafe.Pointer 可以让您的变量在不同的指针类型转来转去,也就是表示为任意可寻址的指针类型 uintptr 常用于与 unsafe.Pointer 打配合,用于做指针运算",normalizedContent:"# go 的指针是不支持指针运算和转换\n\ngo 是一门静态语言,所有的变量都必须为标量类型.不同的类型不能够进行赋值,计算等跨类型的操作 指针也对应着相对的类型,也在 compile 的静态类型检查的范围内 同时静态语言,也称为强类型.也就是一旦定义了,就不能再改变它\n\n\n# unsafe.pointer不安全指针\n\n它表示任意类型且可寻址的指针值,可以在不同的指针类型之间进行转换（类似 c 语言的 void * 的用途） 其包含四种核心操作：\n\n * 任何类型的指针值都可以转换为 pointer\n * pointer 可以转换为任何类型的指针值\n * uintptr 可以转换为 pointer\n * pointer 可以转换为 uintptr\n\nunsafe.pointer 可以让您的变量在不同的指针类型转来转去,也就是表示为任意可寻址的指针类型 uintptr 常用于与 unsafe.pointer 打配合,用于做指针运算",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"go-文件操作",frontmatter:{title:"go-文件操作",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang06/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:'emptyFile, err := os.Create("empty.txt")\ndefer emptyFile.Close()\n_, err := os.Stat("test")',meta:[{name:"twitter:title",content:"go-文件操作"},{name:"twitter:description",content:'emptyFile, err := os.Create("empty.txt")\ndefer emptyFile.Close()\n_, err := os.Stat("test")'},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/06.go-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go-文件操作"},{property:"og:description",content:'emptyFile, err := os.Create("empty.txt")\ndefer emptyFile.Close()\n_, err := os.Stat("test")'},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/06.go-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"go-文件操作"},{itemprop:"description",content:'emptyFile, err := os.Create("empty.txt")\ndefer emptyFile.Close()\n_, err := os.Stat("test")'}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/06.go-%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C.html",relativePath:"01.技术杂谈/04.golang/06.go-文件操作.md",key:"v-5b58f46b",path:"/pages/golang06/",headers:[{level:2,title:"判断文件是否存在/创建空文件",slug:"判断文件是否存在-创建空文件",normalizedTitle:"判断文件是否存在/创建空文件",charIndex:2},{level:2,title:"重命名文件: os.Rename",slug:"重命名文件-os-rename",normalizedTitle:"重命名文件: os.rename",charIndex:263},{level:2,title:"移动文件: os.Rename",slug:"移动文件-os-rename",normalizedTitle:"移动文件: os.rename",charIndex:376},{level:2,title:"复制文件: io.Copy",slug:"复制文件-io-copy",normalizedTitle:"复制文件: io.copy",charIndex:533},{level:2,title:"获取文件的metadata信息: os.Stat()",slug:"获取文件的metadata信息-os-stat",normalizedTitle:"获取文件的metadata信息: os.stat()",charIndex:770},{level:2,title:"删除文件: os.Remove()",slug:"删除文件-os-remove",normalizedTitle:"删除文件: os.remove()",charIndex:1245},{level:2,title:"读取文件字符: bufio.NewScanner()",slug:"读取文件字符-bufio-newscanner",normalizedTitle:"读取文件字符: bufio.newscanner()",charIndex:1267},{level:2,title:"清除文件: os.Truncate()",slug:"清除文件-os-truncate",normalizedTitle:"清除文件: os.truncate()",charIndex:1523},{level:2,title:"向文件添加内容",slug:"向文件添加内容",normalizedTitle:"向文件添加内容",charIndex:1668},{level:2,title:"修改文件权限,时间戳",slug:"修改文件权限-时间戳",normalizedTitle:"修改文件权限,时间戳",charIndex:1793},{level:2,title:'zip操作 "archive/zip"',slug:"zip操作-archive-zip",normalizedTitle:"zip操作 &quot;archive/zip&quot;",charIndex:null}],headersStr:'判断文件是否存在/创建空文件 重命名文件: os.Rename 移动文件: os.Rename 复制文件: io.Copy 获取文件的metadata信息: os.Stat() 删除文件: os.Remove() 读取文件字符: bufio.NewScanner() 清除文件: os.Truncate() 向文件添加内容 修改文件权限,时间戳 zip操作 "archive/zip"',content:'# 判断文件是否存在/创建空文件\n\nemptyFile, err := os.Create("empty.txt")\ndefer emptyFile.Close()\n\n\n1\n2\n\n\n_, err := os.Stat("test")\n \nif os.IsNotExist(err) {\n    errDir := os.MkdirAll("test", 0755)\n    if errDir != nil {\n        log.Fatal(err)\n    }\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 重命名文件: os.Rename\n\noldName := "test.txt"\nnewName := "testing.txt"\nerr := os.Rename(oldName, newName)\n\n\n1\n2\n3\n\n\n\n# 移动文件: os.Rename\n\noldLocation := "/var/www/html/test.txt"\nnewLocation := "/var/www/html/src/test.txt"\nerr := os.Rename(oldLocation, newLocation)\n\n\n1\n2\n3\n\n\n\n# 复制文件: io.Copy\n\nsourceFile, err := os.Open("/var/www/html/src/test.txt")\ndefer sourceFile.Close()\nnewFile, err := os.Create("/var/www/html/test.txt")\ndefer newFile.Close()\nbytesCopied, err := io.Copy(newFile, sourceFile)\n\n\n1\n2\n3\n4\n5\n\n\n\n# 获取文件的metadata信息: os.Stat()\n\nfileStat, err := os.Stat("test.txt")\nfmt.Println("File Name:", fileStat.Name())        // Base name of the file\nfmt.Println("Size:", fileStat.Size())             // Length in bytes for regular files\nfmt.Println("Permissions:", fileStat.Mode())      // File mode bits\nfmt.Println("Last Modified:", fileStat.ModTime()) // Last modification time\nfmt.Println("Is Directory: ", fileStat.IsDir())   // Abbreviation for Mode().IsDir()\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 删除文件: os.Remove()\n\n\n# 读取文件字符: bufio.NewScanner()\n\nfilebuffer, err := ioutil.ReadFile(filename)\ninputdata := string(filebuffer)\ndata := bufio.NewScanner(strings.NewReader(inputdata))\ndata.Split(bufio.ScanRunes)\nfor data.Scan() {\n    fmt.Print(data.Text())\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 清除文件: os.Truncate()\n\n裁剪一个文件到100个字节. 如果文件本来就少于100个字节,则文件中原始内容得以保留,剩余的字节以null字节填充. 如果文件本来超过100个字节,则超过的字节会被抛弃. 这样我们总是得到精确的100个字节的文件. 传入0则会清空文件.\n\n\n# 向文件添加内容\n\nf, err := os.OpenFile(filename, os.O_RDWR|os.O_APPEND|os.O_CREATE, 0660)\nfmt.Fprintf(f, "%s\\n", message)\n\n\n1\n2\n\n\n\n# 修改文件权限,时间戳\n\nerr = os.Chmod("test.txt", 0777)\nerr = os.Chown("test.txt", os.Getuid(), os.Getgid())\nerr = os.Chtimes("test.txt", lastAccessTime, lastModifyTime)\n\n\n1\n2\n3\n\n\n\n# zip操作 "archive/zip"\n\n * 压缩文件到ZIP格式\n * 读取ZIP文件里面的文件\n * 解压ZIP文件',normalizedContent:'# 判断文件是否存在/创建空文件\n\nemptyfile, err := os.create("empty.txt")\ndefer emptyfile.close()\n\n\n1\n2\n\n\n_, err := os.stat("test")\n \nif os.isnotexist(err) {\n    errdir := os.mkdirall("test", 0755)\n    if errdir != nil {\n        log.fatal(err)\n    }\n\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 重命名文件: os.rename\n\noldname := "test.txt"\nnewname := "testing.txt"\nerr := os.rename(oldname, newname)\n\n\n1\n2\n3\n\n\n\n# 移动文件: os.rename\n\noldlocation := "/var/www/html/test.txt"\nnewlocation := "/var/www/html/src/test.txt"\nerr := os.rename(oldlocation, newlocation)\n\n\n1\n2\n3\n\n\n\n# 复制文件: io.copy\n\nsourcefile, err := os.open("/var/www/html/src/test.txt")\ndefer sourcefile.close()\nnewfile, err := os.create("/var/www/html/test.txt")\ndefer newfile.close()\nbytescopied, err := io.copy(newfile, sourcefile)\n\n\n1\n2\n3\n4\n5\n\n\n\n# 获取文件的metadata信息: os.stat()\n\nfilestat, err := os.stat("test.txt")\nfmt.println("file name:", filestat.name())        // base name of the file\nfmt.println("size:", filestat.size())             // length in bytes for regular files\nfmt.println("permissions:", filestat.mode())      // file mode bits\nfmt.println("last modified:", filestat.modtime()) // last modification time\nfmt.println("is directory: ", filestat.isdir())   // abbreviation for mode().isdir()\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 删除文件: os.remove()\n\n\n# 读取文件字符: bufio.newscanner()\n\nfilebuffer, err := ioutil.readfile(filename)\ninputdata := string(filebuffer)\ndata := bufio.newscanner(strings.newreader(inputdata))\ndata.split(bufio.scanrunes)\nfor data.scan() {\n    fmt.print(data.text())\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n\n\n\n# 清除文件: os.truncate()\n\n裁剪一个文件到100个字节. 如果文件本来就少于100个字节,则文件中原始内容得以保留,剩余的字节以null字节填充. 如果文件本来超过100个字节,则超过的字节会被抛弃. 这样我们总是得到精确的100个字节的文件. 传入0则会清空文件.\n\n\n# 向文件添加内容\n\nf, err := os.openfile(filename, os.o_rdwr|os.o_append|os.o_create, 0660)\nfmt.fprintf(f, "%s\\n", message)\n\n\n1\n2\n\n\n\n# 修改文件权限,时间戳\n\nerr = os.chmod("test.txt", 0777)\nerr = os.chown("test.txt", os.getuid(), os.getgid())\nerr = os.chtimes("test.txt", lastaccesstime, lastmodifytime)\n\n\n1\n2\n3\n\n\n\n# zip操作 "archive/zip"\n\n * 压缩文件到zip格式\n * 读取zip文件里面的文件\n * 解压zip文件',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"go-slice切片",frontmatter:{title:"go-slice切片",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang08/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"在 Go 中,Slice（切片）是抽象在 Array（数组）之上的特殊类型",meta:[{name:"twitter:title",content:"go-slice切片"},{name:"twitter:description",content:"在 Go 中,Slice（切片）是抽象在 Array（数组）之上的特殊类型"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/08.go-slice%E5%88%87%E7%89%87.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go-slice切片"},{property:"og:description",content:"在 Go 中,Slice（切片）是抽象在 Array（数组）之上的特殊类型"},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/08.go-slice%E5%88%87%E7%89%87.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"go-slice切片"},{itemprop:"description",content:"在 Go 中,Slice（切片）是抽象在 Array（数组）之上的特殊类型"}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/08.go-slice%E5%88%87%E7%89%87.html",relativePath:"01.技术杂谈/04.golang/08.go-slice切片.md",key:"v-d695f1cc",path:"/pages/golang08/",headers:[{level:2,title:"Array数组",slug:"array数组",normalizedTitle:"array数组",charIndex:42},{level:2,title:"Slice切片",slug:"slice切片",normalizedTitle:"slice切片",charIndex:76},{level:3,title:"Slice 的创建方式：",slug:"slice-的创建方式",normalizedTitle:"slice 的创建方式：",charIndex:522}],headersStr:"Array数组 Slice切片 Slice 的创建方式：",content:"在 Go 中,Slice（切片）是抽象在 Array（数组）之上的特殊类型\n\n\n# Array数组\n\n[3]int{} 表示 3 个整数的数组\n\n\n# Slice切片\n\ntype slice struct {\n\tarray unsafe.Pointer\n\tlen   int\n\tcap   int\n}\n\n\n1\n2\n3\n4\n5\n\n\nSlice 的底层数据结构共分为三部分,如下：\n\n * array：指向所引用的数组指针（unsafe.Pointer 可以表示任何可寻址的值的指针）\n * len：长度,当前引用切片的元素个数\n * cap：容量,当前引用切片的容量（底层数组的元素总数） 在实际使用中,cap 一定是大于或等于 len 的.否则会导致 panic\n\nnums := [3]int{}\nnums[0] = 1\ndnums := nums[0:2]\n# nums: [1 0 0] \n# dnums: [1 0], len: 2, cap: 3\n\n\n1\n2\n3\n4\n5\n\n\nSlice 是对 Array 的抽象,类型为 []T dnums 变量通过 nums[:] 进行赋值 dnums 变量通过 nums[:] 进行赋值\n\n\n# Slice 的创建方式：\n\n * test := []int{2,3}\n * test := make([]int, 5, 5) // 创建一个类型为 int，长度为 5，容量为 5 的切片\n * test1 := make([]int, 3) //如果不指定容量，默认容量等于初始时的长度\n * test := make([]int,0) // 创建一个长度为0，容量为0 的数组 test = append(test, 1) //当数组的容量不够时，会重新申请一个两倍于当前长度的 slice，所以在使用过程中，尤其是频繁去往一个 slice 中 append 数据，需要尽可能给一个相对准确的容量， 减少分配过程的损耗。",normalizedContent:"在 go 中,slice（切片）是抽象在 array（数组）之上的特殊类型\n\n\n# array数组\n\n[3]int{} 表示 3 个整数的数组\n\n\n# slice切片\n\ntype slice struct {\n\tarray unsafe.pointer\n\tlen   int\n\tcap   int\n}\n\n\n1\n2\n3\n4\n5\n\n\nslice 的底层数据结构共分为三部分,如下：\n\n * array：指向所引用的数组指针（unsafe.pointer 可以表示任何可寻址的值的指针）\n * len：长度,当前引用切片的元素个数\n * cap：容量,当前引用切片的容量（底层数组的元素总数） 在实际使用中,cap 一定是大于或等于 len 的.否则会导致 panic\n\nnums := [3]int{}\nnums[0] = 1\ndnums := nums[0:2]\n# nums: [1 0 0] \n# dnums: [1 0], len: 2, cap: 3\n\n\n1\n2\n3\n4\n5\n\n\nslice 是对 array 的抽象,类型为 []t dnums 变量通过 nums[:] 进行赋值 dnums 变量通过 nums[:] 进行赋值\n\n\n# slice 的创建方式：\n\n * test := []int{2,3}\n * test := make([]int, 5, 5) // 创建一个类型为 int，长度为 5，容量为 5 的切片\n * test1 := make([]int, 3) //如果不指定容量，默认容量等于初始时的长度\n * test := make([]int,0) // 创建一个长度为0，容量为0 的数组 test = append(test, 1) //当数组的容量不够时，会重新申请一个两倍于当前长度的 slice，所以在使用过程中，尤其是频繁去往一个 slice 中 append 数据，需要尽可能给一个相对准确的容量， 减少分配过程的损耗。",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"go-json",frontmatter:{title:"go-json",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang07/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"go-json"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/07.go-json.html"},{property:"og:type",content:"article"},{property:"og:title",content:"go-json"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/07.go-json.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"go-json"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/07.go-json.html",relativePath:"01.技术杂谈/04.golang/07.go-json.md",key:"v-92ed690a",path:"/pages/golang07/",headers:[{level:2,title:"定制JSON序列化",slug:"定制json序列化",normalizedTitle:"定制json序列化",charIndex:96},{level:3,title:"临时忽略struct空字段： omitempty",slug:"临时忽略struct空字段-omitempty",normalizedTitle:"临时忽略struct空字段： omitempty",charIndex:366},{level:3,title:"忽略一些字段: -",slug:"忽略一些字段",normalizedTitle:"忽略一些字段: -",charIndex:532},{level:3,title:"临时添加额外的字段:",slug:"临时添加额外的字段",normalizedTitle:"临时添加额外的字段:",charIndex:645},{level:3,title:"临时粘合两个struct",slug:"临时粘合两个struct",normalizedTitle:"临时粘合两个struct",charIndex:858},{level:3,title:"一个json切分成两个struct: todo",slug:"一个json切分成两个struct-todo",normalizedTitle:"一个json切分成两个struct: todo",charIndex:1163},{level:3,title:'用字符串传递数字: json:",string"',slug:"用字符串传递数字-json-string",normalizedTitle:"用字符串传递数字: json:&quot;,string&quot;",charIndex:null}],headersStr:'定制JSON序列化 临时忽略struct空字段： omitempty 忽略一些字段: - 临时添加额外的字段: 临时粘合两个struct 一个json切分成两个struct: todo 用字符串传递数字: json:",string"',content:'Json(Javascript Object Nanotation)是一种数据交换格式，常用于前后端数据传输。 go语言本身为我们提供了json的工具包”encoding/json”\n\n\n# 定制JSON序列化\n\nJson Marshal：将数据编码成json字符串\n\n    jsonStu, err := json.Marshal(stu)\n\n\n1\n\n\njson.Unmarshal: 反序列的函数，将json字符串解码到相应的数据结构；\n\n    jsonstr := `{"a":"aaa","b":"bbb"}`\n    map1 := make(map[string]interface{})\n    err := json.Unmarshal([]byte(jsonstr), &map1)\n\n\n1\n2\n3\n\n\n\n# 临时忽略struct空字段： omitempty\n\njson.Marshal(struct {\n    *User\n    Password bool `json:"password,omitempty"`  //忽略该字段\n    }{\n        User: user,\n    })\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 忽略一些字段: -\n\njson.Marshal(struct {\n    *User\n    Password bool `json:"-"`\n}{\n    User: user,\n})\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 临时添加额外的字段:\n\njson.Marshal(struct {\n    *User\n    Token    string `json:"token"`  //添加该字段\n    Password bool `json:"password,omitempty"`\n    }{\n        User: user,\n        Token: token,\n    })\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 临时粘合两个struct\n\ntype BlogPost struct {\n    URL   string `json:"url"`\n    Title string `json:"title"`\n}\ntype Analytics struct {\n    Visitors  int `json:"visitors"`\n    PageViews int `json:"page_views"`\n}\njson.Marshal(struct{\n    *BlogPost\n    *Analytics\n}{post, analytics})\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 一个json切分成两个struct: todo\n\n\n# 用字符串传递数字: json:",string"\n\ntype TestObject struct {\n    Field1 int    `json:",string"`\n}\n\n\n1\n2\n3\n',normalizedContent:'json(javascript object nanotation)是一种数据交换格式，常用于前后端数据传输。 go语言本身为我们提供了json的工具包”encoding/json”\n\n\n# 定制json序列化\n\njson marshal：将数据编码成json字符串\n\n    jsonstu, err := json.marshal(stu)\n\n\n1\n\n\njson.unmarshal: 反序列的函数，将json字符串解码到相应的数据结构；\n\n    jsonstr := `{"a":"aaa","b":"bbb"}`\n    map1 := make(map[string]interface{})\n    err := json.unmarshal([]byte(jsonstr), &map1)\n\n\n1\n2\n3\n\n\n\n# 临时忽略struct空字段： omitempty\n\njson.marshal(struct {\n    *user\n    password bool `json:"password,omitempty"`  //忽略该字段\n    }{\n        user: user,\n    })\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 忽略一些字段: -\n\njson.marshal(struct {\n    *user\n    password bool `json:"-"`\n}{\n    user: user,\n})\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n# 临时添加额外的字段:\n\njson.marshal(struct {\n    *user\n    token    string `json:"token"`  //添加该字段\n    password bool `json:"password,omitempty"`\n    }{\n        user: user,\n        token: token,\n    })\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n\n\n\n# 临时粘合两个struct\n\ntype blogpost struct {\n    url   string `json:"url"`\n    title string `json:"title"`\n}\ntype analytics struct {\n    visitors  int `json:"visitors"`\n    pageviews int `json:"page_views"`\n}\njson.marshal(struct{\n    *blogpost\n    *analytics\n}{post, analytics})\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n\n\n\n# 一个json切分成两个struct: todo\n\n\n# 用字符串传递数字: json:",string"\n\ntype testobject struct {\n    field1 int    `json:",string"`\n}\n\n\n1\n2\n3\n',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"gin框架使用sockjs-go",frontmatter:{title:"gin框架使用sockjs-go",date:"2022-07-27T14:56:54.000Z",permalink:"/pages/golang09/",categories:["技术杂谈","golang"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"gin框架使用sockjs-go"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/09.gin%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8sockjs-go.html"},{property:"og:type",content:"article"},{property:"og:title",content:"gin框架使用sockjs-go"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/09.gin%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8sockjs-go.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:54.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"gin框架使用sockjs-go"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/04.golang/09.gin%E6%A1%86%E6%9E%B6%E4%BD%BF%E7%94%A8sockjs-go.html",relativePath:"01.技术杂谈/04.golang/09.gin框架使用sockjs-go.md",key:"v-018b12ce",path:"/pages/golang09/",headers:[{level:2,title:"sockjs-go",slug:"sockjs-go",normalizedTitle:"sockjs-go",charIndex:2},{level:2,title:"在gin框架中使用sockjs-go",slug:"在gin框架中使用sockjs-go",normalizedTitle:"在gin框架中使用sockjs-go",charIndex:295},{level:3,title:"问题描述",slug:"问题描述",normalizedTitle:"问题描述",charIndex:362},{level:3,title:"解决办法",slug:"解决办法",normalizedTitle:"解决办法",charIndex:445}],headersStr:"sockjs-go 在gin框架中使用sockjs-go 问题描述 解决办法",content:'# sockjs-go\n\nhttps://github.com/igm/sockjs-go 官方示例：\n\nimport (\n\t"log"\n\t"net/http"\n\n\t"github.com/igm/sockjs-go/v3/sockjs"\n)\n\nfunc main() {\n\thandler := sockjs.NewHandler("/echo", sockjs.DefaultOptions, echoHandler)\n\tlog.Fatal(http.ListenAndServe(":8081", handler))\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 在gin框架中使用sockjs-go\n\nhttps://github.com/igm/sockjs-go/issues/85\n\n\n# 问题描述\n\nGET http://localhost:8000/echo/info?t=1486141708375 404 (Not Found)\n\n\n1\n\n\n\n# 解决办法\n\nhttps://github.com/gin-gonic/gin/issues/799\n\nr.Any("/echo/*info", gin.WrapH(k8spod.CreateAttachHandler("/echo")))\n\n注意： 最后的/echo不能增加/结尾',normalizedContent:'# sockjs-go\n\nhttps://github.com/igm/sockjs-go 官方示例：\n\nimport (\n\t"log"\n\t"net/http"\n\n\t"github.com/igm/sockjs-go/v3/sockjs"\n)\n\nfunc main() {\n\thandler := sockjs.newhandler("/echo", sockjs.defaultoptions, echohandler)\n\tlog.fatal(http.listenandserve(":8081", handler))\n}\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 在gin框架中使用sockjs-go\n\nhttps://github.com/igm/sockjs-go/issues/85\n\n\n# 问题描述\n\nget http://localhost:8000/echo/info?t=1486141708375 404 (not found)\n\n\n1\n\n\n\n# 解决办法\n\nhttps://github.com/gin-gonic/gin/issues/799\n\nr.any("/echo/*info", gin.wraph(k8spod.createattachhandler("/echo")))\n\n注意： 最后的/echo不能增加/结尾',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"关于cgroup",frontmatter:{title:"关于cgroup",date:"2022-10-09T18:31:35.000Z",permalink:"/pages/b5149c/",categories:["技术杂谈","计算机网络基础"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"关于cgroup"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/06.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/01.%E5%85%B3%E4%BA%8Ecgroup.html"},{property:"og:type",content:"article"},{property:"og:title",content:"关于cgroup"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/06.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/01.%E5%85%B3%E4%BA%8Ecgroup.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T18:31:35.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"关于cgroup"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/06.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/01.%E5%85%B3%E4%BA%8Ecgroup.html",relativePath:"01.技术杂谈/06.计算机网络基础/01.关于cgroup.md",key:"v-3f6d3b4e",path:"/pages/b5149c/",headersStr:null,content:"",normalizedContent:"",charsets:{}},{title:"关于cpu内存",frontmatter:{title:"关于cpu内存",date:"2022-10-09T18:31:35.000Z",permalink:"/pages/95ef75/",categories:["技术杂谈","计算机网络基础"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"关于cpu内存"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/06.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/02.%E5%85%B3%E4%BA%8Ecpu%E5%86%85%E5%AD%98.html"},{property:"og:type",content:"article"},{property:"og:title",content:"关于cpu内存"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/06.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/02.%E5%85%B3%E4%BA%8Ecpu%E5%86%85%E5%AD%98.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T18:31:35.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"关于cpu内存"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/06.%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/02.%E5%85%B3%E4%BA%8Ecpu%E5%86%85%E5%AD%98.html",relativePath:"01.技术杂谈/06.计算机网络基础/02.关于cpu内存.md",key:"v-13d7c644",path:"/pages/95ef75/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"centos使用kvm创建虚拟机",frontmatter:{title:"centos使用kvm创建虚拟机",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/33705b/",categories:["技术杂谈","虚拟化"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"centos使用kvm创建虚拟机"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/03.centos%E4%BD%BF%E7%94%A8kvm%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA.html"},{property:"og:type",content:"article"},{property:"og:title",content:"centos使用kvm创建虚拟机"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/03.centos%E4%BD%BF%E7%94%A8kvm%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"centos使用kvm创建虚拟机"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/03.centos%E4%BD%BF%E7%94%A8kvm%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E6%9C%BA.html",relativePath:"01.技术杂谈/07.虚拟化/03.centos使用kvm创建虚拟机.md",key:"v-080925d0",path:"/pages/33705b/",headers:[{level:2,title:"安装完KVM之后，需要配置一下网卡，增加一个桥接网卡：",slug:"安装完kvm之后-需要配置一下网卡-增加一个桥接网卡",normalizedTitle:"安装完kvm之后，需要配置一下网卡，增加一个桥接网卡：",charIndex:60},{level:2,title:"创建卷",slug:"创建卷",normalizedTitle:"创建卷",charIndex:939},{level:2,title:"准备一个操作系统的镜像文件",slug:"准备一个操作系统的镜像文件",normalizedTitle:"准备一个操作系统的镜像文件",charIndex:1254},{level:2,title:"虚拟机操作",slug:"虚拟机操作",normalizedTitle:"虚拟机操作",charIndex:2044},{level:2,title:"安装完成，配置固定IP",slug:"安装完成-配置固定ip",normalizedTitle:"安装完成，配置固定ip",charIndex:2602}],headersStr:"安装完KVM之后，需要配置一下网卡，增加一个桥接网卡： 创建卷 准备一个操作系统的镜像文件 虚拟机操作 安装完成，配置固定IP",content:"https://blog.csdn.net/dhRainer/article/details/83411555\n\n\n# 安装完KVM之后，需要配置一下网卡，增加一个桥接网卡：\n\ncd /etc/sysconfig/network-scripts/\ncp ifcfg-eno16777728 ifcfg-br0  # 拷贝当前的网卡文件\nvim ifcfg-eno16777728  # 修改文件内容如下\nTYPE=Ethernet\nBOOTPROTO=dhcp\nDEFROUTE=yes\nPEERDNS=yes\nPEERROUTES=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_PEERDNS=yes\nIPV6_PEERROUTES=yes\nIPV6_FAILURE_FATAL=no\nNAME=eno16777728\nDEVICE=eno16777728\nONBOOT=yes\nBRIDGE=br0\n\nvim ifcfg-br0  # 修改文件内容如下\nTYPE=Bridge\nBOOTPROTO=dhcp\nDEFROUTE=yes\nPEERDNS=yes\nPEERROUTES=yes\nIPV4_FAILURE_FATAL=no\nIPV6INIT=yes\nIPV6_AUTOCONF=yes\nIPV6_DEFROUTE=yes\nIPV6_PEERDNS=yes\nIPV6_PEERROUTES=yes\nIPV6_FAILURE_FATAL=no\nNAME=br0\nDEVICE=br0\nONBOOT=yes\n\nsystemctl restart network  # 重启服务\n\nsystemctl start libvirtd  # 启动libvirtd服务\n\nbrctl show  # 可以看到两个网卡\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n\n\n\n# 创建卷\n\ncd /root/hff/kvm\nqemu-img create -f qcow2    hfftest.qcow2  10G\nqemu-img info  hfftest.qcow2 \nimage: hfftest.qcow2\nfile format: qcow2\nvirtual size: 10G (10737418240 bytes)\ndisk size: 196K\ncluster_size: 65536\nFormat specific information:\n    compat: 1.1\n    lazy refcounts: false\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 准备一个操作系统的镜像文件\n\na)命令行安装虚拟机\n\nvirt-install \\\n--virt-type=kvm \\\n--name=hfftest \\\n--vcpus=2 \\\n--memory=2048 \\\n--location=/hff/kvm/iso/CentOS-7-x86_64-Minimal-2009.iso \\\n--disk path=/hff/kvm/images/hfftest.qcow2,size=15,format=qcow2 \\\n--network bridge=virbr0 \\\n--graphics none \\\n--extra-args='console=ttyS0' \\\n--force\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n> 命令说明： --name 指定虚拟机的名称 --memory 指定分配给虚拟机的内存资源大小 maxmemory 指定可调节的最大内存资源大小，因为KVM支持热调整虚拟机的资源 --vcpus 指定分配给虚拟机的CPU核心数量 maxvcpus 指定可调节的最大CPU核心数量 --os-type 指定虚拟机安装的操作系统类型 --os-variant 指定系统的发行版本 --location 指定ISO镜像文件所在的路径，支持使用网络资源路径，也就是说可以使用URL --disk path 指定虚拟硬盘所存放的路径及名称，size 则是指定该硬盘的可用大小，单位是G --bridge 指定使用哪一个桥接网卡，也就是说使用桥接的网络模式 --graphics 指定是否开启图形 --console 定义终端的属性，target_type 则是定义终端的类型 --extra-args 定义终端额外的参数\n\n查询虚拟机所使用的vnc端口virsh vncdisplay centos\n\n\n# 虚拟机操作\n\n[root@localhost ~]# virsh console study01  # 进入指定的虚拟机，进入的时候还需要按一下回车\n[root@localhost ~]# virsh start study01  # 启动虚拟机\n[root@localhost ~]# virsh shutdown study01  # 关闭虚拟机\n[root@localhost ~]# virsh destroy study01  # 强制停止虚拟机\n[root@localhost ~]# virsh undefine study01  # 彻底销毁虚拟机，会删除虚拟机配置文件，但不会删除虚拟磁盘\n[root@localhost ~]# virsh autostart study01  # 设置宿主机开机时该虚拟机也开机\n[root@localhost ~]# virsh autostart --disable study01  # 解除开机启动\n[root@localhost ~]# virsh suspend study01 # 挂起虚拟机\n[root@localhost ~]# virsh resume study01 # 恢复挂起的虚拟机\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 安装完成，配置固定IP\n\n[root@localhost network-scripts]# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: ens3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc pfifo_fast state UP group default qlen 1000\n    link/ether 52:54:00:40:a4:ef brd ff:ff:ff:ff:ff:ff\n    inet 192.168.122.151/24 brd 192.168.122.255 scope global noprefixroute dynamic ens3\n       valid_lft 3598sec preferred_lft 3598sec\n    inet6 fe80::f5ed:53d0:e383:59e6/64 scope link noprefixroute\n       valid_lft forever preferred_lft forever\n[root@localhost network-scripts]#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",normalizedContent:"https://blog.csdn.net/dhrainer/article/details/83411555\n\n\n# 安装完kvm之后，需要配置一下网卡，增加一个桥接网卡：\n\ncd /etc/sysconfig/network-scripts/\ncp ifcfg-eno16777728 ifcfg-br0  # 拷贝当前的网卡文件\nvim ifcfg-eno16777728  # 修改文件内容如下\ntype=ethernet\nbootproto=dhcp\ndefroute=yes\npeerdns=yes\npeerroutes=yes\nipv4_failure_fatal=no\nipv6init=yes\nipv6_autoconf=yes\nipv6_defroute=yes\nipv6_peerdns=yes\nipv6_peerroutes=yes\nipv6_failure_fatal=no\nname=eno16777728\ndevice=eno16777728\nonboot=yes\nbridge=br0\n\nvim ifcfg-br0  # 修改文件内容如下\ntype=bridge\nbootproto=dhcp\ndefroute=yes\npeerdns=yes\npeerroutes=yes\nipv4_failure_fatal=no\nipv6init=yes\nipv6_autoconf=yes\nipv6_defroute=yes\nipv6_peerdns=yes\nipv6_peerroutes=yes\nipv6_failure_fatal=no\nname=br0\ndevice=br0\nonboot=yes\n\nsystemctl restart network  # 重启服务\n\nsystemctl start libvirtd  # 启动libvirtd服务\n\nbrctl show  # 可以看到两个网卡\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n\n\n\n# 创建卷\n\ncd /root/hff/kvm\nqemu-img create -f qcow2    hfftest.qcow2  10g\nqemu-img info  hfftest.qcow2 \nimage: hfftest.qcow2\nfile format: qcow2\nvirtual size: 10g (10737418240 bytes)\ndisk size: 196k\ncluster_size: 65536\nformat specific information:\n    compat: 1.1\n    lazy refcounts: false\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n\n# 准备一个操作系统的镜像文件\n\na)命令行安装虚拟机\n\nvirt-install \\\n--virt-type=kvm \\\n--name=hfftest \\\n--vcpus=2 \\\n--memory=2048 \\\n--location=/hff/kvm/iso/centos-7-x86_64-minimal-2009.iso \\\n--disk path=/hff/kvm/images/hfftest.qcow2,size=15,format=qcow2 \\\n--network bridge=virbr0 \\\n--graphics none \\\n--extra-args='console=ttys0' \\\n--force\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n\n\n> 命令说明： --name 指定虚拟机的名称 --memory 指定分配给虚拟机的内存资源大小 maxmemory 指定可调节的最大内存资源大小，因为kvm支持热调整虚拟机的资源 --vcpus 指定分配给虚拟机的cpu核心数量 maxvcpus 指定可调节的最大cpu核心数量 --os-type 指定虚拟机安装的操作系统类型 --os-variant 指定系统的发行版本 --location 指定iso镜像文件所在的路径，支持使用网络资源路径，也就是说可以使用url --disk path 指定虚拟硬盘所存放的路径及名称，size 则是指定该硬盘的可用大小，单位是g --bridge 指定使用哪一个桥接网卡，也就是说使用桥接的网络模式 --graphics 指定是否开启图形 --console 定义终端的属性，target_type 则是定义终端的类型 --extra-args 定义终端额外的参数\n\n查询虚拟机所使用的vnc端口virsh vncdisplay centos\n\n\n# 虚拟机操作\n\n[root@localhost ~]# virsh console study01  # 进入指定的虚拟机，进入的时候还需要按一下回车\n[root@localhost ~]# virsh start study01  # 启动虚拟机\n[root@localhost ~]# virsh shutdown study01  # 关闭虚拟机\n[root@localhost ~]# virsh destroy study01  # 强制停止虚拟机\n[root@localhost ~]# virsh undefine study01  # 彻底销毁虚拟机，会删除虚拟机配置文件，但不会删除虚拟磁盘\n[root@localhost ~]# virsh autostart study01  # 设置宿主机开机时该虚拟机也开机\n[root@localhost ~]# virsh autostart --disable study01  # 解除开机启动\n[root@localhost ~]# virsh suspend study01 # 挂起虚拟机\n[root@localhost ~]# virsh resume study01 # 恢复挂起的虚拟机\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n# 安装完成，配置固定ip\n\n[root@localhost network-scripts]# ip a\n1: lo: <loopback,up,lower_up> mtu 65536 qdisc noqueue state unknown group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n2: ens3: <broadcast,multicast,up,lower_up> mtu 1500 qdisc pfifo_fast state up group default qlen 1000\n    link/ether 52:54:00:40:a4:ef brd ff:ff:ff:ff:ff:ff\n    inet 192.168.122.151/24 brd 192.168.122.255 scope global noprefixroute dynamic ens3\n       valid_lft 3598sec preferred_lft 3598sec\n    inet6 fe80::f5ed:53d0:e383:59e6/64 scope link noprefixroute\n       valid_lft forever preferred_lft forever\n[root@localhost network-scripts]#\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",charsets:{cjk:!0},lastUpdated:"2022/07/27, 18:59:09",lastUpdatedTimestamp:1658919549e3},{title:"虚拟化基础概念",frontmatter:{title:"虚拟化基础概念",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/697e48/",categories:["技术杂谈","虚拟化"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"虚拟化基础概念"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/02.%E8%99%9A%E6%8B%9F%E5%8C%96%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html"},{property:"og:type",content:"article"},{property:"og:title",content:"虚拟化基础概念"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/02.%E8%99%9A%E6%8B%9F%E5%8C%96%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"虚拟化基础概念"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/02.%E8%99%9A%E6%8B%9F%E5%8C%96%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5.html",relativePath:"01.技术杂谈/07.虚拟化/02.虚拟化基础概念.md",key:"v-2e18135a",path:"/pages/697e48/",headers:[{level:2,title:"概念",slug:"概念",normalizedTitle:"概念",charIndex:2},{level:2,title:"虚拟化有两种不同类型的虚拟机监控程序:",slug:"虚拟化有两种不同类型的虚拟机监控程序",normalizedTitle:"虚拟化有两种不同类型的虚拟机监控程序:",charIndex:936}],headersStr:"概念 虚拟化有两种不同类型的虚拟机监控程序:",content:'# 概念\n\n * KVM：Kernel-Based Virtual Machine 基于内核的虚拟机；只负责CPU和内存的虚拟化\n\n * qemu-kvm：kvm用户空间管理工具；\n\n * libvirt：管理kvm虚拟机的软件；\n\n * QEMU： QEMU是一个独立的虚拟化解决方案，并不依赖KVM（它本身自己可以做CPU和内存的模拟，只不过效率较低），而KVM是另一套虚拟化解决方案，对CPU进行虚拟效率较高（采用了硬件辅助虚拟化），但本身不提供其他设备的虚拟化，借用了QEMU的代码进行了定制，所以KVM方案一定要依赖QEMU\n\n * QEMU-KVM：\n   \n   1.提供对cpu，内存（KVM负责），IO设备（QEMU负责）的虚拟\n   \n   2.对各种虚拟设备的创建，调用进行管理（QEMU负责）\n\n * libvirt： 只能简单的认为是个虚拟机管理工具，仍然需要通过用户空间QEMU来与KVM进行交互。 一些常用的虚拟机管理工具如virsh（类似vim编辑器），virt-install，virt-manager等和云计算框架平台（如OpenStack，OpenNebula，Eucalyptus等）都在底层使用libvirt提供的应用程序接口。\n\n * Hyper-V：\n\n * xen:\n\n * VSOCK：软件包vsock提供了对Linux VM套接字（ AF_VSOCK ）的访问，以在虚拟机管理程序与其虚拟机之间进行通信。\n\n * Hypervisor: 借助虚拟化技术，用户能以单个物理硬件系统为基础创建多个模拟环境或专用资源。称为"Hypervisor" （虚拟机监控程序）\n\n * 大页内存：增加内存一页的大小，默认是开启的,提高虚拟机内存的io性能 cat /sys/kernel/mm/transparent_hugepage/enabled\n\n * KSM KSM内存合并,相同的页合并：ps -aux | grep ksm | grep -v grep\n\n * noop： 系统内核io的调度算法，如果是ssd硬盘需要使用的是noop内核调度； cat /sys/block/sda/queue/scheduler\n\n\n# 虚拟化有两种不同类型的虚拟机监控程序:\n\n（1）. 运行与物理机之上；物理机 --\x3e hypervisor 例如：kvm、Microsoft Hyper-V 和 VMware vSphere （2）. 运行与操作系统之上；物理机 --\x3e OS --\x3e Hypervisor 例如：VMware Workstation 和 Oracle VirtualBox',normalizedContent:'# 概念\n\n * kvm：kernel-based virtual machine 基于内核的虚拟机；只负责cpu和内存的虚拟化\n\n * qemu-kvm：kvm用户空间管理工具；\n\n * libvirt：管理kvm虚拟机的软件；\n\n * qemu： qemu是一个独立的虚拟化解决方案，并不依赖kvm（它本身自己可以做cpu和内存的模拟，只不过效率较低），而kvm是另一套虚拟化解决方案，对cpu进行虚拟效率较高（采用了硬件辅助虚拟化），但本身不提供其他设备的虚拟化，借用了qemu的代码进行了定制，所以kvm方案一定要依赖qemu\n\n * qemu-kvm：\n   \n   1.提供对cpu，内存（kvm负责），io设备（qemu负责）的虚拟\n   \n   2.对各种虚拟设备的创建，调用进行管理（qemu负责）\n\n * libvirt： 只能简单的认为是个虚拟机管理工具，仍然需要通过用户空间qemu来与kvm进行交互。 一些常用的虚拟机管理工具如virsh（类似vim编辑器），virt-install，virt-manager等和云计算框架平台（如openstack，opennebula，eucalyptus等）都在底层使用libvirt提供的应用程序接口。\n\n * hyper-v：\n\n * xen:\n\n * vsock：软件包vsock提供了对linux vm套接字（ af_vsock ）的访问，以在虚拟机管理程序与其虚拟机之间进行通信。\n\n * hypervisor: 借助虚拟化技术，用户能以单个物理硬件系统为基础创建多个模拟环境或专用资源。称为"hypervisor" （虚拟机监控程序）\n\n * 大页内存：增加内存一页的大小，默认是开启的,提高虚拟机内存的io性能 cat /sys/kernel/mm/transparent_hugepage/enabled\n\n * ksm ksm内存合并,相同的页合并：ps -aux | grep ksm | grep -v grep\n\n * noop： 系统内核io的调度算法，如果是ssd硬盘需要使用的是noop内核调度； cat /sys/block/sda/queue/scheduler\n\n\n# 虚拟化有两种不同类型的虚拟机监控程序:\n\n（1）. 运行与物理机之上；物理机 --\x3e hypervisor 例如：kvm、microsoft hyper-v 和 vmware vsphere （2）. 运行与操作系统之上；物理机 --\x3e os --\x3e hypervisor 例如：vmware workstation 和 oracle virtualbox',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"Linux系统下的用户审计方法",frontmatter:{title:"Linux系统下的用户审计方法",date:"2022-08-02T11:51:37.000Z",permalink:"/pages/yhsjff/",categories:["技术杂谈","运维脚本"],tags:["脚本"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"Linux系统下的用户审计方法"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/08.%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC/01.Linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E7%94%A8%E6%88%B7%E5%AE%A1%E8%AE%A1%E6%96%B9%E6%B3%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"Linux系统下的用户审计方法"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/08.%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC/01.Linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E7%94%A8%E6%88%B7%E5%AE%A1%E8%AE%A1%E6%96%B9%E6%B3%95.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-08-02T11:51:37.000Z"},{property:"article:tag",content:"脚本"},{itemprop:"name",content:"Linux系统下的用户审计方法"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/08.%E8%BF%90%E7%BB%B4%E8%84%9A%E6%9C%AC/01.Linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E7%9A%84%E7%94%A8%E6%88%B7%E5%AE%A1%E8%AE%A1%E6%96%B9%E6%B3%95.html",relativePath:"01.技术杂谈/08.运维脚本/01.Linux系统下的用户审计方法.md",key:"v-a2c6b924",path:"/pages/yhsjff/",headers:[{level:2,title:"json",slug:"json",normalizedTitle:"json",charIndex:57},{level:2,title:"text",slug:"text",normalizedTitle:"text",charIndex:1136}],headersStr:"json text",content:"通过利用环境变量PROMPT_COMMAND，可以做到将所有用户执行命令的记录，集中记录在一个日志文件。\n\n\n# json\n\n添加下面内容到~/.bashrc\n\nHISTDIR='/var/log/operation'\nif [ ! -d $HISTDIR ]\nthen\n  mkdir -p $HISTDIR\n  chmod -R 777 $HISTDIR\nfi\n\nexport HISTTIMEFORMAT=\"{\\\"time\\\":\\\"%FT%T\\\",\\\"ip\\\":\\\"$(who -u am i 2>/dev/null| awk '{print $NF}'|sed -e 's/[()]//g')\\\",\\\"Luser\\\":\\\"$(who am i|awk '{print $1}')\\\",\\\"Ouser\\\":\\\"$(whoami)\\\",\\\"cmd\\\":\\\"\"\n\n# export PROMPT_COMMAND='history 1|tail -1|sed \"s/^[ ]\\+[0-9]\\+ //\"|sed \"s/$/\\\"}/\">>  $HISTDIR/operation-`date '+%Y-%m-%d'`.log'  这样写会导致空行会重复记录上一个记录\n\nexport PROMPT_COMMAND=\"HistID0=\\$(history 1|awk '{print \\$1}'); \\\nlastcommand=\\$(history 1|awk '{\\$1=\\\"\\\" ;print}');\\\nlogin_pid=\\$(who -u am i | awk '{print \\$(NF-1)}')\nlogin_ip=\\$(who -u am i | awk -F '\\\\\\(|\\\\\\)' '{print \\$2}'); \\\nif [ \\${HistID0}x != \\${HistID1}x ];then \\\nhistory 1|tail -1|sed 's/^[ ]\\+[0-9]\\+ //'|sed 's/$/\\\"}/'>>  $HISTDIR/operation-`date '+%Y-%m-%d'`.log; \\\nHistID1=\\${HistID0}; \\\nfi;\"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\nsource ~/.bashrc\n\nexport PROMPT_COMMAND='history 1|tail -1|sed \"s/^[ ]+[0-9]+ //\"|sed \"s/$/\"}/\">> $HISTDIR/operation-date'+%Y-%m-%d'.log'\n\n\n# text\n\nvi /etc/profile.d/prompt-command.sh\n\nif [ ! -d /var/log/operation ]\nthen\n  mkdir -p /var/log/operation\n  chmod -R 777 /var/log/operation\nfi\n \nexport PROMPT_COMMAND=\"HistID0=\\$(history 1|awk '{print \\$1}'); \\\nlastcommand=\\$(history 1|awk '{\\$1=\\\"\\\" ;print}');\\\nlogin_pid=\\$(who -u am i | awk '{print \\$(NF-1)}')\nlogin_ip=\\$(who -u am i | awk -F '\\\\\\(|\\\\\\)' '{print \\$2}'); \\\nif [ \\${HistID0}x != \\${HistID1}x ];then \\\necho -E [\\$(date \\\"+%Y/%m/%d %H:%M:%S\\\")] [sshpid:\\${login_pid}] [fromip:\\${login_ip}] [\\$(id -un)@\\$(hostname) \\$(pwd)]  \\${lastcommand} >> /var/log/operation/operation-`date '+%Y-%m-%d'`.log; \\\nHistID1=\\${HistID0}; \\\nfi;\"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",normalizedContent:"通过利用环境变量prompt_command，可以做到将所有用户执行命令的记录，集中记录在一个日志文件。\n\n\n# json\n\n添加下面内容到~/.bashrc\n\nhistdir='/var/log/operation'\nif [ ! -d $histdir ]\nthen\n  mkdir -p $histdir\n  chmod -r 777 $histdir\nfi\n\nexport histtimeformat=\"{\\\"time\\\":\\\"%ft%t\\\",\\\"ip\\\":\\\"$(who -u am i 2>/dev/null| awk '{print $nf}'|sed -e 's/[()]//g')\\\",\\\"luser\\\":\\\"$(who am i|awk '{print $1}')\\\",\\\"ouser\\\":\\\"$(whoami)\\\",\\\"cmd\\\":\\\"\"\n\n# export prompt_command='history 1|tail -1|sed \"s/^[ ]\\+[0-9]\\+ //\"|sed \"s/$/\\\"}/\">>  $histdir/operation-`date '+%y-%m-%d'`.log'  这样写会导致空行会重复记录上一个记录\n\nexport prompt_command=\"histid0=\\$(history 1|awk '{print \\$1}'); \\\nlastcommand=\\$(history 1|awk '{\\$1=\\\"\\\" ;print}');\\\nlogin_pid=\\$(who -u am i | awk '{print \\$(nf-1)}')\nlogin_ip=\\$(who -u am i | awk -f '\\\\\\(|\\\\\\)' '{print \\$2}'); \\\nif [ \\${histid0}x != \\${histid1}x ];then \\\nhistory 1|tail -1|sed 's/^[ ]\\+[0-9]\\+ //'|sed 's/$/\\\"}/'>>  $histdir/operation-`date '+%y-%m-%d'`.log; \\\nhistid1=\\${histid0}; \\\nfi;\"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n\n\nsource ~/.bashrc\n\nexport prompt_command='history 1|tail -1|sed \"s/^[ ]+[0-9]+ //\"|sed \"s/$/\"}/\">> $histdir/operation-date'+%y-%m-%d'.log'\n\n\n# text\n\nvi /etc/profile.d/prompt-command.sh\n\nif [ ! -d /var/log/operation ]\nthen\n  mkdir -p /var/log/operation\n  chmod -r 777 /var/log/operation\nfi\n \nexport prompt_command=\"histid0=\\$(history 1|awk '{print \\$1}'); \\\nlastcommand=\\$(history 1|awk '{\\$1=\\\"\\\" ;print}');\\\nlogin_pid=\\$(who -u am i | awk '{print \\$(nf-1)}')\nlogin_ip=\\$(who -u am i | awk -f '\\\\\\(|\\\\\\)' '{print \\$2}'); \\\nif [ \\${histid0}x != \\${histid1}x ];then \\\necho -e [\\$(date \\\"+%y/%m/%d %h:%m:%s\\\")] [sshpid:\\${login_pid}] [fromip:\\${login_ip}] [\\$(id -un)@\\$(hostname) \\$(pwd)]  \\${lastcommand} >> /var/log/operation/operation-`date '+%y-%m-%d'`.log; \\\nhistid1=\\${histid0}; \\\nfi;\"\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"开启硬件虚拟化",frontmatter:{title:"开启硬件虚拟化",date:"2022-07-27T14:56:49.000Z",permalink:"/pages/6f3d25/",categories:["技术杂谈","虚拟化"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"开启硬件虚拟化"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/01.%E5%BC%80%E5%90%AF%E7%A1%AC%E4%BB%B6%E8%99%9A%E6%8B%9F%E5%8C%96.html"},{property:"og:type",content:"article"},{property:"og:title",content:"开启硬件虚拟化"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/01.%E5%BC%80%E5%90%AF%E7%A1%AC%E4%BB%B6%E8%99%9A%E6%8B%9F%E5%8C%96.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T14:56:49.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"开启硬件虚拟化"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/07.%E8%99%9A%E6%8B%9F%E5%8C%96/01.%E5%BC%80%E5%90%AF%E7%A1%AC%E4%BB%B6%E8%99%9A%E6%8B%9F%E5%8C%96.html",relativePath:"01.技术杂谈/07.虚拟化/01.开启硬件虚拟化.md",key:"v-4a20ad90",path:"/pages/6f3d25/",headers:[{level:2,title:"开启硬件虚拟化",slug:"开启硬件虚拟化",normalizedTitle:"开启硬件虚拟化",charIndex:2},{level:3,title:"1.BIOS 启用虚拟化",slug:"_1-bios-启用虚拟化",normalizedTitle:"1.bios 启用虚拟化",charIndex:14},{level:3,title:"2.加载内核模块",slug:"_2-加载内核模块",normalizedTitle:"2.加载内核模块",charIndex:61},{level:3,title:"3.IOMMU开启：",slug:"_3-iommu开启",normalizedTitle:"3.iommu开启：",charIndex:115},{level:3,title:'4.egrep --color -i "svm|vmx" /proc/cpuinfo',slug:"_4-egrep-color-i-svm-vmx-proc-cpuinfo",normalizedTitle:"4.egrep --color -i &quot;svm|vmx&quot; /proc/cpuinfo",charIndex:null},{level:2,title:"检查虚拟化",slug:"检查虚拟化",normalizedTitle:"检查虚拟化",charIndex:663}],headersStr:'开启硬件虚拟化 1.BIOS 启用虚拟化 2.加载内核模块 3.IOMMU开启： 4.egrep --color -i "svm|vmx" /proc/cpuinfo 检查虚拟化',content:'# 开启硬件虚拟化\n\n\n# 1.BIOS 启用虚拟化\n\n设置bios中的硬件支持VT-x，即CPU支持的虚拟化；\n\n\n# 2.加载内核模块\n\nmodprobe kvm-intel modprobe vhost-vsock\n\n\n# 3.IOMMU开启：\n\n判断是否amd/intel: ls /sys/firmware/ | grep efi\n\n1 修改/etc/default/grub, 调整GRUB_CMDLINE_LINUX内容\n\n * amd_iommu：\n\n> GRUB_CMDLINE_LINUX="crashkernel=auto rhgb quiet amd_iommu=on iommu=pt"\n\n * intel_iommu：\n\n> GRUB_CMDLINE_LINUX="crashkernel=auto rhgb quiet intel_iommu=on iommu=pt"\n\n2 重新创建引导\n\n * 如果服务器是UEFI启动\n\n> grub2-mkconfig -o /boot/efi/EFI/centos/grub.cfg\n\n * 普通LEGACY模式启动\n\n> grub2-mkconfig -o /boot/grub2/grub.cfg\n\n3 reboot\n\nIOMMU关闭：\n\n1 修改/etc/default/grub，删除iommu配置\n\n2 重新创建引导同上\n\n3 reboot\n\n\n# 4.egrep --color -i "svm|vmx" /proc/cpuinfo\n\n\n# 检查虚拟化\n\n检查是否虚拟机：\n\n> systemd-detect-virt egrep --color -i "svm|vmx" /proc/cpuinfo\n\n判断当前环境所使用的虚拟技术：\n\n> virt-what\n\n检测 Linux 底层的虚拟化类型:\n\n> dmidecode -s system-manufacturer virsh vcpuinfo --domain hfftest',normalizedContent:'# 开启硬件虚拟化\n\n\n# 1.bios 启用虚拟化\n\n设置bios中的硬件支持vt-x，即cpu支持的虚拟化；\n\n\n# 2.加载内核模块\n\nmodprobe kvm-intel modprobe vhost-vsock\n\n\n# 3.iommu开启：\n\n判断是否amd/intel: ls /sys/firmware/ | grep efi\n\n1 修改/etc/default/grub, 调整grub_cmdline_linux内容\n\n * amd_iommu：\n\n> grub_cmdline_linux="crashkernel=auto rhgb quiet amd_iommu=on iommu=pt"\n\n * intel_iommu：\n\n> grub_cmdline_linux="crashkernel=auto rhgb quiet intel_iommu=on iommu=pt"\n\n2 重新创建引导\n\n * 如果服务器是uefi启动\n\n> grub2-mkconfig -o /boot/efi/efi/centos/grub.cfg\n\n * 普通legacy模式启动\n\n> grub2-mkconfig -o /boot/grub2/grub.cfg\n\n3 reboot\n\niommu关闭：\n\n1 修改/etc/default/grub，删除iommu配置\n\n2 重新创建引导同上\n\n3 reboot\n\n\n# 4.egrep --color -i "svm|vmx" /proc/cpuinfo\n\n\n# 检查虚拟化\n\n检查是否虚拟机：\n\n> systemd-detect-virt egrep --color -i "svm|vmx" /proc/cpuinfo\n\n判断当前环境所使用的虚拟技术：\n\n> virt-what\n\n检测 linux 底层的虚拟化类型:\n\n> dmidecode -s system-manufacturer virsh vcpuinfo --domain hfftest',charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"养桃花销",frontmatter:{title:"养桃花销",date:"2022-12-25T14:27:01.000Z",permalink:"/pages/ythx",categories:["生活随写","养桃日记"],tags:["桃子"],author:{name:"fangfenghuang",link:"https://github.com/fangfenghuang"},titleTag:"原创",readingShow:"top",description:"|日期|物品|总价|备注|\n|----|----|--------|---------|\n|2019/7/5|桃子|1700",meta:[{name:"twitter:title",content:"养桃花销"},{name:"twitter:description",content:"|日期|物品|总价|备注|\n|----|----|--------|---------|\n|2019/7/5|桃子|1700"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/01.%E5%85%BB%E6%A1%83%E8%8A%B1%E9%94%80.html"},{property:"og:type",content:"article"},{property:"og:title",content:"养桃花销"},{property:"og:description",content:"|日期|物品|总价|备注|\n|----|----|--------|---------|\n|2019/7/5|桃子|1700"},{property:"og:url",content:"https://fangfenghuang.github.io/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/01.%E5%85%BB%E6%A1%83%E8%8A%B1%E9%94%80.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-12-25T14:27:01.000Z"},{property:"article:tag",content:"桃子"},{itemprop:"name",content:"养桃花销"},{itemprop:"description",content:"|日期|物品|总价|备注|\n|----|----|--------|---------|\n|2019/7/5|桃子|1700"}]},regularPath:"/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/01.%E5%85%BB%E6%A1%83%E8%8A%B1%E9%94%80.html",relativePath:"02.生活随写/01.养桃日记/01.养桃花销.md",key:"v-51e55098",path:"/pages/ythx/",headers:[{level:2,title:"养桃花销",slug:"养桃花销",normalizedTitle:"养桃花销",charIndex:2},{level:2,title:"猫粮明细",slug:"猫粮明细",normalizedTitle:"猫粮明细",charIndex:62}],headersStr:"养桃花销 猫粮明细",content:"# 养桃花销\n\n日期         物品   总价     备注\n2019/7/5   桃子   1700   \n\n\n# 猫粮明细\n\n日期     物品   总价   备注\n2019   猫粮        \n2020   猫粮        \n2021   猫粮        ",normalizedContent:"# 养桃花销\n\n日期         物品   总价     备注\n2019/7/5   桃子   1700   \n\n\n# 猫粮明细\n\n日期     物品   总价   备注\n2019   猫粮        \n2020   猫粮        \n2021   猫粮        ",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"敬请等待",frontmatter:{title:"敬请等待",date:"2022-10-09T17:51:37.000Z",permalink:"/pages/jqdd/",categories:["技术杂谈","软考高项"],tags:["软考","项目管理"],author:"fangfenghuang",titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"敬请等待"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/09.%E8%BD%AF%E8%80%83%E9%AB%98%E9%A1%B9/01.%E6%95%AC%E8%AF%B7%E7%AD%89%E5%BE%85.html"},{property:"og:type",content:"article"},{property:"og:title",content:"敬请等待"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/09.%E8%BD%AF%E8%80%83%E9%AB%98%E9%A1%B9/01.%E6%95%AC%E8%AF%B7%E7%AD%89%E5%BE%85.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T17:51:37.000Z"},{property:"article:tag",content:"软考"},{property:"article:tag",content:"项目管理"},{itemprop:"name",content:"敬请等待"},{itemprop:"description",content:""}]},regularPath:"/01.%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/09.%E8%BD%AF%E8%80%83%E9%AB%98%E9%A1%B9/01.%E6%95%AC%E8%AF%B7%E7%AD%89%E5%BE%85.html",relativePath:"01.技术杂谈/09.软考高项/01.敬请等待.md",key:"v-20df4130",path:"/pages/jqdd/",headers:[{level:2,title:"等我考过再说",slug:"等我考过再说",normalizedTitle:"等我考过再说",charIndex:2}],headersStr:"等我考过再说",content:"# 等我考过再说",normalizedContent:"# 等我考过再说",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"养猫劝退",frontmatter:{title:"养猫劝退",date:"2022-10-09T18:28:02.000Z",permalink:"/pages/2bb179/",categories:["生活随写","养桃日记"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"养猫劝退"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/02.%E5%85%BB%E7%8C%AB%E5%8A%9D%E9%80%80.html"},{property:"og:type",content:"article"},{property:"og:title",content:"养猫劝退"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/02.%E5%85%BB%E7%8C%AB%E5%8A%9D%E9%80%80.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T18:28:02.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"养猫劝退"},{itemprop:"description",content:""}]},regularPath:"/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/02.%E5%85%BB%E7%8C%AB%E5%8A%9D%E9%80%80.html",relativePath:"02.生活随写/01.养桃日记/02.养猫劝退.md",key:"v-1efcbbda",path:"/pages/2bb179/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"养桃笔记",frontmatter:{title:"养桃笔记",date:"2022-10-09T18:28:02.000Z",permalink:"/pages/b5e483/",categories:["生活随写","养桃日记"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"养桃笔记"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/03.%E5%85%BB%E6%A1%83%E7%AC%94%E8%AE%B0.html"},{property:"og:type",content:"article"},{property:"og:title",content:"养桃笔记"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/03.%E5%85%BB%E6%A1%83%E7%AC%94%E8%AE%B0.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-10-09T18:28:02.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"养桃笔记"},{itemprop:"description",content:""}]},regularPath:"/02.%E7%94%9F%E6%B4%BB%E9%9A%8F%E5%86%99/01.%E5%85%BB%E6%A1%83%E6%97%A5%E8%AE%B0/03.%E5%85%BB%E6%A1%83%E7%AC%94%E8%AE%B0.html",relativePath:"02.生活随写/01.养桃日记/03.养桃笔记.md",key:"v-09ac84c7",path:"/pages/b5e483/",headers:[{level:2,title:"疫苗记录",slug:"疫苗记录",normalizedTitle:"疫苗记录",charIndex:2},{level:2,title:"驱虫记录",slug:"驱虫记录",normalizedTitle:"驱虫记录",charIndex:11},{level:2,title:"",slug:"",normalizedTitle:"",charIndex:0}],headersStr:"疫苗记录 驱虫记录 ",content:"# 疫苗记录\n\n\n# 驱虫记录\n\n\n#",normalizedContent:"# 疫苗记录\n\n\n# 驱虫记录\n\n\n#",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"书单",frontmatter:{title:"书单",permalink:"/books/",date:"2022-04-19T11:33:04.000Z",article:!1,author:{name:"fangfenghuang",link:"https://github.com/fangfenghuang"},titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"书单"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/04.%E9%98%85%E8%AF%BB/01.%E4%B9%A6%E5%8D%95.html"},{property:"og:type",content:"article"},{property:"og:title",content:"书单"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/04.%E9%98%85%E8%AF%BB/01.%E4%B9%A6%E5%8D%95.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-04-19T11:33:04.000Z"},{itemprop:"name",content:"书单"},{itemprop:"description",content:""}]},regularPath:"/04.%E9%98%85%E8%AF%BB/01.%E4%B9%A6%E5%8D%95.html",relativePath:"04.阅读/01.书单.md",key:"v-7d5d8b2d",path:"/books/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"关于",frontmatter:{title:"关于",date:"2022-12-25T14:27:01.000Z",permalink:"/about/",sidebar:!1,article:!1,author:{name:"fangfenghuang",link:"https://github.com/fangfenghuang"},titleTag:"原创",readingShow:"top",description:"当前代码为博客源码，博客网页为静态部署，发布分支（pages source）为gh-pages",meta:[{name:"twitter:title",content:"关于"},{name:"twitter:description",content:"当前代码为博客源码，博客网页为静态部署，发布分支（pages source）为gh-pages"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/03.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html"},{property:"og:type",content:"article"},{property:"og:title",content:"关于"},{property:"og:description",content:"当前代码为博客源码，博客网页为静态部署，发布分支（pages source）为gh-pages"},{property:"og:url",content:"https://fangfenghuang.github.io/03.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-12-25T14:27:01.000Z"},{itemprop:"name",content:"关于"},{itemprop:"description",content:"当前代码为博客源码，博客网页为静态部署，发布分支（pages source）为gh-pages"}]},regularPath:"/03.%E5%85%B3%E4%BA%8E/01.%E5%85%B3%E4%BA%8E.html",relativePath:"03.关于/01.关于.md",key:"v-4ed9e4ca",path:"/about/",headers:[{level:2,title:"关于本站",slug:"关于本站",normalizedTitle:"关于本站",charIndex:2},{level:2,title:"关于我",slug:"关于我",normalizedTitle:"关于我",charIndex:129}],headersStr:"关于本站 关于我",content:"# 关于本站\n\n一个基于vuepress-theme-vdoing + github page + markdown生成的个人网站\n\n当前代码为博客源码，博客网页为静态部署，发布分支（pages source）为gh-pages\n\ngithub地址\n\n\n# 关于我\n\n我的简历",normalizedContent:"# 关于本站\n\n一个基于vuepress-theme-vdoing + github page + markdown生成的个人网站\n\n当前代码为博客源码，博客网页为静态部署，发布分支（pages source）为gh-pages\n\ngithub地址\n\n\n# 关于我\n\n我的简历",charsets:{cjk:!0},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3},{title:"优质博客",frontmatter:{title:"优质博客",date:"2022-07-27T15:12:21.000Z",permalink:"/pages/yzbook/",categories:["阅读"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"优质博客"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/04.%E9%98%85%E8%AF%BB/02.%E4%BC%98%E8%B4%A8%E5%8D%9A%E5%AE%A2.html"},{property:"og:type",content:"article"},{property:"og:title",content:"优质博客"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/04.%E9%98%85%E8%AF%BB/02.%E4%BC%98%E8%B4%A8%E5%8D%9A%E5%AE%A2.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T15:12:21.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"优质博客"},{itemprop:"description",content:""}]},regularPath:"/04.%E9%98%85%E8%AF%BB/02.%E4%BC%98%E8%B4%A8%E5%8D%9A%E5%AE%A2.html",relativePath:"04.阅读/02.优质博客.md",key:"v-6202dee6",path:"/pages/yzbook/",headers:[{level:2,title:"go",slug:"go",normalizedTitle:"go",charIndex:121},{level:2,title:"k8s",slug:"k8s",normalizedTitle:"k8s",charIndex:139},{level:2,title:"leetcode",slug:"leetcode",normalizedTitle:"leetcode",charIndex:248}],headersStr:"go k8s leetcode",content:"https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/\n\nhttps://github1s.com/xmapst/kubefilebrowser/blob/HEAD/README.md\n\n\n# go\n\n讲通关Go语言-完\n\n\n# k8s\n\nhttps://cloudnative.to/blog/ 云原生社区 https://jimmysong.io/blog/ https://lib.jimmysong.io/blog/ 云原生资料库\n\n\n# leetcode\n\nhttps://github.com/honglei24/leetcode\n\nhttps://mojotv.cn/golang/golang-html5-websocket-remote-desktop golang python\n\n二丫讲梵 运维 技术\n\nhttps://houmin.cc/\n\nhttps://qiankunli.github.io/ 李乾坤的博客",normalizedContent:"https://learn.lianglianglee.com/%e4%b8%93%e6%a0%8f/\n\nhttps://github1s.com/xmapst/kubefilebrowser/blob/head/readme.md\n\n\n# go\n\n讲通关go语言-完\n\n\n# k8s\n\nhttps://cloudnative.to/blog/ 云原生社区 https://jimmysong.io/blog/ https://lib.jimmysong.io/blog/ 云原生资料库\n\n\n# leetcode\n\nhttps://github.com/honglei24/leetcode\n\nhttps://mojotv.cn/golang/golang-html5-websocket-remote-desktop golang python\n\n二丫讲梵 运维 技术\n\nhttps://houmin.cc/\n\nhttps://qiankunli.github.io/ 李乾坤的博客",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"优质开源项目",frontmatter:{title:"优质开源项目",date:"2022-07-27T15:12:21.000Z",permalink:"/pages/yzgihub/",categories:["阅读"],tags:[null],titleTag:"原创",readingShow:"top",description:"",meta:[{name:"twitter:title",content:"优质开源项目"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/04.%E9%98%85%E8%AF%BB/03.%E4%BC%98%E8%B4%A8%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE.html"},{property:"og:type",content:"article"},{property:"og:title",content:"优质开源项目"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/04.%E9%98%85%E8%AF%BB/03.%E4%BC%98%E8%B4%A8%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE.html"},{property:"og:site_name",content:"fangfenghuang"},{property:"article:published_time",content:"2022-07-27T15:12:21.000Z"},{property:"article:tag",content:null},{itemprop:"name",content:"优质开源项目"},{itemprop:"description",content:""}]},regularPath:"/04.%E9%98%85%E8%AF%BB/03.%E4%BC%98%E8%B4%A8%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE.html",relativePath:"04.阅读/03.优质开源项目.md",key:"v-18dfbaf2",path:"/pages/yzgihub/",headers:[{level:2,title:"面经",slug:"面经",normalizedTitle:"面经",charIndex:2},{level:2,title:"软考",slug:"软考",normalizedTitle:"软考",charIndex:85}],headersStr:"面经 软考",content:"# 面经\n\nhttps://github.com/CyC2018/CS-Notes 技术面试必备基础知识、Leetcode、计算机操作系统、计算机网络、系统设计\n\n\n# 软考\n\nhttps://github.com/xxlllq/system_architect 系统架构设计师复习资料",normalizedContent:"# 面经\n\nhttps://github.com/cyc2018/cs-notes 技术面试必备基础知识、leetcode、计算机操作系统、计算机网络、系统设计\n\n\n# 软考\n\nhttps://github.com/xxlllq/system_architect 系统架构设计师复习资料",charsets:{cjk:!0},lastUpdated:"2022/10/09, 17:42:01",lastUpdatedTimestamp:1665308521e3},{title:"归档",frontmatter:{archivesPage:!0,title:"归档",permalink:"/archives/",article:!1,readingShow:"top",description:"",meta:[{name:"twitter:title",content:"归档"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/@pages/archivesPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"归档"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/@pages/archivesPage.html"},{property:"og:site_name",content:"fangfenghuang"},{itemprop:"name",content:"归档"},{itemprop:"description",content:""}]},regularPath:"/@pages/archivesPage.html",relativePath:"@pages/archivesPage.md",key:"v-994f98d2",path:"/archives/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/27, 18:59:09",lastUpdatedTimestamp:1658919549e3},{title:"分类",frontmatter:{categoriesPage:!0,title:"分类",permalink:"/categories/",article:!1,readingShow:"top",description:"",meta:[{name:"twitter:title",content:"分类"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/@pages/categoriesPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"分类"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/@pages/categoriesPage.html"},{property:"og:site_name",content:"fangfenghuang"},{itemprop:"name",content:"分类"},{itemprop:"description",content:""}]},regularPath:"/@pages/categoriesPage.html",relativePath:"@pages/categoriesPage.md",key:"v-ea545412",path:"/categories/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/27, 18:59:09",lastUpdatedTimestamp:1658919549e3},{title:"标签",frontmatter:{tagsPage:!0,title:"标签",permalink:"/tags/",article:!1,readingShow:"top",description:"",meta:[{name:"twitter:title",content:"标签"},{name:"twitter:description",content:""},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/@pages/tagsPage.html"},{property:"og:type",content:"article"},{property:"og:title",content:"标签"},{property:"og:description",content:""},{property:"og:url",content:"https://fangfenghuang.github.io/@pages/tagsPage.html"},{property:"og:site_name",content:"fangfenghuang"},{itemprop:"name",content:"标签"},{itemprop:"description",content:""}]},regularPath:"/@pages/tagsPage.html",relativePath:"@pages/tagsPage.md",key:"v-1d3069d2",path:"/tags/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/07/27, 18:59:09",lastUpdatedTimestamp:1658919549e3},{title:"Home",frontmatter:{home:!0,heroText:"hff's blog",tagline:"天道酬勤",bannerBg:"/img/bg.jpg",features:[{title:"技术杂谈",details:"工作、学习",link:"/tech/"},{title:"生活随写",details:"个人、生活",link:"/life/"}],readingShow:"top",description:"https://fangfenghuang.github.io/",meta:[{name:"twitter:title",content:"hff"},{name:"twitter:description",content:"https://fangfenghuang.github.io/"},{name:"twitter:card",content:"summary"},{name:"twitter:url",content:"https://fangfenghuang.github.io/"},{property:"og:type",content:"website"},{property:"og:title",content:"hff"},{property:"og:description",content:"https://fangfenghuang.github.io/"},{property:"og:url",content:"https://fangfenghuang.github.io/"},{property:"og:site_name",content:"fangfenghuang"},{itemprop:"name",content:"hff"},{itemprop:"description",content:"https://fangfenghuang.github.io/"}]},regularPath:"/",relativePath:"index.md",key:"v-0c8b6730",path:"/",headersStr:null,content:"",normalizedContent:"",charsets:{},lastUpdated:"2022/08/24, 18:07:47",lastUpdatedTimestamp:1661335667e3}],themeConfig:{nav:[{text:"首页",link:"/"},{text:"学习",link:"/tech/"},{text:"生活",link:"/life/",items:[{text:"养桃日记",link:"/pages/ythx/"}]},{text:"关于",link:"/about/"},{text:"索引",link:"/categories/",items:[{text:"分类",link:"/categories/"},{text:"标签",link:"/tags/"},{text:"归档",link:"/archives/"},{items:[{text:"github",link:"https://github.com/fangfenghuang"},{text:"scdn",link:"https://blog.csdn.net/qq_26572567"},{text:"知乎",link:"https://www.zhihu.com/people/huangfangfeng-20"},{text:"linkin",link:"https://www.linkedin.com/"}]}]},{text:"阅读",link:"/books/",items:[{items:[{text:"书单",link:"/books/"},{text:"电子书",link:"/pages/dianzishu/"},{text:"优质博客",link:"/pages/yzbook/"}]}]}],sidebarDepth:2,logo:"/img/logo.png",repo:"https://github.com/fangfenghuang/fangfenghuang.github.io",searchMaxSuggestions:10,lastUpdated:"上次更新",editLinks:!1,sidebarHoverTriggerOpen:!0,searchPlaceholder:"按下 𝑺 搜索",extendFrontmatter:{titleTag:"原创"},pageButton:!1,sidebar:{"/00.目录页/":[["01.技术杂谈.md","技术杂谈","/tech/","原创"],["02.生活随写.md","生活随写","/life/","原创"]],catalogue:{"技术杂谈":"/tech/","生活随写":"/life/"},"/01.技术杂谈/":[{title:"常用总结",collapsable:!0,children:[["01.常用总结/01.一些常用配置.md","一些常用配置","/pages/yxcypz/","原创"],["01.常用总结/02.一些工具网站.md","一些工具网站","/pages/yxgjwz/","原创"],["01.常用总结/03.一些工具安装.md","一些工具安装","/pages/yxgjaz/","原创"],["01.常用总结/04.markdown常用语法组件.md","markdown常用语法组件","/pages/markdown/","原创"]]},{title:"踩坑记录",collapsable:!0,children:[["02.踩坑记录/01.2022踩坑记录.md","2022踩坑记录","/pages/2022ckjl/","原创"]]},{title:"kubernetes",collapsable:!0,children:[["03.kubernetes/01.k8s基础.md","k8s基础","/pages/k8s01/","原创"],["03.kubernetes/02.k8s存储.md","k8s存储","/pages/k8s02/","原创"],["03.kubernetes/03.k8s网络.md","k8s网络","/pages/k8s03/","原创"],["03.kubernetes/04.pod cgroup和资源限制.md","pod cgroup和资源限制","/pages/k8s04/","原创"],["03.kubernetes/05.流量限制.md","流量限制","/pages/k8s05/","原创"],["03.kubernetes/06.网络策略calico.md","网络策略calico","/pages/k8s06/","原创"],["03.kubernetes/07.grafana和promuthues.md","grafana和promuthues","/pages/k8s07/","原创"],["03.kubernetes/08.etcd节点down机数据恢复.md","etcd节点down机数据恢复","/pages/k8s08/","原创"],["03.kubernetes/09.ceph.md","ceph","/pages/k8s09/","原创"],["03.kubernetes/10.chrony.md","chrony","/pages/k8s10/","原创"],["03.kubernetes/11.crd operator.md","crd operator","/pages/k8s11/","原创"],["03.kubernetes/12.cri之containerd shimv2.md","cri之containerd shimv2","/pages/k8s12/","原创"],["03.kubernetes/13.harbor.md","harbor","/pages/k8s13/","原创"],["03.kubernetes/14.helm chart.md","helm chart","/pages/k8s14/","原创"],["03.kubernetes/15.Loongnix mips64.md","Loongnix mips64","/pages/k8s15/","原创"],["03.kubernetes/16.openebs-lvm-localpv.md","openebs-lvm-localpv","/pages/k8s16/","原创"],["03.kubernetes/17.traefik-ingressroute.md","traefik-IngressRoute","/pages/ingressroute/","原创"],["03.kubernetes/18.DevOps.md","DevOps","/pages/devops/","原创"],["03.kubernetes/19.serverless.md","Serverless","/pages/serverless/","原创"],["03.kubernetes/20.k8s容器故障处理.md","k8s容器故障处理","/pages/k8s20/","原创"],{title:"k8s面试",collapsable:!0,children:[["03.kubernetes/301.k8s面试/01.1.md",1,"/pages/k8smianshi1/","原创"]]},{title:"kubevirt",collapsable:!0,children:[["03.kubernetes/302.kubevirt/01.kubevirt原理.md","kubevirt原理","/pages/kubevirtyuanli/","原创"],["03.kubernetes/302.kubevirt/02.kubevirt部署.md","kubevirt部署","/pages/kubevirtdeploy/","原创"]]},{title:"kata-containers",collapsable:!0,children:[{title:"kata初识",collapsable:!0,children:[["03.kubernetes/303.kata-containers/01.kata初识/01.kata基本原理与架构.md","kata基本原理与架构","/pages/kata1/","原创"],["03.kubernetes/303.kata-containers/01.kata初识/02.kata网络和存储文件系统分析.md","kata网络和存储文件系统分析","/pages/kata2/","原创"],["03.kubernetes/303.kata-containers/01.kata初识/03.kata cgroup及资源限制.md","kata cgroup及资源限制","/pages/kata3/","原创"],["03.kubernetes/303.kata-containers/01.kata初识/04.guest kernel和guestos.md","guest kernel和guestos","/pages/kata4/","原创"],["03.kubernetes/303.kata-containers/01.kata初识/05.kata-monitor监控.md","kata-monitor监控","/pages/kata5/","原创"],["03.kubernetes/303.kata-containers/01.kata初识/06.kata使用限制.md","kata使用限制","/pages/kata6/","原创"],["03.kubernetes/303.kata-containers/01.kata初识/07.其他特性.md","其他特性","/pages/kata7/","原创"],["03.kubernetes/303.kata-containers/01.kata初识/08.一个kata容器的创建示例.md","一个kata容器的创建示例","/pages/kata8/","原创"]]},{title:"kata部署",collapsable:!0,children:[["03.kubernetes/303.kata-containers/02.kata部署/01.kata-deploy部署、卸载与升级.md","kata-deploy部署、卸载与升级","/pages/kata0201/","原创"],["03.kubernetes/303.kata-containers/02.kata部署/02.kata-deploy分析.md","kata-deploy分析","/pages/kata0202/","原创"]]},{title:"kata应用",collapsable:!0,children:[["03.kubernetes/303.kata-containers/04.kata应用/01.常用命令.md","常用命令","/pages/kata0401/","原创"],["03.kubernetes/303.kata-containers/04.kata应用/02.kata使用问题汇总.md","kata使用问题汇总","/pages/kata0402/","原创"],["03.kubernetes/303.kata-containers/04.kata应用/03.kata相关配置及路径.md","kata相关配置及路径","/pages/kata0403/","原创"],["03.kubernetes/303.kata-containers/04.kata应用/04.kata debug与日志.md","kata debug与日志","/pages/kata0404/","原创"]]},{title:"kataV3.0",collapsable:!0,children:[["03.kubernetes/303.kata-containers/05.kataV3.0/01.kata v3.0.md","kata3.0","/pages/kata0501/","原创"]]}]},{title:"docker",collapsable:!0,children:[["03.kubernetes/304.docker/01.buildx多平台构建.md","buildx多平台构建","/pages/docker01/","原创"],["03.kubernetes/304.docker/02.dockerfile改源.md","dockerfile改源","/pages/docker02/","原创"],["03.kubernetes/304.docker/03.docker镜像.md","docker镜像","/pages/docker03/","原创"],["03.kubernetes/304.docker/04.docker镜像优化.md","docker镜像优化","/pages/docker04/","原创"],["03.kubernetes/304.docker/05.在Docker中设置时区.md","在Docker中设置时区","/pages/docker05/","原创"],["03.kubernetes/304.docker/06.docker基础.md","docker基础","/pages/docker06/","原创"]]},{title:"日志采集",collapsable:!0,children:[["03.kubernetes/305.日志采集/01.日志采集方案.md","日志采集方案","/pages/rzcjfa/","原创"],["03.kubernetes/305.日志采集/02.fluentd配置.md","日志采集方案","/pages/fluentd-log/","原创"],["03.kubernetes/305.日志采集/03.events持久化.md","events持久化","/pages/fadb16/","原创"],["03.kubernetes/305.日志采集/04.alertmanager持久化.md","alertmanager持久化","/pages/alert-log/","原创"],["03.kubernetes/305.日志采集/05.loki.md","loki","/pages/loki/","原创"]]},{title:"GPU",collapsable:!0,children:[["03.kubernetes/306.GPU/01.nvidia-device-plugins.md","nvidia-device-plugin","/pages/gpu01/","原创"],["03.kubernetes/306.GPU/02.第四范式vGPU.md","第四范式vgpu","/pages/4paradigm/","原创"],["03.kubernetes/306.GPU/03.腾讯gpu-manager.md","腾讯gpu-manager","/pages/tencnt-cpu-manager/","原创"],["03.kubernetes/306.GPU/04.阿里gpu-share.md","阿里gpu-share","/pages/ali-gpushare/","原创"],["03.kubernetes/306.GPU/05.英伟达驱动安装.md","英伟达驱动安装","/pages/nvidiadevice/","原创"],["03.kubernetes/306.GPU/06.腾讯云qGPU.md","腾讯云qGPU","/pages/qgpu/","原创"]]}]},{title:"golang",collapsable:!0,children:[["04.golang/01.常用计算.md","常用计算","/pages/golang01/","原创"],["04.golang/02.golang面试问题.md","golang面试问题","/pages/golang02/","原创"],["04.golang/03.go-指针.md","go-指针","/pages/golang03/","原创"],["04.golang/04.go embed.md","go embed","/pages/golang04/","原创"],["04.golang/05.go-封装继承和多态.md","go-封装继承和多态","/pages/golang05/","原创"],["04.golang/06.go-文件操作.md","go-文件操作","/pages/golang06/","原创"],["04.golang/07.go-json.md","go-json","/pages/golang07/","原创"],["04.golang/08.go-slice切片.md","go-slice切片","/pages/golang08/","原创"],["04.golang/09.gin框架使用sockjs-go.md","gin框架使用sockjs-go","/pages/golang09/","原创"]]},{title:"python",collapsable:!0,children:[]},{title:"计算机网络基础",collapsable:!0,children:[["06.计算机网络基础/01.关于cgroup.md","关于cgroup","/pages/b5149c/","原创"],["06.计算机网络基础/02.关于cpu内存.md","关于cpu内存","/pages/95ef75/","原创"]]},{title:"虚拟化",collapsable:!0,children:[["07.虚拟化/01.开启硬件虚拟化.md","开启硬件虚拟化","/pages/6f3d25/","原创"],["07.虚拟化/02.虚拟化基础概念.md","虚拟化基础概念","/pages/697e48/","原创"],["07.虚拟化/03.centos使用kvm创建虚拟机.md","centos使用kvm创建虚拟机","/pages/33705b/","原创"]]},{title:"运维脚本",collapsable:!0,children:[["08.运维脚本/01.Linux系统下的用户审计方法.md","Linux系统下的用户审计方法","/pages/yhsjff/","原创"]]},{title:"软考高项",collapsable:!0,children:[["09.软考高项/01.敬请等待.md","敬请等待","/pages/jqdd/","原创"]]}],"/02.生活随写/":[{title:"养桃日记",collapsable:!0,children:[["01.养桃日记/01.养桃花销.md","养桃花销","/pages/ythx","原创"],["01.养桃日记/02.养猫劝退.md","养猫劝退","/pages/2bb179/","原创"],["01.养桃日记/03.养桃笔记.md","养桃笔记","/pages/b5e483/","原创"]]},{title:"菜谱",collapsable:!0,children:[]}],"/03.关于/":[["01.关于.md","关于","/about/","原创"]],"/04.阅读/":[["01.书单.md","书单","/books/","原创"],["02.优质博客.md","优质博客","/pages/yzbook/","原创"],["03.优质开源项目.md","优质开源项目","/pages/yzgihub/","原创"]]},author:{name:"hff",link:"https://github.com/fangfenghuang"},blogger:{avatar:"/img/bg.jpeg",name:"hff",slogan:"一个有思想的程序猿"},social:{icons:[{iconClass:"icon-github",title:"GitHub",link:"https://github.com/fangfenghuang"},{iconClass:"icon-youjian",title:"发邮件",link:"mailto:15068704759@163.com"},{iconClass:"icon-rss",title:"linkedin",link:"https://www.linkedin.com/in/huang-fangfeng-60887981/"}]},htmlModules:{homeSidebarB:'<div style="padding: 0.95rem">\n        <p style="\n          color: var(--textColor);\n          opacity: 0.9;\n          font-size: 20px;\n          font-weight: bold;\n          margin: 0 0 8px 0;\n        ">微信</p>\n        <img src="/img/weixin.jpg"  style="width:100%;" />\n        <p>\n        联系方式:fangfeng_huang\n        </p>\n        </div>'},footer:{createYear:2022,copyrightInfo:'| <a rel="nofollow " target="_blank" href="https://github.com/fangfenghuang/fangfenghuang.GitHub.io">@fangfenghuang</a>'}}};var yc=t(94),Ec=t(95),_c=t(11);var xc={computed:{$filterPosts(){return this.$site.pages.filter(n=>{const{frontmatter:{pageComponent:e,article:t,home:r}}=n;return!(e||!1===t||!0===r)})},$sortPosts(){return(n=this.$filterPosts).sort((n,e)=>{const t=n.frontmatter.sticky,r=e.frontmatter.sticky;return t&&r?t==r?Object(_c.a)(n,e):t-r:t&&!r?-1:!t&&r?1:Object(_c.a)(n,e)}),n;var n},$sortPostsByDate(){return(n=this.$filterPosts).sort((n,e)=>Object(_c.a)(n,e)),n;var n},$groupPosts(){return function(n){const e={},t={};for(let r=0,a=n.length;r<a;r++){const{frontmatter:{categories:a,tags:o}}=n[r];"array"===Object(_c.n)(a)&&a.forEach(t=>{t&&(e[t]||(e[t]=[]),e[t].push(n[r]))}),"array"===Object(_c.n)(o)&&o.forEach(e=>{e&&(t[e]||(t[e]=[]),t[e].push(n[r]))})}return{categories:e,tags:t}}(this.$sortPosts)},$categoriesAndTags(){return function(n){const e=[],t=[];for(let t in n.categories)e.push({key:t,length:n.categories[t].length});for(let e in n.tags)t.push({key:e,length:n.tags[e].length});return{categories:e,tags:t}}(this.$groupPosts)}}};Kt.component(yc.default),Kt.component(Ec.default);function wc(n){return n.toString().padStart(2,"0")}t(237);Kt.component("Badge",()=>Promise.all([t.e(0),t.e(4)]).then(t.bind(null,421))),Kt.component("CodeBlock",()=>Promise.resolve().then(t.bind(null,94))),Kt.component("CodeGroup",()=>Promise.resolve().then(t.bind(null,95)));t(238);var Ac,Cc,Bc,Tc,Pc=Object.defineProperty,Ic=Object.getOwnPropertySymbols,Sc=Object.prototype.hasOwnProperty,zc=Object.prototype.propertyIsEnumerable,Dc=(n,e,t)=>e in n?Pc(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,Oc=(n,e)=>{for(var t in e||(e={}))Sc.call(e,t)&&Dc(n,t,e[t]);if(Ic)for(var t of Ic(e))zc.call(e,t)&&Dc(n,t,e[t]);return n},jc=(n,e,t)=>{if(!e.has(n))throw TypeError("Cannot "+t)},qc=(n,e,t)=>(jc(n,e,"read from private field"),t?t.call(n):e.get(n)),$c=(n,e,t)=>{if(e.has(n))throw TypeError("Cannot add the same private member more than once");e instanceof WeakSet?e.add(n):e.set(n,t)},Mc=(n,e,t,r)=>(jc(n,e,"write to private field"),r?r.call(n,t):e.set(n,t),t);const Fc=class{constructor(n,e,t,r=!0){$c(this,Ac,void 0),$c(this,Cc,void 0),Mc(this,Ac,{width:0,height:0});const{el:a,ctx:o}=Fc.initCanvas(n);this.el=a,this.ctx=o,Mc(this,Cc,r),this.size={width:e||window.innerWidth,height:t||window.innerHeight}}get size(){return Oc({},qc(this,Ac))}set size({width:n,height:e}){var t;if(qc(this,Ac).width===n&&qc(this,Ac).height===e)return;qc(this,Ac).width=n,qc(this,Ac).height=e;const r=null!=(t=qc(this,Cc)?window.devicePixelRatio:1)?t:1;this.el.width=Math.round(qc(this,Ac).width*r),this.el.height=Math.round(qc(this,Ac).height*r),this.el.style.width=qc(this,Ac).width+"px",this.el.style.height=qc(this,Ac).height+"px",qc(this,Cc)&&this.ctx.scale(r,r)}clear(){Fc.clearCanvas(this.ctx,Oc({},qc(this,Ac)))}to(n){n.ctx.drawImage(this.el,0,0,qc(this,Ac).width,qc(this,Ac).height)}handleResize(n){this.size={width:window.innerWidth,height:window.innerHeight}}static setCanvasStyle(n,e,t){const r=n.style,{zIndex:a=0,opacity:o=1}=e;r.position="fixed",r.top="0",r.left="0",r.zIndex=a.toString(),r.width=(t?t.width:n.width).toString()+"px",r.height=(t?t.height:n.height).toString()+"px",1!==o&&(r.opacity=o.toString()),r.pointerEvents="none"}static initCanvas(n){n||(n=document.createElement("canvas"));const e=n.getContext("2d");return{el:n,ctx:e}}static createOffscreenCanvas(){return new Fc}static clearCanvas(n,e){const{width:t,height:r}=e;n.clearRect(0,0,t,r)}};let Uc=Fc;Ac=new WeakMap,Cc=new WeakMap;class Rc{constructor(n,e,t,r=!0,a=!0,o={zIndex:0,opacity:1}){$c(this,Bc,void 0),$c(this,Tc,void 0),Mc(this,Bc,new Uc(n,e,t,r)),Uc.setCanvasStyle(qc(this,Bc).el,o,{width:e,height:t}),Mc(this,Tc,a?new Uc(void 0,e,t,r):null)}get size(){return qc(this,Bc).size}draw(n){var e;const t=null!=(e=qc(this,Tc))?e:qc(this,Bc);t.clear(),n(t.ctx,Oc({},t.size))}render(){qc(this,Tc)&&(qc(this,Bc).clear(),qc(this,Tc).to(qc(this,Bc)))}handleResize(n){qc(this,Bc).handleResize(n),qc(this,Tc)&&qc(this,Tc).handleResize(n)}clear(){qc(this,Bc).clear(),qc(this,Tc)&&qc(this,Tc).clear()}}Bc=new WeakMap,Tc=new WeakMap;var Lc,Nc=(n,e,t)=>{if(!e.has(n))throw TypeError("Cannot "+t)},Gc=(n,e,t)=>(Nc(n,e,"read from private field"),t?t.call(n):e.get(n));class Kc{constructor(){var n,e,t,r;((n,e,t)=>{if(e.has(n))throw TypeError("Cannot add the same private member more than once");e instanceof WeakSet?e.add(n):e.set(n,t)})(this,Lc,void 0),n=this,e=Lc,t=new Map,Nc(n,e,"write to private field"),r?r.call(n,t):e.set(n,t)}add(n,e){var t;Gc(this,Lc).has(n)||Gc(this,Lc).set(n,new Set),null==(t=Gc(this,Lc).get(n))||t.add(e)}start(n){if(Gc(this,Lc).has(n))for(const e of Gc(this,Lc).get(n))window.addEventListener(n,e)}stop(n){if(Gc(this,Lc).has(n))for(const e of Gc(this,Lc).get(n))window.removeEventListener(n,e)}startAll(){for(const n of Gc(this,Lc).keys())this.start(n)}stopAll(){for(const n of Gc(this,Lc).keys())this.stop(n)}clear(){Gc(this,Lc).clear()}}function Vc(n){return!!n.touches}Lc=new WeakMap;class Hc{static randomFloat(n,e){return Math.random()*(e-n)+n}static randomInt(n,e){return Math.floor(Hc.randomFloat(n,e))}static choice(n){const e=n.length;return n[Math.floor(e*Math.random())]}static color(n="0123456789ABCDEF"){return"#"+Hc.choice(n)+Hc.choice(n)+Hc.choice(n)+Hc.choice(n)+Hc.choice(n)+Hc.choice(n)}}var Zc,Wc,Xc,Yc,Qc,Jc,nl,el,tl,rl,al,ol,il,sl,cl,ll,pl,dl,ul,ml,hl,gl,fl,vl,bl,kl=Object.defineProperty,yl=Object.getOwnPropertySymbols,El=Object.prototype.hasOwnProperty,_l=Object.prototype.propertyIsEnumerable,xl=(n,e,t)=>e in n?kl(n,e,{enumerable:!0,configurable:!0,writable:!0,value:t}):n[e]=t,wl=(n,e)=>{for(var t in e||(e={}))El.call(e,t)&&xl(n,t,e[t]);if(yl)for(var t of yl(e))_l.call(e,t)&&xl(n,t,e[t]);return n},Al=(n,e,t)=>{if(!e.has(n))throw TypeError("Cannot "+t)},Cl=(n,e,t)=>(Al(n,e,"read from private field"),t?t.call(n):e.get(n)),Bl=(n,e,t)=>{if(e.has(n))throw TypeError("Cannot add the same private member more than once");e instanceof WeakSet?e.add(n):e.set(n,t)},Tl=(n,e,t,r)=>(Al(n,e,"write to private field"),r?r.call(n,t):e.set(n,t),t),Pl=(n,e,t)=>(Al(n,e,"access private method"),t);class Il{constructor(n,e,t,r,a){Bl(this,Zc,void 0),Bl(this,Wc,void 0),Bl(this,Xc,void 0),this.size=t,this.color=r,Tl(this,Xc,0),Tl(this,Zc,a),Tl(this,Wc,e),this.position=wl({},n)}move(){var n,e,t,r;this.position.x=Math.sin(Cl(this,Zc))*Cl(this,Wc)+this.position.x,this.position.y=Math.cos(Cl(this,Zc))*Cl(this,Wc)+this.position.y+.3*Cl(this,Xc),(n=this,e=Xc,{set _(r){Tl(n,e,r,t)},get _(){return Cl(n,e,r)}})._++}shouleRemove(n){return this.position.x<0||this.position.x>n.width||this.position.y>n.height}}Zc=new WeakMap,Wc=new WeakMap,Xc=new WeakMap;Yc=new WeakMap;class Sl{static create(n,e,t,r,a,o){return new(this.shapeMap.get(n))(e,t,r,a,o)}}Sl.shapeMap=new Map([["star",class extends Il{constructor(n,e,t,r,a){super(n,e,t,r,a),Bl(this,Yc,0)}draw(n,e){n.fillStyle=this.color,n.beginPath();const t=2*this.size,r=this.size;for(let e=0;e<5;e++)n.lineTo(Math.cos((18+72*e-Cl(this,Yc))/180*Math.PI)*t+this.position.x,-Math.sin((18+72*e-Cl(this,Yc))/180*Math.PI)*t+this.position.y),n.lineTo(Math.cos((54+72*e-Cl(this,Yc))/180*Math.PI)*r+this.position.x,-Math.sin((54+72*e-Cl(this,Yc))/180*Math.PI)*r+this.position.y);n.fill(),Tl(this,Yc,Cl(this,Yc)+5)}}],["circle",class extends Il{draw(n,e){n.fillStyle=this.color,n.beginPath(),n.arc(this.position.x,this.position.y,this.size,0,2*Math.PI),n.fill()}}]]);class zl{constructor(n,e,t,r){Bl(this,Qc,void 0),this.stopped=!1,Tl(this,Qc,new Set);for(let a=0;a<r;a++){const r=Sl.create(n,e,Hc.randomFloat(1,6),t,Hc.color("89ABCDEF"),Hc.randomFloat(Math.PI-1,Math.PI+1));Cl(this,Qc).add(r)}}move(n){for(const e of Cl(this,Qc))e.shouleRemove(n)?Cl(this,Qc).delete(e):e.move();0===Cl(this,Qc).size&&(this.stopped=!0)}draw(n,e){for(const t of Cl(this,Qc))t.draw(n,e)}}Qc=new WeakMap;class Dl{constructor({shape:n="star",size:e=2,numParticles:t=10}={},r={}){Bl(this,sl),Bl(this,ll),Bl(this,dl),Bl(this,ml),Bl(this,gl),Bl(this,vl),Bl(this,Jc,void 0),Bl(this,nl,void 0),Bl(this,el,void 0),Bl(this,tl,null),Bl(this,rl,new Set),Bl(this,al,!1),Bl(this,ol,void 0),Bl(this,il,new Kc),Tl(this,Jc,n),Tl(this,nl,e),Tl(this,el,t),Tl(this,ol,r),this.animate=this.animate.bind(this)}mount(n){Tl(this,tl,new Rc(n,window.innerWidth,window.innerHeight,!0,!0,Cl(this,ol))),Pl(this,sl,cl).call(this),function(n,{leftColor:e="#fff",rightColor:t="#444",leftBgColor:r="#35495e",rightBgColor:a="#00ffc0"}={}){console.log(`%c ${n} %c v0.3.3 a117dec %c`,`background: ${r}; padding: 2px; color: ${e}; font-weight: bold; text-transform: uppercase;`,`background: ${a}; padding: 2px; color: ${t}; font-weight: bold; text-transform: uppercase;`,"background: transparent")}("Theme Popper 🎉",{leftBgColor:"#ffb366"})}unmount(){Pl(this,ll,pl).call(this),Tl(this,al,!1)}animate(){if(Tl(this,al,!0),0===Cl(this,rl).size)return Tl(this,al,!1),void Cl(this,tl).clear();requestAnimationFrame(this.animate);for(const n of Cl(this,rl)){if(n.stopped)return void Cl(this,rl).delete(n);n.move(Cl(this,tl).size)}Cl(this,tl).draw((n,e)=>{for(const t of Cl(this,rl))t.draw(n,e)}),Cl(this,tl).render()}}Jc=new WeakMap,nl=new WeakMap,el=new WeakMap,tl=new WeakMap,rl=new WeakMap,al=new WeakMap,ol=new WeakMap,il=new WeakMap,sl=new WeakSet,cl=function(){/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)?Cl(this,il).add("touchstart",Pl(this,dl,ul).bind(this)):Cl(this,il).add("mousedown",Pl(this,dl,ul).bind(this)),Cl(this,il).add("visibilitychange",Pl(this,gl,fl).bind(this)),Cl(this,il).add("resize",function(n,e,t){var r,a,o;void 0===e&&(e=50),void 0===t&&(t={});var i=null!=(r=t.isImmediate)&&r,s=null!=(a=t.callback)&&a,c=t.maxWait,l=Date.now(),p=[];function d(){if(void 0!==c){var n=Date.now()-l;if(n+e>=c)return c-n}return e}var u=function(){var e=[].slice.call(arguments),t=this;return new Promise((function(r,a){var c=i&&void 0===o;if(void 0!==o&&clearTimeout(o),o=setTimeout((function(){if(o=void 0,l=Date.now(),!i){var r=n.apply(t,e);s&&s(r),p.forEach((function(n){return(0,n.resolve)(r)})),p=[]}}),d()),c){var u=n.apply(t,e);return s&&s(u),r(u)}p.push({resolve:r,reject:a})}))};return u.cancel=function(n){void 0!==o&&clearTimeout(o),p.forEach((function(e){return(0,e.reject)(n)})),p=[]},u}(Pl(this,ml,hl).bind(this),500)),Cl(this,il).startAll()},ll=new WeakSet,pl=function(){Cl(this,il).stopAll(),Cl(this,il).clear()},dl=new WeakSet,ul=function(n){const e={x:Vc(n)?n.touches[0].clientX:n.clientX,y:Vc(n)?n.touches[0].clientY:n.clientY},t=new zl(Cl(this,Jc),wl({},e),Cl(this,nl),Cl(this,el));Cl(this,rl).add(t),Cl(this,al)||Pl(this,vl,bl).call(this)},ml=new WeakSet,hl=function(n){Cl(this,tl).handleResize(n)},gl=new WeakSet,fl=function(n){Cl(this,rl).clear(),Tl(this,al,!1)},vl=new WeakSet,bl=function(){requestAnimationFrame(this.animate)};var Ol={name:"CursorEffects",data:()=>({popper:new Dl({shape:"star",size:2},{opacity:1,zIndex:999999999})}),mounted(){this.popper.mount(this.$el)},beforeDestroy(){this.popper.unmount()}},jl=Object(fc.a)(Ol,(function(){return(0,this._self._c)("canvas",{attrs:{id:"vuepress-canvas-cursor"}})}),[],!1,null,null,null).exports,ql={name:"ReadingProgress",data:()=>({readingTop:0,readingHeight:1,progressStyle:null,transform:void 0,running:!1}),watch:{$readingShow(){this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)}},mounted(){this.transform=this.getTransform(),this.progressStyle=this.getProgressStyle(),this.$readingShow&&window.addEventListener("scroll",this.base)},beforeDestroy(){this.$readingShow&&window.removeEventListener("scroll",this.base)},methods:{base(){this.running||(this.running=!0,requestAnimationFrame(this.getReadingBase))},getReadingBase(){this.readingHeight=this.getReadingHeight()-this.getScreenHeight(),this.readingTop=this.getReadingTop(),this.progressStyle=this.getProgressStyle(),this.running=!1},getReadingHeight:()=>Math.max(document.body.scrollHeight,document.body.offsetHeight,0),getScreenHeight:()=>Math.max(window.innerHeight,document.documentElement.clientHeight,0),getReadingTop:()=>Math.max(window.pageYOffset,document.documentElement.scrollTop,0),getTransform(){const n=document.createElement("div");return["transform","-webkit-transform","-moz-transform","-o-transform","-ms-transform"].find(e=>e in n.style)||void 0},getProgressStyle(){const n=this.readingTop/this.readingHeight;switch(this.$readingShow){case"top":case"bottom":return this.transform?`${this.transform}: scaleX(${n})`:`width: ${100*n}%`;case"left":case"right":return this.transform?`${this.transform}: scaleY(${n})`:`height: ${100*n}%`;default:return null}}}},$l=(t(239),Object(fc.a)(ql,(function(){var n=this._self._c;return n("ClientOnly",[this.$readingShow?n("div",{staticClass:"reading-progress",class:this.$readingShow},[n("div",{staticClass:"progress",style:this.progressStyle})]):this._e()])}),[],!1,null,"3640397f",null).exports),Ml={props:{color:{required:!1,default:"rgb(66, 185, 131)"}}},Fl=(t(240),Object(fc.a)(Ml,(function(){return(0,this._self._c)("div",{staticClass:"spinner",style:{background:this.color}})}),[],!1,null,"1bbcb91a",null).exports);const Ul={name:"Mermaid",props:{id:{type:String,required:!1,default:()=>"diagram_"+Date.now()},graph:{type:String,required:!1}},data:()=>({svg:void 0}),computed:{graphData(){return this.graph?this.graph:this.$slots.default[0].text}},render(n){return void 0===this.svg?n("Loading"):n("div",{class:["mermaid-diagram"],domProps:{innerHTML:this.svg,style:"width: 100%"}})},mounted(){t.e(94).then(t.t.bind(null,329,7)).then(n=>{n.initialize({startOnLoad:!0}),n.render(this.id,this.graphData,n=>{this.svg=n})})},components:{Loading:Fl}};var Rl=[({Vue:n,options:e,router:t,siteData:r})=>{},({Vue:n,options:e,router:t,siteData:r})=>{r.pages.map(n=>{const{frontmatter:{date:e,author:t}}=n;"string"==typeof e&&"Z"===e.charAt(e.length-1)&&(n.frontmatter.date=function(n){n instanceof Date||(n=new Date(n));return`${n.getUTCFullYear()}-${wc(n.getUTCMonth()+1)}-${wc(n.getUTCDate())} ${wc(n.getUTCHours())}:${wc(n.getUTCMinutes())}:${wc(n.getUTCSeconds())}`}(e)),t?n.author=t:r.themeConfig.author&&(n.author=r.themeConfig.author)}),n.mixin(xc)},{},({Vue:n})=>{n.mixin({computed:{$dataBlock(){return this.$options.__data__block__}}})},{},{},({router:n})=>{"undefined"!=typeof window&&function(){var n=document.createElement("script"),e=window.location.protocol.split(":")[0];n.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(n,t)}()},({Vue:n})=>{n.component("CursorEffects",jl)},({Vue:n})=>{n.component($l.name,$l),n.mixin({computed:{$readingShow(){return this.$page.frontmatter.readingShow}}})},({router:n})=>{"undefined"!=typeof window&&(window._hmt=window._hmt||[],function(){var n=document.createElement("script");n.src="https://hm.baidu.com/hm.js?f8fd5c4e21ca384b4785396a87bcc468";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(n,e)}(),n.afterEach((function(n){_hmt.push(["_trackPageview",n.fullPath])})))},({Vue:n})=>{n.component(Ul.name,Ul)}],Ll=["CursorEffects","ReadingProgress","PageInfo","BlockToggle"];class Nl extends class{constructor(){this.store=new Kt({data:{state:{}}})}$get(n){return this.store.state[n]}$set(n,e){Kt.set(this.store.state,n,e)}$emit(...n){this.store.$emit(...n)}$on(...n){this.store.$on(...n)}}{}Object.assign(Nl.prototype,{getPageAsyncComponent:os,getLayoutAsyncComponent:is,getAsyncComponent:ss,getVueComponent:cs});var Gl={install(n){const e=new Nl;n.$vuepress=e,n.prototype.$vuepress=e}};function Kl(n,e){const t=e.toLowerCase();return n.options.routes.some(n=>n.path.toLowerCase()===t)}var Vl={props:{pageKey:String,slotKey:{type:String,default:"default"}},render(n){const e=this.pageKey||this.$parent.$page.key;return ps("pageKey",e),Kt.component(e)||Kt.component(e,os(e)),Kt.component(e)?n(e):n("")}},Hl={functional:!0,props:{slotKey:String,required:!0},render:(n,{props:e,slots:t})=>n("div",{class:["content__"+e.slotKey]},t()[e.slotKey])},Zl={computed:{openInNewWindowTitle(){return this.$themeLocaleConfig.openNewWindowText||"(opens new window)"}}},Wl=(t(241),t(242),Object(fc.a)(Zl,(function(){var n=this._self._c;return n("span",[n("svg",{staticClass:"icon outbound",attrs:{xmlns:"http://www.w3.org/2000/svg","aria-hidden":"true",focusable:"false",x:"0px",y:"0px",viewBox:"0 0 100 100",width:"15",height:"15"}},[n("path",{attrs:{fill:"currentColor",d:"M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"}}),this._v(" "),n("polygon",{attrs:{fill:"currentColor",points:"45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"}})]),this._v(" "),n("span",{staticClass:"sr-only"},[this._v(this._s(this.openInNewWindowTitle))])])}),[],!1,null,null,null).exports),Xl={functional:!0,render(n,{parent:e,children:t}){if(e._isMounted)return t;e.$once("hook:mounted",()=>{e.$forceUpdate()})}};Kt.config.productionTip=!1,Kt.use(Gi),Kt.use(Gl),Kt.mixin(function(n,e,t=Kt){!function(n){n.locales&&Object.keys(n.locales).forEach(e=>{n.locales[e].path=e});Object.freeze(n)}(e),t.$vuepress.$set("siteData",e);const r=new(n(t.$vuepress.$get("siteData"))),a=Object.getOwnPropertyDescriptors(Object.getPrototypeOf(r)),o={};return Object.keys(a).reduce((n,e)=>(e.startsWith("$")&&(n[e]=a[e].get),n),o),{computed:o}}(n=>class{setPage(n){this.__page=n}get $site(){return n}get $themeConfig(){return this.$site.themeConfig}get $frontmatter(){return this.$page.frontmatter}get $localeConfig(){const{locales:n={}}=this.$site;let e,t;for(const r in n)"/"===r?t=n[r]:0===this.$page.path.indexOf(r)&&(e=n[r]);return e||t||{}}get $siteTitle(){return this.$localeConfig.title||this.$site.title||""}get $canonicalUrl(){const{canonicalUrl:n}=this.$page.frontmatter;return"string"==typeof n&&n}get $title(){const n=this.$page,{metaTitle:e}=this.$page.frontmatter;if("string"==typeof e)return e;const t=this.$siteTitle,r=n.frontmatter.home?null:n.frontmatter.title||n.title;return t?r?r+" | "+t:t:r||"VuePress"}get $description(){const n=function(n){if(n){const e=n.filter(n=>"description"===n.name)[0];if(e)return e.content}}(this.$page.frontmatter.meta);return n||(this.$page.frontmatter.description||this.$localeConfig.description||this.$site.description||"")}get $lang(){return this.$page.frontmatter.lang||this.$localeConfig.lang||"en-US"}get $localePath(){return this.$localeConfig.path||"/"}get $themeLocaleConfig(){return(this.$site.themeConfig.locales||{})[this.$localePath]||{}}get $page(){return this.__page?this.__page:function(n,e){for(let t=0;t<n.length;t++){const r=n[t];if(r.path.toLowerCase()===e.toLowerCase())return r}return{path:"",frontmatter:{}}}(this.$site.pages,this.$route.path)}},kc)),Kt.component("Content",Vl),Kt.component("ContentSlotsDistributor",Hl),Kt.component("OutboundLink",Wl),Kt.component("ClientOnly",Xl),Kt.component("Layout",is("Layout")),Kt.component("NotFound",is("NotFound")),Kt.prototype.$withBase=function(n){const e=this.$site.base;return"/"===n.charAt(0)?e+n.slice(1):n},window.__VUEPRESS__={version:"1.9.5",hash:"e539265"},async function(n){const e="undefined"!=typeof window&&window.__VUEPRESS_ROUTER_BASE__?window.__VUEPRESS_ROUTER_BASE__:kc.routerBase||kc.base,t=new Gi({base:e,mode:"history",fallback:!1,routes:bc,scrollBehavior:(n,e,t)=>t||(n.hash?!Kt.$vuepress.$get("disableScrollBehavior")&&{selector:decodeURIComponent(n.hash)}:{x:0,y:0})});!function(n){n.beforeEach((e,t,r)=>{if(Kl(n,e.path))r();else if(/(\/|\.html)$/.test(e.path))if(/\/$/.test(e.path)){const t=e.path.replace(/\/$/,"")+".html";Kl(n,t)?r(t):r()}else r();else{const t=e.path+"/",a=e.path+".html";Kl(n,a)?r(a):Kl(n,t)?r(t):r()}})}(t);const r={};try{await Promise.all(Rl.filter(n=>"function"==typeof n).map(e=>e({Vue:Kt,options:r,router:t,siteData:kc,isServer:n})))}catch(n){console.error(n)}return{app:new Kt(Object.assign(r,{router:t,render:n=>n("div",{attrs:{id:"app"}},[n("RouterView",{ref:"layout"}),n("div",{class:"global-ui"},Ll.map(e=>n(e)))])})),router:t}}(!1).then(({app:n,router:e})=>{e.onReady(()=>{n.$mount("#app")})})}]);