---
title: 第四范式vgpu
date: 2022-07-27 14:56:55
permalink: /pages/4paradigm/
categories:
  - 技术杂谈
  - kubernetes
tags:
  - gpu
titleTag: 原创
---


github地址：https://github.com/4paradigm/k8s-device-plugin/blob/master/README_cn.md

vGPU device plugin 基于NVIDIA官方插件(NVIDIA/k8s-device-plugin)，在保留官方功能的基础上，实现了对物理GPU进行切分，并对显存和计算单元进行限制，从而模拟出多张小的vGPU卡。

第四范式的GPU共享方案还叫vGPU，也是CUDA劫持方案。由于没有开源资源隔离部分的代码，从文档中推测，其实现和GaiaGPU的vcuda较为类似：显存隔离使用的是经典CUDA劫持方法，通过预估获得context大小；使用监控隔离的方案隔离算力。同样地，方案的优缺点也和vCUDA类似。较为特别的一点是，和阿里Antman相同地，第四范式vGPU通过Nvidia UVM实现了虚拟显存。不过UVM实质上是使用内存来虚拟显存，因此会消耗较大的内存，且性能会有较大下降。若要使用虚拟显存功能，还需思考程序本身占用的内存和虚拟显存的trade off。

同时，采用这种方案不需重新设计调度器。

## 部署
docker pull 4pdosc/k8s-device-plugin:latest  (注意v1.8镜像使用有问题，拉最新的镜像验证没问题)
kubectl apply -f nvidia-device-plugin.yml

## 参数
--device-split-count=3 
整数类型，预设值是2。NVIDIA装置的分割数。对于一个总共包含N张NVIDIA GPU的Kubernetes集群，如果我们将device-split-count参数配置为K，这个Kubernetes集群将有K * N个可分配的vGPU资源
--device-memory-scaling=3 
浮点数类型，预设值是1。NVIDIA装置显存使用比例，可以大于1（启用虚拟显存，实验功能）。对于有M​显存大小的NVIDIA GPU，如果我们配置device-memory-scaling参数为S，在部署了我们装置插件的Kubenetes集群中，这张GPU分出的vGPU将总共包含 S * M显存。张vGPU的显存大小也受device-split-count参数影响。在先前的例子中，如果device-split-count参数配置为K，那每一张vGPU最后会取得 S * M / K 大小的显存。

## 验证
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: test-gpu-4paradigm
spec:
  restartPolicy: OnFailure
  containers:
    - name: cuda
      image: nvidia/cuda:10.0-base
      imagePullPolicy: IfNotPresent
      tty: true
      resources:
        limits:
          nvidia.com/gpu: 1
  nodeName: node01
```

```bash
[root@master02 4paradigm]# kubectl describe node node01 | grep gpu
  nvidia.com/gpu:     3
  nvidia.com/gpu:     3
  nvidia.com/gpu     0            0
```